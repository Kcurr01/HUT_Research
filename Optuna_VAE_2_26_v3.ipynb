{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Kcurr01/HUT_Research/blob/main/Optuna_VAE_2_26_v3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M8iJEJRDVWqt"
      },
      "source": [
        "---\n",
        "Instalation \n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Du8slAkNSRBk",
        "outputId": "025b6ffc-fc6d-4124-cbc3-5acfd2354592"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tensorboardX in /usr/local/lib/python3.8/dist-packages (2.6)\n",
            "Requirement already satisfied: protobuf<4,>=3.8.0 in /usr/local/lib/python3.8/dist-packages (from tensorboardX) (3.19.6)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from tensorboardX) (1.22.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from tensorboardX) (23.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: optuna in /usr/local/lib/python3.8/dist-packages (3.1.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from optuna) (1.22.4)\n",
            "Requirement already satisfied: sqlalchemy>=1.3.0 in /usr/local/lib/python3.8/dist-packages (from optuna) (1.4.46)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from optuna) (4.64.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from optuna) (23.0)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.8/dist-packages (from optuna) (6.0)\n",
            "Requirement already satisfied: colorlog in /usr/local/lib/python3.8/dist-packages (from optuna) (6.7.0)\n",
            "Requirement already satisfied: cmaes>=0.9.1 in /usr/local/lib/python3.8/dist-packages (from optuna) (0.9.1)\n",
            "Requirement already satisfied: alembic>=1.5.0 in /usr/local/lib/python3.8/dist-packages (from optuna) (1.9.4)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.8/dist-packages (from alembic>=1.5.0->optuna) (5.12.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.8/dist-packages (from alembic>=1.5.0->optuna) (6.0.0)\n",
            "Requirement already satisfied: Mako in /usr/local/lib/python3.8/dist-packages (from alembic>=1.5.0->optuna) (1.2.4)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.8/dist-packages (from sqlalchemy>=1.3.0->optuna) (2.0.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/dist-packages (from importlib-metadata->alembic>=1.5.0->optuna) (3.14.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.8/dist-packages (from Mako->alembic>=1.5.0->optuna) (2.0.1)\n"
          ]
        }
      ],
      "source": [
        "# !pip install captum\n",
        "# !pip install umap-learn\n",
        "# !pip install datashader\n",
        "# !pip install bokeh\n",
        "# !pip install holoviews\n",
        "!pip install tensorboardX\n",
        "!pip install optuna"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nXr0DgjjvCJa"
      },
      "source": [
        "---\n",
        "VAE Initializaiton, Visualization and Training\n",
        "--- "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ATqtpHxlVJdO"
      },
      "outputs": [],
      "source": [
        "import torch   \n",
        "import torch.nn as nn                          \n",
        "import torch.nn.functional as F                \n",
        "import torch.optim as optim   \n",
        "from torch.utils.data import TensorDataset, Dataset, DataLoader\n",
        "from torch.autograd import Variable\n",
        "import torch.utils.data\n",
        "\n",
        "import pandas as pd \n",
        "import numpy as np\n",
        "import os                             \n",
        "\n",
        "# from captum.attr import LayerConductance, LayerActivation, LayerIntegratedGradients\n",
        "# from captum.attr import IntegratedGradients, DeepLift, GradientShap, NoiseTunnel, FeatureAblation\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns    \n",
        "# import plotly.offline as py\n",
        "# import plotly.graph_objs as go        \n",
        "                \n",
        "# from tqdm import tqdm\n",
        "\n",
        "# import umap\n",
        "# import umap.plot\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import preprocessing\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import accuracy_score, roc_auc_score, f1_score, precision_score, recall_score\n",
        "from sklearn.manifold import TSNE\n",
        "from sklearn.decomposition import PCA, TruncatedSVD\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "#based on sensor data can you determine the stimulus that is currently in use?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "msgUiu6VVLb2"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(\"/content/drive/MyDrive/WEAR_LAB/Research_Pytorch/S1_E1_A1_v6.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 305
        },
        "id": "1YWNrSbVhwqw",
        "outputId": "2fd0bfd7-af3a-43e8-e795-9f0c6571cca6"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-47cd4fe5-26b8-46e3-9811-6ec9139b0233\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>stimulus</th>\n",
              "      <th>Acc 1</th>\n",
              "      <th>Acc 2</th>\n",
              "      <th>Acc 3</th>\n",
              "      <th>EMG Channel 1</th>\n",
              "      <th>EMG Channel 2</th>\n",
              "      <th>EMG Channe 3</th>\n",
              "      <th>EMG Channel 4</th>\n",
              "      <th>EMG Channel 5</th>\n",
              "      <th>EMG Channel 6</th>\n",
              "      <th>EMG Channel 7</th>\n",
              "      <th>EMG Channel 8</th>\n",
              "      <th>EMG Channel 9</th>\n",
              "      <th>EMG Channel 10</th>\n",
              "      <th>EMG Channel 11</th>\n",
              "      <th>EMG Channel 12</th>\n",
              "      <th>EMG Channel 13</th>\n",
              "      <th>EMG Channel 14</th>\n",
              "      <th>EMG Channel 15</th>\n",
              "      <th>EMG Channel 16</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0.30176</td>\n",
              "      <td>0.78809</td>\n",
              "      <td>-0.66699</td>\n",
              "      <td>-22</td>\n",
              "      <td>-2</td>\n",
              "      <td>-16</td>\n",
              "      <td>-7</td>\n",
              "      <td>-3</td>\n",
              "      <td>-1</td>\n",
              "      <td>-2</td>\n",
              "      <td>-4</td>\n",
              "      <td>-2</td>\n",
              "      <td>-46</td>\n",
              "      <td>-49</td>\n",
              "      <td>-5</td>\n",
              "      <td>9</td>\n",
              "      <td>1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0.30176</td>\n",
              "      <td>0.78809</td>\n",
              "      <td>-0.66699</td>\n",
              "      <td>5</td>\n",
              "      <td>-4</td>\n",
              "      <td>-12</td>\n",
              "      <td>-3</td>\n",
              "      <td>8</td>\n",
              "      <td>25</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>-2</td>\n",
              "      <td>66</td>\n",
              "      <td>28</td>\n",
              "      <td>3</td>\n",
              "      <td>22</td>\n",
              "      <td>10</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0.30176</td>\n",
              "      <td>0.78809</td>\n",
              "      <td>-0.66699</td>\n",
              "      <td>-6</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>-1</td>\n",
              "      <td>-9</td>\n",
              "      <td>0</td>\n",
              "      <td>-10</td>\n",
              "      <td>-3</td>\n",
              "      <td>-9</td>\n",
              "      <td>-52</td>\n",
              "      <td>-24</td>\n",
              "      <td>-2</td>\n",
              "      <td>-52</td>\n",
              "      <td>-14</td>\n",
              "      <td>-24</td>\n",
              "      <td>-3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0.30176</td>\n",
              "      <td>0.78809</td>\n",
              "      <td>-0.66699</td>\n",
              "      <td>15</td>\n",
              "      <td>10</td>\n",
              "      <td>19</td>\n",
              "      <td>9</td>\n",
              "      <td>10</td>\n",
              "      <td>7</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>-4</td>\n",
              "      <td>-13</td>\n",
              "      <td>19</td>\n",
              "      <td>4</td>\n",
              "      <td>28</td>\n",
              "      <td>6</td>\n",
              "      <td>-5</td>\n",
              "      <td>-12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0.24609</td>\n",
              "      <td>0.73535</td>\n",
              "      <td>-0.66309</td>\n",
              "      <td>-1</td>\n",
              "      <td>-16</td>\n",
              "      <td>-17</td>\n",
              "      <td>0</td>\n",
              "      <td>-2</td>\n",
              "      <td>-7</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>-6</td>\n",
              "      <td>27</td>\n",
              "      <td>7</td>\n",
              "      <td>-1</td>\n",
              "      <td>-22</td>\n",
              "      <td>-2</td>\n",
              "      <td>-7</td>\n",
              "      <td>15</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-47cd4fe5-26b8-46e3-9811-6ec9139b0233')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-47cd4fe5-26b8-46e3-9811-6ec9139b0233 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-47cd4fe5-26b8-46e3-9811-6ec9139b0233');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "   stimulus    Acc 1    Acc 2    Acc 3  EMG Channel 1  EMG Channel 2  \\\n",
              "0         0  0.30176  0.78809 -0.66699            -22             -2   \n",
              "1         0  0.30176  0.78809 -0.66699              5             -4   \n",
              "2         0  0.30176  0.78809 -0.66699             -6              1   \n",
              "3         0  0.30176  0.78809 -0.66699             15             10   \n",
              "4         0  0.24609  0.73535 -0.66309             -1            -16   \n",
              "\n",
              "   EMG Channe 3  EMG Channel 4  EMG Channel 5  EMG Channel 6  EMG Channel 7  \\\n",
              "0           -16             -7             -3             -1             -2   \n",
              "1           -12             -3              8             25              1   \n",
              "2             4             -1             -9              0            -10   \n",
              "3            19              9             10              7              2   \n",
              "4           -17              0             -2             -7              2   \n",
              "\n",
              "   EMG Channel 8  EMG Channel 9  EMG Channel 10  EMG Channel 11  \\\n",
              "0             -4             -2             -46             -49   \n",
              "1              1             -2              66              28   \n",
              "2             -3             -9             -52             -24   \n",
              "3              1             -4             -13              19   \n",
              "4              0             -6              27               7   \n",
              "\n",
              "   EMG Channel 12  EMG Channel 13  EMG Channel 14  EMG Channel 15  \\\n",
              "0              -5               9               1              -1   \n",
              "1               3              22              10               2   \n",
              "2              -2             -52             -14             -24   \n",
              "3               4              28               6              -5   \n",
              "4              -1             -22              -2              -7   \n",
              "\n",
              "   EMG Channel 16  \n",
              "0              -2  \n",
              "1               1  \n",
              "2              -3  \n",
              "3             -12  \n",
              "4              15  "
            ]
          },
          "execution_count": 121,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#df = df.drop(columns=['series_id'])\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VLnkrC9o_CzK",
        "outputId": "a3f26ef8-21b4-4676-aabc-f270869e293e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "pandas.core.frame.DataFrame"
            ]
          },
          "execution_count": 122,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "type(df)\n",
        "#df.describe()\n",
        "#df.plot()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A6VzjKYRRBt7",
        "outputId": "407dedf5-5207-4846-f66b-5f4f970e8bae"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(130200, 19) <class 'pandas.core.frame.DataFrame'> (130200, 1) <class 'pandas.core.frame.DataFrame'>\n",
            "\n"
          ]
        }
      ],
      "source": [
        "X = df.iloc[:,1:]\n",
        "y = df.iloc[:, 0:1]\n",
        "print(X.shape, type(X), y.shape, type(y))\n",
        "print()\n",
        "#print(y.value_counts())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 305
        },
        "id": "RkM1pDIrRWqM",
        "outputId": "50765359-b2a4-4125-ad5a-8d1e499f680e"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-3172b9b3-d0b6-43c9-80f8-ee180ff2612c\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Acc 1</th>\n",
              "      <th>Acc 2</th>\n",
              "      <th>Acc 3</th>\n",
              "      <th>EMG Channel 1</th>\n",
              "      <th>EMG Channel 2</th>\n",
              "      <th>EMG Channe 3</th>\n",
              "      <th>EMG Channel 4</th>\n",
              "      <th>EMG Channel 5</th>\n",
              "      <th>EMG Channel 6</th>\n",
              "      <th>EMG Channel 7</th>\n",
              "      <th>EMG Channel 8</th>\n",
              "      <th>EMG Channel 9</th>\n",
              "      <th>EMG Channel 10</th>\n",
              "      <th>EMG Channel 11</th>\n",
              "      <th>EMG Channel 12</th>\n",
              "      <th>EMG Channel 13</th>\n",
              "      <th>EMG Channel 14</th>\n",
              "      <th>EMG Channel 15</th>\n",
              "      <th>EMG Channel 16</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.30176</td>\n",
              "      <td>0.78809</td>\n",
              "      <td>-0.66699</td>\n",
              "      <td>-22</td>\n",
              "      <td>-2</td>\n",
              "      <td>-16</td>\n",
              "      <td>-7</td>\n",
              "      <td>-3</td>\n",
              "      <td>-1</td>\n",
              "      <td>-2</td>\n",
              "      <td>-4</td>\n",
              "      <td>-2</td>\n",
              "      <td>-46</td>\n",
              "      <td>-49</td>\n",
              "      <td>-5</td>\n",
              "      <td>9</td>\n",
              "      <td>1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.30176</td>\n",
              "      <td>0.78809</td>\n",
              "      <td>-0.66699</td>\n",
              "      <td>5</td>\n",
              "      <td>-4</td>\n",
              "      <td>-12</td>\n",
              "      <td>-3</td>\n",
              "      <td>8</td>\n",
              "      <td>25</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>-2</td>\n",
              "      <td>66</td>\n",
              "      <td>28</td>\n",
              "      <td>3</td>\n",
              "      <td>22</td>\n",
              "      <td>10</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.30176</td>\n",
              "      <td>0.78809</td>\n",
              "      <td>-0.66699</td>\n",
              "      <td>-6</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>-1</td>\n",
              "      <td>-9</td>\n",
              "      <td>0</td>\n",
              "      <td>-10</td>\n",
              "      <td>-3</td>\n",
              "      <td>-9</td>\n",
              "      <td>-52</td>\n",
              "      <td>-24</td>\n",
              "      <td>-2</td>\n",
              "      <td>-52</td>\n",
              "      <td>-14</td>\n",
              "      <td>-24</td>\n",
              "      <td>-3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.30176</td>\n",
              "      <td>0.78809</td>\n",
              "      <td>-0.66699</td>\n",
              "      <td>15</td>\n",
              "      <td>10</td>\n",
              "      <td>19</td>\n",
              "      <td>9</td>\n",
              "      <td>10</td>\n",
              "      <td>7</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>-4</td>\n",
              "      <td>-13</td>\n",
              "      <td>19</td>\n",
              "      <td>4</td>\n",
              "      <td>28</td>\n",
              "      <td>6</td>\n",
              "      <td>-5</td>\n",
              "      <td>-12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.24609</td>\n",
              "      <td>0.73535</td>\n",
              "      <td>-0.66309</td>\n",
              "      <td>-1</td>\n",
              "      <td>-16</td>\n",
              "      <td>-17</td>\n",
              "      <td>0</td>\n",
              "      <td>-2</td>\n",
              "      <td>-7</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>-6</td>\n",
              "      <td>27</td>\n",
              "      <td>7</td>\n",
              "      <td>-1</td>\n",
              "      <td>-22</td>\n",
              "      <td>-2</td>\n",
              "      <td>-7</td>\n",
              "      <td>15</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3172b9b3-d0b6-43c9-80f8-ee180ff2612c')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-3172b9b3-d0b6-43c9-80f8-ee180ff2612c button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-3172b9b3-d0b6-43c9-80f8-ee180ff2612c');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "     Acc 1    Acc 2    Acc 3  EMG Channel 1  EMG Channel 2  EMG Channe 3  \\\n",
              "0  0.30176  0.78809 -0.66699            -22             -2           -16   \n",
              "1  0.30176  0.78809 -0.66699              5             -4           -12   \n",
              "2  0.30176  0.78809 -0.66699             -6              1             4   \n",
              "3  0.30176  0.78809 -0.66699             15             10            19   \n",
              "4  0.24609  0.73535 -0.66309             -1            -16           -17   \n",
              "\n",
              "   EMG Channel 4  EMG Channel 5  EMG Channel 6  EMG Channel 7  EMG Channel 8  \\\n",
              "0             -7             -3             -1             -2             -4   \n",
              "1             -3              8             25              1              1   \n",
              "2             -1             -9              0            -10             -3   \n",
              "3              9             10              7              2              1   \n",
              "4              0             -2             -7              2              0   \n",
              "\n",
              "   EMG Channel 9  EMG Channel 10  EMG Channel 11  EMG Channel 12  \\\n",
              "0             -2             -46             -49              -5   \n",
              "1             -2              66              28               3   \n",
              "2             -9             -52             -24              -2   \n",
              "3             -4             -13              19               4   \n",
              "4             -6              27               7              -1   \n",
              "\n",
              "   EMG Channel 13  EMG Channel 14  EMG Channel 15  EMG Channel 16  \n",
              "0               9               1              -1              -2  \n",
              "1              22              10               2               1  \n",
              "2             -52             -14             -24              -3  \n",
              "3              28               6              -5             -12  \n",
              "4             -22              -2              -7              15  "
            ]
          },
          "execution_count": 124,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "6XIsEYVmRloI",
        "outputId": "42e29be5-e062-44b1-8e82-8d10c815d1a9"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-44e89443-b3cc-41f6-ae07-6bc93ff183d5\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>stimulus</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-44e89443-b3cc-41f6-ae07-6bc93ff183d5')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-44e89443-b3cc-41f6-ae07-6bc93ff183d5 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-44e89443-b3cc-41f6-ae07-6bc93ff183d5');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "   stimulus\n",
              "0         0\n",
              "1         0\n",
              "2         0\n",
              "3         0\n",
              "4         0"
            ]
          },
          "execution_count": 125,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IA8-K5g_qNvJ"
      },
      "source": [
        "---\n",
        "Visulaize number of lables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 534
        },
        "id": "6GZFlYtuh4g3",
        "outputId": "37e99769-2533-421e-906b-ed746a834ff9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0     49599\n",
              "8      6795\n",
              "5      6782\n",
              "6      6776\n",
              "7      6776\n",
              "11     6773\n",
              "1      6753\n",
              "12     6701\n",
              "10     6696\n",
              "2      6656\n",
              "4      6654\n",
              "9      6626\n",
              "3      6613\n",
              "Name: stimulus, dtype: int64"
            ]
          },
          "execution_count": 126,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "sns.countplot(x = 'stimulus', data=df)\n",
        "df.loc[:,'stimulus'].value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SpiqlKfjqDhy"
      },
      "source": [
        "---\n",
        "Visualize Data Disturbutions\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5sGkzQcdlBZ5"
      },
      "outputs": [],
      "source": [
        "# #distribution of first 19 features\n",
        "\n",
        "\n",
        "# fig, axs = plt.subplots(nrows=5, ncols=4, figsize=(40, 40))\n",
        "# axs = axs.flatten()\n",
        "# index = 0\n",
        "# for k, v in df.items():\n",
        "#   print(f\"[{index +1}] Updating plot\")\n",
        "#   sns.distplot(v, ax=axs[index])\n",
        "#   index += 1\n",
        "#   if index == 20:\n",
        "#     break \n",
        "# plt.tight_layout()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UJ6JhVncSg-a",
        "outputId": "a7e7adbd-e375-429d-9ffc-a2a5f857d181"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(130200, 19) <class 'numpy.ndarray'> (130200, 1) <class 'numpy.ndarray'>\n",
            "\n",
            "X_train size: 78120 | X_val size: 26040 | X_test size: 26040\n",
            "y_train size: 78120 | y_val size: 26040 | y_test size: 26040\n",
            "\n",
            "Training Feature Split: (78120, 19) | Training Labels (78120, 1)\n",
            "Validation Feature Split: (26040, 19) | Validation Labels (26040, 1)\n",
            "Testing Feature Split: (26040, 19) | Testing Labels (26040, 1)\n",
            "\n",
            "X_train: <class 'torch.Tensor'> | y_train <class 'torch.Tensor'>\n",
            "X_val: <class 'torch.Tensor'> | y_train <class 'torch.Tensor'>\n",
            "X_test: <class 'torch.Tensor'> | y_test <class 'torch.Tensor'>\n",
            "\n",
            "Training: torch.Size([78120, 19]) , torch.Size([78120, 1])\n",
            "Validation: torch.Size([26040, 19]) , torch.Size([26040, 1])\n",
            "Testing:  torch.Size([26040, 19]) , torch.Size([26040, 1])\n"
          ]
        }
      ],
      "source": [
        "X = df.iloc[:,1:].values\n",
        "y = df.iloc[:, 0:1].values\n",
        "print(X.shape, type(X), y.shape, type(y))\n",
        "print()\n",
        "\n",
        "# Data Split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.25, random_state=42) # 0.25 x 0.8 = 0.2\n",
        "\n",
        "print(f\"X_train size: {len(X_train)} | X_val size: {len(X_val)} | X_test size: {len(X_test)}\")\n",
        "print(f\"y_train size: {len(y_train)} | y_val size: {len(y_val)} | y_test size: {len(y_test)}\")\n",
        "print()\n",
        "print(f\"Training Feature Split: {X_train.shape} | Training Labels { y_train.shape}\")\n",
        "print(f\"Validation Feature Split: {X_val.shape} | Validation Labels { y_val.shape}\")\n",
        "print(f\"Testing Feature Split: {X_test.shape} | Testing Labels { y_test.shape}\")\n",
        "print()\n",
        "\n",
        "#Normalization Data \n",
        "Minmax = preprocessing.MinMaxScaler()\n",
        "#Standardized = preprocessing.StandardScaler()\n",
        "X_train_Minmax= Minmax.fit_transform(X_train)\n",
        "X_val_Minmax = Minmax.transform(X_val)\n",
        "X_test_Minmax = Minmax.transform(X_test)\n",
        "\n",
        "#Convert to numpy then to torch \n",
        "\n",
        "X_train = torch.from_numpy(X_train_Minmax).float()\n",
        "y_train = torch.from_numpy(y_train).float()\n",
        "\n",
        "X_val = torch.from_numpy(X_val_Minmax).float()\n",
        "y_val = torch.from_numpy(y_val).float()\n",
        "\n",
        "X_test = torch.from_numpy(X_test_Minmax).float()\n",
        "y_test = torch.from_numpy(y_test).float()\n",
        "\n",
        "print(f\"X_train: {type(X_train)} | y_train {type(y_train)}\")\n",
        "print(f\"X_val: {type(X_val)} | y_train {type(y_val)}\")\n",
        "print(f\"X_test: {type(X_test)} | y_test {type(y_test)}\")\n",
        "print()\n",
        "print(f\"Training: {X_train.shape} , { y_train.shape}\")\n",
        "print(f\"Validation: {X_val.shape} , { y_val.shape}\")\n",
        "print(f\"Testing:  {X_test.shape} , { y_test.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y7rZppwdVzdJ"
      },
      "outputs": [],
      "source": [
        "class ClassifierDataset(Dataset):\n",
        "    def __init__(self, X_data, y_data):\n",
        "        self.X_data = X_data\n",
        "        self.y_data = y_data\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        return self.X_data[index], self.y_data[index]\n",
        "\n",
        "    def __len__ (self):\n",
        "        return len(self.X_data)\n",
        "\n",
        "training = ClassifierDataset(X_train, y_train)\n",
        "validating = ClassifierDataset(X_val, y_val)\n",
        "testing = ClassifierDataset(X_test, y_test)\n",
        "\n",
        "##########################################################################################################################################################################################################\n",
        "#############################################################################################################################################################################################################\n",
        "\n",
        "#Hyperparameters\n",
        "latent_dim = 2\n",
        "input_dim= 19\n",
        "hidden_dim= 9\n",
        "output_dim = 19\n",
        "num_classes = 13\n",
        "\n",
        "num_epochs= 100\n",
        "batch_size= 100\n",
        "learning_rate= 0.0001 #3e-4 #Karpathy constant\n",
        "\n",
        "\n",
        "#beta = 1\n",
        "beta = 0.001\n",
        "alpha = 1\n",
        "\n",
        "#############################################################################################################################################################################################################\n",
        "#############################################################################################################################################################################################################\n",
        "\n",
        "train_loader = DataLoader(training, batch_size=batch_size, shuffle=True)\n",
        "val_loader = DataLoader(validating, batch_size=batch_size, shuffle=False)\n",
        "test_loader = DataLoader(testing, batch_size=batch_size, shuffle=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2UbXfasD8HQn",
        "outputId": "ea75c393-aeec-4689-bdc2-ea5d35e2a359"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([100, 19])\n",
            "torch.Size([100, 2])\n",
            "torch.Size([100, 2])\n",
            "torch.Size([100, 2])\n",
            "torch.Size([100, 13])\n"
          ]
        }
      ],
      "source": [
        "class VAE(nn.Module):  \n",
        "  def __init__(self, input_dim, hidden_dim, latent_dim):\n",
        "    super(VAE,self).__init__()  \n",
        "    self.fc1 = nn.Linear(input_dim, hidden_dim)  # no labels\n",
        "    self.mu = nn.Linear(hidden_dim, latent_dim)   # mu\n",
        "    self.logvar = nn.Linear(hidden_dim,latent_dim)   # log-var\n",
        "\n",
        "    self.fc3 = nn.Linear(latent_dim, hidden_dim) \n",
        "    self.fc4 = nn.Linear(hidden_dim, input_dim)\n",
        "    \n",
        "    self.classifier = nn.Sequential(\n",
        "        nn.Linear(latent_dim, 13),\n",
        "        nn.Sigmoid(),\n",
        "        nn.Softmax(dim=1)\n",
        "    )\n",
        "\n",
        "  def encode(self, x):     \n",
        "#    print(f'encoder {type(x)}')         \n",
        "    z = F.relu(self.fc1(x))\n",
        "    z = torch.tanh(z) \n",
        "    z1 = self.mu(z)               \n",
        "    z2 = self.logvar(z) \n",
        "    return z1, z2                 # (mu, log-var)\n",
        "\n",
        "  def decode(self, x):\n",
        "#    print(f'decoder {type(x)}')\n",
        "    z = F.relu(self.fc3(x))                    \n",
        "    z = torch.sigmoid(self.fc4(z))      # in [0, 1]\n",
        "    #print(f\"z: {z}\")\n",
        "    return z \n",
        "\n",
        "  def forward(self, x):\n",
        "#    print(f'forward {type(x)}')\n",
        "\n",
        "#  Reparamaterize\n",
        "    mu, logvar = self.encode(x)\n",
        "    stdev = torch.exp(0.5 * logvar)\n",
        "    esp = torch.randn_like(stdev)\n",
        "    z_reparmeterized = mu + (esp * stdev)   \n",
        "    #print(f\"z_reparmeterized : {z_reparmeterized}\")      \n",
        "    x_reconstructed = self.decode(z_reparmeterized)\n",
        "    #print(f\"x_reconstructed : {x_reconstructed}\")\n",
        "\n",
        "    classified = self.classifier(z_reparmeterized)\n",
        "\n",
        "    return (x_reconstructed, z_reparmeterized, classified, mu, logvar)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "  x = torch.rand(batch_size,input_dim)\n",
        "  vae = VAE(input_dim, hidden_dim, latent_dim)\n",
        "  x_reconstructed, z_reparmeterized, classified, mu, logvar = vae(x)\n",
        "  print(x_reconstructed.shape)\n",
        "  print(mu.shape)\n",
        "  print(logvar.shape)\n",
        "  print(z_reparmeterized.shape)\n",
        "  print(classified.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-UoGJdYPZONI",
        "outputId": "f5b27490-5d7b-4aa8-aff4-b300273506dd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "VAE(\n",
            "  (fc1): Linear(in_features=19, out_features=9, bias=True)\n",
            "  (mu): Linear(in_features=9, out_features=2, bias=True)\n",
            "  (logvar): Linear(in_features=9, out_features=2, bias=True)\n",
            "  (fc3): Linear(in_features=2, out_features=9, bias=True)\n",
            "  (fc4): Linear(in_features=9, out_features=19, bias=True)\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=2, out_features=13, bias=True)\n",
            "    (1): Sigmoid()\n",
            "    (2): Softmax(dim=1)\n",
            "  )\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "model  = VAE(input_dim, hidden_dim, latent_dim).to(device)\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "print(model)\n",
        "loss_fn = nn.MSELoss(reduction=\"sum\")\n",
        "classifier_loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "def accuracy(y_pred, y_act):\n",
        "  y_pred = torch.round(y_pred)\n",
        "  correct = (y_pred == y_act)\n",
        "  acc1 = correct.sum()/len(correct)\n",
        "  acc2 = torch.round(acc1*100)\n",
        "  # print(f\"z_pred: {y_pred} | lable: {y_act} | correct: {correct} | accuracy {acc1} | accuracy {acc2}\")\n",
        "  return acc2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YyxFhL0SXN-_",
        "outputId": "950c75ae-fed5-4d38-bc91-12cd3cac8d08"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 1 / 200 | reconst_loss: 3.104 | kldiv loss: 8.09943 | total loss: 24.054 | train acc: 495.662 ||| Val Loss: 16.296 | val acc: 0.000\n",
            "------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 2 / 200 | reconst_loss: 1.574 | kldiv loss: 24.58802 | total loss: 12.769 | train acc: 495.662 ||| Val Loss: 10.124 | val acc: 0.000\n",
            "------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 3 / 200 | reconst_loss: 0.801 | kldiv loss: 45.93206 | total loss: 8.234 | train acc: 495.463 ||| Val Loss: 6.572 | val acc: 0.000\n",
            "------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 4 / 200 | reconst_loss: 0.830 | kldiv loss: 72.12294 | total loss: 5.349 | train acc: 495.529 ||| Val Loss: 4.502 | val acc: 0.000\n",
            "------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 5 / 200 | reconst_loss: 0.522 | kldiv loss: 93.06513 | total loss: 4.108 | train acc: 495.529 ||| Val Loss: 3.924 | val acc: 0.000\n",
            "------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 6 / 200 | reconst_loss: 0.691 | kldiv loss: 104.21429 | total loss: 3.840 | train acc: 495.064 ||| Val Loss: 3.840 | val acc: 0.000\n",
            "------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 7 / 200 | reconst_loss: 0.595 | kldiv loss: 109.26250 | total loss: 3.799 | train acc: 495.529 ||| Val Loss: 3.823 | val acc: 0.000\n",
            "------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 8 / 200 | reconst_loss: 0.607 | kldiv loss: 112.11343 | total loss: 3.781 | train acc: 495.529 ||| Val Loss: 3.798 | val acc: 0.000\n",
            "------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 9 / 200 | reconst_loss: 0.274 | kldiv loss: 114.97272 | total loss: 3.765 | train acc: 495.662 ||| Val Loss: 3.784 | val acc: 0.000\n",
            "------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 10 / 200 | reconst_loss: 1.492 | kldiv loss: 116.55564 | total loss: 3.749 | train acc: 495.330 ||| Val Loss: 3.773 | val acc: 0.000\n",
            "------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 11 / 200 | reconst_loss: 0.819 | kldiv loss: 115.79742 | total loss: 3.733 | train acc: 495.396 ||| Val Loss: 3.753 | val acc: 0.000\n",
            "------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 12 / 200 | reconst_loss: 0.403 | kldiv loss: 111.90889 | total loss: 3.719 | train acc: 495.662 ||| Val Loss: 3.740 | val acc: 0.000\n",
            "------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 13 / 200 | reconst_loss: 0.705 | kldiv loss: 103.41063 | total loss: 3.698 | train acc: 495.662 ||| Val Loss: 3.708 | val acc: 0.000\n",
            "------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 14 / 200 | reconst_loss: 0.709 | kldiv loss: 90.96264 | total loss: 3.663 | train acc: 495.330 ||| Val Loss: 3.670 | val acc: 0.000\n",
            "------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 15 / 200 | reconst_loss: 0.452 | kldiv loss: 78.40666 | total loss: 3.619 | train acc: 495.529 ||| Val Loss: 3.617 | val acc: 0.000\n",
            "------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 16 / 200 | reconst_loss: 1.203 | kldiv loss: 69.69981 | total loss: 3.564 | train acc: 495.529 ||| Val Loss: 3.556 | val acc: 0.000\n",
            "------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 17 / 200 | reconst_loss: 0.554 | kldiv loss: 63.74577 | total loss: 3.497 | train acc: 495.396 ||| Val Loss: 3.483 | val acc: 0.000\n",
            "------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 18 / 200 | reconst_loss: 0.430 | kldiv loss: 56.12208 | total loss: 3.405 | train acc: 495.596 ||| Val Loss: 3.361 | val acc: 0.000\n",
            "------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 19 / 200 | reconst_loss: 0.619 | kldiv loss: 68.11777 | total loss: 3.227 | train acc: 495.463 ||| Val Loss: 3.159 | val acc: 0.000\n",
            "------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 20 / 200 | reconst_loss: 0.749 | kldiv loss: 83.03758 | total loss: 3.083 | train acc: 495.596 ||| Val Loss: 3.056 | val acc: 0.000\n",
            "------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 21 / 200 | reconst_loss: 0.280 | kldiv loss: 78.99770 | total loss: 3.006 | train acc: 495.662 ||| Val Loss: 3.003 | val acc: 0.000\n",
            "------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 22 / 200 | reconst_loss: 0.293 | kldiv loss: 87.30567 | total loss: 2.970 | train acc: 495.795 ||| Val Loss: 2.977 | val acc: 0.000\n",
            "------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 23 / 200 | reconst_loss: 0.331 | kldiv loss: 96.38091 | total loss: 2.948 | train acc: 495.529 ||| Val Loss: 2.960 | val acc: 0.000\n",
            "------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 24 / 200 | reconst_loss: 0.604 | kldiv loss: 92.92609 | total loss: 2.934 | train acc: 495.396 ||| Val Loss: 2.949 | val acc: 0.000\n",
            "------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 25 / 200 | reconst_loss: 0.658 | kldiv loss: 99.55359 | total loss: 2.925 | train acc: 495.396 ||| Val Loss: 2.939 | val acc: 0.000\n",
            "------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 26 / 200 | reconst_loss: 0.702 | kldiv loss: 113.63976 | total loss: 2.917 | train acc: 495.596 ||| Val Loss: 2.932 | val acc: 0.000\n",
            "------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 27 / 200 | reconst_loss: 0.551 | kldiv loss: 97.64484 | total loss: 2.911 | train acc: 495.330 ||| Val Loss: 2.926 | val acc: 0.000\n",
            "------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 28 / 200 | reconst_loss: 1.006 | kldiv loss: 103.26349 | total loss: 2.905 | train acc: 495.197 ||| Val Loss: 2.920 | val acc: 0.000\n",
            "------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 29 / 200 | reconst_loss: 0.563 | kldiv loss: 102.70401 | total loss: 2.900 | train acc: 495.529 ||| Val Loss: 2.916 | val acc: 0.000\n",
            "------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 30 / 200 | reconst_loss: 0.481 | kldiv loss: 99.59195 | total loss: 2.897 | train acc: 495.263 ||| Val Loss: 2.913 | val acc: 0.000\n",
            "------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 31 / 200 | reconst_loss: 0.651 | kldiv loss: 98.29823 | total loss: 2.893 | train acc: 495.263 ||| Val Loss: 2.909 | val acc: 0.000\n",
            "------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 32 / 200 | reconst_loss: 0.480 | kldiv loss: 97.67671 | total loss: 2.890 | train acc: 495.596 ||| Val Loss: 2.906 | val acc: 0.000\n",
            "------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 33 / 200 | reconst_loss: 0.834 | kldiv loss: 95.61042 | total loss: 2.887 | train acc: 495.463 ||| Val Loss: 2.903 | val acc: 0.000\n",
            "------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 34 / 200 | reconst_loss: 0.809 | kldiv loss: 100.08225 | total loss: 2.885 | train acc: 495.596 ||| Val Loss: 2.902 | val acc: 0.000\n",
            "------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 35 / 200 | reconst_loss: 0.140 | kldiv loss: 96.12631 | total loss: 2.883 | train acc: 495.729 ||| Val Loss: 2.899 | val acc: 0.000\n",
            "------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 36 / 200 | reconst_loss: 0.650 | kldiv loss: 103.84365 | total loss: 2.881 | train acc: 495.662 ||| Val Loss: 2.897 | val acc: 0.000\n",
            "------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 37 / 200 | reconst_loss: 0.509 | kldiv loss: 105.86162 | total loss: 2.879 | train acc: 495.463 ||| Val Loss: 2.895 | val acc: 0.000\n",
            "------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 38 / 200 | reconst_loss: 0.444 | kldiv loss: 91.69939 | total loss: 2.878 | train acc: 495.396 ||| Val Loss: 2.894 | val acc: 0.000\n",
            "------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 39 / 200 | reconst_loss: 0.550 | kldiv loss: 90.71125 | total loss: 2.876 | train acc: 495.529 ||| Val Loss: 2.893 | val acc: 0.000\n",
            "------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 40 / 200 | reconst_loss: 0.194 | kldiv loss: 87.55217 | total loss: 2.874 | train acc: 495.662 ||| Val Loss: 2.889 | val acc: 0.000\n",
            "------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 41 / 200 | reconst_loss: 0.728 | kldiv loss: 90.97185 | total loss: 2.873 | train acc: 495.596 ||| Val Loss: 2.889 | val acc: 0.000\n",
            "------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 42 / 200 | reconst_loss: 0.637 | kldiv loss: 91.90107 | total loss: 2.871 | train acc: 495.396 ||| Val Loss: 2.888 | val acc: 0.000\n",
            "------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 43 / 200 | reconst_loss: 0.578 | kldiv loss: 92.64964 | total loss: 2.869 | train acc: 495.463 ||| Val Loss: 2.886 | val acc: 0.000\n",
            "------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 44 / 200 | reconst_loss: 0.873 | kldiv loss: 85.84353 | total loss: 2.868 | train acc: 495.463 ||| Val Loss: 2.885 | val acc: 0.000\n",
            "------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 45 / 200 | reconst_loss: 0.984 | kldiv loss: 86.80672 | total loss: 2.867 | train acc: 495.463 ||| Val Loss: 2.883 | val acc: 0.000\n",
            "------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 46 / 200 | reconst_loss: 0.304 | kldiv loss: 87.70580 | total loss: 2.866 | train acc: 495.729 ||| Val Loss: 2.883 | val acc: 0.000\n",
            "------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 47 / 200 | reconst_loss: 0.315 | kldiv loss: 87.29476 | total loss: 2.865 | train acc: 495.529 ||| Val Loss: 2.882 | val acc: 0.000\n",
            "------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 48 / 200 | reconst_loss: 0.392 | kldiv loss: 86.65052 | total loss: 2.864 | train acc: 495.263 ||| Val Loss: 2.880 | val acc: 0.000\n",
            "------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 49 / 200 | reconst_loss: 0.554 | kldiv loss: 84.93972 | total loss: 2.863 | train acc: 495.463 ||| Val Loss: 2.879 | val acc: 0.000\n",
            "------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 50 / 200 | reconst_loss: 0.546 | kldiv loss: 81.21242 | total loss: 2.862 | train acc: 495.795 ||| Val Loss: 2.877 | val acc: 0.000\n",
            "------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 51 / 200 | reconst_loss: 0.534 | kldiv loss: 88.47079 | total loss: 2.861 | train acc: 495.330 ||| Val Loss: 2.878 | val acc: 0.000\n",
            "------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 52 / 200 | reconst_loss: 0.888 | kldiv loss: 82.65987 | total loss: 2.860 | train acc: 495.197 ||| Val Loss: 2.876 | val acc: 0.000\n",
            "------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 53 / 200 | reconst_loss: 0.357 | kldiv loss: 84.74307 | total loss: 2.858 | train acc: 495.396 ||| Val Loss: 2.872 | val acc: 0.000\n",
            "------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 54 / 200 | reconst_loss: 0.496 | kldiv loss: 83.46922 | total loss: 2.855 | train acc: 495.596 ||| Val Loss: 2.871 | val acc: 0.000\n",
            "------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 55 / 200 | reconst_loss: 0.625 | kldiv loss: 81.53780 | total loss: 2.853 | train acc: 495.529 ||| Val Loss: 2.866 | val acc: 0.000\n",
            "------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 56 / 200 | reconst_loss: 0.383 | kldiv loss: 81.05933 | total loss: 2.847 | train acc: 495.596 ||| Val Loss: 2.860 | val acc: 0.000\n",
            "------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 57 / 200 | reconst_loss: 0.499 | kldiv loss: 84.16245 | total loss: 2.840 | train acc: 495.463 ||| Val Loss: 2.852 | val acc: 0.000\n",
            "------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 58 / 200 | reconst_loss: 0.536 | kldiv loss: 84.94994 | total loss: 2.832 | train acc: 495.396 ||| Val Loss: 2.844 | val acc: 0.000\n",
            "------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 59 / 200 | reconst_loss: 0.927 | kldiv loss: 82.41914 | total loss: 2.823 | train acc: 495.529 ||| Val Loss: 2.834 | val acc: 0.000\n",
            "------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 60 / 200 | reconst_loss: 0.664 | kldiv loss: 85.95744 | total loss: 2.816 | train acc: 495.596 ||| Val Loss: 2.829 | val acc: 0.000\n",
            "------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 61 / 200 | reconst_loss: 0.758 | kldiv loss: 85.19289 | total loss: 2.808 | train acc: 495.263 ||| Val Loss: 2.819 | val acc: 0.000\n",
            "------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 62 / 200 | reconst_loss: 0.717 | kldiv loss: 90.54928 | total loss: 2.800 | train acc: 495.197 ||| Val Loss: 2.811 | val acc: 0.000\n",
            "------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 63 / 200 | reconst_loss: 0.456 | kldiv loss: 88.14705 | total loss: 2.791 | train acc: 495.396 ||| Val Loss: 2.803 | val acc: 0.000\n",
            "------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 64 / 200 | reconst_loss: 0.974 | kldiv loss: 92.06771 | total loss: 2.782 | train acc: 495.330 ||| Val Loss: 2.793 | val acc: 0.000\n",
            "------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 65 / 200 | reconst_loss: 0.554 | kldiv loss: 92.17776 | total loss: 2.772 | train acc: 495.596 ||| Val Loss: 2.779 | val acc: 0.000\n",
            "------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 66 / 200 | reconst_loss: 0.304 | kldiv loss: 94.58048 | total loss: 2.762 | train acc: 495.529 ||| Val Loss: 2.769 | val acc: 0.000\n",
            "------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 67 / 200 | reconst_loss: 0.390 | kldiv loss: 97.33337 | total loss: 2.749 | train acc: 495.529 ||| Val Loss: 2.755 | val acc: 0.000\n",
            "------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 68 / 200 | reconst_loss: 0.614 | kldiv loss: 96.83952 | total loss: 2.735 | train acc: 495.596 ||| Val Loss: 2.739 | val acc: 0.000\n",
            "------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 69 / 200 | reconst_loss: 0.225 | kldiv loss: 101.70627 | total loss: 2.717 | train acc: 495.662 ||| Val Loss: 2.716 | val acc: 0.000\n",
            "------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 70 / 200 | reconst_loss: 0.456 | kldiv loss: 99.46258 | total loss: 2.693 | train acc: 495.263 ||| Val Loss: 2.688 | val acc: 0.000\n",
            "------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 71 / 200 | reconst_loss: 0.341 | kldiv loss: 102.97295 | total loss: 2.660 | train acc: 495.529 ||| Val Loss: 2.647 | val acc: 0.000\n",
            "------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 72 / 200 | reconst_loss: 0.555 | kldiv loss: 105.28322 | total loss: 2.608 | train acc: 495.330 ||| Val Loss: 2.580 | val acc: 0.000\n",
            "------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 73 / 200 | reconst_loss: 0.641 | kldiv loss: 107.32375 | total loss: 2.539 | train acc: 495.396 ||| Val Loss: 2.500 | val acc: 0.000\n",
            "------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 74 / 200 | reconst_loss: 0.300 | kldiv loss: 111.42205 | total loss: 2.466 | train acc: 495.729 ||| Val Loss: 2.432 | val acc: 0.000\n",
            "------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 75 / 200 | reconst_loss: 0.284 | kldiv loss: 118.67467 | total loss: 2.414 | train acc: 495.463 ||| Val Loss: 2.390 | val acc: 0.000\n",
            "------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 76 / 200 | reconst_loss: 0.218 | kldiv loss: 124.25983 | total loss: 2.383 | train acc: 495.463 ||| Val Loss: 2.368 | val acc: 0.000\n",
            "------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 77 / 200 | reconst_loss: 0.424 | kldiv loss: 129.46614 | total loss: 2.366 | train acc: 495.596 ||| Val Loss: 2.354 | val acc: 0.000\n",
            "------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 78 / 200 | reconst_loss: 0.184 | kldiv loss: 127.46015 | total loss: 2.356 | train acc: 495.596 ||| Val Loss: 2.346 | val acc: 0.000\n",
            "------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 79 / 200 | reconst_loss: 0.382 | kldiv loss: 134.41998 | total loss: 2.348 | train acc: 495.596 ||| Val Loss: 2.339 | val acc: 0.000\n",
            "------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 80 / 200 | reconst_loss: 0.458 | kldiv loss: 140.69247 | total loss: 2.343 | train acc: 495.463 ||| Val Loss: 2.333 | val acc: 0.000\n",
            "------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 81 / 200 | reconst_loss: 0.426 | kldiv loss: 141.71429 | total loss: 2.338 | train acc: 495.463 ||| Val Loss: 2.329 | val acc: 0.000\n",
            "------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 82 / 200 | reconst_loss: 0.878 | kldiv loss: 136.84758 | total loss: 2.334 | train acc: 495.662 ||| Val Loss: 2.325 | val acc: 0.000\n",
            "------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 83 / 200 | reconst_loss: 0.370 | kldiv loss: 137.24780 | total loss: 2.330 | train acc: 495.263 ||| Val Loss: 2.322 | val acc: 0.000\n",
            "------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 84 / 200 | reconst_loss: 0.447 | kldiv loss: 138.06320 | total loss: 2.328 | train acc: 495.529 ||| Val Loss: 2.319 | val acc: 0.000\n",
            "------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 85 / 200 | reconst_loss: 0.395 | kldiv loss: 138.50546 | total loss: 2.324 | train acc: 495.529 ||| Val Loss: 2.316 | val acc: 0.000\n",
            "------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 86 / 200 | reconst_loss: 0.450 | kldiv loss: 140.78322 | total loss: 2.322 | train acc: 495.529 ||| Val Loss: 2.313 | val acc: 0.000\n",
            "------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 87 / 200 | reconst_loss: 0.443 | kldiv loss: 141.70337 | total loss: 2.319 | train acc: 495.330 ||| Val Loss: 2.310 | val acc: 0.000\n",
            "------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 88 / 200 | reconst_loss: 0.355 | kldiv loss: 144.15953 | total loss: 2.316 | train acc: 495.396 ||| Val Loss: 2.307 | val acc: 0.000\n",
            "------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 89 / 200 | reconst_loss: 0.234 | kldiv loss: 138.76797 | total loss: 2.313 | train acc: 495.662 ||| Val Loss: 2.304 | val acc: 0.000\n",
            "------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 90 / 200 | reconst_loss: 0.426 | kldiv loss: 141.67303 | total loss: 2.310 | train acc: 495.463 ||| Val Loss: 2.301 | val acc: 0.000\n",
            "------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 91 / 200 | reconst_loss: 0.497 | kldiv loss: 143.16444 | total loss: 2.307 | train acc: 495.463 ||| Val Loss: 2.299 | val acc: 0.000\n",
            "------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 92 / 200 | reconst_loss: 0.577 | kldiv loss: 142.43713 | total loss: 2.305 | train acc: 495.330 ||| Val Loss: 2.295 | val acc: 0.000\n",
            "------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 93 / 200 | reconst_loss: 0.674 | kldiv loss: 142.08473 | total loss: 2.302 | train acc: 495.596 ||| Val Loss: 2.292 | val acc: 0.000\n",
            "------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 94 / 200 | reconst_loss: 0.199 | kldiv loss: 138.32359 | total loss: 2.299 | train acc: 495.795 ||| Val Loss: 2.290 | val acc: 0.000\n",
            "------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 95 / 200 | reconst_loss: 0.387 | kldiv loss: 142.88745 | total loss: 2.296 | train acc: 495.529 ||| Val Loss: 2.287 | val acc: 0.000\n",
            "------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 96 / 200 | reconst_loss: 0.710 | kldiv loss: 141.31351 | total loss: 2.293 | train acc: 495.529 ||| Val Loss: 2.283 | val acc: 0.000\n",
            "------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 97 / 200 | reconst_loss: 0.345 | kldiv loss: 138.75523 | total loss: 2.290 | train acc: 495.263 ||| Val Loss: 2.281 | val acc: 0.000\n",
            "------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 98 / 200 | reconst_loss: 0.551 | kldiv loss: 142.23102 | total loss: 2.287 | train acc: 495.330 ||| Val Loss: 2.278 | val acc: 0.000\n",
            "------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 99 / 200 | reconst_loss: 0.334 | kldiv loss: 142.68607 | total loss: 2.285 | train acc: 495.330 ||| Val Loss: 2.275 | val acc: 0.000\n",
            "------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 100 / 200 | reconst_loss: 0.425 | kldiv loss: 142.15259 | total loss: 2.282 | train acc: 495.130 ||| Val Loss: 2.273 | val acc: 0.000\n",
            "------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 101 / 200 | reconst_loss: 0.476 | kldiv loss: 138.59444 | total loss: 2.279 | train acc: 495.662 ||| Val Loss: 2.270 | val acc: 0.000\n",
            "------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 102 / 200 | reconst_loss: 0.304 | kldiv loss: 143.63240 | total loss: 2.276 | train acc: 495.529 ||| Val Loss: 2.267 | val acc: 0.000\n",
            "------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 103 / 200 | reconst_loss: 0.458 | kldiv loss: 142.77678 | total loss: 2.274 | train acc: 495.529 ||| Val Loss: 2.264 | val acc: 0.000\n",
            "------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 104 / 200 | reconst_loss: 0.333 | kldiv loss: 139.75171 | total loss: 2.271 | train acc: 495.729 ||| Val Loss: 2.261 | val acc: 0.000\n",
            "------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 105 / 200 | reconst_loss: 0.529 | kldiv loss: 135.37242 | total loss: 2.267 | train acc: 495.463 ||| Val Loss: 2.258 | val acc: 0.000\n",
            "------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 106 / 200 | reconst_loss: 0.510 | kldiv loss: 138.07037 | total loss: 2.265 | train acc: 495.263 ||| Val Loss: 2.255 | val acc: 0.000\n",
            "------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 107 / 200 | reconst_loss: 0.346 | kldiv loss: 138.51350 | total loss: 2.262 | train acc: 495.596 ||| Val Loss: 2.253 | val acc: 0.000\n",
            "------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 108 / 200 | reconst_loss: 0.378 | kldiv loss: 137.05701 | total loss: 2.259 | train acc: 495.529 ||| Val Loss: 2.249 | val acc: 0.000\n",
            "------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 109 / 200 | reconst_loss: 0.423 | kldiv loss: 141.67096 | total loss: 2.255 | train acc: 495.662 ||| Val Loss: 2.246 | val acc: 0.000\n",
            "------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 110 / 200 | reconst_loss: 0.213 | kldiv loss: 133.02591 | total loss: 2.252 | train acc: 495.662 ||| Val Loss: 2.243 | val acc: 0.000\n",
            "------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 111 / 200 | reconst_loss: 0.765 | kldiv loss: 137.58653 | total loss: 2.248 | train acc: 495.529 ||| Val Loss: 2.239 | val acc: 0.000\n",
            "------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 112 / 200 | reconst_loss: 0.183 | kldiv loss: 136.33711 | total loss: 2.245 | train acc: 495.463 ||| Val Loss: 2.235 | val acc: 0.000\n",
            "------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 113 / 200 | reconst_loss: 0.370 | kldiv loss: 136.63336 | total loss: 2.240 | train acc: 495.529 ||| Val Loss: 2.230 | val acc: 0.000\n",
            "------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 114 / 200 | reconst_loss: 0.256 | kldiv loss: 137.76878 | total loss: 2.235 | train acc: 495.463 ||| Val Loss: 2.223 | val acc: 0.000\n",
            "------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 115 / 200 | reconst_loss: 0.441 | kldiv loss: 135.54190 | total loss: 2.227 | train acc: 495.396 ||| Val Loss: 2.216 | val acc: 0.000\n",
            "------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 116 / 200 | reconst_loss: 0.310 | kldiv loss: 138.14645 | total loss: 2.219 | train acc: 495.596 ||| Val Loss: 2.209 | val acc: 0.000\n",
            "------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 117 / 200 | reconst_loss: 0.496 | kldiv loss: 141.41751 | total loss: 2.213 | train acc: 495.529 ||| Val Loss: 2.203 | val acc: 0.000\n",
            "------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 118 / 200 | reconst_loss: 0.362 | kldiv loss: 138.36179 | total loss: 2.207 | train acc: 495.596 ||| Val Loss: 2.199 | val acc: 0.000\n",
            "------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 119 / 200 | reconst_loss: 0.378 | kldiv loss: 135.74316 | total loss: 2.203 | train acc: 495.463 ||| Val Loss: 2.195 | val acc: 0.000\n",
            "------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 120 / 200 | reconst_loss: 0.789 | kldiv loss: 139.33356 | total loss: 2.199 | train acc: 495.463 ||| Val Loss: 2.191 | val acc: 0.000\n",
            "------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 121 / 200 | reconst_loss: 0.444 | kldiv loss: 139.15549 | total loss: 2.195 | train acc: 495.529 ||| Val Loss: 2.188 | val acc: 0.000\n",
            "------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 122 / 200 | reconst_loss: 0.461 | kldiv loss: 136.81302 | total loss: 2.191 | train acc: 495.396 ||| Val Loss: 2.184 | val acc: 0.000\n",
            "------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 123 / 200 | reconst_loss: 0.328 | kldiv loss: 138.72522 | total loss: 2.188 | train acc: 495.529 ||| Val Loss: 2.182 | val acc: 0.000\n",
            "------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 124 / 200 | reconst_loss: 0.728 | kldiv loss: 138.23837 | total loss: 2.185 | train acc: 495.596 ||| Val Loss: 2.180 | val acc: 0.000\n",
            "------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 125 / 200 | reconst_loss: 0.269 | kldiv loss: 139.87233 | total loss: 2.182 | train acc: 495.596 ||| Val Loss: 2.176 | val acc: 0.000\n",
            "------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 126 / 200 | reconst_loss: 0.859 | kldiv loss: 139.52498 | total loss: 2.179 | train acc: 495.330 ||| Val Loss: 2.175 | val acc: 0.000\n",
            "------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 127 / 200 | reconst_loss: 0.240 | kldiv loss: 138.10016 | total loss: 2.177 | train acc: 495.729 ||| Val Loss: 2.173 | val acc: 0.000\n",
            "------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 128 / 200 | reconst_loss: 0.723 | kldiv loss: 138.32599 | total loss: 2.175 | train acc: 495.396 ||| Val Loss: 2.172 | val acc: 0.000\n",
            "------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 129 / 200 | reconst_loss: 0.757 | kldiv loss: 137.69806 | total loss: 2.172 | train acc: 495.396 ||| Val Loss: 2.169 | val acc: 0.000\n",
            "------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 130 / 200 | reconst_loss: 0.440 | kldiv loss: 140.82364 | total loss: 2.171 | train acc: 495.396 ||| Val Loss: 2.167 | val acc: 0.000\n",
            "------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 131 / 200 | reconst_loss: 0.303 | kldiv loss: 139.80075 | total loss: 2.169 | train acc: 495.396 ||| Val Loss: 2.165 | val acc: 0.000\n",
            "------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 132 / 200 | reconst_loss: 0.338 | kldiv loss: 138.98065 | total loss: 2.167 | train acc: 495.596 ||| Val Loss: 2.165 | val acc: 0.000\n",
            "------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 133 / 200 | reconst_loss: 0.440 | kldiv loss: 142.42451 | total loss: 2.165 | train acc: 495.263 ||| Val Loss: 2.163 | val acc: 0.000\n",
            "------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 134 / 200 | reconst_loss: 0.363 | kldiv loss: 140.51610 | total loss: 2.164 | train acc: 495.529 ||| Val Loss: 2.161 | val acc: 0.000\n",
            "------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 135 / 200 | reconst_loss: 0.439 | kldiv loss: 139.77367 | total loss: 2.162 | train acc: 495.729 ||| Val Loss: 2.161 | val acc: 0.000\n",
            "------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 136 / 200 | reconst_loss: 0.226 | kldiv loss: 138.70729 | total loss: 2.161 | train acc: 495.662 ||| Val Loss: 2.158 | val acc: 0.000\n",
            "------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 137 / 200 | reconst_loss: 0.438 | kldiv loss: 143.33315 | total loss: 2.159 | train acc: 495.463 ||| Val Loss: 2.158 | val acc: 0.000\n",
            "------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 138 / 200 | reconst_loss: 0.564 | kldiv loss: 139.66669 | total loss: 2.158 | train acc: 495.529 ||| Val Loss: 2.157 | val acc: 0.000\n",
            "------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 139 / 200 | reconst_loss: 0.287 | kldiv loss: 137.74664 | total loss: 2.157 | train acc: 495.596 ||| Val Loss: 2.156 | val acc: 0.000\n",
            "------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 140 / 200 | reconst_loss: 0.537 | kldiv loss: 141.22557 | total loss: 2.155 | train acc: 495.463 ||| Val Loss: 2.154 | val acc: 0.000\n",
            "------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 141 / 200 | reconst_loss: 0.228 | kldiv loss: 136.17451 | total loss: 2.155 | train acc: 495.596 ||| Val Loss: 2.154 | val acc: 0.000\n",
            "------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 142 / 200 | reconst_loss: 0.241 | kldiv loss: 140.77968 | total loss: 2.154 | train acc: 495.662 ||| Val Loss: 2.152 | val acc: 0.000\n",
            "------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 143 / 200 | reconst_loss: 0.395 | kldiv loss: 141.08438 | total loss: 2.153 | train acc: 495.396 ||| Val Loss: 2.153 | val acc: 0.000\n",
            "------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 144 / 200 | reconst_loss: 0.554 | kldiv loss: 137.74710 | total loss: 2.152 | train acc: 495.662 ||| Val Loss: 2.151 | val acc: 0.000\n",
            "------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 145 / 200 | reconst_loss: 0.138 | kldiv loss: 139.65088 | total loss: 2.151 | train acc: 495.795 ||| Val Loss: 2.151 | val acc: 0.000\n",
            "------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 146 / 200 | reconst_loss: 0.222 | kldiv loss: 139.42560 | total loss: 2.150 | train acc: 495.862 ||| Val Loss: 2.150 | val acc: 0.000\n",
            "------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 147 / 200 | reconst_loss: 0.520 | kldiv loss: 142.05502 | total loss: 2.149 | train acc: 495.330 ||| Val Loss: 2.149 | val acc: 0.000\n",
            "------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 148 / 200 | reconst_loss: 0.720 | kldiv loss: 142.25279 | total loss: 2.148 | train acc: 495.596 ||| Val Loss: 2.148 | val acc: 0.000\n",
            "------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 149 / 200 | reconst_loss: 0.449 | kldiv loss: 140.55119 | total loss: 2.147 | train acc: 495.529 ||| Val Loss: 2.147 | val acc: 0.000\n",
            "------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 150 / 200 | reconst_loss: 0.192 | kldiv loss: 139.12213 | total loss: 2.147 | train acc: 495.662 ||| Val Loss: 2.147 | val acc: 0.000\n",
            "------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 151 / 200 | reconst_loss: 0.397 | kldiv loss: 142.95383 | total loss: 2.146 | train acc: 495.330 ||| Val Loss: 2.146 | val acc: 0.000\n",
            "------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 152 / 200 | reconst_loss: 0.267 | kldiv loss: 139.48586 | total loss: 2.145 | train acc: 495.662 ||| Val Loss: 2.146 | val acc: 0.000\n",
            "------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 153 / 200 | reconst_loss: 0.411 | kldiv loss: 143.26620 | total loss: 2.145 | train acc: 495.463 ||| Val Loss: 2.145 | val acc: 0.000\n",
            "------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 154 / 200 | reconst_loss: 0.661 | kldiv loss: 139.94611 | total loss: 2.144 | train acc: 495.529 ||| Val Loss: 2.144 | val acc: 0.000\n",
            "------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 155 / 200 | reconst_loss: 0.221 | kldiv loss: 138.95024 | total loss: 2.143 | train acc: 495.662 ||| Val Loss: 2.143 | val acc: 0.000\n",
            "------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 156 / 200 | reconst_loss: 0.467 | kldiv loss: 144.52509 | total loss: 2.143 | train acc: 495.463 ||| Val Loss: 2.143 | val acc: 0.000\n",
            "------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 157 / 200 | reconst_loss: 0.511 | kldiv loss: 140.73705 | total loss: 2.142 | train acc: 495.729 ||| Val Loss: 2.143 | val acc: 0.000\n",
            "------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 158 / 200 | reconst_loss: 0.629 | kldiv loss: 142.47038 | total loss: 2.142 | train acc: 495.662 ||| Val Loss: 2.142 | val acc: 0.000\n",
            "------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 159 / 200 | reconst_loss: 0.543 | kldiv loss: 141.81943 | total loss: 2.141 | train acc: 495.396 ||| Val Loss: 2.142 | val acc: 0.000\n",
            "------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 160 / 200 | reconst_loss: 0.353 | kldiv loss: 142.64250 | total loss: 2.140 | train acc: 495.396 ||| Val Loss: 2.141 | val acc: 0.000\n",
            "------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 161 / 200 | reconst_loss: 0.501 | kldiv loss: 144.01517 | total loss: 2.140 | train acc: 495.396 ||| Val Loss: 2.141 | val acc: 0.000\n",
            "------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 162 / 200 | reconst_loss: 0.231 | kldiv loss: 141.36040 | total loss: 2.140 | train acc: 495.596 ||| Val Loss: 2.140 | val acc: 0.000\n",
            "------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 163 / 200 | reconst_loss: 0.556 | kldiv loss: 142.87250 | total loss: 2.139 | train acc: 495.729 ||| Val Loss: 2.140 | val acc: 0.000\n",
            "------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 164 / 200 | reconst_loss: 0.507 | kldiv loss: 142.77478 | total loss: 2.139 | train acc: 495.263 ||| Val Loss: 2.138 | val acc: 0.000\n",
            "------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 165 / 200 | reconst_loss: 0.233 | kldiv loss: 143.34138 | total loss: 2.138 | train acc: 495.596 ||| Val Loss: 2.139 | val acc: 0.000\n",
            "------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 166 / 200 | reconst_loss: 0.588 | kldiv loss: 141.44614 | total loss: 2.138 | train acc: 495.596 ||| Val Loss: 2.138 | val acc: 0.000\n",
            "------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 167 / 200 | reconst_loss: 0.653 | kldiv loss: 144.76392 | total loss: 2.137 | train acc: 495.662 ||| Val Loss: 2.138 | val acc: 0.000\n",
            "------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 168 / 200 | reconst_loss: 0.248 | kldiv loss: 144.06018 | total loss: 2.137 | train acc: 495.662 ||| Val Loss: 2.138 | val acc: 0.000\n",
            "------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 169 / 200 | reconst_loss: 0.218 | kldiv loss: 141.85510 | total loss: 2.136 | train acc: 495.729 ||| Val Loss: 2.137 | val acc: 0.000\n",
            "------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 170 / 200 | reconst_loss: 0.580 | kldiv loss: 144.07993 | total loss: 2.136 | train acc: 495.330 ||| Val Loss: 2.137 | val acc: 0.000\n",
            "------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 171 / 200 | reconst_loss: 0.101 | kldiv loss: 141.81564 | total loss: 2.136 | train acc: 495.662 ||| Val Loss: 2.137 | val acc: 0.000\n",
            "------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 172 / 200 | reconst_loss: 0.618 | kldiv loss: 141.49695 | total loss: 2.135 | train acc: 495.529 ||| Val Loss: 2.136 | val acc: 0.000\n",
            "------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 173 / 200 | reconst_loss: 0.359 | kldiv loss: 142.28528 | total loss: 2.135 | train acc: 495.396 ||| Val Loss: 2.135 | val acc: 0.000\n",
            "------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 174 / 200 | reconst_loss: 0.558 | kldiv loss: 142.59747 | total loss: 2.134 | train acc: 495.463 ||| Val Loss: 2.136 | val acc: 0.000\n",
            "------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 175 / 200 | reconst_loss: 0.511 | kldiv loss: 143.37726 | total loss: 2.134 | train acc: 495.396 ||| Val Loss: 2.137 | val acc: 0.000\n",
            "------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 176 / 200 | reconst_loss: 0.514 | kldiv loss: 145.01210 | total loss: 2.133 | train acc: 495.396 ||| Val Loss: 2.134 | val acc: 0.000\n",
            "------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 177 / 200 | reconst_loss: 0.440 | kldiv loss: 144.63976 | total loss: 2.133 | train acc: 495.396 ||| Val Loss: 2.134 | val acc: 0.000\n",
            "------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 178 / 200 | reconst_loss: 0.166 | kldiv loss: 141.72635 | total loss: 2.133 | train acc: 495.529 ||| Val Loss: 2.134 | val acc: 0.000\n",
            "------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 179 / 200 | reconst_loss: 0.267 | kldiv loss: 141.64264 | total loss: 2.132 | train acc: 495.529 ||| Val Loss: 2.133 | val acc: 0.000\n",
            "------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 180 / 200 | reconst_loss: 0.352 | kldiv loss: 141.72191 | total loss: 2.132 | train acc: 495.662 ||| Val Loss: 2.133 | val acc: 0.000\n",
            "------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 181 / 200 | reconst_loss: 0.550 | kldiv loss: 146.06058 | total loss: 2.132 | train acc: 495.263 ||| Val Loss: 2.132 | val acc: 0.000\n",
            "------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 182 / 200 | reconst_loss: 0.441 | kldiv loss: 145.87247 | total loss: 2.131 | train acc: 495.463 ||| Val Loss: 2.132 | val acc: 0.000\n",
            "------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 183 / 200 | reconst_loss: 0.324 | kldiv loss: 143.25087 | total loss: 2.131 | train acc: 495.396 ||| Val Loss: 2.132 | val acc: 0.000\n",
            "------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 184 / 200 | reconst_loss: 0.166 | kldiv loss: 143.33607 | total loss: 2.131 | train acc: 495.596 ||| Val Loss: 2.132 | val acc: 0.000\n",
            "------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 185 / 200 | reconst_loss: 0.274 | kldiv loss: 147.16003 | total loss: 2.130 | train acc: 495.596 ||| Val Loss: 2.132 | val acc: 0.000\n",
            "------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 186 / 200 | reconst_loss: 0.216 | kldiv loss: 140.36418 | total loss: 2.130 | train acc: 495.330 ||| Val Loss: 2.131 | val acc: 0.000\n",
            "------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 187 / 200 | reconst_loss: 0.321 | kldiv loss: 142.92627 | total loss: 2.129 | train acc: 495.662 ||| Val Loss: 2.130 | val acc: 0.000\n",
            "------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 188 / 200 | reconst_loss: 0.619 | kldiv loss: 142.10585 | total loss: 2.129 | train acc: 495.529 ||| Val Loss: 2.129 | val acc: 0.000\n",
            "------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 189 / 200 | reconst_loss: 0.514 | kldiv loss: 143.98102 | total loss: 2.129 | train acc: 495.596 ||| Val Loss: 2.130 | val acc: 0.000\n",
            "------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 190 / 200 | reconst_loss: 0.136 | kldiv loss: 143.34740 | total loss: 2.129 | train acc: 495.596 ||| Val Loss: 2.129 | val acc: 0.000\n",
            "------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 191 / 200 | reconst_loss: 0.480 | kldiv loss: 144.81976 | total loss: 2.128 | train acc: 495.330 ||| Val Loss: 2.129 | val acc: 0.000\n",
            "------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 192 / 200 | reconst_loss: 0.154 | kldiv loss: 142.92966 | total loss: 2.128 | train acc: 495.596 ||| Val Loss: 2.129 | val acc: 0.000\n",
            "------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 193 / 200 | reconst_loss: 0.493 | kldiv loss: 146.36945 | total loss: 2.128 | train acc: 495.529 ||| Val Loss: 2.129 | val acc: 0.000\n",
            "------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 194 / 200 | reconst_loss: 0.471 | kldiv loss: 144.95583 | total loss: 2.127 | train acc: 495.795 ||| Val Loss: 2.128 | val acc: 0.000\n",
            "------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 195 / 200 | reconst_loss: 0.107 | kldiv loss: 142.22910 | total loss: 2.127 | train acc: 495.862 ||| Val Loss: 2.131 | val acc: 0.000\n",
            "------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 196 / 200 | reconst_loss: 0.437 | kldiv loss: 142.77124 | total loss: 2.126 | train acc: 495.529 ||| Val Loss: 2.128 | val acc: 0.000\n",
            "------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 197 / 200 | reconst_loss: 0.265 | kldiv loss: 143.35211 | total loss: 2.126 | train acc: 495.729 ||| Val Loss: 2.128 | val acc: 0.000\n",
            "------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 198 / 200 | reconst_loss: 0.317 | kldiv loss: 146.34698 | total loss: 2.126 | train acc: 495.529 ||| Val Loss: 2.127 | val acc: 0.000\n",
            "------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 199 / 200 | reconst_loss: 0.393 | kldiv loss: 145.52461 | total loss: 2.126 | train acc: 495.529 ||| Val Loss: 2.127 | val acc: 0.000\n",
            "------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 200 / 200 | reconst_loss: 0.321 | kldiv loss: 142.17972 | total loss: 2.125 | train acc: 495.463 ||| Val Loss: 2.127 | val acc: 0.000\n",
            "------------------------------------------------------------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "train_losses=[]\n",
        "val_losses=[]\n",
        "train_accuracy = []\n",
        "val_accuracy = []\n",
        "\n",
        "\n",
        "dic = dict(latent_space = list(), mu_list=list(), logsig2_list=list(), y=list())\n",
        "for epoch in range(num_epochs):\n",
        "  model.train()\n",
        "  #print(f\"zvalue loop begin {z}\")\n",
        "  train_running_loss = 0\n",
        "  train_running_acc = 0\n",
        "#  loop = tqdm(train_loader)\n",
        "  for i, data in enumerate(train_loader):\n",
        "    inputs, labels = data\n",
        "    #print(f'type data: {type(data)}')\n",
        "    #print(f'type inputs: {type(inputs)}')\n",
        "    #print(f'type labels: {type(labels)}')\n",
        "\n",
        "    x_reconstructed, z_reparmeterized, classified, mu, logvar = model(inputs)\n",
        "    #print(x_reconstructed, type(x_reconstructed))\n",
        "    #print(mu, type(mu))\n",
        "    #print(logvar, type(logvar))\n",
        "\n",
        "    reconstruction_loss = loss_fn(x_reconstructed, inputs)\n",
        "    kld_loss = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
        "    loss = alpha*reconstruction_loss + kld_loss*beta\n",
        "\n",
        "    acc_train = accuracy(classified, labels)\n",
        "    #print(reconstruction_loss, kld_loss, loss)\n",
        "    \n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    train_running_loss += loss.item()\n",
        "    train_loss= train_running_loss/len(train_loader)\n",
        "\n",
        "    train_running_acc += acc_train.item()\n",
        "    train_acc = train_running_acc/len(train_loader)\n",
        "\n",
        "  \n",
        "  z_list, means, logvars , labels = list(), list(), list(), list()\n",
        "\n",
        "  #Evaluation\n",
        "  with torch.inference_mode():\n",
        "    val_running_loss = 0\n",
        "\n",
        "    model.eval()\n",
        "    for X, Y in val_loader:\n",
        "      #print(labels)\n",
        "      #inputs = torch.autograd.Variable(inputs)\n",
        "      y_pred, z_reparmeterized, classified, mu, logvar = model(X)\n",
        "      v_reconstruction_loss = loss_fn(y_pred, X)\n",
        "      v_kld_loss = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
        "      vloss = alpha*v_reconstruction_loss + v_kld_loss*beta\n",
        "      #print(v_reconstruction_loss, v_kld_loss, vloss)\n",
        "\n",
        "      # yhat = torch.max(z.data,1)\n",
        "      # correct+=(yhat==y_test).sum().int()\n",
        "      # accuracy = correct / n_test\n",
        "      # accuracy_list.append(accuracy)\n",
        "  \n",
        "\n",
        "      # val_acc = accuracy(classified, labels)\n",
        "      val_acc = 0\n",
        "\n",
        "      val_running_loss += vloss.item()\n",
        "      val_loss = val_running_loss/len(val_loader)\n",
        "\n",
        "      # log ...\n",
        "      z_list.append(z_reparmeterized.detach())\n",
        "      means.append(mu.detach())\n",
        "      logvars.append(logvar.detach())\n",
        "      labels.append(Y.detach())\n",
        "\n",
        "  dic['latent_space'].append(torch.cat(z_list))\n",
        "  dic['mu_list'].append(torch.cat(means))\n",
        "  dic['logsig2_list'].append(torch.cat(logvars))\n",
        "  dic['y'].append(torch.cat(labels))\n",
        "\n",
        "  print(f\"Epoch: {epoch+1}/{num_epochs} | reconst_loss: {reconstruction_loss:.3f} | kldiv loss: {kld_loss:.5f} | total loss: {train_loss:.3f} | train acc: {train_acc:.3f} ||| Val Loss: {val_loss:.3f} | val acc: {val_acc:.3f}\")\n",
        "  print(\"--------------------------------------------------------------------------------------------------------------------------------------------------------------\")\n",
        "  #print(f\"Epoch: {epoch+1} / {num_epochs} | reconst_loss: {v_reconstruction_loss:.3f} | kldiv loss: {v_kld_loss:.3f} | Val Loss: {val_loss:.3f}\")\n",
        "  train_losses.append(train_loss)\n",
        "  val_losses.append(val_loss)\n",
        "  train_accuracy.append(train_acc)\n",
        "  \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vaK_eSTWACl3"
      },
      "outputs": [],
      "source": [
        "torch.save(model.state_dict(), 'VAE_Model.pt') # Save"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "Www1IBIuH4EY",
        "outputId": "8b042676-f261-4fd5-cb63-08a8012316de"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.plot(train_losses,'-o', label=\"Training loss\")\n",
        "plt.plot(val_losses,'-r',  label=\"Validation loss\")\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('losses')\n",
        "plt.title('Training and Validation Losses')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "cHWCgtgq6OJd",
        "outputId": "b3ddf39b-207c-4002-ab34-228c4c87c524"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.plot(train_accuracy,'-o', label=\"Training acc\")\n",
        "# plt.plot(val_acc,'-r',  label=\"Validation acc\")\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('acc')\n",
        "plt.title('Training and Validation Losses')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6KSX5IZj2KZ0",
        "outputId": "e53e0192-eece-44a8-da87-cea84678c3a4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Latent Space Visualization\n",
            "Latent Space Image 1 stored.\n",
            "Latent Space Image 2 stored.\n",
            "Latent Space Image 3 stored.\n",
            "Latent Space Image 4 stored.\n",
            "Latent Space Image 5 stored.\n",
            "Latent Space Image 6 stored.\n",
            "Latent Space Image 7 stored.\n",
            "Latent Space Image 8 stored.\n",
            "Latent Space Image 9 stored.\n",
            "Latent Space Image 10 stored.\n",
            "Latent Space Image 11 stored.\n",
            "Latent Space Image 12 stored.\n",
            "Latent Space Image 13 stored.\n",
            "Latent Space Image 14 stored.\n",
            "Latent Space Image 15 stored.\n",
            "Latent Space Image 16 stored.\n",
            "Latent Space Image 17 stored.\n",
            "Latent Space Image 18 stored.\n",
            "Latent Space Image 19 stored.\n",
            "Latent Space Image 20 stored.\n",
            "Latent Space Image 21 stored.\n",
            "Latent Space Image 22 stored.\n",
            "Latent Space Image 23 stored.\n",
            "Latent Space Image 24 stored.\n",
            "Latent Space Image 25 stored.\n",
            "Latent Space Image 26 stored.\n",
            "Latent Space Image 27 stored.\n",
            "Latent Space Image 28 stored.\n",
            "Latent Space Image 29 stored.\n",
            "Latent Space Image 30 stored.\n",
            "Latent Space Image 31 stored.\n",
            "Latent Space Image 32 stored.\n",
            "Latent Space Image 33 stored.\n",
            "Latent Space Image 34 stored.\n",
            "Latent Space Image 35 stored.\n",
            "Latent Space Image 36 stored.\n",
            "Latent Space Image 37 stored.\n",
            "Latent Space Image 38 stored.\n",
            "Latent Space Image 39 stored.\n",
            "Latent Space Image 40 stored.\n",
            "Latent Space Image 41 stored.\n",
            "Latent Space Image 42 stored.\n",
            "Latent Space Image 43 stored.\n",
            "Latent Space Image 44 stored.\n",
            "Latent Space Image 45 stored.\n",
            "Latent Space Image 46 stored.\n",
            "Latent Space Image 47 stored.\n",
            "Latent Space Image 48 stored.\n",
            "Latent Space Image 49 stored.\n",
            "Latent Space Image 50 stored.\n",
            "Latent Space Image 51 stored.\n",
            "Latent Space Image 52 stored.\n",
            "Latent Space Image 53 stored.\n",
            "Latent Space Image 54 stored.\n",
            "Latent Space Image 55 stored.\n",
            "Latent Space Image 56 stored.\n",
            "Latent Space Image 57 stored.\n",
            "Latent Space Image 58 stored.\n",
            "Latent Space Image 59 stored.\n",
            "Latent Space Image 60 stored.\n",
            "Latent Space Image 61 stored.\n",
            "Latent Space Image 62 stored.\n",
            "Latent Space Image 63 stored.\n",
            "Latent Space Image 64 stored.\n",
            "Latent Space Image 65 stored.\n",
            "Latent Space Image 66 stored.\n",
            "Latent Space Image 67 stored.\n",
            "Latent Space Image 68 stored.\n",
            "Latent Space Image 69 stored.\n",
            "Latent Space Image 70 stored.\n",
            "Latent Space Image 71 stored.\n",
            "Latent Space Image 72 stored.\n",
            "Latent Space Image 73 stored.\n",
            "Latent Space Image 74 stored.\n",
            "Latent Space Image 75 stored.\n",
            "Latent Space Image 76 stored.\n",
            "Latent Space Image 77 stored.\n",
            "Latent Space Image 78 stored.\n",
            "Latent Space Image 79 stored.\n",
            "Latent Space Image 80 stored.\n",
            "Latent Space Image 81 stored.\n",
            "Latent Space Image 82 stored.\n",
            "Latent Space Image 83 stored.\n",
            "Latent Space Image 84 stored.\n",
            "Latent Space Image 85 stored.\n",
            "Latent Space Image 86 stored.\n",
            "Latent Space Image 87 stored.\n",
            "Latent Space Image 88 stored.\n",
            "Latent Space Image 89 stored.\n",
            "Latent Space Image 90 stored.\n",
            "Latent Space Image 91 stored.\n",
            "Latent Space Image 92 stored.\n",
            "Latent Space Image 93 stored.\n",
            "Latent Space Image 94 stored.\n",
            "Latent Space Image 95 stored.\n",
            "Latent Space Image 96 stored.\n",
            "Latent Space Image 97 stored.\n",
            "Latent Space Image 98 stored.\n",
            "Latent Space Image 99 stored.\n",
            "Latent Space Image 100 stored.\n",
            "Latent Space Image 101 stored.\n",
            "Latent Space Image 102 stored.\n",
            "Latent Space Image 103 stored.\n",
            "Latent Space Image 104 stored.\n",
            "Latent Space Image 105 stored.\n",
            "Latent Space Image 106 stored.\n",
            "Latent Space Image 107 stored.\n",
            "Latent Space Image 108 stored.\n",
            "Latent Space Image 109 stored.\n",
            "Latent Space Image 110 stored.\n",
            "Latent Space Image 111 stored.\n",
            "Latent Space Image 112 stored.\n",
            "Latent Space Image 113 stored.\n",
            "Latent Space Image 114 stored.\n",
            "Latent Space Image 115 stored.\n",
            "Latent Space Image 116 stored.\n",
            "Latent Space Image 117 stored.\n",
            "Latent Space Image 118 stored.\n",
            "Latent Space Image 119 stored.\n",
            "Latent Space Image 120 stored.\n",
            "Latent Space Image 121 stored.\n",
            "Latent Space Image 122 stored.\n",
            "Latent Space Image 123 stored.\n",
            "Latent Space Image 124 stored.\n",
            "Latent Space Image 125 stored.\n",
            "Latent Space Image 126 stored.\n",
            "Latent Space Image 127 stored.\n",
            "Latent Space Image 128 stored.\n",
            "Latent Space Image 129 stored.\n",
            "Latent Space Image 130 stored.\n",
            "Latent Space Image 131 stored.\n",
            "Latent Space Image 132 stored.\n",
            "Latent Space Image 133 stored.\n",
            "Latent Space Image 134 stored.\n",
            "Latent Space Image 135 stored.\n",
            "Latent Space Image 136 stored.\n",
            "Latent Space Image 137 stored.\n",
            "Latent Space Image 138 stored.\n",
            "Latent Space Image 139 stored.\n",
            "Latent Space Image 140 stored.\n",
            "Latent Space Image 141 stored.\n",
            "Latent Space Image 142 stored.\n",
            "Latent Space Image 143 stored.\n",
            "Latent Space Image 144 stored.\n",
            "Latent Space Image 145 stored.\n",
            "Latent Space Image 146 stored.\n",
            "Latent Space Image 147 stored.\n",
            "Latent Space Image 148 stored.\n",
            "Latent Space Image 149 stored.\n",
            "Latent Space Image 150 stored.\n",
            "Latent Space Image 151 stored.\n",
            "Latent Space Image 152 stored.\n",
            "Latent Space Image 153 stored.\n",
            "Latent Space Image 154 stored.\n",
            "Latent Space Image 155 stored.\n",
            "Latent Space Image 156 stored.\n",
            "Latent Space Image 157 stored.\n",
            "Latent Space Image 158 stored.\n",
            "Latent Space Image 159 stored.\n",
            "Latent Space Image 160 stored.\n",
            "Latent Space Image 161 stored.\n",
            "Latent Space Image 162 stored.\n",
            "Latent Space Image 163 stored.\n",
            "Latent Space Image 164 stored.\n",
            "Latent Space Image 165 stored.\n",
            "Latent Space Image 166 stored.\n",
            "Latent Space Image 167 stored.\n",
            "Latent Space Image 168 stored.\n",
            "Latent Space Image 169 stored.\n",
            "Latent Space Image 170 stored.\n",
            "Latent Space Image 171 stored.\n",
            "Latent Space Image 172 stored.\n",
            "Latent Space Image 173 stored.\n",
            "Latent Space Image 174 stored.\n",
            "Latent Space Image 175 stored.\n",
            "Latent Space Image 176 stored.\n",
            "Latent Space Image 177 stored.\n",
            "Latent Space Image 178 stored.\n",
            "Latent Space Image 179 stored.\n",
            "Latent Space Image 180 stored.\n",
            "Latent Space Image 181 stored.\n",
            "Latent Space Image 182 stored.\n",
            "Latent Space Image 183 stored.\n",
            "Latent Space Image 184 stored.\n",
            "Latent Space Image 185 stored.\n",
            "Latent Space Image 186 stored.\n",
            "Latent Space Image 187 stored.\n",
            "Latent Space Image 188 stored.\n",
            "Latent Space Image 189 stored.\n",
            "Latent Space Image 190 stored.\n",
            "Latent Space Image 191 stored.\n",
            "Latent Space Image 192 stored.\n",
            "Latent Space Image 193 stored.\n",
            "Latent Space Image 194 stored.\n",
            "Latent Space Image 195 stored.\n",
            "Latent Space Image 196 stored.\n",
            "Latent Space Image 197 stored.\n",
            "Latent Space Image 198 stored.\n",
            "Latent Space Image 199 stored.\n",
            "Latent Space Image 200 stored.\n"
          ]
        }
      ],
      "source": [
        "print(\"Latent Space Visualization\")\n",
        "for i in range (num_epochs):\n",
        "  fig = plt.figure(figsize=(10,10))\n",
        "  z_arr = dic['latent_space'][i].cpu().numpy()\n",
        "  y_arr = dic['y'][i].cpu().numpy()\n",
        "\n",
        "  #Experiment 1\n",
        "  plt.scatter(z_arr[:,0], z_arr[:,1], c = y_arr, edgecolor='none', alpha=0.5,\n",
        "              cmap=plt.cm.get_cmap('hsv', 13))\n",
        "  cb = plt.colorbar(ticks=[0,1,2,3,4,5,6,7,8,9,10,11,12],values=[0,1,2,3,4,5,6,7,8,9,10,11,12])\n",
        "\n",
        "  #Experiment 3\n",
        "  # plt.scatter(z_arr[:,0], z_arr[:,1], c = y_arr, edgecolor='none', alpha=0.5,\n",
        "  #             cmap=plt.cm.get_cmap('hsv', 23))\n",
        "  #cb = plt.colorbar(ticks=[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23],values=[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23])\n",
        "  \n",
        "  cb.ax.tick_params(labelsize=10)\n",
        "  plt.xticks(fontsize= 10)\n",
        "  plt.yticks(fontsize= 10)\n",
        "  plt.xlabel('z[0]', fontsize= 10)\n",
        "  plt.ylabel('z[1]', fontsize= 10)\n",
        "  plt.title(f'VAE train dataset with latent space Dim=2  Epoch number: {i+1} ', fontsize= 12)\n",
        "  # plt.show()\n",
        "  plt.close()\n",
        "  fig.savefig(f\"/content/drive/MyDrive/WEAR_LAB/Research_Pytorch/VAE_Images/VAEtrain_images{i:001}\" + \".png\")\n",
        "  print(f\"Latent Space Image {i+1} stored.\")\n",
        "\n",
        "import imageio\n",
        "gif = []\n",
        "for i in range(num_epochs):\n",
        "  each_image = imageio.imread(f\"/content/drive/MyDrive/WEAR_LAB/Research_Pytorch/VAE_Images/VAEtrain_images{i}\" + \".png\")# here read all images\n",
        "  gif.append(each_image)\n",
        "imageio.mimsave(\"/content/result.gif\",gif)\n",
        "\n",
        "from IPython.display import Image\n",
        "\n",
        "fname = '/content/result.gif'\n",
        "Image(open(fname, 'rb').read())  # local"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fKwtgkkkqljv"
      },
      "outputs": [],
      "source": [
        "# for i in range (num_epochs):\n",
        "#   z_arr = dic['latent_space'][i].cpu().numpy()\n",
        "#   y_arr = dic['y'][i].cpu().numpy()\n",
        "#   plt.figure(figsize = (10,5))\n",
        "#   plt.subplot(1,2,1)\n",
        "#   plt.scatter(z_arr[:,0], z_arr[:,1], c = y_arr)\n",
        "#   plt.colorbar()\n",
        "#   plt.tight_layout()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bERxPXvorNic"
      },
      "source": [
        "---\n",
        "VAE Experiment 1 **[]** 2/26\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R9Op8v3LrcHv"
      },
      "outputs": [],
      "source": [
        "import torch   \n",
        "import torch.nn as nn                          \n",
        "import torch.nn.functional as F                \n",
        "import torch.optim as optim   \n",
        "from torch.utils.data import TensorDataset, Dataset, DataLoader\n",
        "from torch.autograd import Variable\n",
        "import torch.utils.data\n",
        "\n",
        "import pandas as pd \n",
        "import numpy as np\n",
        "import os                             \n",
        "\n",
        "import matplotlib.cm as cm\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns    \n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import preprocessing\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import accuracy_score, roc_auc_score, f1_score, precision_score, recall_score\n",
        "from sklearn.manifold import TSNE\n",
        "from sklearn.decomposition import PCA, TruncatedSVD\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "import torchvision\n",
        "from torchvision import datasets\n",
        "\n",
        "#based on sensor data can you determine the stimulus that is currently in use?\n",
        "import optuna"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FNJdjUb6ulmv"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(\"/content/drive/MyDrive/WEAR_LAB/Research_Pytorch/Subject_Experiment_1/S2_E1_A1.csv\")\n",
        "#drops all 0 labels (no label)\n",
        "indices_to_drop = df[df[\"stimulus\"] == 0].index\n",
        "df.drop(indices_to_drop, inplace=True)\n",
        "\n",
        "#Removes number of features from data\n",
        "# df.drop('Cyber Glove (angles of the joints) Sensor 1', inplace=True, axis=1)\n",
        "# df.drop('Cyber Glove (angles of the joints) Sensor 2', inplace=True, axis=1)\n",
        "# df.drop('Cyber Glove (angles of the joints) Sensor 3', inplace=True, axis=1)\n",
        "# df.drop('Cyber Glove (angles of the joints) Sensor 4', inplace=True, axis=1)\n",
        "# df.drop('Cyber Glove (angles of the joints) Sensor 5', inplace=True, axis=1)\n",
        "# df.drop('Cyber Glove (angles of the joints) Sensor 6', inplace=True, axis=1)\n",
        "# df.drop('Cyber Glove (angles of the joints) Sensor 7', inplace=True, axis=1)\n",
        "# df.drop('Cyber Glove (angles of the joints) Sensor 8', inplace=True, axis=1)\n",
        "# df.drop('Cyber Glove (angles of the joints) Sensor 9', inplace=True, axis=1)\n",
        "# df.drop('Cyber Glove (angles of the joints) Sensor 10', inplace=True, axis=1)\n",
        "# df.drop('Cyber Glove (angles of the joints) Sensor 11', inplace=True, axis=1)\n",
        "# df.drop('Cyber Glove (angles of the joints) Sensor 12', inplace=True, axis=1)\n",
        "# df.drop('Cyber Glove (angles of the joints) Sensor 13', inplace=True, axis=1)\n",
        "# df.drop('Cyber Glove (angles of the joints) Sensor 14', inplace=True, axis=1)\n",
        "# df.drop('Cyber Glove (angles of the joints) Sensor 15', inplace=True, axis=1)\n",
        "# df.drop('Cyber Glove (angles of the joints) Sensor 16', inplace=True, axis=1)\n",
        "# df.drop('Cyber Glove (angles of the joints) Sensor 17', inplace=True, axis=1)\n",
        "# df.drop('Cyber Glove (angles of the joints) Sensor 18', inplace=True, axis=1)\n",
        "# df.drop('Cyber Glove (angles of the joints) Sensor 19', inplace=True, axis=1)\n",
        "# df.drop('Cyber Glove (angles of the joints) Sensor 20', inplace=True, axis=1)\n",
        "# df.drop('Cyber Glove (angles of the joints) Sensor 21', inplace=True, axis=1)\n",
        "# df.drop('Cyber Glove (angles of the joints) Sensor 22', inplace=True, axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XAq5Zx7euqOH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 332
        },
        "outputId": "8dccbd2b-40ed-4890-c254-9ed80676a9af"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     stimulus    Acc 1    Acc 2    Acc 3  EMG Channel 1  EMG Channel 2  \\\n",
              "862         1 -0.03418  0.84131 -0.51855              0             -1   \n",
              "863         1 -0.03418  0.84131 -0.51855              0              0   \n",
              "864         1 -0.03418  0.84131 -0.51855             -1              0   \n",
              "865         1 -0.03418  0.84131 -0.51855             -4             -5   \n",
              "866         1 -0.03418  0.84131 -0.51855              0             -2   \n",
              "\n",
              "     EMG Channel 3  EMG Channel 4  EMG Channel 5  EMG Channel 6  ...  \\\n",
              "862             -1              0              0              0  ...   \n",
              "863             -2             -2             -2              0  ...   \n",
              "864             -1             -2             -1             -2  ...   \n",
              "865             -5             -1              0             -1  ...   \n",
              "866             -1             -1             -1             -1  ...   \n",
              "\n",
              "     Cyber Glove (angles of the joints) Sensor 13  \\\n",
              "862                                         67.71   \n",
              "863                                         67.71   \n",
              "864                                         67.71   \n",
              "865                                         67.71   \n",
              "866                                         67.71   \n",
              "\n",
              "     Cyber Glove (angles of the joints) Sensor 14  \\\n",
              "862                                       -25.952   \n",
              "863                                       -25.952   \n",
              "864                                       -25.952   \n",
              "865                                       -25.952   \n",
              "866                                       -25.952   \n",
              "\n",
              "     Cyber Glove (angles of the joints) Sensor 15  \\\n",
              "862                                        2.4988   \n",
              "863                                        2.4988   \n",
              "864                                        2.4988   \n",
              "865                                        2.4988   \n",
              "866                                        2.4988   \n",
              "\n",
              "     Cyber Glove (angles of the joints) Sensor 16  \\\n",
              "862                                        49.344   \n",
              "863                                        49.344   \n",
              "864                                        49.344   \n",
              "865                                        49.344   \n",
              "866                                        49.344   \n",
              "\n",
              "     Cyber Glove (angles of the joints) Sensor 17  \\\n",
              "862                                        63.171   \n",
              "863                                        63.171   \n",
              "864                                        63.171   \n",
              "865                                        63.171   \n",
              "866                                        63.171   \n",
              "\n",
              "     Cyber Glove (angles of the joints) Sensor 18  \\\n",
              "862                                       -3.4729   \n",
              "863                                       -3.4729   \n",
              "864                                       -3.4729   \n",
              "865                                       -3.4729   \n",
              "866                                       -3.4729   \n",
              "\n",
              "     Cyber Glove (angles of the joints) Sensor 19  \\\n",
              "862                                        15.409   \n",
              "863                                        15.409   \n",
              "864                                        15.409   \n",
              "865                                        15.409   \n",
              "866                                        15.409   \n",
              "\n",
              "     Cyber Glove (angles of the joints) Sensor 20  \\\n",
              "862                                        21.185   \n",
              "863                                        21.185   \n",
              "864                                        21.185   \n",
              "865                                        21.185   \n",
              "866                                        21.185   \n",
              "\n",
              "     Cyber Glove (angles of the joints) Sensor 21  \\\n",
              "862                                       -3.1765   \n",
              "863                                       -3.1765   \n",
              "864                                       -3.1765   \n",
              "865                                       -3.1765   \n",
              "866                                       -3.1765   \n",
              "\n",
              "     Cyber Glove (angles of the joints) Sensor 22  \n",
              "862                                        13.553  \n",
              "863                                        13.553  \n",
              "864                                        13.553  \n",
              "865                                        13.553  \n",
              "866                                        13.553  \n",
              "\n",
              "[5 rows x 42 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f6fb32bd-8798-4081-8960-4bd3a19d5e48\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>stimulus</th>\n",
              "      <th>Acc 1</th>\n",
              "      <th>Acc 2</th>\n",
              "      <th>Acc 3</th>\n",
              "      <th>EMG Channel 1</th>\n",
              "      <th>EMG Channel 2</th>\n",
              "      <th>EMG Channel 3</th>\n",
              "      <th>EMG Channel 4</th>\n",
              "      <th>EMG Channel 5</th>\n",
              "      <th>EMG Channel 6</th>\n",
              "      <th>...</th>\n",
              "      <th>Cyber Glove (angles of the joints) Sensor 13</th>\n",
              "      <th>Cyber Glove (angles of the joints) Sensor 14</th>\n",
              "      <th>Cyber Glove (angles of the joints) Sensor 15</th>\n",
              "      <th>Cyber Glove (angles of the joints) Sensor 16</th>\n",
              "      <th>Cyber Glove (angles of the joints) Sensor 17</th>\n",
              "      <th>Cyber Glove (angles of the joints) Sensor 18</th>\n",
              "      <th>Cyber Glove (angles of the joints) Sensor 19</th>\n",
              "      <th>Cyber Glove (angles of the joints) Sensor 20</th>\n",
              "      <th>Cyber Glove (angles of the joints) Sensor 21</th>\n",
              "      <th>Cyber Glove (angles of the joints) Sensor 22</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>862</th>\n",
              "      <td>1</td>\n",
              "      <td>-0.03418</td>\n",
              "      <td>0.84131</td>\n",
              "      <td>-0.51855</td>\n",
              "      <td>0</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>67.71</td>\n",
              "      <td>-25.952</td>\n",
              "      <td>2.4988</td>\n",
              "      <td>49.344</td>\n",
              "      <td>63.171</td>\n",
              "      <td>-3.4729</td>\n",
              "      <td>15.409</td>\n",
              "      <td>21.185</td>\n",
              "      <td>-3.1765</td>\n",
              "      <td>13.553</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>863</th>\n",
              "      <td>1</td>\n",
              "      <td>-0.03418</td>\n",
              "      <td>0.84131</td>\n",
              "      <td>-0.51855</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>-2</td>\n",
              "      <td>-2</td>\n",
              "      <td>-2</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>67.71</td>\n",
              "      <td>-25.952</td>\n",
              "      <td>2.4988</td>\n",
              "      <td>49.344</td>\n",
              "      <td>63.171</td>\n",
              "      <td>-3.4729</td>\n",
              "      <td>15.409</td>\n",
              "      <td>21.185</td>\n",
              "      <td>-3.1765</td>\n",
              "      <td>13.553</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>864</th>\n",
              "      <td>1</td>\n",
              "      <td>-0.03418</td>\n",
              "      <td>0.84131</td>\n",
              "      <td>-0.51855</td>\n",
              "      <td>-1</td>\n",
              "      <td>0</td>\n",
              "      <td>-1</td>\n",
              "      <td>-2</td>\n",
              "      <td>-1</td>\n",
              "      <td>-2</td>\n",
              "      <td>...</td>\n",
              "      <td>67.71</td>\n",
              "      <td>-25.952</td>\n",
              "      <td>2.4988</td>\n",
              "      <td>49.344</td>\n",
              "      <td>63.171</td>\n",
              "      <td>-3.4729</td>\n",
              "      <td>15.409</td>\n",
              "      <td>21.185</td>\n",
              "      <td>-3.1765</td>\n",
              "      <td>13.553</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>865</th>\n",
              "      <td>1</td>\n",
              "      <td>-0.03418</td>\n",
              "      <td>0.84131</td>\n",
              "      <td>-0.51855</td>\n",
              "      <td>-4</td>\n",
              "      <td>-5</td>\n",
              "      <td>-5</td>\n",
              "      <td>-1</td>\n",
              "      <td>0</td>\n",
              "      <td>-1</td>\n",
              "      <td>...</td>\n",
              "      <td>67.71</td>\n",
              "      <td>-25.952</td>\n",
              "      <td>2.4988</td>\n",
              "      <td>49.344</td>\n",
              "      <td>63.171</td>\n",
              "      <td>-3.4729</td>\n",
              "      <td>15.409</td>\n",
              "      <td>21.185</td>\n",
              "      <td>-3.1765</td>\n",
              "      <td>13.553</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>866</th>\n",
              "      <td>1</td>\n",
              "      <td>-0.03418</td>\n",
              "      <td>0.84131</td>\n",
              "      <td>-0.51855</td>\n",
              "      <td>0</td>\n",
              "      <td>-2</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>...</td>\n",
              "      <td>67.71</td>\n",
              "      <td>-25.952</td>\n",
              "      <td>2.4988</td>\n",
              "      <td>49.344</td>\n",
              "      <td>63.171</td>\n",
              "      <td>-3.4729</td>\n",
              "      <td>15.409</td>\n",
              "      <td>21.185</td>\n",
              "      <td>-3.1765</td>\n",
              "      <td>13.553</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows  42 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f6fb32bd-8798-4081-8960-4bd3a19d5e48')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-f6fb32bd-8798-4081-8960-4bd3a19d5e48 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-f6fb32bd-8798-4081-8960-4bd3a19d5e48');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uBKcgR245EOX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0504d551-eea6-4019-fa07-5658c06b749e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(90015, 41) <class 'pandas.core.frame.DataFrame'> (90015, 1) <class 'pandas.core.frame.DataFrame'>\n",
            "\n"
          ]
        }
      ],
      "source": [
        "X = df.drop('stimulus', axis=1)\n",
        "#y = df['stimulus']\n",
        "y = df.iloc[:, 0:1]\n",
        "print(X.shape, type(X), y.shape, type(y))\n",
        "print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XlcbdijIOabG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 332
        },
        "outputId": "9ee64ce3-6927-47b4-e5ce-45e827e0ea79"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       Acc 1    Acc 2    Acc 3  EMG Channel 1  EMG Channel 2  EMG Channel 3  \\\n",
              "862 -0.03418  0.84131 -0.51855              0             -1             -1   \n",
              "863 -0.03418  0.84131 -0.51855              0              0             -2   \n",
              "864 -0.03418  0.84131 -0.51855             -1              0             -1   \n",
              "865 -0.03418  0.84131 -0.51855             -4             -5             -5   \n",
              "866 -0.03418  0.84131 -0.51855              0             -2             -1   \n",
              "\n",
              "     EMG Channel 4  EMG Channel 5  EMG Channel 6  EMG Channel 7  ...  \\\n",
              "862              0              0              0             -1  ...   \n",
              "863             -2             -2              0              1  ...   \n",
              "864             -2             -1             -2              0  ...   \n",
              "865             -1              0             -1             -1  ...   \n",
              "866             -1             -1             -1             -2  ...   \n",
              "\n",
              "     Cyber Glove (angles of the joints) Sensor 13  \\\n",
              "862                                         67.71   \n",
              "863                                         67.71   \n",
              "864                                         67.71   \n",
              "865                                         67.71   \n",
              "866                                         67.71   \n",
              "\n",
              "     Cyber Glove (angles of the joints) Sensor 14  \\\n",
              "862                                       -25.952   \n",
              "863                                       -25.952   \n",
              "864                                       -25.952   \n",
              "865                                       -25.952   \n",
              "866                                       -25.952   \n",
              "\n",
              "     Cyber Glove (angles of the joints) Sensor 15  \\\n",
              "862                                        2.4988   \n",
              "863                                        2.4988   \n",
              "864                                        2.4988   \n",
              "865                                        2.4988   \n",
              "866                                        2.4988   \n",
              "\n",
              "     Cyber Glove (angles of the joints) Sensor 16  \\\n",
              "862                                        49.344   \n",
              "863                                        49.344   \n",
              "864                                        49.344   \n",
              "865                                        49.344   \n",
              "866                                        49.344   \n",
              "\n",
              "     Cyber Glove (angles of the joints) Sensor 17  \\\n",
              "862                                        63.171   \n",
              "863                                        63.171   \n",
              "864                                        63.171   \n",
              "865                                        63.171   \n",
              "866                                        63.171   \n",
              "\n",
              "     Cyber Glove (angles of the joints) Sensor 18  \\\n",
              "862                                       -3.4729   \n",
              "863                                       -3.4729   \n",
              "864                                       -3.4729   \n",
              "865                                       -3.4729   \n",
              "866                                       -3.4729   \n",
              "\n",
              "     Cyber Glove (angles of the joints) Sensor 19  \\\n",
              "862                                        15.409   \n",
              "863                                        15.409   \n",
              "864                                        15.409   \n",
              "865                                        15.409   \n",
              "866                                        15.409   \n",
              "\n",
              "     Cyber Glove (angles of the joints) Sensor 20  \\\n",
              "862                                        21.185   \n",
              "863                                        21.185   \n",
              "864                                        21.185   \n",
              "865                                        21.185   \n",
              "866                                        21.185   \n",
              "\n",
              "     Cyber Glove (angles of the joints) Sensor 21  \\\n",
              "862                                       -3.1765   \n",
              "863                                       -3.1765   \n",
              "864                                       -3.1765   \n",
              "865                                       -3.1765   \n",
              "866                                       -3.1765   \n",
              "\n",
              "     Cyber Glove (angles of the joints) Sensor 22  \n",
              "862                                        13.553  \n",
              "863                                        13.553  \n",
              "864                                        13.553  \n",
              "865                                        13.553  \n",
              "866                                        13.553  \n",
              "\n",
              "[5 rows x 41 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-2571a410-84ad-4545-85c8-1afaa39990b0\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Acc 1</th>\n",
              "      <th>Acc 2</th>\n",
              "      <th>Acc 3</th>\n",
              "      <th>EMG Channel 1</th>\n",
              "      <th>EMG Channel 2</th>\n",
              "      <th>EMG Channel 3</th>\n",
              "      <th>EMG Channel 4</th>\n",
              "      <th>EMG Channel 5</th>\n",
              "      <th>EMG Channel 6</th>\n",
              "      <th>EMG Channel 7</th>\n",
              "      <th>...</th>\n",
              "      <th>Cyber Glove (angles of the joints) Sensor 13</th>\n",
              "      <th>Cyber Glove (angles of the joints) Sensor 14</th>\n",
              "      <th>Cyber Glove (angles of the joints) Sensor 15</th>\n",
              "      <th>Cyber Glove (angles of the joints) Sensor 16</th>\n",
              "      <th>Cyber Glove (angles of the joints) Sensor 17</th>\n",
              "      <th>Cyber Glove (angles of the joints) Sensor 18</th>\n",
              "      <th>Cyber Glove (angles of the joints) Sensor 19</th>\n",
              "      <th>Cyber Glove (angles of the joints) Sensor 20</th>\n",
              "      <th>Cyber Glove (angles of the joints) Sensor 21</th>\n",
              "      <th>Cyber Glove (angles of the joints) Sensor 22</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>862</th>\n",
              "      <td>-0.03418</td>\n",
              "      <td>0.84131</td>\n",
              "      <td>-0.51855</td>\n",
              "      <td>0</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>-1</td>\n",
              "      <td>...</td>\n",
              "      <td>67.71</td>\n",
              "      <td>-25.952</td>\n",
              "      <td>2.4988</td>\n",
              "      <td>49.344</td>\n",
              "      <td>63.171</td>\n",
              "      <td>-3.4729</td>\n",
              "      <td>15.409</td>\n",
              "      <td>21.185</td>\n",
              "      <td>-3.1765</td>\n",
              "      <td>13.553</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>863</th>\n",
              "      <td>-0.03418</td>\n",
              "      <td>0.84131</td>\n",
              "      <td>-0.51855</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>-2</td>\n",
              "      <td>-2</td>\n",
              "      <td>-2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>67.71</td>\n",
              "      <td>-25.952</td>\n",
              "      <td>2.4988</td>\n",
              "      <td>49.344</td>\n",
              "      <td>63.171</td>\n",
              "      <td>-3.4729</td>\n",
              "      <td>15.409</td>\n",
              "      <td>21.185</td>\n",
              "      <td>-3.1765</td>\n",
              "      <td>13.553</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>864</th>\n",
              "      <td>-0.03418</td>\n",
              "      <td>0.84131</td>\n",
              "      <td>-0.51855</td>\n",
              "      <td>-1</td>\n",
              "      <td>0</td>\n",
              "      <td>-1</td>\n",
              "      <td>-2</td>\n",
              "      <td>-1</td>\n",
              "      <td>-2</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>67.71</td>\n",
              "      <td>-25.952</td>\n",
              "      <td>2.4988</td>\n",
              "      <td>49.344</td>\n",
              "      <td>63.171</td>\n",
              "      <td>-3.4729</td>\n",
              "      <td>15.409</td>\n",
              "      <td>21.185</td>\n",
              "      <td>-3.1765</td>\n",
              "      <td>13.553</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>865</th>\n",
              "      <td>-0.03418</td>\n",
              "      <td>0.84131</td>\n",
              "      <td>-0.51855</td>\n",
              "      <td>-4</td>\n",
              "      <td>-5</td>\n",
              "      <td>-5</td>\n",
              "      <td>-1</td>\n",
              "      <td>0</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>...</td>\n",
              "      <td>67.71</td>\n",
              "      <td>-25.952</td>\n",
              "      <td>2.4988</td>\n",
              "      <td>49.344</td>\n",
              "      <td>63.171</td>\n",
              "      <td>-3.4729</td>\n",
              "      <td>15.409</td>\n",
              "      <td>21.185</td>\n",
              "      <td>-3.1765</td>\n",
              "      <td>13.553</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>866</th>\n",
              "      <td>-0.03418</td>\n",
              "      <td>0.84131</td>\n",
              "      <td>-0.51855</td>\n",
              "      <td>0</td>\n",
              "      <td>-2</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-2</td>\n",
              "      <td>...</td>\n",
              "      <td>67.71</td>\n",
              "      <td>-25.952</td>\n",
              "      <td>2.4988</td>\n",
              "      <td>49.344</td>\n",
              "      <td>63.171</td>\n",
              "      <td>-3.4729</td>\n",
              "      <td>15.409</td>\n",
              "      <td>21.185</td>\n",
              "      <td>-3.1765</td>\n",
              "      <td>13.553</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows  41 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2571a410-84ad-4545-85c8-1afaa39990b0')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-2571a410-84ad-4545-85c8-1afaa39990b0 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-2571a410-84ad-4545-85c8-1afaa39990b0');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ],
      "source": [
        "X.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3WHYTiyNxjbB"
      },
      "source": [
        "---\n",
        "Visualization number of labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GrBPneNpxio1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 522
        },
        "outputId": "1c725a3f-1c29-4c24-8154-2163093204ff"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "stimulus\n",
              "10          7931\n",
              "6           7619\n",
              "8           7580\n",
              "7           7567\n",
              "5           7564\n",
              "11          7539\n",
              "4           7473\n",
              "3           7424\n",
              "9           7397\n",
              "12          7357\n",
              "2           7329\n",
              "1           7235\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 30
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "sns.countplot(x = 'stimulus', data=df)\n",
        "y.value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ac9B5iPx9HWR"
      },
      "source": [
        "---\n",
        "Fixing Data Imbalance via Undersampling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F8Pf2yx55xks",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 364
        },
        "outputId": "4f53e33f-90cc-4ea4-88f6-f59b1f4b4a18"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<AxesSubplot:xlabel='stimulus'>"
            ]
          },
          "metadata": {},
          "execution_count": 31
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 576x360 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "\n",
        "sampling_strategy = \"not minority\"\n",
        "rus = RandomUnderSampler(sampling_strategy=sampling_strategy)\n",
        "X_res, y_res = rus.fit_resample(X, y)\n",
        "y_res.value_counts().plot(kind='bar', figsize=(8,5))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yYCz3Q5H9gN9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "02df71a9-c4bb-4440-92dc-f131deccebcf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "stimulus\n",
            "1           7235\n",
            "2           7235\n",
            "3           7235\n",
            "4           7235\n",
            "5           7235\n",
            "6           7235\n",
            "7           7235\n",
            "8           7235\n",
            "9           7235\n",
            "10          7235\n",
            "11          7235\n",
            "12          7235\n",
            "dtype: int64\n",
            "86820\n"
          ]
        }
      ],
      "source": [
        "print(y_res.value_counts())\n",
        "print(len(X_res.value_counts()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hpNYb9reRugs",
        "outputId": "c2ddf98c-e651-4b0f-eb92-19b189f83f58",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "        stimulus\n",
            "862            1\n",
            "863            1\n",
            "864            1\n",
            "865            1\n",
            "866            1\n",
            "...          ...\n",
            "148362        12\n",
            "148363        12\n",
            "148364        12\n",
            "148365        12\n",
            "148366        12\n",
            "\n",
            "[90015 rows x 1 columns]\n"
          ]
        }
      ],
      "source": [
        "print(y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hPN8DmEJxrse"
      },
      "source": [
        "---\n",
        "Visualization of Data Distributions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y5a9acbLxwRe"
      },
      "outputs": [],
      "source": [
        "# #distribution of first 19 features\n",
        "\n",
        "\n",
        "# fig, axs = plt.subplots(nrows=5, ncols=4, figsize=(40, 40))\n",
        "# axs = axs.flatten()\n",
        "# index = 0\n",
        "# for k, v in df.items():\n",
        "#   print(f\"[{index +1}] Updating plot\")\n",
        "#   sns.distplot(v, ax=axs[index])\n",
        "#   index += 1\n",
        "#   if index == 20:\n",
        "#     break \n",
        "# plt.tight_layout()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j-Q8ps35WPO3"
      },
      "source": [
        "---\n",
        "Defining Hyperparmaeters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MZoF6guXlSot"
      },
      "outputs": [],
      "source": [
        "#############################################################################################################################################################################################################\n",
        "#############################################################################################################################################################################################################\n",
        "#############################################################################################################################################################################################################\n",
        "#############################################################################################################################################################################################################\n",
        "\n",
        "#Hyperparameters\n",
        "emg_channels = 16\n",
        "imu_channels = 3\n",
        "\n",
        "latent_dim = 2\n",
        "input_dim= len(X.columns)\n",
        "\n",
        "hidden_dim= round(input_dim/2)\n",
        "hidden_dim_2 = round(input_dim/4)\n",
        "output_dim = len(X.columns)\n",
        "num_classes = 12\n",
        "num_layers = round(num_classes/2)\n",
        "tempature = 1\n",
        "\n",
        "num_epochs= 10\n",
        "batch_size= 100\n",
        "learning_rate= 0.001 #3e-4 #Karpathy constant\n",
        "l2_lambda = 0\n",
        "\n",
        "\n",
        "alpha = 2        # Reconstruction Loss\n",
        "beta = 2         # Kl Divergence Loss\n",
        "gamma = 3        # Classifcation Loss\n",
        "delta = 5        # Contrastive Loss\n",
        "epsilon = 3      # Triplet Loss\n",
        "\n",
        "#############################################################################################################################################################################################################\n",
        "#############################################################################################################################################################################################################\n",
        "#############################################################################################################################################################################################################\n",
        "#############################################################################################################################################################################################################"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D3t0Wyvt9zUN"
      },
      "source": [
        "---\n",
        "Train Test Split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XmDYv1vB9Wyh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a1e634ad-c220-4887-b853-7eed94c32c2c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(86820, 41) <class 'numpy.ndarray'> (86820, 1) <class 'numpy.ndarray'>\n",
            "\n",
            "X_train size: 52092 | X_val size: 17364 | X_test size: 17364\n",
            "y_train size: 52092 | y_val size: 17364 | y_test size: 17364\n",
            "\n",
            "Training Feature Split: (52092, 41) | Training Labels (52092, 1)\n",
            "Validation Feature Split: (17364, 41) | Validation Labels (17364, 1)\n",
            "Testing Feature Split: (17364, 41) | Testing Labels (17364, 1)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "X = X_res.values\n",
        "y = y_res.values\n",
        "print(X.shape, type(X), y.shape, type(y))\n",
        "print()\n",
        "\n",
        "# Data Split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.25, random_state=42) # 0.25 x 0.8 = 0.2\n",
        "\n",
        "print(f\"X_train size: {len(X_train)} | X_val size: {len(X_val)} | X_test size: {len(X_test)}\")\n",
        "print(f\"y_train size: {len(y_train)} | y_val size: {len(y_val)} | y_test size: {len(y_test)}\")\n",
        "print()\n",
        "print(f\"Training Feature Split: {X_train.shape} | Training Labels { y_train.shape}\")\n",
        "print(f\"Validation Feature Split: {X_val.shape} | Validation Labels { y_val.shape}\")\n",
        "print(f\"Testing Feature Split: {X_test.shape} | Testing Labels { y_test.shape}\")\n",
        "print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4cC0dknyWXmN"
      },
      "source": [
        "---\n",
        "Scaling/Normalizing Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f1X-8DFZMt_M",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5daf66b7-a678-4a67-b2b8-164eccf49b51"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train: <class 'torch.Tensor'> | y_train <class 'torch.Tensor'>\n",
            "X_val: <class 'torch.Tensor'> | y_train <class 'torch.Tensor'>\n",
            "X_test: <class 'torch.Tensor'> | y_test <class 'torch.Tensor'>\n",
            "\n",
            "Training: torch.Size([52092, 41]) , torch.Size([52092, 1])\n",
            "Validation: torch.Size([17364, 41]) , torch.Size([17364, 1])\n",
            "Testing:  torch.Size([17364, 41]) , torch.Size([17364, 1])\n"
          ]
        }
      ],
      "source": [
        "#Normalization Data \n",
        "\n",
        "#No Normalization \n",
        "# X_train_Normalized = X_train\n",
        "# X_val_Normalized = X_val\n",
        "# X_test_Normalized = X_test\n",
        "#----------------------------------------------------------------------------------------------------------\n",
        "# Minmax without preprocessing\n",
        "# Minmax = preprocessing.MinMaxScaler()\n",
        "# X_train_Normalized= Minmax.fit_transform(X_train)\n",
        "# X_val_Normalized = Minmax.transform(X_val)\n",
        "# X_test_Normalized = Minmax.transform(X_test)\n",
        "#----------------------------------------------------------------------------------------------------------\n",
        "# Minmax with preprocessing\n",
        "# Minmax = preprocessing.MinMaxScaler()\n",
        "# X_train_Normalized= Minmax.fit_transform(X_train_preprocessed)\n",
        "# X_val_Normalized = Minmax.transform(X_val_preprocessed)\n",
        "# X_test_Normalized = Minmax.transform(X_test_preprocessed)\n",
        "\n",
        "#----------------------------------------------------------------------------------------------------------\n",
        "# # Standardization without preprocessing\n",
        "Standardized = preprocessing.StandardScaler()\n",
        "X_train_Normalized= Standardized.fit_transform(X_train)\n",
        "X_val_Normalized = Standardized.transform(X_val)\n",
        "X_test_Normalized = Standardized.transform(X_test)\n",
        "\n",
        "# Standardization with preprocessing\n",
        "# Standardized = preprocessing.StandardScaler()\n",
        "# X_train_Normalized= Standardized.fit_transform(X_train_preprocessed)\n",
        "# X_val_Normalized = Standardized.transform(X_val_preprocessed)\n",
        "# X_test_Normalized = Standardized.transform(X_test_preprocessed)\n",
        "#----------------------------------------------------------------------------------------------------------\n",
        "\n",
        "#Convert to numpy then to torch \n",
        "\n",
        "X_train = torch.from_numpy(X_train_Normalized).float()\n",
        "y_train = torch.from_numpy(y_train).long()\n",
        "\n",
        "X_val = torch.from_numpy(X_val_Normalized).float()\n",
        "y_val = torch.from_numpy(y_val).long()\n",
        "\n",
        "X_test = torch.from_numpy(X_test_Normalized).float()\n",
        "y_test = torch.from_numpy(y_test).long()\n",
        "\n",
        "print(f\"X_train: {type(X_train)} | y_train {type(y_train)}\")\n",
        "print(f\"X_val: {type(X_val)} | y_train {type(y_val)}\")\n",
        "print(f\"X_test: {type(X_test)} | y_test {type(y_test)}\")\n",
        "print()\n",
        "print(f\"Training: {X_train.shape} , { y_train.shape}\")\n",
        "print(f\"Validation: {X_val.shape} , { y_val.shape}\")\n",
        "print(f\"Testing:  {X_test.shape} , { y_test.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C3UmdyVaWc2f"
      },
      "source": [
        "---\n",
        "Defining Dataloaders\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pnr0p08ESkXE"
      },
      "outputs": [],
      "source": [
        "class ClassifierDataset(Dataset):\n",
        "    def __init__(self, X_data, y_data):\n",
        "        self.X_data = X_data\n",
        "        self.y_data = y_data\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        return self.X_data[index], self.y_data[index]\n",
        "\n",
        "    def __len__ (self):\n",
        "        return len(self.X_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "45Ta3rYVknAi"
      },
      "outputs": [],
      "source": [
        "training = ClassifierDataset(X_train, y_train)\n",
        "validating = ClassifierDataset(X_val, y_val)\n",
        "testing = ClassifierDataset(X_test, y_test)\n",
        "\n",
        "\n",
        "train_loader = DataLoader(training, batch_size=batch_size, shuffle=True)\n",
        "val_loader = DataLoader(validating, batch_size=batch_size, shuffle=False)\n",
        "test_loader = DataLoader(testing, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "def get_data_loader(optuna_batch_size):\n",
        "  train_loader = DataLoader(training, batch_size=optuna_batch_size, shuffle=True)\n",
        "  val_loader = DataLoader(validating, batch_size=optuna_batch_size, shuffle=False)\n",
        "  test_loader = DataLoader(testing, batch_size=optuna_batch_size, shuffle=False)\n",
        "  return train_loader, val_loader, test_loader"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dTrRsJbCWmG-"
      },
      "source": [
        "---\n",
        "Defining VAE Model, Loss and Optmizers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sgYYoP4DSnAB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6a8aa465-0466-45a1-eb8d-dde528b089aa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reconstruction X: torch.Size([100, 41])\n",
            "Mu: torch.Size([100, 2]) \n",
            "Logvar: torch.Size([100, 2])\n",
            "Latent Space Z: torch.Size([100, 2])\n",
            "Classifier: torch.Size([100, 13])\n"
          ]
        }
      ],
      "source": [
        "class VAE(nn.Module):  \n",
        "  def __init__(self, input_dim, hidden_dim, latent_dim):\n",
        "    super(VAE,self).__init__()  \n",
        "    self.encoder = nn.Sequential(\n",
        "        nn.Linear(input_dim, hidden_dim),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(hidden_dim, hidden_dim),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(hidden_dim, hidden_dim),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(hidden_dim, hidden_dim_2),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(hidden_dim_2, hidden_dim_2),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(hidden_dim_2, hidden_dim_2),\n",
        "    )\n",
        "    self.mu = nn.Linear(hidden_dim_2, latent_dim)   # mu\n",
        "    self.logvar = nn.Linear(hidden_dim_2, latent_dim)   # log-var\n",
        "    self.decoder = nn.Sequential(\n",
        "        nn.Linear(latent_dim, hidden_dim_2),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(hidden_dim_2, hidden_dim_2),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(hidden_dim_2, hidden_dim_2),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(hidden_dim_2, hidden_dim),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(hidden_dim, hidden_dim),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(hidden_dim, hidden_dim),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(hidden_dim, input_dim),\n",
        "    )\n",
        "    self.classifier = nn.Sequential(\n",
        "        nn.Linear(latent_dim, num_layers),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(num_layers, 13),\n",
        "        nn.Softmax(dim=1)\n",
        "    )\n",
        "\n",
        "  def encode(self, x):  \n",
        "    z = self.encoder(x)\n",
        "    z1 = self.mu(z)               \n",
        "    z2 = self.logvar(z) \n",
        "    return z1, z2                 # (mu, log-var)\n",
        "\n",
        "  def decode(self, x):\n",
        "\n",
        "    return self.decoder(x)\n",
        "\n",
        "  def forward(self, x):\n",
        "#  Reparamaterize\n",
        "    mu, logvar = self.encode(x)\n",
        "    stdev = torch.exp(0.5 * logvar)\n",
        "    esp = torch.randn_like(stdev)\n",
        "    z_reparmeterized = mu + (esp * stdev)   \n",
        "\n",
        "    x_reconstructed = self.decode(z_reparmeterized)\n",
        "    classified = self.classifier(z_reparmeterized)\n",
        "    classified = classified / tempature\n",
        "\n",
        "    return (x_reconstructed, z_reparmeterized, classified, mu, logvar)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "  x = torch.rand(batch_size,input_dim)\n",
        "  vae = VAE(input_dim, hidden_dim, latent_dim)\n",
        "  x_reconstructed, z_reparmeterized, classified, mu, logvar = vae(x)\n",
        "  print(f\"Reconstruction X: {x_reconstructed.shape}\")\n",
        "\n",
        "  print(f\"Mu: {mu.shape} \")\n",
        "  \n",
        "  print(f\"Logvar: {logvar.shape}\")\n",
        " \n",
        "  print(f\"Latent Space Z: {z_reparmeterized.shape}\")\n",
        " \n",
        "  print(f\"Classifier: {classified.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class ContrastiveLoss(nn.Module):\n",
        "  def __init__(self, margin=1.0):\n",
        "    super(ContrastiveLoss, self).__init__()\n",
        "    self.margin = margin\n",
        "        \n",
        "  def forward(self, z_reparmeterized, labels):\n",
        "    # Compute the pairwise euclidean distances between the examples in the latent space\n",
        "    distances = torch.pow(z_reparmeterized, 2).sum(dim=1, keepdim=True) + torch.pow(z_reparmeterized, 2).sum(dim=1, keepdim=True).t() - 2 * torch.matmul(z_reparmeterized, z_reparmeterized.t())\n",
        "    # Create a mask for the positive pairs (i.e. examples with the same label)\n",
        "    positive_mask = labels.expand(z_reparmeterized.size(0), z_reparmeterized.size(0)).eq(labels.expand(z_reparmeterized.size(0), z_reparmeterized.size(0)).t())\n",
        "    # Create a mask for the negative pairs (i.e. examples with different labels)\n",
        "    negative_mask = labels.expand(z_reparmeterized.size(0), z_reparmeterized.size(0)).ne(labels.expand(z_reparmeterized.size(0), z_reparmeterized.size(0)).t())\n",
        "    # Set the distances for the positive pairs to a large value\n",
        "    distances.masked_fill_(positive_mask, 1e7)\n",
        "    # Compute the contrastive loss as the sum of the max(0, margin - distance) for the negative pairs\n",
        "    contrastive_loss = torch.sum(torch.max(torch.zeros_like(distances), self.margin - distances))\n",
        "    return contrastive_loss"
      ],
      "metadata": {
        "id": "fusjHJ7PMDSS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_VAE(model, train_loader, val_loader, optimizer, epoch,alpha,beta,gamma, delta):\n",
        "  train_losses=[]\n",
        "  train_accuracy = []\n",
        "  accuracy_log = []\n",
        "  val_losses=[]\n",
        "  val_accuracy=[]\n",
        "\n",
        "  recon_loss_fn = nn.MSELoss(reduction=\"sum\")\n",
        "  classifier_loss_fn = nn.CrossEntropyLoss()\n",
        "  contrastive_loss_fn = ContrastiveLoss(margin=1)\n",
        "\n",
        "  train_running_loss = 0\n",
        "  model.train()\n",
        "  for i, data in enumerate(train_loader):\n",
        "    inputs, labels = data\n",
        "    # print(f\"Input shape: {inputs.shape}\")\n",
        "    # print(f\"Labels shape: {labels.shape}\")\n",
        "    optimizer.zero_grad()\n",
        "    \n",
        "    x_reconstructed, z_reparmeterized, classified, mu, logvar = model(inputs)\n",
        "\n",
        "    # Compute the reconstruction loss and KL divergence loss #################################################\n",
        "\n",
        "    reconstruction_loss = recon_loss_fn(x_reconstructed, inputs)\n",
        "    kld_loss = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
        "\n",
        "    contrastive_loss = contrastive_loss_fn(mu, labels)\n",
        "\n",
        "    # Compute the classificaiton loss #########################################################################\n",
        "    classified = classified.view(-1, 13)\n",
        "    classification_loss = classifier_loss_fn(classified, labels.flatten())\n",
        "\n",
        "  \n",
        "    loss = (alpha*reconstruction_loss + kld_loss*beta) + gamma*classification_loss + (delta*contrastive_loss)\n",
        "\n",
        "    accuracy = accuracy_score(labels, classified.argmax(dim=1))\n",
        "    train_accuracy.append(accuracy)\n",
        "    train_acc = sum(train_accuracy)/len(train_accuracy)\n",
        "    accuracy_log.append(train_acc)\n",
        "\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    train_running_loss += loss.item()\n",
        "    train_loss= train_running_loss/len(train_loader)\n",
        "\n",
        "  with torch.inference_mode():\n",
        "    val_running_loss = 0\n",
        "    val_running_acc = 0\n",
        "\n",
        "    model.eval()\n",
        "    # Iterate over the validation data\n",
        "    for X, Y in val_loader:\n",
        "      # Pass the data through the model and get the reconstructed data and the latent representation\n",
        "      y_pred, z_reparmeterized, v_classified, mu, logvar = model(X)\n",
        "\n",
        "      # Compute the reconstruction loss\n",
        "      v_reconstruction_loss = recon_loss_fn(y_pred, X)\n",
        "\n",
        "      # Compute the KL divergence loss\n",
        "      v_kld_loss = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
        "\n",
        "      v_contrastive_loss_value = contrastive_loss_fn(mu, Y)\n",
        "\n",
        "      # Reshape the classified output to have the same shape as the labels\n",
        "      v_classified = v_classified.view(-1, 13)\n",
        "      # Compute the classification loss\n",
        "      v_classification_loss = classifier_loss_fn(v_classified, Y.flatten())\n",
        "\n",
        "      # Compute the total loss\n",
        "      vloss = (alpha*v_reconstruction_loss + v_kld_loss*beta) + gamma*v_classification_loss + delta*v_contrastive_loss_value\n",
        "      val_running_loss += vloss.item()\n",
        "      val_loss = val_running_loss/len(val_loader)\n",
        "\n",
        "      v_accuracy = accuracy_score(Y, v_classified.argmax(dim=1))\n",
        "      val_accuracy.append(v_accuracy)\n",
        "      val_acc = sum(val_accuracy)/len(val_accuracy)\n",
        "\n",
        "  print(f\"Epoch: {epoch+1} / {num_epochs} | Reconst_loss: {reconstruction_loss:.3f} | Kldiv loss: {kld_loss:.3f} | Classifcation loss: {classification_loss:.3f} | Constrast loss: {contrastive_loss:.2f} | Total loss: {train_loss:.3f} | Train acc: {train_acc*100:.3f} % ||| Val Loss: {val_loss:.3f} | Val acc: {val_acc*100:.3f} %\")\n",
        "  print(\"-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\")\n",
        "  train_losses.append(train_loss)\n",
        "  val_losses.append(val_loss)\n",
        "\n",
        "  return train_losses, val_losses, train_acc, val_acc\n",
        "\n"
      ],
      "metadata": {
        "id": "k1-AmtAYjZpS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def objective(trial):\n",
        "  params = {\n",
        "          'optuna_batch_size' : trial.suggest_int('optuna_batch_size', 1e1, 1e3),\n",
        "          'num_epochs' : num_epochs,\n",
        "          'optimizer': trial.suggest_categorical(\"optimizer\", [\"Adam\", \"RMSprop\"]),\n",
        "          \"lr\": trial.suggest_float('lr', 1e-4, 1e-2),\n",
        "          'alpha': trial.suggest_float('alpha', 1e-1, 1e1),\n",
        "          'beta': trial.suggest_float('beta', 1e-1, 1e1), \n",
        "          'gamma': trial.suggest_float('gamma', 1e-1, 1e1), \n",
        "          'delta': trial.suggest_float('delta', 1e-1, 1e1),        \n",
        "  }\n",
        "\n",
        "  train_loader, val_loader, test_loader = get_data_loader(params['optuna_batch_size'])\n",
        "  model  = VAE(input_dim, hidden_dim, latent_dim).to(device)\n",
        "  optimizer = getattr(optim, params['optimizer'])(model.parameters(), lr=params['lr'])\n",
        "\n",
        "  for epoch in range(params['num_epochs']):\n",
        "    train_losses, val_losses, train_acc, val_acc = train_VAE(model, train_loader, val_loader, optimizer, epoch, alpha, beta, gamma, delta)\n",
        "  return train_acc\n"
      ],
      "metadata": {
        "id": "p-3XPHXlpsve"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sampler = optuna.samplers.TPESampler()    \n",
        "study = optuna.create_study(\n",
        "    sampler=sampler,\n",
        "    pruner=optuna.pruners.MedianPruner(\n",
        "        n_startup_trials=3, n_warmup_steps=5, interval_steps=3\n",
        "    ),\n",
        "    direction='maximize')\n",
        "study.optimize(func=objective, n_trials=100)"
      ],
      "metadata": {
        "id": "23icBK73s9bH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7117f8ac-95b9-47a7-a0bf-273772265614"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2023-02-27 04:55:43,192]\u001b[0m A new study created in memory with name: no-name-e9316b28-db1a-4c9a-b673-bbb717e8cb14\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1 / 10 | Reconst_loss: 3346.966 | Kldiv loss: 943.055 | Classifcation loss: 2.294 | Constrast loss: 54.79 | Total loss: 207895.909 | Train acc: 25.821 % ||| Val Loss: 85180.185 | Val acc: 36.129 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 2 / 10 | Reconst_loss: 2528.846 | Kldiv loss: 900.897 | Classifcation loss: 2.352 | Constrast loss: 19.47 | Total loss: 81743.639 | Train acc: 39.079 % ||| Val Loss: 74129.552 | Val acc: 43.167 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 3 / 10 | Reconst_loss: 2553.695 | Kldiv loss: 823.871 | Classifcation loss: 2.239 | Constrast loss: 23.54 | Total loss: 73460.284 | Train acc: 44.787 % ||| Val Loss: 69777.155 | Val acc: 47.449 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 4 / 10 | Reconst_loss: 3120.659 | Kldiv loss: 891.901 | Classifcation loss: 2.252 | Constrast loss: 8.94 | Total loss: 69755.443 | Train acc: 48.640 % ||| Val Loss: 65753.787 | Val acc: 51.716 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 5 / 10 | Reconst_loss: 2594.072 | Kldiv loss: 640.609 | Classifcation loss: 2.176 | Constrast loss: 29.99 | Total loss: 66887.136 | Train acc: 51.838 % ||| Val Loss: 64626.319 | Val acc: 52.831 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 6 / 10 | Reconst_loss: 2955.119 | Kldiv loss: 659.265 | Classifcation loss: 2.139 | Constrast loss: 6.81 | Total loss: 64147.281 | Train acc: 53.872 % ||| Val Loss: 61198.282 | Val acc: 56.813 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 7 / 10 | Reconst_loss: 2186.267 | Kldiv loss: 646.990 | Classifcation loss: 2.134 | Constrast loss: 5.61 | Total loss: 62584.269 | Train acc: 55.483 % ||| Val Loss: 57473.831 | Val acc: 57.884 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 8 / 10 | Reconst_loss: 2065.500 | Kldiv loss: 592.767 | Classifcation loss: 2.141 | Constrast loss: 27.82 | Total loss: 60848.386 | Train acc: 57.153 % ||| Val Loss: 56587.555 | Val acc: 60.473 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 9 / 10 | Reconst_loss: 1858.730 | Kldiv loss: 664.101 | Classifcation loss: 2.137 | Constrast loss: 17.75 | Total loss: 59501.967 | Train acc: 59.788 % ||| Val Loss: 56177.710 | Val acc: 63.744 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2023-02-27 04:56:06,155]\u001b[0m Trial 0 finished with value: 0.6206991811354621 and parameters: {'optuna_batch_size': 743, 'optimizer': 'RMSprop', 'lr': 0.007044878226407033, 'alpha': 3.2162710834834574, 'beta': 3.1628201715005972, 'gamma': 7.745098714381568, 'delta': 4.123415553751628}. Best is trial 0 with value: 0.6206991811354621.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 10 / 10 | Reconst_loss: 2951.441 | Kldiv loss: 537.276 | Classifcation loss: 2.159 | Constrast loss: 15.37 | Total loss: 57427.092 | Train acc: 62.070 % ||| Val Loss: 56201.293 | Val acc: 61.167 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 1 / 10 | Reconst_loss: 2853.344 | Kldiv loss: 469.476 | Classifcation loss: 2.178 | Constrast loss: 79.01 | Total loss: 12205.449 | Train acc: 37.805 % ||| Val Loss: 9596.018 | Val acc: 49.818 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 2 / 10 | Reconst_loss: 1793.348 | Kldiv loss: 361.833 | Classifcation loss: 2.142 | Constrast loss: 67.44 | Total loss: 9638.078 | Train acc: 51.037 % ||| Val Loss: 8847.482 | Val acc: 56.197 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 3 / 10 | Reconst_loss: 2024.090 | Kldiv loss: 324.204 | Classifcation loss: 2.212 | Constrast loss: 73.21 | Total loss: 9141.589 | Train acc: 55.915 % ||| Val Loss: 8776.385 | Val acc: 58.851 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 4 / 10 | Reconst_loss: 1900.196 | Kldiv loss: 443.652 | Classifcation loss: 2.136 | Constrast loss: 16.02 | Total loss: 8899.609 | Train acc: 58.211 % ||| Val Loss: 8331.054 | Val acc: 59.617 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 5 / 10 | Reconst_loss: 2038.177 | Kldiv loss: 471.492 | Classifcation loss: 2.082 | Constrast loss: 25.05 | Total loss: 8633.838 | Train acc: 59.704 % ||| Val Loss: 8211.705 | Val acc: 61.462 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 6 / 10 | Reconst_loss: 2437.342 | Kldiv loss: 446.093 | Classifcation loss: 2.031 | Constrast loss: 33.20 | Total loss: 8496.667 | Train acc: 60.452 % ||| Val Loss: 8095.596 | Val acc: 61.594 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 7 / 10 | Reconst_loss: 2172.032 | Kldiv loss: 438.364 | Classifcation loss: 2.038 | Constrast loss: 32.27 | Total loss: 8356.306 | Train acc: 61.246 % ||| Val Loss: 8009.536 | Val acc: 63.035 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 8 / 10 | Reconst_loss: 1979.071 | Kldiv loss: 380.207 | Classifcation loss: 2.028 | Constrast loss: 29.68 | Total loss: 8248.234 | Train acc: 61.579 % ||| Val Loss: 7927.575 | Val acc: 62.841 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 9 / 10 | Reconst_loss: 2063.488 | Kldiv loss: 397.368 | Classifcation loss: 2.096 | Constrast loss: 26.46 | Total loss: 8197.071 | Train acc: 61.550 % ||| Val Loss: 7926.741 | Val acc: 62.973 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2023-02-27 04:56:37,714]\u001b[0m Trial 1 finished with value: 0.6122965641952984 and parameters: {'optuna_batch_size': 132, 'optimizer': 'RMSprop', 'lr': 0.009491602538775758, 'alpha': 3.909100924977496, 'beta': 1.0316845120419385, 'gamma': 3.5408275409935115, 'delta': 8.452433881636516}. Best is trial 0 with value: 0.6206991811354621.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 10 / 10 | Reconst_loss: 1970.556 | Kldiv loss: 488.467 | Classifcation loss: 1.994 | Constrast loss: 12.89 | Total loss: 8227.093 | Train acc: 61.230 % ||| Val Loss: 7885.730 | Val acc: 61.621 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 1 / 10 | Reconst_loss: 3323.617 | Kldiv loss: 2702.077 | Classifcation loss: 2.544 | Constrast loss: 519.70 | Total loss: 530152.815 | Train acc: 10.708 % ||| Val Loss: 129560.428 | Val acc: 14.947 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 2 / 10 | Reconst_loss: 3279.776 | Kldiv loss: 2313.531 | Classifcation loss: 2.533 | Constrast loss: 118.24 | Total loss: 112796.553 | Train acc: 15.015 % ||| Val Loss: 75294.716 | Val acc: 14.312 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 3 / 10 | Reconst_loss: 3508.668 | Kldiv loss: 1392.038 | Classifcation loss: 2.475 | Constrast loss: 106.31 | Total loss: 70467.246 | Train acc: 18.753 % ||| Val Loss: 65136.853 | Val acc: 25.148 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 4 / 10 | Reconst_loss: 3193.383 | Kldiv loss: 1259.306 | Classifcation loss: 2.346 | Constrast loss: 91.52 | Total loss: 61936.247 | Train acc: 27.250 % ||| Val Loss: 57695.531 | Val acc: 32.553 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 5 / 10 | Reconst_loss: 3009.041 | Kldiv loss: 1011.956 | Classifcation loss: 2.327 | Constrast loss: 136.93 | Total loss: 56085.889 | Train acc: 36.600 % ||| Val Loss: 53570.417 | Val acc: 39.623 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 6 / 10 | Reconst_loss: 3112.611 | Kldiv loss: 1039.550 | Classifcation loss: 2.256 | Constrast loss: 49.40 | Total loss: 52012.568 | Train acc: 44.927 % ||| Val Loss: 49610.069 | Val acc: 50.925 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 7 / 10 | Reconst_loss: 2458.346 | Kldiv loss: 1108.954 | Classifcation loss: 2.109 | Constrast loss: 33.77 | Total loss: 48815.558 | Train acc: 54.691 % ||| Val Loss: 47226.217 | Val acc: 57.387 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 8 / 10 | Reconst_loss: 3138.148 | Kldiv loss: 972.183 | Classifcation loss: 2.158 | Constrast loss: 56.93 | Total loss: 46551.110 | Train acc: 58.583 % ||| Val Loss: 45172.744 | Val acc: 60.733 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 9 / 10 | Reconst_loss: 2507.742 | Kldiv loss: 905.361 | Classifcation loss: 2.065 | Constrast loss: 51.68 | Total loss: 44926.452 | Train acc: 62.465 % ||| Val Loss: 43851.422 | Val acc: 64.440 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2023-02-27 04:56:59,125]\u001b[0m Trial 2 finished with value: 0.6532950327487305 and parameters: {'optuna_batch_size': 553, 'optimizer': 'Adam', 'lr': 0.0026636660004030074, 'alpha': 0.6751162450804987, 'beta': 3.385299775999059, 'gamma': 9.892900229613428, 'delta': 9.485558049627901}. Best is trial 2 with value: 0.6532950327487305.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 10 / 10 | Reconst_loss: 2974.415 | Kldiv loss: 1057.752 | Classifcation loss: 2.086 | Constrast loss: 54.09 | Total loss: 43791.341 | Train acc: 65.330 % ||| Val Loss: 42943.343 | Val acc: 66.328 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 1 / 10 | Reconst_loss: 6955.964 | Kldiv loss: 2542.064 | Classifcation loss: 2.347 | Constrast loss: 215.87 | Total loss: 296739.193 | Train acc: 24.584 % ||| Val Loss: 95653.852 | Val acc: 36.177 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 2 / 10 | Reconst_loss: 6289.326 | Kldiv loss: 1761.964 | Classifcation loss: 2.298 | Constrast loss: 151.73 | Total loss: 92752.830 | Train acc: 39.853 % ||| Val Loss: 83228.202 | Val acc: 44.775 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 3 / 10 | Reconst_loss: 5734.197 | Kldiv loss: 1882.308 | Classifcation loss: 2.248 | Constrast loss: 81.14 | Total loss: 83081.804 | Train acc: 44.674 % ||| Val Loss: 77027.557 | Val acc: 45.739 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 4 / 10 | Reconst_loss: 5792.144 | Kldiv loss: 1560.018 | Classifcation loss: 2.232 | Constrast loss: 121.79 | Total loss: 78689.864 | Train acc: 44.859 % ||| Val Loss: 72124.082 | Val acc: 46.723 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 5 / 10 | Reconst_loss: 5352.654 | Kldiv loss: 1547.407 | Classifcation loss: 2.221 | Constrast loss: 76.21 | Total loss: 75631.475 | Train acc: 45.451 % ||| Val Loss: 69550.708 | Val acc: 47.778 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 6 / 10 | Reconst_loss: 5302.788 | Kldiv loss: 1522.313 | Classifcation loss: 2.149 | Constrast loss: 73.15 | Total loss: 73475.567 | Train acc: 46.434 % ||| Val Loss: 67875.354 | Val acc: 48.989 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 7 / 10 | Reconst_loss: 5985.729 | Kldiv loss: 1410.697 | Classifcation loss: 2.179 | Constrast loss: 48.18 | Total loss: 71466.254 | Train acc: 46.988 % ||| Val Loss: 66693.426 | Val acc: 48.104 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 8 / 10 | Reconst_loss: 5920.180 | Kldiv loss: 1278.001 | Classifcation loss: 2.250 | Constrast loss: 77.91 | Total loss: 70461.256 | Train acc: 48.108 % ||| Val Loss: 68304.552 | Val acc: 47.468 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 9 / 10 | Reconst_loss: 5814.754 | Kldiv loss: 1198.075 | Classifcation loss: 2.180 | Constrast loss: 70.45 | Total loss: 68735.169 | Train acc: 48.997 % ||| Val Loss: 64169.099 | Val acc: 48.443 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2023-02-27 04:57:21,060]\u001b[0m Trial 3 finished with value: 0.4908862594390505 and parameters: {'optuna_batch_size': 824, 'optimizer': 'RMSprop', 'lr': 0.009709010774104979, 'alpha': 3.390768343889916, 'beta': 9.593216992828463, 'gamma': 5.31952440654823, 'delta': 8.539225040482275}. Best is trial 2 with value: 0.6532950327487305.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 10 / 10 | Reconst_loss: 5205.827 | Kldiv loss: 1374.565 | Classifcation loss: 2.233 | Constrast loss: 52.92 | Total loss: 68049.330 | Train acc: 49.089 % ||| Val Loss: 62941.858 | Val acc: 49.639 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 1 / 10 | Reconst_loss: 835.096 | Kldiv loss: 165.276 | Classifcation loss: 2.050 | Constrast loss: 2.60 | Total loss: 6407.062 | Train acc: 37.444 % ||| Val Loss: 5460.110 | Val acc: 49.637 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 2 / 10 | Reconst_loss: 778.671 | Kldiv loss: 127.720 | Classifcation loss: 2.169 | Constrast loss: 7.77 | Total loss: 5341.765 | Train acc: 55.776 % ||| Val Loss: 5248.198 | Val acc: 59.138 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 3 / 10 | Reconst_loss: 1053.163 | Kldiv loss: 190.807 | Classifcation loss: 1.988 | Constrast loss: 2.56 | Total loss: 5055.856 | Train acc: 62.872 % ||| Val Loss: 4855.025 | Val acc: 65.535 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 4 / 10 | Reconst_loss: 695.793 | Kldiv loss: 152.884 | Classifcation loss: 1.915 | Constrast loss: 1.51 | Total loss: 4886.141 | Train acc: 65.773 % ||| Val Loss: 4704.416 | Val acc: 67.626 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 5 / 10 | Reconst_loss: 639.757 | Kldiv loss: 163.838 | Classifcation loss: 1.827 | Constrast loss: 2.91 | Total loss: 4740.651 | Train acc: 67.231 % ||| Val Loss: 4581.129 | Val acc: 67.512 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 6 / 10 | Reconst_loss: 787.525 | Kldiv loss: 166.444 | Classifcation loss: 1.993 | Constrast loss: 2.90 | Total loss: 4655.851 | Train acc: 67.655 % ||| Val Loss: 4511.533 | Val acc: 68.411 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 7 / 10 | Reconst_loss: 1003.449 | Kldiv loss: 149.942 | Classifcation loss: 2.185 | Constrast loss: 12.15 | Total loss: 4594.167 | Train acc: 68.274 % ||| Val Loss: 4480.257 | Val acc: 69.172 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 8 / 10 | Reconst_loss: 805.602 | Kldiv loss: 152.592 | Classifcation loss: 2.010 | Constrast loss: 7.99 | Total loss: 4532.553 | Train acc: 69.008 % ||| Val Loss: 4471.767 | Val acc: 69.463 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 9 / 10 | Reconst_loss: 690.894 | Kldiv loss: 159.743 | Classifcation loss: 2.126 | Constrast loss: 11.51 | Total loss: 4500.086 | Train acc: 69.360 % ||| Val Loss: 4429.742 | Val acc: 69.602 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2023-02-27 04:58:04,991]\u001b[0m Trial 4 finished with value: 0.6995341326701048 and parameters: {'optuna_batch_size': 79, 'optimizer': 'RMSprop', 'lr': 0.0037383955283961825, 'alpha': 4.815267307543385, 'beta': 9.67674005317561, 'gamma': 5.417006825232157, 'delta': 2.2007460761161273}. Best is trial 4 with value: 0.6995341326701048.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 10 / 10 | Reconst_loss: 591.508 | Kldiv loss: 167.220 | Classifcation loss: 1.888 | Constrast loss: 6.28 | Total loss: 4472.249 | Train acc: 69.953 % ||| Val Loss: 4446.480 | Val acc: 70.314 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 1 / 10 | Reconst_loss: 2939.074 | Kldiv loss: 2205.238 | Classifcation loss: 2.466 | Constrast loss: 394.60 | Total loss: 114076.302 | Train acc: 14.327 % ||| Val Loss: 56714.247 | Val acc: 20.895 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 2 / 10 | Reconst_loss: 3338.325 | Kldiv loss: 992.810 | Classifcation loss: 2.397 | Constrast loss: 153.11 | Total loss: 52032.269 | Train acc: 27.477 % ||| Val Loss: 34790.629 | Val acc: 36.789 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 3 / 10 | Reconst_loss: 2939.994 | Kldiv loss: 656.997 | Classifcation loss: 2.188 | Constrast loss: 92.65 | Total loss: 29921.941 | Train acc: 44.949 % ||| Val Loss: 26013.915 | Val acc: 51.381 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 4 / 10 | Reconst_loss: 2629.705 | Kldiv loss: 816.262 | Classifcation loss: 2.079 | Constrast loss: 21.39 | Total loss: 24804.101 | Train acc: 56.173 % ||| Val Loss: 23269.226 | Val acc: 60.679 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 5 / 10 | Reconst_loss: 1989.520 | Kldiv loss: 746.514 | Classifcation loss: 2.052 | Constrast loss: 33.47 | Total loss: 22821.777 | Train acc: 62.190 % ||| Val Loss: 22055.015 | Val acc: 63.175 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 6 / 10 | Reconst_loss: 2683.806 | Kldiv loss: 720.158 | Classifcation loss: 2.062 | Constrast loss: 41.94 | Total loss: 22158.903 | Train acc: 64.009 % ||| Val Loss: 21750.568 | Val acc: 65.972 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 7 / 10 | Reconst_loss: 2432.523 | Kldiv loss: 643.812 | Classifcation loss: 2.084 | Constrast loss: 24.91 | Total loss: 21714.922 | Train acc: 66.700 % ||| Val Loss: 21145.940 | Val acc: 67.739 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 8 / 10 | Reconst_loss: 2376.010 | Kldiv loss: 686.724 | Classifcation loss: 2.017 | Constrast loss: 32.94 | Total loss: 21327.185 | Train acc: 67.992 % ||| Val Loss: 21241.993 | Val acc: 67.993 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 9 / 10 | Reconst_loss: 2018.110 | Kldiv loss: 728.223 | Classifcation loss: 2.025 | Constrast loss: 22.61 | Total loss: 21146.088 | Train acc: 68.621 % ||| Val Loss: 20795.536 | Val acc: 68.962 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2023-02-27 04:58:28,005]\u001b[0m Trial 5 finished with value: 0.6906420859975907 and parameters: {'optuna_batch_size': 327, 'optimizer': 'Adam', 'lr': 0.0060571810422021975, 'alpha': 0.8469236419659504, 'beta': 6.14969027121666, 'gamma': 1.5226720949545016, 'delta': 1.5649722090851543}. Best is trial 4 with value: 0.6995341326701048.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 10 / 10 | Reconst_loss: 2069.485 | Kldiv loss: 631.727 | Classifcation loss: 2.048 | Constrast loss: 44.23 | Total loss: 20954.097 | Train acc: 69.064 % ||| Val Loss: 20599.975 | Val acc: 69.177 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 1 / 10 | Reconst_loss: 10862.117 | Kldiv loss: 4084.169 | Classifcation loss: 2.389 | Constrast loss: 623.71 | Total loss: 267991.691 | Train acc: 23.349 % ||| Val Loss: 101393.208 | Val acc: 33.205 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 2 / 10 | Reconst_loss: 9932.187 | Kldiv loss: 2802.493 | Classifcation loss: 2.261 | Constrast loss: 353.29 | Total loss: 94587.722 | Train acc: 41.681 % ||| Val Loss: 84168.035 | Val acc: 45.560 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 3 / 10 | Reconst_loss: 10986.920 | Kldiv loss: 3370.158 | Classifcation loss: 2.168 | Constrast loss: 228.54 | Total loss: 85645.507 | Train acc: 46.964 % ||| Val Loss: 79327.080 | Val acc: 49.725 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 4 / 10 | Reconst_loss: 9817.610 | Kldiv loss: 2856.732 | Classifcation loss: 2.192 | Constrast loss: 238.33 | Total loss: 81590.230 | Train acc: 50.315 % ||| Val Loss: 75060.595 | Val acc: 52.422 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 5 / 10 | Reconst_loss: 10257.318 | Kldiv loss: 3368.879 | Classifcation loss: 2.139 | Constrast loss: 136.07 | Total loss: 78918.666 | Train acc: 53.616 % ||| Val Loss: 74014.137 | Val acc: 56.697 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 6 / 10 | Reconst_loss: 8810.237 | Kldiv loss: 2635.734 | Classifcation loss: 2.130 | Constrast loss: 167.00 | Total loss: 76972.636 | Train acc: 55.344 % ||| Val Loss: 71145.515 | Val acc: 58.970 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 7 / 10 | Reconst_loss: 8812.930 | Kldiv loss: 2276.839 | Classifcation loss: 2.101 | Constrast loss: 167.87 | Total loss: 74922.161 | Train acc: 57.588 % ||| Val Loss: 67941.953 | Val acc: 60.685 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 8 / 10 | Reconst_loss: 9458.479 | Kldiv loss: 1929.063 | Classifcation loss: 2.116 | Constrast loss: 228.79 | Total loss: 71944.585 | Train acc: 59.982 % ||| Val Loss: 65813.531 | Val acc: 64.303 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 9 / 10 | Reconst_loss: 9364.860 | Kldiv loss: 2190.355 | Classifcation loss: 2.025 | Constrast loss: 179.04 | Total loss: 70441.781 | Train acc: 62.264 % ||| Val Loss: 64631.909 | Val acc: 64.789 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2023-02-27 04:58:50,282]\u001b[0m Trial 6 finished with value: 0.6310760629046062 and parameters: {'optuna_batch_size': 863, 'optimizer': 'RMSprop', 'lr': 0.008104382736509676, 'alpha': 0.19827390499842593, 'beta': 7.433612799850968, 'gamma': 9.503789443341585, 'delta': 0.7184508849712268}. Best is trial 4 with value: 0.6995341326701048.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 10 / 10 | Reconst_loss: 8613.661 | Kldiv loss: 2180.601 | Classifcation loss: 2.045 | Constrast loss: 162.53 | Total loss: 69317.012 | Train acc: 63.108 % ||| Val Loss: 63419.848 | Val acc: 67.642 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 1 / 10 | Reconst_loss: 22762.275 | Kldiv loss: 16012.462 | Classifcation loss: 2.479 | Constrast loss: 4075.35 | Total loss: 599125.607 | Train acc: 13.524 % ||| Val Loss: 118309.754 | Val acc: 18.899 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 2 / 10 | Reconst_loss: 19728.000 | Kldiv loss: 7153.510 | Classifcation loss: 2.302 | Constrast loss: 2215.42 | Total loss: 93075.623 | Train acc: 31.541 % ||| Val Loss: 77915.806 | Val acc: 40.198 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 3 / 10 | Reconst_loss: 17906.492 | Kldiv loss: 6072.747 | Classifcation loss: 2.252 | Constrast loss: 1805.41 | Total loss: 74916.509 | Train acc: 41.674 % ||| Val Loss: 68186.653 | Val acc: 45.599 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 4 / 10 | Reconst_loss: 15961.985 | Kldiv loss: 6042.417 | Classifcation loss: 2.187 | Constrast loss: 1585.81 | Total loss: 67500.367 | Train acc: 49.758 % ||| Val Loss: 63300.829 | Val acc: 52.662 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 5 / 10 | Reconst_loss: 16090.910 | Kldiv loss: 6299.012 | Classifcation loss: 2.122 | Constrast loss: 1006.41 | Total loss: 63930.208 | Train acc: 55.020 % ||| Val Loss: 60645.267 | Val acc: 55.484 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 6 / 10 | Reconst_loss: 15424.694 | Kldiv loss: 6034.747 | Classifcation loss: 2.131 | Constrast loss: 957.88 | Total loss: 62056.013 | Train acc: 56.494 % ||| Val Loss: 59494.442 | Val acc: 56.834 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 7 / 10 | Reconst_loss: 15379.645 | Kldiv loss: 5996.657 | Classifcation loss: 2.109 | Constrast loss: 858.66 | Total loss: 60946.338 | Train acc: 58.009 % ||| Val Loss: 59014.256 | Val acc: 56.402 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 8 / 10 | Reconst_loss: 14592.574 | Kldiv loss: 5712.187 | Classifcation loss: 2.125 | Constrast loss: 1188.13 | Total loss: 59630.660 | Train acc: 59.260 % ||| Val Loss: 57644.806 | Val acc: 59.803 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 9 / 10 | Reconst_loss: 14883.973 | Kldiv loss: 5589.197 | Classifcation loss: 2.085 | Constrast loss: 1178.37 | Total loss: 59034.859 | Train acc: 59.992 % ||| Val Loss: 56855.688 | Val acc: 60.164 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2023-02-27 04:59:15,209]\u001b[0m Trial 7 finished with value: 0.6055410951178668 and parameters: {'optuna_batch_size': 746, 'optimizer': 'Adam', 'lr': 0.009066990202001284, 'alpha': 7.163965699200228, 'beta': 5.648476722632847, 'gamma': 9.43029343943856, 'delta': 9.00299888468433}. Best is trial 4 with value: 0.6995341326701048.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 10 / 10 | Reconst_loss: 15262.551 | Kldiv loss: 5515.735 | Classifcation loss: 2.111 | Constrast loss: 999.41 | Total loss: 58281.580 | Train acc: 60.554 % ||| Val Loss: 56154.877 | Val acc: 60.668 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 1 / 10 | Reconst_loss: 7075.258 | Kldiv loss: 1656.418 | Classifcation loss: 2.463 | Constrast loss: 506.92 | Total loss: 74334.404 | Train acc: 13.045 % ||| Val Loss: 24777.252 | Val acc: 23.371 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 2 / 10 | Reconst_loss: 6355.294 | Kldiv loss: 1565.356 | Classifcation loss: 2.285 | Constrast loss: 353.94 | Total loss: 22105.172 | Train acc: 40.290 % ||| Val Loss: 19925.975 | Val acc: 46.804 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 3 / 10 | Reconst_loss: 5198.928 | Kldiv loss: 1491.522 | Classifcation loss: 2.112 | Constrast loss: 200.42 | Total loss: 19205.269 | Train acc: 54.459 % ||| Val Loss: 18303.350 | Val acc: 59.338 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 4 / 10 | Reconst_loss: 4797.107 | Kldiv loss: 1397.684 | Classifcation loss: 2.066 | Constrast loss: 182.31 | Total loss: 18164.504 | Train acc: 61.724 % ||| Val Loss: 17757.373 | Val acc: 63.345 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 5 / 10 | Reconst_loss: 5463.557 | Kldiv loss: 1461.807 | Classifcation loss: 2.044 | Constrast loss: 192.62 | Total loss: 17642.997 | Train acc: 64.329 % ||| Val Loss: 17348.033 | Val acc: 64.865 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 6 / 10 | Reconst_loss: 5185.660 | Kldiv loss: 1424.297 | Classifcation loss: 2.009 | Constrast loss: 228.23 | Total loss: 17211.371 | Train acc: 66.694 % ||| Val Loss: 16858.519 | Val acc: 68.663 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 7 / 10 | Reconst_loss: 4812.939 | Kldiv loss: 1291.985 | Classifcation loss: 2.024 | Constrast loss: 215.26 | Total loss: 16930.060 | Train acc: 68.947 % ||| Val Loss: 16551.891 | Val acc: 69.487 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 8 / 10 | Reconst_loss: 4495.408 | Kldiv loss: 1360.142 | Classifcation loss: 2.017 | Constrast loss: 145.96 | Total loss: 16606.233 | Train acc: 70.143 % ||| Val Loss: 16488.968 | Val acc: 69.255 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 9 / 10 | Reconst_loss: 5418.015 | Kldiv loss: 1360.094 | Classifcation loss: 1.985 | Constrast loss: 135.03 | Total loss: 16339.335 | Train acc: 70.676 % ||| Val Loss: 16045.124 | Val acc: 71.235 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2023-02-27 04:59:40,394]\u001b[0m Trial 8 finished with value: 0.7036271618198428 and parameters: {'optuna_batch_size': 262, 'optimizer': 'Adam', 'lr': 0.003606224568103176, 'alpha': 9.28638495530031, 'beta': 9.350961131733353, 'gamma': 3.8350716421937894, 'delta': 7.461047207784562}. Best is trial 8 with value: 0.7036271618198428.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 10 / 10 | Reconst_loss: 5205.645 | Kldiv loss: 1266.856 | Classifcation loss: 1.955 | Constrast loss: 155.60 | Total loss: 16403.573 | Train acc: 70.363 % ||| Val Loss: 15938.411 | Val acc: 71.281 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 1 / 10 | Reconst_loss: 22676.359 | Kldiv loss: 3768.208 | Classifcation loss: 2.551 | Constrast loss: 65241.32 | Total loss: 3247826.187 | Train acc: 9.318 % ||| Val Loss: 1036020.307 | Val acc: 11.206 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 2 / 10 | Reconst_loss: 20650.312 | Kldiv loss: 28303.566 | Classifcation loss: 2.506 | Constrast loss: 12892.07 | Total loss: 555910.549 | Train acc: 13.006 % ||| Val Loss: 365502.760 | Val acc: 15.165 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 3 / 10 | Reconst_loss: 20928.529 | Kldiv loss: 23036.113 | Classifcation loss: 2.501 | Constrast loss: 10636.09 | Total loss: 333418.940 | Train acc: 15.129 % ||| Val Loss: 306546.157 | Val acc: 15.057 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 4 / 10 | Reconst_loss: 19072.184 | Kldiv loss: 21134.277 | Classifcation loss: 2.496 | Constrast loss: 4534.78 | Total loss: 271495.976 | Train acc: 14.727 % ||| Val Loss: 203038.942 | Val acc: 14.401 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 5 / 10 | Reconst_loss: 19891.342 | Kldiv loss: 14166.150 | Classifcation loss: 2.478 | Constrast loss: 3507.37 | Total loss: 186619.363 | Train acc: 18.736 % ||| Val Loss: 165302.522 | Val acc: 19.304 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 6 / 10 | Reconst_loss: 17441.320 | Kldiv loss: 11722.177 | Classifcation loss: 2.461 | Constrast loss: 3181.58 | Total loss: 158392.503 | Train acc: 19.927 % ||| Val Loss: 145020.350 | Val acc: 20.860 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 7 / 10 | Reconst_loss: 16957.402 | Kldiv loss: 10919.592 | Classifcation loss: 2.390 | Constrast loss: 2488.46 | Total loss: 143464.778 | Train acc: 23.539 % ||| Val Loss: 135157.694 | Val acc: 28.574 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 8 / 10 | Reconst_loss: 16271.207 | Kldiv loss: 9973.069 | Classifcation loss: 2.397 | Constrast loss: 2657.37 | Total loss: 135613.755 | Train acc: 29.528 % ||| Val Loss: 129501.049 | Val acc: 30.175 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 9 / 10 | Reconst_loss: 17847.410 | Kldiv loss: 9758.733 | Classifcation loss: 2.375 | Constrast loss: 2379.06 | Total loss: 130612.859 | Train acc: 30.957 % ||| Val Loss: 124658.902 | Val acc: 31.733 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2023-02-27 05:00:07,538]\u001b[0m Trial 9 finished with value: 0.32268788367545104 and parameters: {'optuna_batch_size': 991, 'optimizer': 'Adam', 'lr': 0.001429273119000515, 'alpha': 8.80619852346651, 'beta': 4.724615522414608, 'gamma': 6.910660787282006, 'delta': 4.769746152060371}. Best is trial 8 with value: 0.7036271618198428.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 10 / 10 | Reconst_loss: 16560.703 | Kldiv loss: 9016.066 | Classifcation loss: 2.359 | Constrast loss: 2300.96 | Total loss: 125778.167 | Train acc: 32.269 % ||| Val Loss: 119955.056 | Val acc: 33.189 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 1 / 10 | Reconst_loss: 5557.098 | Kldiv loss: 9.207 | Classifcation loss: 2.564 | Constrast loss: 18477.36 | Total loss: 529974.985 | Train acc: 8.232 % ||| Val Loss: 512030.192 | Val acc: 8.401 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 2 / 10 | Reconst_loss: 5041.295 | Kldiv loss: 82.100 | Classifcation loss: 2.564 | Constrast loss: 7004.04 | Total loss: 350415.807 | Train acc: 8.650 % ||| Val Loss: 204946.454 | Val acc: 9.006 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 3 / 10 | Reconst_loss: 5280.260 | Kldiv loss: 660.594 | Classifcation loss: 2.544 | Constrast loss: 2089.51 | Total loss: 133423.884 | Train acc: 10.693 % ||| Val Loss: 87746.645 | Val acc: 14.929 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 4 / 10 | Reconst_loss: 6091.027 | Kldiv loss: 1534.550 | Classifcation loss: 2.516 | Constrast loss: 1345.23 | Total loss: 76728.979 | Train acc: 15.932 % ||| Val Loss: 67496.096 | Val acc: 15.495 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 5 / 10 | Reconst_loss: 5346.946 | Kldiv loss: 2401.371 | Classifcation loss: 2.505 | Constrast loss: 1170.86 | Total loss: 65721.151 | Train acc: 15.487 % ||| Val Loss: 63069.217 | Val acc: 15.541 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 6 / 10 | Reconst_loss: 5008.317 | Kldiv loss: 2295.863 | Classifcation loss: 2.511 | Constrast loss: 1094.26 | Total loss: 63482.063 | Train acc: 15.974 % ||| Val Loss: 62159.197 | Val acc: 16.634 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 7 / 10 | Reconst_loss: 5382.291 | Kldiv loss: 2920.949 | Classifcation loss: 2.513 | Constrast loss: 970.20 | Total loss: 62906.174 | Train acc: 16.333 % ||| Val Loss: 61799.232 | Val acc: 15.897 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 8 / 10 | Reconst_loss: 4373.257 | Kldiv loss: 2237.058 | Classifcation loss: 2.501 | Constrast loss: 1081.66 | Total loss: 62592.742 | Train acc: 15.852 % ||| Val Loss: 61448.014 | Val acc: 15.784 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 9 / 10 | Reconst_loss: 5148.796 | Kldiv loss: 3214.968 | Classifcation loss: 2.508 | Constrast loss: 913.80 | Total loss: 62194.371 | Train acc: 15.730 % ||| Val Loss: 61155.592 | Val acc: 15.760 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2023-02-27 05:00:29,809]\u001b[0m Trial 10 finished with value: 0.158119106367514 and parameters: {'optuna_batch_size': 333, 'optimizer': 'Adam', 'lr': 0.00015379999898672107, 'alpha': 9.79227806639333, 'beta': 7.939767486641814, 'gamma': 1.1140333127500925, 'delta': 7.235782514161249}. Best is trial 8 with value: 0.7036271618198428.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 10 / 10 | Reconst_loss: 4908.529 | Kldiv loss: 2888.423 | Classifcation loss: 2.488 | Constrast loss: 978.93 | Total loss: 61959.242 | Train acc: 15.812 % ||| Val Loss: 60842.611 | Val acc: 15.829 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 1 / 10 | Reconst_loss: 1080.243 | Kldiv loss: 186.056 | Classifcation loss: 2.277 | Constrast loss: 24.71 | Total loss: 3977.183 | Train acc: 40.995 % ||| Val Loss: 3388.941 | Val acc: 57.764 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 2 / 10 | Reconst_loss: 837.826 | Kldiv loss: 216.749 | Classifcation loss: 1.972 | Constrast loss: 7.02 | Total loss: 3304.544 | Train acc: 61.624 % ||| Val Loss: 3152.661 | Val acc: 66.233 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 3 / 10 | Reconst_loss: 991.426 | Kldiv loss: 171.316 | Classifcation loss: 2.088 | Constrast loss: 18.87 | Total loss: 3126.066 | Train acc: 65.959 % ||| Val Loss: 2985.935 | Val acc: 67.690 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 4 / 10 | Reconst_loss: 862.167 | Kldiv loss: 185.531 | Classifcation loss: 1.894 | Constrast loss: 9.25 | Total loss: 3004.615 | Train acc: 67.731 % ||| Val Loss: 2922.430 | Val acc: 68.605 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 5 / 10 | Reconst_loss: 578.819 | Kldiv loss: 149.463 | Classifcation loss: 2.036 | Constrast loss: 22.63 | Total loss: 2951.220 | Train acc: 68.783 % ||| Val Loss: 2894.030 | Val acc: 69.217 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 6 / 10 | Reconst_loss: 910.435 | Kldiv loss: 165.466 | Classifcation loss: 2.052 | Constrast loss: 18.82 | Total loss: 2916.091 | Train acc: 69.884 % ||| Val Loss: 3043.577 | Val acc: 65.738 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 7 / 10 | Reconst_loss: 890.173 | Kldiv loss: 197.451 | Classifcation loss: 1.988 | Constrast loss: 4.36 | Total loss: 2887.517 | Train acc: 70.295 % ||| Val Loss: 2868.565 | Val acc: 71.601 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 8 / 10 | Reconst_loss: 706.712 | Kldiv loss: 193.920 | Classifcation loss: 2.100 | Constrast loss: 17.57 | Total loss: 2875.510 | Train acc: 70.330 % ||| Val Loss: 2851.903 | Val acc: 71.331 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 9 / 10 | Reconst_loss: 1075.861 | Kldiv loss: 169.778 | Classifcation loss: 2.014 | Constrast loss: 8.55 | Total loss: 2852.987 | Train acc: 70.622 % ||| Val Loss: 2796.414 | Val acc: 70.916 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2023-02-27 05:01:34,871]\u001b[0m Trial 11 finished with value: 0.7086864732074313 and parameters: {'optuna_batch_size': 52, 'optimizer': 'RMSprop', 'lr': 0.0038623416470803065, 'alpha': 6.348718998181586, 'beta': 9.830274382925392, 'gamma': 4.031997371774362, 'delta': 6.459866630196646}. Best is trial 11 with value: 0.7086864732074313.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 10 / 10 | Reconst_loss: 595.043 | Kldiv loss: 171.026 | Classifcation loss: 2.001 | Constrast loss: 13.00 | Total loss: 2843.332 | Train acc: 70.869 % ||| Val Loss: 2806.323 | Val acc: 70.864 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 1 / 10 | Reconst_loss: 1449.120 | Kldiv loss: 302.220 | Classifcation loss: 2.425 | Constrast loss: 18.98 | Total loss: 53486.998 | Train acc: 16.863 % ||| Val Loss: 20699.209 | Val acc: 30.213 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 2 / 10 | Reconst_loss: 980.810 | Kldiv loss: 222.487 | Classifcation loss: 2.212 | Constrast loss: 5.34 | Total loss: 18613.379 | Train acc: 48.229 % ||| Val Loss: 17118.854 | Val acc: 53.519 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 3 / 10 | Reconst_loss: 898.835 | Kldiv loss: 269.076 | Classifcation loss: 2.149 | Constrast loss: 3.87 | Total loss: 16672.955 | Train acc: 55.014 % ||| Val Loss: 16113.699 | Val acc: 55.389 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 4 / 10 | Reconst_loss: 703.453 | Kldiv loss: 213.458 | Classifcation loss: 2.036 | Constrast loss: 9.75 | Total loss: 15756.379 | Train acc: 57.054 % ||| Val Loss: 15367.374 | Val acc: 57.925 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 5 / 10 | Reconst_loss: 853.385 | Kldiv loss: 265.698 | Classifcation loss: 2.128 | Constrast loss: 3.91 | Total loss: 15360.308 | Train acc: 58.333 % ||| Val Loss: 15170.412 | Val acc: 59.096 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 6 / 10 | Reconst_loss: 633.082 | Kldiv loss: 189.332 | Classifcation loss: 2.170 | Constrast loss: 11.34 | Total loss: 15161.766 | Train acc: 59.410 % ||| Val Loss: 15071.581 | Val acc: 59.471 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 7 / 10 | Reconst_loss: 716.995 | Kldiv loss: 237.940 | Classifcation loss: 2.019 | Constrast loss: 4.04 | Total loss: 14989.552 | Train acc: 59.932 % ||| Val Loss: 14904.215 | Val acc: 59.954 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 8 / 10 | Reconst_loss: 756.999 | Kldiv loss: 212.410 | Classifcation loss: 2.134 | Constrast loss: 3.01 | Total loss: 14836.815 | Train acc: 60.452 % ||| Val Loss: 14714.392 | Val acc: 61.102 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 9 / 10 | Reconst_loss: 656.250 | Kldiv loss: 214.801 | Classifcation loss: 2.053 | Constrast loss: 7.24 | Total loss: 14724.124 | Train acc: 60.795 % ||| Val Loss: 14571.915 | Val acc: 61.222 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2023-02-27 05:01:59,019]\u001b[0m Trial 12 finished with value: 0.613801407771425 and parameters: {'optuna_batch_size': 241, 'optimizer': 'Adam', 'lr': 0.004293815734801606, 'alpha': 7.247937357584653, 'beta': 9.672335315193042, 'gamma': 3.5018160397344236, 'delta': 6.80540134543722}. Best is trial 11 with value: 0.7086864732074313.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 10 / 10 | Reconst_loss: 860.539 | Kldiv loss: 237.017 | Classifcation loss: 2.037 | Constrast loss: 3.01 | Total loss: 14603.813 | Train acc: 61.380 % ||| Val Loss: 14475.342 | Val acc: 62.126 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 1 / 10 | Reconst_loss: 65.930 | Kldiv loss: 6.069 | Classifcation loss: 2.562 | Constrast loss: 0.00 | Total loss: 677.830 | Train acc: 46.706 % ||| Val Loss: 599.991 | Val acc: 58.244 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 2 / 10 | Reconst_loss: 42.027 | Kldiv loss: 8.606 | Classifcation loss: 1.690 | Constrast loss: 0.00 | Total loss: 589.118 | Train acc: 57.536 % ||| Val Loss: 712.900 | Val acc: 41.376 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 3 / 10 | Reconst_loss: 85.669 | Kldiv loss: 6.944 | Classifcation loss: 2.185 | Constrast loss: 0.00 | Total loss: 593.279 | Train acc: 57.136 % ||| Val Loss: 604.257 | Val acc: 57.631 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 4 / 10 | Reconst_loss: 13.368 | Kldiv loss: 7.718 | Classifcation loss: 2.180 | Constrast loss: 0.00 | Total loss: 579.995 | Train acc: 59.547 % ||| Val Loss: 608.946 | Val acc: 53.742 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 5 / 10 | Reconst_loss: 95.742 | Kldiv loss: 10.667 | Classifcation loss: 2.189 | Constrast loss: 0.00 | Total loss: 566.762 | Train acc: 59.409 % ||| Val Loss: 579.826 | Val acc: 56.203 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 6 / 10 | Reconst_loss: 25.718 | Kldiv loss: 15.017 | Classifcation loss: 2.191 | Constrast loss: 0.00 | Total loss: 573.410 | Train acc: 56.708 % ||| Val Loss: 558.213 | Val acc: 56.169 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 7 / 10 | Reconst_loss: 12.049 | Kldiv loss: 5.727 | Classifcation loss: 1.693 | Constrast loss: 0.00 | Total loss: 588.313 | Train acc: 48.996 % ||| Val Loss: 570.579 | Val acc: 48.460 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 8 / 10 | Reconst_loss: 78.772 | Kldiv loss: 11.930 | Classifcation loss: 2.689 | Constrast loss: 0.00 | Total loss: 575.843 | Train acc: 51.370 % ||| Val Loss: 562.743 | Val acc: 51.888 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 9 / 10 | Reconst_loss: 38.337 | Kldiv loss: 6.456 | Classifcation loss: 2.189 | Constrast loss: 0.00 | Total loss: 565.319 | Train acc: 53.060 % ||| Val Loss: 584.478 | Val acc: 51.074 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2023-02-27 05:07:20,320]\u001b[0m Trial 13 finished with value: 0.5351631477927036 and parameters: {'optuna_batch_size': 10, 'optimizer': 'RMSprop', 'lr': 0.0053620127698157695, 'alpha': 7.12734713071115, 'beta': 8.135677684971698, 'gamma': 3.359807372723433, 'delta': 6.3247242493050475}. Best is trial 11 with value: 0.7086864732074313.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 10 / 10 | Reconst_loss: 66.868 | Kldiv loss: 8.621 | Classifcation loss: 1.689 | Constrast loss: 0.00 | Total loss: 569.882 | Train acc: 53.516 % ||| Val Loss: 573.879 | Val acc: 52.536 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 1 / 10 | Reconst_loss: 1968.125 | Kldiv loss: 435.477 | Classifcation loss: 2.248 | Constrast loss: 20.04 | Total loss: 23301.130 | Train acc: 31.802 % ||| Val Loss: 17420.158 | Val acc: 42.053 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 2 / 10 | Reconst_loss: 1799.579 | Kldiv loss: 379.917 | Classifcation loss: 2.222 | Constrast loss: 32.31 | Total loss: 16718.158 | Train acc: 44.630 % ||| Val Loss: 15740.693 | Val acc: 47.884 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 3 / 10 | Reconst_loss: 1744.449 | Kldiv loss: 340.707 | Classifcation loss: 2.273 | Constrast loss: 14.83 | Total loss: 15847.538 | Train acc: 50.239 % ||| Val Loss: 15376.985 | Val acc: 52.939 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 4 / 10 | Reconst_loss: 1581.571 | Kldiv loss: 407.834 | Classifcation loss: 2.053 | Constrast loss: 25.09 | Total loss: 15019.751 | Train acc: 56.466 % ||| Val Loss: 14311.713 | Val acc: 59.949 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 5 / 10 | Reconst_loss: 1209.399 | Kldiv loss: 404.608 | Classifcation loss: 2.183 | Constrast loss: 21.93 | Total loss: 14441.562 | Train acc: 61.123 % ||| Val Loss: 14030.311 | Val acc: 63.284 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 6 / 10 | Reconst_loss: 1370.745 | Kldiv loss: 319.132 | Classifcation loss: 2.120 | Constrast loss: 18.45 | Total loss: 14174.404 | Train acc: 62.684 % ||| Val Loss: 13634.600 | Val acc: 64.367 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 7 / 10 | Reconst_loss: 1667.439 | Kldiv loss: 421.795 | Classifcation loss: 2.101 | Constrast loss: 6.19 | Total loss: 13816.186 | Train acc: 64.159 % ||| Val Loss: 13201.489 | Val acc: 66.530 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 8 / 10 | Reconst_loss: 1722.214 | Kldiv loss: 433.767 | Classifcation loss: 2.039 | Constrast loss: 2.99 | Total loss: 13514.119 | Train acc: 65.659 % ||| Val Loss: 13016.133 | Val acc: 67.287 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 9 / 10 | Reconst_loss: 1218.111 | Kldiv loss: 360.619 | Classifcation loss: 2.073 | Constrast loss: 14.39 | Total loss: 13351.692 | Train acc: 66.652 % ||| Val Loss: 12986.640 | Val acc: 66.749 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2023-02-27 05:07:44,234]\u001b[0m Trial 14 finished with value: 0.6712230526767499 and parameters: {'optuna_batch_size': 215, 'optimizer': 'RMSprop', 'lr': 0.00337286766867469, 'alpha': 9.99153147499835, 'beta': 8.623050901482578, 'gamma': 2.628378552349232, 'delta': 5.833116996308775}. Best is trial 11 with value: 0.7086864732074313.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 10 / 10 | Reconst_loss: 1513.116 | Kldiv loss: 336.809 | Classifcation loss: 1.977 | Constrast loss: 22.43 | Total loss: 13278.550 | Train acc: 67.122 % ||| Val Loss: 12925.232 | Val acc: 67.718 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 1 / 10 | Reconst_loss: 2500.841 | Kldiv loss: 1336.116 | Classifcation loss: 2.503 | Constrast loss: 171.77 | Total loss: 347571.260 | Train acc: 13.555 % ||| Val Loss: 89331.634 | Val acc: 17.829 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 2 / 10 | Reconst_loss: 2563.192 | Kldiv loss: 841.279 | Classifcation loss: 2.415 | Constrast loss: 51.60 | Total loss: 70412.912 | Train acc: 23.063 % ||| Val Loss: 55787.145 | Val acc: 30.674 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 3 / 10 | Reconst_loss: 1770.672 | Kldiv loss: 613.766 | Classifcation loss: 2.310 | Constrast loss: 51.49 | Total loss: 49480.661 | Train acc: 39.055 % ||| Val Loss: 44914.624 | Val acc: 43.331 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 4 / 10 | Reconst_loss: 1944.339 | Kldiv loss: 723.745 | Classifcation loss: 2.236 | Constrast loss: 30.80 | Total loss: 43020.218 | Train acc: 46.924 % ||| Val Loss: 40693.760 | Val acc: 49.226 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 5 / 10 | Reconst_loss: 1992.541 | Kldiv loss: 621.627 | Classifcation loss: 2.167 | Constrast loss: 44.33 | Total loss: 40232.500 | Train acc: 50.033 % ||| Val Loss: 38919.428 | Val acc: 50.827 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 6 / 10 | Reconst_loss: 1917.453 | Kldiv loss: 738.897 | Classifcation loss: 2.179 | Constrast loss: 17.15 | Total loss: 38621.150 | Train acc: 50.927 % ||| Val Loss: 37846.428 | Val acc: 51.579 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 7 / 10 | Reconst_loss: 2066.867 | Kldiv loss: 615.856 | Classifcation loss: 2.190 | Constrast loss: 17.91 | Total loss: 37415.250 | Train acc: 51.990 % ||| Val Loss: 36420.385 | Val acc: 52.290 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 8 / 10 | Reconst_loss: 1683.049 | Kldiv loss: 702.638 | Classifcation loss: 2.086 | Constrast loss: 16.78 | Total loss: 36425.329 | Train acc: 52.818 % ||| Val Loss: 36117.087 | Val acc: 53.055 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 9 / 10 | Reconst_loss: 1708.491 | Kldiv loss: 618.928 | Classifcation loss: 2.218 | Constrast loss: 24.35 | Total loss: 35744.314 | Train acc: 53.334 % ||| Val Loss: 35145.244 | Val acc: 53.263 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2023-02-27 05:08:04,935]\u001b[0m Trial 15 finished with value: 0.5331472982463082 and parameters: {'optuna_batch_size': 505, 'optimizer': 'Adam', 'lr': 0.004826744325701524, 'alpha': 6.085822592489251, 'beta': 7.139558316553357, 'gamma': 4.801971214679744, 'delta': 7.501802834361564}. Best is trial 11 with value: 0.7086864732074313.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 10 / 10 | Reconst_loss: 1791.632 | Kldiv loss: 619.720 | Classifcation loss: 2.155 | Constrast loss: 11.89 | Total loss: 35194.003 | Train acc: 53.315 % ||| Val Loss: 34437.512 | Val acc: 53.995 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 1 / 10 | Reconst_loss: 6018.383 | Kldiv loss: 1847.445 | Classifcation loss: 2.352 | Constrast loss: 326.39 | Total loss: 104596.075 | Train acc: 21.634 % ||| Val Loss: 49141.704 | Val acc: 27.991 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 2 / 10 | Reconst_loss: 5182.171 | Kldiv loss: 1629.632 | Classifcation loss: 2.330 | Constrast loss: 195.93 | Total loss: 46965.966 | Train acc: 33.331 % ||| Val Loss: 43615.935 | Val acc: 39.636 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 3 / 10 | Reconst_loss: 5281.197 | Kldiv loss: 1635.137 | Classifcation loss: 2.288 | Constrast loss: 176.03 | Total loss: 42400.518 | Train acc: 42.247 % ||| Val Loss: 39866.709 | Val acc: 46.868 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 4 / 10 | Reconst_loss: 5653.061 | Kldiv loss: 1428.752 | Classifcation loss: 2.253 | Constrast loss: 214.49 | Total loss: 39816.581 | Train acc: 47.512 % ||| Val Loss: 38325.008 | Val acc: 49.535 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 5 / 10 | Reconst_loss: 5001.548 | Kldiv loss: 1629.001 | Classifcation loss: 2.192 | Constrast loss: 92.47 | Total loss: 38447.239 | Train acc: 49.780 % ||| Val Loss: 36915.337 | Val acc: 50.649 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 6 / 10 | Reconst_loss: 5250.596 | Kldiv loss: 1526.354 | Classifcation loss: 2.161 | Constrast loss: 121.02 | Total loss: 37447.019 | Train acc: 52.144 % ||| Val Loss: 36007.830 | Val acc: 53.381 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 7 / 10 | Reconst_loss: 5138.305 | Kldiv loss: 1465.135 | Classifcation loss: 2.172 | Constrast loss: 129.40 | Total loss: 36608.691 | Train acc: 54.251 % ||| Val Loss: 35358.964 | Val acc: 55.657 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 8 / 10 | Reconst_loss: 5319.705 | Kldiv loss: 1507.748 | Classifcation loss: 2.164 | Constrast loss: 166.39 | Total loss: 36061.528 | Train acc: 55.930 % ||| Val Loss: 35198.229 | Val acc: 57.034 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 9 / 10 | Reconst_loss: 5289.769 | Kldiv loss: 1424.227 | Classifcation loss: 2.124 | Constrast loss: 65.04 | Total loss: 35466.411 | Train acc: 56.915 % ||| Val Loss: 34344.728 | Val acc: 57.383 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2023-02-27 05:08:26,089]\u001b[0m Trial 16 finished with value: 0.5753347753530915 and parameters: {'optuna_batch_size': 485, 'optimizer': 'RMSprop', 'lr': 0.0026317769914188257, 'alpha': 8.545625000845847, 'beta': 8.784268997968853, 'gamma': 0.572446927602229, 'delta': 9.921727013256158}. Best is trial 11 with value: 0.7086864732074313.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 10 / 10 | Reconst_loss: 5243.787 | Kldiv loss: 1453.893 | Classifcation loss: 2.239 | Constrast loss: 125.68 | Total loss: 34706.678 | Train acc: 57.533 % ||| Val Loss: 33933.736 | Val acc: 58.447 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 1 / 10 | Reconst_loss: 5773.121 | Kldiv loss: 1697.532 | Classifcation loss: 2.436 | Constrast loss: 294.09 | Total loss: 132148.917 | Train acc: 15.924 % ||| Val Loss: 39635.322 | Val acc: 28.500 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 2 / 10 | Reconst_loss: 4906.793 | Kldiv loss: 1471.445 | Classifcation loss: 2.299 | Constrast loss: 208.53 | Total loss: 35442.903 | Train acc: 35.678 % ||| Val Loss: 32416.752 | Val acc: 45.115 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 3 / 10 | Reconst_loss: 4156.540 | Kldiv loss: 1357.419 | Classifcation loss: 2.189 | Constrast loss: 135.50 | Total loss: 30991.336 | Train acc: 49.232 % ||| Val Loss: 29555.839 | Val acc: 53.195 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 4 / 10 | Reconst_loss: 4720.923 | Kldiv loss: 1288.271 | Classifcation loss: 2.192 | Constrast loss: 145.70 | Total loss: 28785.752 | Train acc: 58.375 % ||| Val Loss: 28455.717 | Val acc: 61.138 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 5 / 10 | Reconst_loss: 3550.733 | Kldiv loss: 1229.137 | Classifcation loss: 2.086 | Constrast loss: 154.03 | Total loss: 27556.670 | Train acc: 62.794 % ||| Val Loss: 27611.759 | Val acc: 62.553 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 6 / 10 | Reconst_loss: 3959.486 | Kldiv loss: 1282.753 | Classifcation loss: 2.074 | Constrast loss: 122.69 | Total loss: 26480.204 | Train acc: 64.633 % ||| Val Loss: 26292.909 | Val acc: 64.592 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 7 / 10 | Reconst_loss: 3424.340 | Kldiv loss: 1272.128 | Classifcation loss: 2.043 | Constrast loss: 70.55 | Total loss: 25750.431 | Train acc: 65.821 % ||| Val Loss: 25328.930 | Val acc: 65.434 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 8 / 10 | Reconst_loss: 4552.302 | Kldiv loss: 1273.650 | Classifcation loss: 2.017 | Constrast loss: 118.19 | Total loss: 25066.255 | Train acc: 66.734 % ||| Val Loss: 25292.423 | Val acc: 66.433 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 9 / 10 | Reconst_loss: 4295.058 | Kldiv loss: 1136.260 | Classifcation loss: 2.054 | Constrast loss: 91.85 | Total loss: 24718.308 | Train acc: 67.296 % ||| Val Loss: 24653.740 | Val acc: 66.794 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2023-02-27 05:08:46,682]\u001b[0m Trial 17 finished with value: 0.6801244660335211 and parameters: {'optuna_batch_size': 379, 'optimizer': 'Adam', 'lr': 0.005801942944535984, 'alpha': 5.822725855703346, 'beta': 9.902983410783248, 'gamma': 2.2916781938455215, 'delta': 5.1778221522684085}. Best is trial 11 with value: 0.7086864732074313.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 10 / 10 | Reconst_loss: 4681.586 | Kldiv loss: 1223.606 | Classifcation loss: 2.002 | Constrast loss: 97.12 | Total loss: 24415.160 | Train acc: 68.012 % ||| Val Loss: 24496.955 | Val acc: 67.221 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 1 / 10 | Reconst_loss: 299.320 | Kldiv loss: 4.032 | Classifcation loss: 2.500 | Constrast loss: 0.00 | Total loss: 24218.194 | Train acc: 23.251 % ||| Val Loss: 15115.021 | Val acc: 35.720 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 2 / 10 | Reconst_loss: 215.679 | Kldiv loss: 7.988 | Classifcation loss: 2.432 | Constrast loss: 0.00 | Total loss: 14677.706 | Train acc: 46.244 % ||| Val Loss: 16001.015 | Val acc: 36.028 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 3 / 10 | Reconst_loss: 46.668 | Kldiv loss: 15.957 | Classifcation loss: 2.035 | Constrast loss: 0.00 | Total loss: 13591.468 | Train acc: 55.911 % ||| Val Loss: 13666.389 | Val acc: 54.264 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 4 / 10 | Reconst_loss: 167.705 | Kldiv loss: 20.769 | Classifcation loss: 1.720 | Constrast loss: 0.00 | Total loss: 13031.966 | Train acc: 62.704 % ||| Val Loss: 12655.229 | Val acc: 66.714 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 5 / 10 | Reconst_loss: 45.523 | Kldiv loss: 11.561 | Classifcation loss: 1.716 | Constrast loss: 0.00 | Total loss: 12689.999 | Train acc: 67.736 % ||| Val Loss: 12132.883 | Val acc: 71.360 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 6 / 10 | Reconst_loss: 57.730 | Kldiv loss: 11.231 | Classifcation loss: 2.386 | Constrast loss: 0.00 | Total loss: 12353.380 | Train acc: 70.390 % ||| Val Loss: 12015.785 | Val acc: 73.367 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 7 / 10 | Reconst_loss: 138.508 | Kldiv loss: 20.256 | Classifcation loss: 1.785 | Constrast loss: 0.00 | Total loss: 12018.068 | Train acc: 72.189 % ||| Val Loss: 11483.375 | Val acc: 74.370 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 8 / 10 | Reconst_loss: 196.265 | Kldiv loss: 18.937 | Classifcation loss: 2.025 | Constrast loss: 0.00 | Total loss: 11790.457 | Train acc: 73.135 % ||| Val Loss: 11538.750 | Val acc: 74.917 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 9 / 10 | Reconst_loss: 54.198 | Kldiv loss: 11.023 | Classifcation loss: 2.027 | Constrast loss: 0.00 | Total loss: 11632.295 | Train acc: 73.725 % ||| Val Loss: 11471.379 | Val acc: 74.490 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2023-02-27 05:09:12,142]\u001b[0m Trial 18 finished with value: 0.7392859876023578 and parameters: {'optuna_batch_size': 179, 'optimizer': 'RMSprop', 'lr': 0.004241535378828112, 'alpha': 8.090879914376183, 'beta': 6.946878848461386, 'gamma': 0.22907758535130718, 'delta': 7.75461694301157}. Best is trial 18 with value: 0.7392859876023578.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 10 / 10 | Reconst_loss: 155.997 | Kldiv loss: 15.521 | Classifcation loss: 1.692 | Constrast loss: 0.00 | Total loss: 11518.302 | Train acc: 73.929 % ||| Val Loss: 11131.910 | Val acc: 75.972 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 1 / 10 | Reconst_loss: 3124.479 | Kldiv loss: 416.244 | Classifcation loss: 2.247 | Constrast loss: 108.70 | Total loss: 12361.757 | Train acc: 39.387 % ||| Val Loss: 10078.534 | Val acc: 54.842 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 2 / 10 | Reconst_loss: 2901.458 | Kldiv loss: 537.711 | Classifcation loss: 2.092 | Constrast loss: 65.97 | Total loss: 9829.983 | Train acc: 62.735 % ||| Val Loss: 9260.368 | Val acc: 68.197 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 3 / 10 | Reconst_loss: 3101.782 | Kldiv loss: 511.328 | Classifcation loss: 2.131 | Constrast loss: 81.51 | Total loss: 9338.980 | Train acc: 68.820 % ||| Val Loss: 8951.741 | Val acc: 72.523 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 4 / 10 | Reconst_loss: 2514.912 | Kldiv loss: 551.565 | Classifcation loss: 1.926 | Constrast loss: 42.44 | Total loss: 9078.614 | Train acc: 71.830 % ||| Val Loss: 8917.376 | Val acc: 73.608 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 5 / 10 | Reconst_loss: 2880.936 | Kldiv loss: 501.662 | Classifcation loss: 1.962 | Constrast loss: 69.63 | Total loss: 8842.792 | Train acc: 74.998 % ||| Val Loss: 8554.081 | Val acc: 76.678 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 6 / 10 | Reconst_loss: 2512.240 | Kldiv loss: 481.581 | Classifcation loss: 1.916 | Constrast loss: 24.34 | Total loss: 8663.389 | Train acc: 76.674 % ||| Val Loss: 8439.109 | Val acc: 77.233 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 7 / 10 | Reconst_loss: 2460.021 | Kldiv loss: 456.367 | Classifcation loss: 1.957 | Constrast loss: 44.35 | Total loss: 8478.492 | Train acc: 77.558 % ||| Val Loss: 8142.453 | Val acc: 78.103 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 8 / 10 | Reconst_loss: 2339.406 | Kldiv loss: 488.754 | Classifcation loss: 1.963 | Constrast loss: 35.91 | Total loss: 8311.582 | Train acc: 78.091 % ||| Val Loss: 8101.824 | Val acc: 79.323 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 9 / 10 | Reconst_loss: 2498.129 | Kldiv loss: 576.129 | Classifcation loss: 1.952 | Constrast loss: 12.16 | Total loss: 8214.691 | Train acc: 78.214 % ||| Val Loss: 7974.146 | Val acc: 80.056 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2023-02-27 05:09:40,709]\u001b[0m Trial 19 finished with value: 0.7874105244106601 and parameters: {'optuna_batch_size': 139, 'optimizer': 'RMSprop', 'lr': 0.004719220775933039, 'alpha': 8.280888310348951, 'beta': 6.828714629358917, 'gamma': 1.6879434577552987, 'delta': 6.021646289570443}. Best is trial 19 with value: 0.7874105244106601.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 10 / 10 | Reconst_loss: 2808.561 | Kldiv loss: 499.085 | Classifcation loss: 1.892 | Constrast loss: 27.47 | Total loss: 8095.939 | Train acc: 78.741 % ||| Val Loss: 8054.629 | Val acc: 80.127 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 1 / 10 | Reconst_loss: 16871.760 | Kldiv loss: 5246.145 | Classifcation loss: 2.288 | Constrast loss: 1033.50 | Total loss: 146842.738 | Train acc: 30.741 % ||| Val Loss: 64594.675 | Val acc: 41.970 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 2 / 10 | Reconst_loss: 13247.482 | Kldiv loss: 3848.346 | Classifcation loss: 2.240 | Constrast loss: 1008.11 | Total loss: 63255.779 | Train acc: 44.492 % ||| Val Loss: 56010.255 | Val acc: 49.085 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 3 / 10 | Reconst_loss: 14508.175 | Kldiv loss: 4382.979 | Classifcation loss: 2.224 | Constrast loss: 714.12 | Total loss: 57137.771 | Train acc: 48.174 % ||| Val Loss: 53967.570 | Val acc: 49.727 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 4 / 10 | Reconst_loss: 12228.262 | Kldiv loss: 3183.033 | Classifcation loss: 2.132 | Constrast loss: 593.90 | Total loss: 53275.638 | Train acc: 52.606 % ||| Val Loss: 48254.611 | Val acc: 57.602 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 5 / 10 | Reconst_loss: 12575.742 | Kldiv loss: 3454.642 | Classifcation loss: 2.142 | Constrast loss: 451.24 | Total loss: 50132.454 | Train acc: 58.010 % ||| Val Loss: 46616.688 | Val acc: 63.224 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 6 / 10 | Reconst_loss: 11823.656 | Kldiv loss: 3668.772 | Classifcation loss: 2.056 | Constrast loss: 363.08 | Total loss: 48270.181 | Train acc: 63.277 % ||| Val Loss: 44869.279 | Val acc: 65.723 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 7 / 10 | Reconst_loss: 11159.707 | Kldiv loss: 3199.878 | Classifcation loss: 2.041 | Constrast loss: 451.22 | Total loss: 46427.273 | Train acc: 66.911 % ||| Val Loss: 43552.324 | Val acc: 68.483 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 8 / 10 | Reconst_loss: 11246.390 | Kldiv loss: 2879.454 | Classifcation loss: 2.006 | Constrast loss: 255.09 | Total loss: 45323.465 | Train acc: 68.666 % ||| Val Loss: 41596.240 | Val acc: 71.589 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 9 / 10 | Reconst_loss: 11173.493 | Kldiv loss: 2632.977 | Classifcation loss: 1.985 | Constrast loss: 386.15 | Total loss: 43811.355 | Train acc: 70.497 % ||| Val Loss: 40631.503 | Val acc: 73.001 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2023-02-27 05:10:02,139]\u001b[0m Trial 20 finished with value: 0.7116912428928207 and parameters: {'optuna_batch_size': 615, 'optimizer': 'RMSprop', 'lr': 0.006616922409655494, 'alpha': 8.14611577931032, 'beta': 6.773118626096289, 'gamma': 0.18783197628407364, 'delta': 8.06746447279243}. Best is trial 19 with value: 0.7874105244106601.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 10 / 10 | Reconst_loss: 10707.510 | Kldiv loss: 3116.604 | Classifcation loss: 2.019 | Constrast loss: 338.66 | Total loss: 43583.441 | Train acc: 71.169 % ||| Val Loss: 40372.813 | Val acc: 73.385 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 1 / 10 | Reconst_loss: 498.788 | Kldiv loss: 131.476 | Classifcation loss: 2.563 | Constrast loss: 1.19 | Total loss: 180433.335 | Train acc: 26.730 % ||| Val Loss: 72048.342 | Val acc: 35.303 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 2 / 10 | Reconst_loss: 546.814 | Kldiv loss: 122.324 | Classifcation loss: 2.322 | Constrast loss: 1.12 | Total loss: 69830.655 | Train acc: 38.991 % ||| Val Loss: 67954.775 | Val acc: 39.887 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 3 / 10 | Reconst_loss: 371.040 | Kldiv loss: 102.572 | Classifcation loss: 2.192 | Constrast loss: 0.00 | Total loss: 64437.599 | Train acc: 43.899 % ||| Val Loss: 62036.831 | Val acc: 43.860 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 4 / 10 | Reconst_loss: 284.186 | Kldiv loss: 74.345 | Classifcation loss: 2.247 | Constrast loss: 0.60 | Total loss: 60790.912 | Train acc: 47.133 % ||| Val Loss: 58563.145 | Val acc: 49.765 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 5 / 10 | Reconst_loss: 199.624 | Kldiv loss: 107.614 | Classifcation loss: 2.468 | Constrast loss: 0.00 | Total loss: 57576.180 | Train acc: 51.542 % ||| Val Loss: 55866.473 | Val acc: 51.821 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 6 / 10 | Reconst_loss: 335.316 | Kldiv loss: 100.200 | Classifcation loss: 2.017 | Constrast loss: 0.00 | Total loss: 54887.147 | Train acc: 54.833 % ||| Val Loss: 52673.179 | Val acc: 55.054 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 7 / 10 | Reconst_loss: 293.627 | Kldiv loss: 91.684 | Classifcation loss: 2.126 | Constrast loss: 0.00 | Total loss: 52921.428 | Train acc: 56.003 % ||| Val Loss: 50563.807 | Val acc: 57.016 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 8 / 10 | Reconst_loss: 292.778 | Kldiv loss: 94.341 | Classifcation loss: 2.222 | Constrast loss: 0.00 | Total loss: 51539.070 | Train acc: 57.950 % ||| Val Loss: 49697.064 | Val acc: 59.266 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 9 / 10 | Reconst_loss: 222.770 | Kldiv loss: 158.331 | Classifcation loss: 2.188 | Constrast loss: 0.00 | Total loss: 49616.454 | Train acc: 59.992 % ||| Val Loss: 48330.567 | Val acc: 60.426 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2023-02-27 05:10:23,861]\u001b[0m Trial 21 finished with value: 0.6227977849841653 and parameters: {'optuna_batch_size': 651, 'optimizer': 'RMSprop', 'lr': 0.007054013630777302, 'alpha': 8.118506613073375, 'beta': 6.892185183792005, 'gamma': 0.21164001482467942, 'delta': 8.125092390102814}. Best is trial 19 with value: 0.7874105244106601.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 10 / 10 | Reconst_loss: 187.151 | Kldiv loss: 94.083 | Classifcation loss: 2.114 | Constrast loss: 0.66 | Total loss: 48626.640 | Train acc: 62.280 % ||| Val Loss: 46564.129 | Val acc: 65.602 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 1 / 10 | Reconst_loss: 1628.653 | Kldiv loss: 250.770 | Classifcation loss: 2.357 | Constrast loss: 10.10 | Total loss: 15538.989 | Train acc: 22.269 % ||| Val Loss: 12636.627 | Val acc: 30.047 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 2 / 10 | Reconst_loss: 1163.810 | Kldiv loss: 234.073 | Classifcation loss: 2.446 | Constrast loss: 31.84 | Total loss: 12509.460 | Train acc: 33.283 % ||| Val Loss: 11761.933 | Val acc: 35.596 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 3 / 10 | Reconst_loss: 1651.802 | Kldiv loss: 219.911 | Classifcation loss: 2.322 | Constrast loss: 15.32 | Total loss: 11837.577 | Train acc: 39.138 % ||| Val Loss: 11156.129 | Val acc: 42.049 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 4 / 10 | Reconst_loss: 1285.624 | Kldiv loss: 190.280 | Classifcation loss: 2.323 | Constrast loss: 12.64 | Total loss: 11001.183 | Train acc: 44.317 % ||| Val Loss: 10342.364 | Val acc: 45.842 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 5 / 10 | Reconst_loss: 1005.237 | Kldiv loss: 246.060 | Classifcation loss: 2.129 | Constrast loss: 1.20 | Total loss: 10604.397 | Train acc: 46.059 % ||| Val Loss: 10134.309 | Val acc: 47.677 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 6 / 10 | Reconst_loss: 686.200 | Kldiv loss: 230.285 | Classifcation loss: 2.140 | Constrast loss: 8.44 | Total loss: 10280.972 | Train acc: 47.693 % ||| Val Loss: 9966.210 | Val acc: 47.364 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 7 / 10 | Reconst_loss: 1354.272 | Kldiv loss: 229.275 | Classifcation loss: 2.126 | Constrast loss: 7.86 | Total loss: 10121.504 | Train acc: 48.051 % ||| Val Loss: 9971.260 | Val acc: 48.766 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 8 / 10 | Reconst_loss: 917.010 | Kldiv loss: 230.214 | Classifcation loss: 2.260 | Constrast loss: 2.78 | Total loss: 9904.673 | Train acc: 49.664 % ||| Val Loss: 9500.730 | Val acc: 50.783 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 9 / 10 | Reconst_loss: 953.442 | Kldiv loss: 246.761 | Classifcation loss: 2.135 | Constrast loss: 2.96 | Total loss: 9680.007 | Train acc: 50.691 % ||| Val Loss: 9451.706 | Val acc: 50.644 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2023-02-27 05:10:50,852]\u001b[0m Trial 22 finished with value: 0.5092795847220627 and parameters: {'optuna_batch_size': 154, 'optimizer': 'RMSprop', 'lr': 0.004764002886543785, 'alpha': 8.057628050718588, 'beta': 6.449289476973492, 'gamma': 0.10758160955759248, 'delta': 7.824721212341584}. Best is trial 19 with value: 0.7874105244106601.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 10 / 10 | Reconst_loss: 1185.190 | Kldiv loss: 225.437 | Classifcation loss: 2.265 | Constrast loss: 6.35 | Total loss: 9572.372 | Train acc: 50.928 % ||| Val Loss: 9322.543 | Val acc: 51.582 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 1 / 10 | Reconst_loss: 12535.489 | Kldiv loss: 3600.230 | Classifcation loss: 2.378 | Constrast loss: 692.46 | Total loss: 73806.534 | Train acc: 27.210 % ||| Val Loss: 44288.363 | Val acc: 34.942 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 2 / 10 | Reconst_loss: 10407.213 | Kldiv loss: 2640.313 | Classifcation loss: 2.243 | Constrast loss: 454.39 | Total loss: 40230.466 | Train acc: 41.129 % ||| Val Loss: 37671.968 | Val acc: 45.436 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 3 / 10 | Reconst_loss: 9621.574 | Kldiv loss: 2449.107 | Classifcation loss: 2.256 | Constrast loss: 507.65 | Total loss: 37569.936 | Train acc: 47.104 % ||| Val Loss: 35064.021 | Val acc: 49.597 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 4 / 10 | Reconst_loss: 10759.528 | Kldiv loss: 2960.936 | Classifcation loss: 2.199 | Constrast loss: 276.46 | Total loss: 35397.641 | Train acc: 50.233 % ||| Val Loss: 34174.575 | Val acc: 51.229 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 5 / 10 | Reconst_loss: 10384.065 | Kldiv loss: 3526.312 | Classifcation loss: 2.253 | Constrast loss: 307.13 | Total loss: 33755.015 | Train acc: 52.465 % ||| Val Loss: 33389.565 | Val acc: 53.199 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 6 / 10 | Reconst_loss: 9811.488 | Kldiv loss: 2607.882 | Classifcation loss: 2.165 | Constrast loss: 329.93 | Total loss: 32721.435 | Train acc: 53.552 % ||| Val Loss: 30914.093 | Val acc: 55.311 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 7 / 10 | Reconst_loss: 11441.490 | Kldiv loss: 2574.986 | Classifcation loss: 2.200 | Constrast loss: 508.17 | Total loss: 32111.974 | Train acc: 54.373 % ||| Val Loss: 33836.748 | Val acc: 52.823 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 8 / 10 | Reconst_loss: 8463.089 | Kldiv loss: 2304.641 | Classifcation loss: 2.159 | Constrast loss: 429.13 | Total loss: 31430.376 | Train acc: 54.916 % ||| Val Loss: 29586.982 | Val acc: 56.281 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 9 / 10 | Reconst_loss: 8928.490 | Kldiv loss: 2682.611 | Classifcation loss: 2.123 | Constrast loss: 240.35 | Total loss: 31047.996 | Train acc: 55.337 % ||| Val Loss: 29585.940 | Val acc: 56.718 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2023-02-27 05:11:09,508]\u001b[0m Trial 23 finished with value: 0.5580963602327033 and parameters: {'optuna_batch_size': 446, 'optimizer': 'RMSprop', 'lr': 0.0063523434319295415, 'alpha': 9.091926878119938, 'beta': 7.4187086784860785, 'gamma': 1.1516544900551586, 'delta': 9.192458818018663}. Best is trial 19 with value: 0.7874105244106601.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 10 / 10 | Reconst_loss: 8282.908 | Kldiv loss: 2906.884 | Classifcation loss: 2.111 | Constrast loss: 141.15 | Total loss: 30282.434 | Train acc: 55.810 % ||| Val Loss: 29451.924 | Val acc: 56.665 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 1 / 10 | Reconst_loss: 15111.105 | Kldiv loss: 4638.842 | Classifcation loss: 2.353 | Constrast loss: 1451.72 | Total loss: 134411.888 | Train acc: 25.053 % ||| Val Loss: 60896.610 | Val acc: 35.062 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 2 / 10 | Reconst_loss: 13716.150 | Kldiv loss: 4018.906 | Classifcation loss: 2.277 | Constrast loss: 879.70 | Total loss: 56979.452 | Train acc: 36.481 % ||| Val Loss: 52030.067 | Val acc: 41.987 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 3 / 10 | Reconst_loss: 14460.623 | Kldiv loss: 3774.203 | Classifcation loss: 2.253 | Constrast loss: 622.31 | Total loss: 52082.649 | Train acc: 43.697 % ||| Val Loss: 49352.190 | Val acc: 46.756 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 4 / 10 | Reconst_loss: 15529.370 | Kldiv loss: 3663.903 | Classifcation loss: 2.252 | Constrast loss: 948.41 | Total loss: 49856.730 | Train acc: 47.175 % ||| Val Loss: 48623.692 | Val acc: 49.528 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 5 / 10 | Reconst_loss: 14273.143 | Kldiv loss: 3428.169 | Classifcation loss: 2.254 | Constrast loss: 881.66 | Total loss: 48099.614 | Train acc: 48.877 % ||| Val Loss: 46768.671 | Val acc: 50.129 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 6 / 10 | Reconst_loss: 14411.369 | Kldiv loss: 3521.867 | Classifcation loss: 2.176 | Constrast loss: 643.43 | Total loss: 47082.707 | Train acc: 49.658 % ||| Val Loss: 44870.366 | Val acc: 51.782 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 7 / 10 | Reconst_loss: 12575.897 | Kldiv loss: 3608.083 | Classifcation loss: 2.184 | Constrast loss: 451.19 | Total loss: 45796.459 | Train acc: 50.737 % ||| Val Loss: 43720.274 | Val acc: 52.228 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 8 / 10 | Reconst_loss: 13224.809 | Kldiv loss: 3150.884 | Classifcation loss: 2.183 | Constrast loss: 555.73 | Total loss: 44844.797 | Train acc: 51.537 % ||| Val Loss: 42273.981 | Val acc: 54.209 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 9 / 10 | Reconst_loss: 13088.482 | Kldiv loss: 3575.080 | Classifcation loss: 2.190 | Constrast loss: 566.02 | Total loss: 43919.898 | Train acc: 52.058 % ||| Val Loss: 42506.930 | Val acc: 53.621 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2023-02-27 05:11:29,627]\u001b[0m Trial 24 finished with value: 0.5304686992661861 and parameters: {'optuna_batch_size': 580, 'optimizer': 'RMSprop', 'lr': 0.0047594786989160545, 'alpha': 7.9966350863665765, 'beta': 5.568431491163764, 'gamma': 1.844340504125797, 'delta': 8.04698289120069}. Best is trial 19 with value: 0.7874105244106601.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 10 / 10 | Reconst_loss: 12475.181 | Kldiv loss: 3069.116 | Classifcation loss: 2.128 | Constrast loss: 547.80 | Total loss: 43322.775 | Train acc: 53.047 % ||| Val Loss: 41403.119 | Val acc: 54.300 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 1 / 10 | Reconst_loss: 9304.074 | Kldiv loss: 2560.517 | Classifcation loss: 2.323 | Constrast loss: 490.31 | Total loss: 62450.700 | Train acc: 29.951 % ||| Val Loss: 36182.549 | Val acc: 42.863 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 2 / 10 | Reconst_loss: 9364.531 | Kldiv loss: 2249.623 | Classifcation loss: 2.206 | Constrast loss: 477.61 | Total loss: 35657.472 | Train acc: 48.473 % ||| Val Loss: 33332.745 | Val acc: 53.718 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 3 / 10 | Reconst_loss: 8701.804 | Kldiv loss: 2057.113 | Classifcation loss: 2.147 | Constrast loss: 402.02 | Total loss: 33305.619 | Train acc: 55.225 % ||| Val Loss: 30606.063 | Val acc: 58.585 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 4 / 10 | Reconst_loss: 8184.216 | Kldiv loss: 2230.508 | Classifcation loss: 2.056 | Constrast loss: 278.20 | Total loss: 31601.288 | Train acc: 59.506 % ||| Val Loss: 29378.091 | Val acc: 63.604 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 5 / 10 | Reconst_loss: 8947.428 | Kldiv loss: 2314.898 | Classifcation loss: 2.034 | Constrast loss: 130.48 | Total loss: 30210.865 | Train acc: 63.839 % ||| Val Loss: 29345.152 | Val acc: 65.093 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 6 / 10 | Reconst_loss: 7759.751 | Kldiv loss: 2212.447 | Classifcation loss: 1.989 | Constrast loss: 231.45 | Total loss: 29232.870 | Train acc: 66.057 % ||| Val Loss: 27224.092 | Val acc: 67.979 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 7 / 10 | Reconst_loss: 7507.610 | Kldiv loss: 2003.760 | Classifcation loss: 2.024 | Constrast loss: 179.62 | Total loss: 28670.329 | Train acc: 66.729 % ||| Val Loss: 27297.000 | Val acc: 69.049 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 8 / 10 | Reconst_loss: 7500.343 | Kldiv loss: 1924.830 | Classifcation loss: 2.000 | Constrast loss: 212.26 | Total loss: 28017.032 | Train acc: 67.836 % ||| Val Loss: 26310.279 | Val acc: 69.858 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 9 / 10 | Reconst_loss: 7073.552 | Kldiv loss: 2121.245 | Classifcation loss: 2.002 | Constrast loss: 187.45 | Total loss: 27599.183 | Train acc: 68.494 % ||| Val Loss: 26146.483 | Val acc: 70.034 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2023-02-27 05:11:50,320]\u001b[0m Trial 25 finished with value: 0.6956212643878942 and parameters: {'optuna_batch_size': 411, 'optimizer': 'RMSprop', 'lr': 0.005783294358100279, 'alpha': 7.5696959889388875, 'beta': 6.188908304752374, 'gamma': 0.8031906298248189, 'delta': 7.075061414183983}. Best is trial 19 with value: 0.7874105244106601.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 10 / 10 | Reconst_loss: 7556.950 | Kldiv loss: 1932.256 | Classifcation loss: 2.036 | Constrast loss: 305.74 | Total loss: 27070.790 | Train acc: 69.562 % ||| Val Loss: 25588.080 | Val acc: 70.979 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 1 / 10 | Reconst_loss: 723.627 | Kldiv loss: 312.063 | Classifcation loss: 2.315 | Constrast loss: 4.43 | Total loss: 178259.143 | Train acc: 21.637 % ||| Val Loss: 76735.168 | Val acc: 32.331 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 2 / 10 | Reconst_loss: 985.013 | Kldiv loss: 172.947 | Classifcation loss: 2.148 | Constrast loss: 4.02 | Total loss: 68814.295 | Train acc: 40.596 % ||| Val Loss: 61446.347 | Val acc: 44.586 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 3 / 10 | Reconst_loss: 941.109 | Kldiv loss: 166.958 | Classifcation loss: 2.252 | Constrast loss: 1.27 | Total loss: 59873.841 | Train acc: 48.592 % ||| Val Loss: 55373.076 | Val acc: 52.189 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 4 / 10 | Reconst_loss: 717.992 | Kldiv loss: 167.018 | Classifcation loss: 2.222 | Constrast loss: 1.60 | Total loss: 55825.482 | Train acc: 52.939 % ||| Val Loss: 56347.422 | Val acc: 52.933 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 5 / 10 | Reconst_loss: 811.428 | Kldiv loss: 160.829 | Classifcation loss: 2.220 | Constrast loss: 1.95 | Total loss: 53497.653 | Train acc: 54.994 % ||| Val Loss: 51201.180 | Val acc: 55.481 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 6 / 10 | Reconst_loss: 703.818 | Kldiv loss: 159.181 | Classifcation loss: 2.173 | Constrast loss: 3.78 | Total loss: 51479.487 | Train acc: 56.117 % ||| Val Loss: 50366.929 | Val acc: 56.273 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 7 / 10 | Reconst_loss: 523.814 | Kldiv loss: 126.826 | Classifcation loss: 2.281 | Constrast loss: 0.12 | Total loss: 50126.490 | Train acc: 56.880 % ||| Val Loss: 47700.988 | Val acc: 59.098 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 8 / 10 | Reconst_loss: 502.183 | Kldiv loss: 159.860 | Classifcation loss: 2.161 | Constrast loss: 0.00 | Total loss: 48573.665 | Train acc: 58.041 % ||| Val Loss: 47762.190 | Val acc: 57.334 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 9 / 10 | Reconst_loss: 534.661 | Kldiv loss: 156.856 | Classifcation loss: 2.057 | Constrast loss: 0.00 | Total loss: 47419.795 | Train acc: 59.268 % ||| Val Loss: 45549.500 | Val acc: 60.367 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2023-02-27 05:12:10,586]\u001b[0m Trial 26 finished with value: 0.6116592353666637 and parameters: {'optuna_batch_size': 635, 'optimizer': 'RMSprop', 'lr': 0.005166173283602819, 'alpha': 9.047195414421548, 'beta': 7.874008272763823, 'gamma': 1.7542802179172636, 'delta': 8.87919921786162}. Best is trial 19 with value: 0.7874105244106601.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 10 / 10 | Reconst_loss: 631.477 | Kldiv loss: 174.556 | Classifcation loss: 2.237 | Constrast loss: 1.70 | Total loss: 46108.143 | Train acc: 61.166 % ||| Val Loss: 44554.945 | Val acc: 62.472 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 1 / 10 | Reconst_loss: 3099.390 | Kldiv loss: 531.032 | Classifcation loss: 2.288 | Constrast loss: 79.77 | Total loss: 16515.211 | Train acc: 34.783 % ||| Val Loss: 12251.010 | Val acc: 45.196 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 2 / 10 | Reconst_loss: 2988.274 | Kldiv loss: 492.893 | Classifcation loss: 2.173 | Constrast loss: 91.42 | Total loss: 12051.677 | Train acc: 53.908 % ||| Val Loss: 11261.330 | Val acc: 60.280 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 3 / 10 | Reconst_loss: 2128.156 | Kldiv loss: 653.188 | Classifcation loss: 2.093 | Constrast loss: 27.96 | Total loss: 11510.792 | Train acc: 60.182 % ||| Val Loss: 10930.289 | Val acc: 65.227 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 4 / 10 | Reconst_loss: 2814.848 | Kldiv loss: 502.837 | Classifcation loss: 2.063 | Constrast loss: 64.14 | Total loss: 10972.695 | Train acc: 65.625 % ||| Val Loss: 10419.290 | Val acc: 69.496 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 5 / 10 | Reconst_loss: 2295.266 | Kldiv loss: 517.072 | Classifcation loss: 2.001 | Constrast loss: 32.77 | Total loss: 10584.407 | Train acc: 67.882 % ||| Val Loss: 9980.588 | Val acc: 70.555 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 6 / 10 | Reconst_loss: 1899.104 | Kldiv loss: 556.139 | Classifcation loss: 1.950 | Constrast loss: 42.83 | Total loss: 10280.986 | Train acc: 68.301 % ||| Val Loss: 9679.207 | Val acc: 70.257 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 7 / 10 | Reconst_loss: 2629.963 | Kldiv loss: 456.501 | Classifcation loss: 1.974 | Constrast loss: 50.00 | Total loss: 10155.542 | Train acc: 68.700 % ||| Val Loss: 9610.878 | Val acc: 69.844 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 8 / 10 | Reconst_loss: 2741.517 | Kldiv loss: 484.571 | Classifcation loss: 1.985 | Constrast loss: 55.70 | Total loss: 10000.513 | Train acc: 69.463 % ||| Val Loss: 9479.022 | Val acc: 71.106 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 9 / 10 | Reconst_loss: 2022.521 | Kldiv loss: 505.223 | Classifcation loss: 1.954 | Constrast loss: 18.08 | Total loss: 9912.135 | Train acc: 69.545 % ||| Val Loss: 9437.246 | Val acc: 69.180 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2023-02-27 05:12:37,252]\u001b[0m Trial 27 finished with value: 0.6900355182434613 and parameters: {'optuna_batch_size': 163, 'optimizer': 'RMSprop', 'lr': 0.007173328093453042, 'alpha': 8.46615902651586, 'beta': 6.5516473134723086, 'gamma': 0.7690447215654844, 'delta': 5.926967213163463}. Best is trial 19 with value: 0.7874105244106601.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 10 / 10 | Reconst_loss: 1847.000 | Kldiv loss: 517.296 | Classifcation loss: 1.915 | Constrast loss: 25.11 | Total loss: 9935.731 | Train acc: 69.004 % ||| Val Loss: 9653.823 | Val acc: 68.674 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 1 / 10 | Reconst_loss: 6195.461 | Kldiv loss: 1730.252 | Classifcation loss: 2.317 | Constrast loss: 365.31 | Total loss: 4406718.589 | Train acc: 27.545 % ||| Val Loss: 25906.085 | Val acc: 37.873 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 2 / 10 | Reconst_loss: 6664.567 | Kldiv loss: 1423.669 | Classifcation loss: 2.235 | Constrast loss: 263.85 | Total loss: 25047.714 | Train acc: 43.654 % ||| Val Loss: 24037.435 | Val acc: 46.830 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 3 / 10 | Reconst_loss: 6356.344 | Kldiv loss: 1300.468 | Classifcation loss: 2.153 | Constrast loss: 212.18 | Total loss: 23821.672 | Train acc: 50.954 % ||| Val Loss: 23066.445 | Val acc: 52.229 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 4 / 10 | Reconst_loss: 6667.653 | Kldiv loss: 1245.659 | Classifcation loss: 2.145 | Constrast loss: 164.18 | Total loss: 22865.980 | Train acc: 54.087 % ||| Val Loss: 22143.831 | Val acc: 54.595 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 5 / 10 | Reconst_loss: 6401.986 | Kldiv loss: 1021.639 | Classifcation loss: 2.112 | Constrast loss: 167.28 | Total loss: 22212.962 | Train acc: 55.708 % ||| Val Loss: 21684.664 | Val acc: 55.810 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 6 / 10 | Reconst_loss: 6559.557 | Kldiv loss: 1343.838 | Classifcation loss: 2.160 | Constrast loss: 145.26 | Total loss: 21738.495 | Train acc: 56.353 % ||| Val Loss: 21322.246 | Val acc: 55.914 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 7 / 10 | Reconst_loss: 6278.038 | Kldiv loss: 1204.271 | Classifcation loss: 2.136 | Constrast loss: 143.59 | Total loss: 21170.758 | Train acc: 58.303 % ||| Val Loss: 20556.644 | Val acc: 60.161 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 8 / 10 | Reconst_loss: 6534.086 | Kldiv loss: 1232.291 | Classifcation loss: 2.120 | Constrast loss: 177.00 | Total loss: 20598.862 | Train acc: 60.492 % ||| Val Loss: 19821.022 | Val acc: 61.772 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 9 / 10 | Reconst_loss: 5114.818 | Kldiv loss: 1294.942 | Classifcation loss: 2.045 | Constrast loss: 149.87 | Total loss: 20143.706 | Train acc: 62.641 % ||| Val Loss: 19461.905 | Val acc: 63.725 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2023-02-27 05:12:58,569]\u001b[0m Trial 28 finished with value: 0.6418208185045366 and parameters: {'optuna_batch_size': 276, 'optimizer': 'RMSprop', 'lr': 0.006356990700504342, 'alpha': 6.678471634972052, 'beta': 4.942050617034708, 'gamma': 2.4829365967887544, 'delta': 6.86282377974869}. Best is trial 19 with value: 0.7874105244106601.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 10 / 10 | Reconst_loss: 5189.060 | Kldiv loss: 1225.223 | Classifcation loss: 2.039 | Constrast loss: 137.70 | Total loss: 19743.914 | Train acc: 64.182 % ||| Val Loss: 18949.455 | Val acc: 65.853 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 1 / 10 | Reconst_loss: 23291.641 | Kldiv loss: 6705.981 | Classifcation loss: 2.303 | Constrast loss: 1954.97 | Total loss: 148787.393 | Train acc: 29.253 % ||| Val Loss: 76059.977 | Val acc: 37.523 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 2 / 10 | Reconst_loss: 23208.713 | Kldiv loss: 6045.253 | Classifcation loss: 2.210 | Constrast loss: 1165.07 | Total loss: 74218.449 | Train acc: 46.203 % ||| Val Loss: 68578.453 | Val acc: 47.864 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 3 / 10 | Reconst_loss: 20408.133 | Kldiv loss: 4591.954 | Classifcation loss: 2.145 | Constrast loss: 1070.47 | Total loss: 68275.792 | Train acc: 55.382 % ||| Val Loss: 63984.681 | Val acc: 61.516 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 4 / 10 | Reconst_loss: 20554.900 | Kldiv loss: 5163.661 | Classifcation loss: 2.095 | Constrast loss: 727.98 | Total loss: 65565.513 | Train acc: 58.655 % ||| Val Loss: 62302.885 | Val acc: 59.276 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 5 / 10 | Reconst_loss: 19548.756 | Kldiv loss: 5048.930 | Classifcation loss: 2.071 | Constrast loss: 917.71 | Total loss: 62919.265 | Train acc: 62.132 % ||| Val Loss: 59200.891 | Val acc: 62.283 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 6 / 10 | Reconst_loss: 17060.338 | Kldiv loss: 4346.262 | Classifcation loss: 2.009 | Constrast loss: 851.11 | Total loss: 60241.171 | Train acc: 65.630 % ||| Val Loss: 55137.275 | Val acc: 71.354 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 7 / 10 | Reconst_loss: 17250.604 | Kldiv loss: 4671.169 | Classifcation loss: 2.052 | Constrast loss: 1119.81 | Total loss: 58319.972 | Train acc: 69.217 % ||| Val Loss: 54634.230 | Val acc: 73.575 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 8 / 10 | Reconst_loss: 15902.768 | Kldiv loss: 5039.967 | Classifcation loss: 1.979 | Constrast loss: 821.48 | Total loss: 57499.985 | Train acc: 70.757 % ||| Val Loss: 53539.270 | Val acc: 74.224 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 9 / 10 | Reconst_loss: 17846.430 | Kldiv loss: 5170.268 | Classifcation loss: 1.954 | Constrast loss: 493.67 | Total loss: 55505.697 | Train acc: 73.145 % ||| Val Loss: 52094.413 | Val acc: 76.393 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2023-02-27 05:13:21,841]\u001b[0m Trial 29 finished with value: 0.7371519131877476 and parameters: {'optuna_batch_size': 705, 'optimizer': 'RMSprop', 'lr': 0.0076246127126403124, 'alpha': 7.569781980368177, 'beta': 6.885585159891202, 'gamma': 0.2721475985916, 'delta': 4.017815030192448}. Best is trial 19 with value: 0.7874105244106601.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 10 / 10 | Reconst_loss: 17511.082 | Kldiv loss: 4904.770 | Classifcation loss: 1.950 | Constrast loss: 687.82 | Total loss: 54807.130 | Train acc: 73.715 % ||| Val Loss: 50825.510 | Val acc: 77.970 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 1 / 10 | Reconst_loss: 9522.971 | Kldiv loss: 7328.455 | Classifcation loss: 2.488 | Constrast loss: 2508.63 | Total loss: 255513.060 | Train acc: 17.370 % ||| Val Loss: 162954.283 | Val acc: 23.483 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 2 / 10 | Reconst_loss: 9395.306 | Kldiv loss: 4870.400 | Classifcation loss: 2.454 | Constrast loss: 846.94 | Total loss: 153714.197 | Train acc: 26.854 % ||| Val Loss: 93118.057 | Val acc: 21.476 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 3 / 10 | Reconst_loss: 8241.372 | Kldiv loss: 2853.382 | Classifcation loss: 2.355 | Constrast loss: 355.26 | Total loss: 74299.475 | Train acc: 31.890 % ||| Val Loss: 64983.524 | Val acc: 41.750 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 4 / 10 | Reconst_loss: 7577.417 | Kldiv loss: 2540.675 | Classifcation loss: 2.279 | Constrast loss: 323.55 | Total loss: 67336.601 | Train acc: 43.826 % ||| Val Loss: 62626.915 | Val acc: 47.883 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 5 / 10 | Reconst_loss: 7834.601 | Kldiv loss: 2417.536 | Classifcation loss: 2.216 | Constrast loss: 206.52 | Total loss: 63182.370 | Train acc: 47.860 % ||| Val Loss: 57447.919 | Val acc: 51.501 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 6 / 10 | Reconst_loss: 7407.726 | Kldiv loss: 2633.904 | Classifcation loss: 2.185 | Constrast loss: 138.71 | Total loss: 60448.703 | Train acc: 49.649 % ||| Val Loss: 54826.812 | Val acc: 52.614 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 7 / 10 | Reconst_loss: 7084.827 | Kldiv loss: 2137.807 | Classifcation loss: 2.159 | Constrast loss: 171.62 | Total loss: 58389.581 | Train acc: 51.765 % ||| Val Loss: 53432.871 | Val acc: 54.491 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 8 / 10 | Reconst_loss: 7850.755 | Kldiv loss: 1825.150 | Classifcation loss: 2.293 | Constrast loss: 336.45 | Total loss: 56934.596 | Train acc: 52.880 % ||| Val Loss: 54194.622 | Val acc: 54.385 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 9 / 10 | Reconst_loss: 8363.111 | Kldiv loss: 1888.471 | Classifcation loss: 2.177 | Constrast loss: 207.58 | Total loss: 55669.629 | Train acc: 54.188 % ||| Val Loss: 54201.915 | Val acc: 56.142 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2023-02-27 05:13:43,607]\u001b[0m Trial 30 finished with value: 0.5541767474182295 and parameters: {'optuna_batch_size': 691, 'optimizer': 'RMSprop', 'lr': 0.007311511201884055, 'alpha': 7.580865348434209, 'beta': 4.246538524029619, 'gamma': 1.4326460660194282, 'delta': 3.756134372074066}. Best is trial 19 with value: 0.7874105244106601.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 10 / 10 | Reconst_loss: 7065.599 | Kldiv loss: 2368.767 | Classifcation loss: 2.194 | Constrast loss: 207.08 | Total loss: 54761.153 | Train acc: 55.418 % ||| Val Loss: 51153.361 | Val acc: 57.370 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 1 / 10 | Reconst_loss: 25413.904 | Kldiv loss: 9152.029 | Classifcation loss: 2.419 | Constrast loss: 4700.19 | Total loss: 229068.376 | Train acc: 20.178 % ||| Val Loss: 100528.476 | Val acc: 26.993 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 2 / 10 | Reconst_loss: 23782.500 | Kldiv loss: 8002.649 | Classifcation loss: 2.369 | Constrast loss: 3368.49 | Total loss: 91938.595 | Train acc: 31.219 % ||| Val Loss: 86107.604 | Val acc: 34.511 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 3 / 10 | Reconst_loss: 21818.818 | Kldiv loss: 7440.291 | Classifcation loss: 2.315 | Constrast loss: 2753.44 | Total loss: 85115.969 | Train acc: 35.203 % ||| Val Loss: 80147.587 | Val acc: 40.224 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 4 / 10 | Reconst_loss: 20626.637 | Kldiv loss: 7335.178 | Classifcation loss: 2.329 | Constrast loss: 2555.06 | Total loss: 80665.115 | Train acc: 37.772 % ||| Val Loss: 78010.173 | Val acc: 38.737 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 5 / 10 | Reconst_loss: 25697.736 | Kldiv loss: 7950.565 | Classifcation loss: 2.398 | Constrast loss: 2452.28 | Total loss: 76468.733 | Train acc: 38.983 % ||| Val Loss: 75564.528 | Val acc: 42.694 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 6 / 10 | Reconst_loss: 20832.502 | Kldiv loss: 6998.445 | Classifcation loss: 2.254 | Constrast loss: 1517.05 | Total loss: 73029.121 | Train acc: 41.091 % ||| Val Loss: 72242.008 | Val acc: 40.780 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 7 / 10 | Reconst_loss: 20179.699 | Kldiv loss: 7648.573 | Classifcation loss: 2.228 | Constrast loss: 1387.65 | Total loss: 71833.281 | Train acc: 42.424 % ||| Val Loss: 67964.310 | Val acc: 46.719 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 8 / 10 | Reconst_loss: 19455.689 | Kldiv loss: 7380.885 | Classifcation loss: 2.242 | Constrast loss: 1533.94 | Total loss: 69510.674 | Train acc: 44.886 % ||| Val Loss: 66909.636 | Val acc: 48.526 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 9 / 10 | Reconst_loss: 18849.131 | Kldiv loss: 6669.550 | Classifcation loss: 2.229 | Constrast loss: 1386.95 | Total loss: 68106.255 | Train acc: 46.549 % ||| Val Loss: 64399.427 | Val acc: 50.916 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2023-02-27 05:14:05,110]\u001b[0m Trial 31 finished with value: 0.47621065546313446 and parameters: {'optuna_batch_size': 756, 'optimizer': 'RMSprop', 'lr': 0.007606265910226082, 'alpha': 8.132269039808701, 'beta': 6.956863430251919, 'gamma': 0.3718747296717911, 'delta': 3.8218062650160345}. Best is trial 19 with value: 0.7874105244106601.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 10 / 10 | Reconst_loss: 18879.557 | Kldiv loss: 6760.856 | Classifcation loss: 2.197 | Constrast loss: 1163.16 | Total loss: 66156.775 | Train acc: 47.621 % ||| Val Loss: 64464.494 | Val acc: 50.794 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 1 / 10 | Reconst_loss: 14599.830 | Kldiv loss: 5174.354 | Classifcation loss: 2.405 | Constrast loss: 868.17 | Total loss: 249588.622 | Train acc: 20.134 % ||| Val Loss: 94377.083 | Val acc: 30.495 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 2 / 10 | Reconst_loss: 13673.355 | Kldiv loss: 4134.299 | Classifcation loss: 2.319 | Constrast loss: 501.10 | Total loss: 91402.296 | Train acc: 32.717 % ||| Val Loss: 81755.637 | Val acc: 37.460 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 3 / 10 | Reconst_loss: 11449.010 | Kldiv loss: 4549.601 | Classifcation loss: 2.328 | Constrast loss: 389.69 | Total loss: 82220.236 | Train acc: 36.669 % ||| Val Loss: 73836.817 | Val acc: 39.344 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 4 / 10 | Reconst_loss: 11099.496 | Kldiv loss: 4318.307 | Classifcation loss: 2.329 | Constrast loss: 568.60 | Total loss: 76292.764 | Train acc: 38.651 % ||| Val Loss: 72239.087 | Val acc: 40.967 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 5 / 10 | Reconst_loss: 10658.829 | Kldiv loss: 3452.801 | Classifcation loss: 2.255 | Constrast loss: 449.80 | Total loss: 73361.538 | Train acc: 43.227 % ||| Val Loss: 66960.679 | Val acc: 46.501 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 6 / 10 | Reconst_loss: 12240.989 | Kldiv loss: 3102.416 | Classifcation loss: 2.222 | Constrast loss: 387.86 | Total loss: 71172.985 | Train acc: 44.695 % ||| Val Loss: 64790.985 | Val acc: 47.077 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 7 / 10 | Reconst_loss: 9683.551 | Kldiv loss: 3252.228 | Classifcation loss: 2.232 | Constrast loss: 317.56 | Total loss: 68873.271 | Train acc: 45.867 % ||| Val Loss: 62413.074 | Val acc: 48.686 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 8 / 10 | Reconst_loss: 11503.619 | Kldiv loss: 3199.175 | Classifcation loss: 2.262 | Constrast loss: 361.44 | Total loss: 66558.262 | Train acc: 46.667 % ||| Val Loss: 60886.329 | Val acc: 49.308 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 9 / 10 | Reconst_loss: 10982.492 | Kldiv loss: 3183.271 | Classifcation loss: 2.208 | Constrast loss: 272.56 | Total loss: 64994.409 | Train acc: 47.620 % ||| Val Loss: 59523.267 | Val acc: 50.794 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2023-02-27 05:14:28,336]\u001b[0m Trial 32 finished with value: 0.4804974546037598 and parameters: {'optuna_batch_size': 808, 'optimizer': 'RMSprop', 'lr': 0.006507592632714543, 'alpha': 6.890565420229657, 'beta': 7.471614959559053, 'gamma': 0.18939462554584363, 'delta': 5.319341153138201}. Best is trial 19 with value: 0.7874105244106601.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 10 / 10 | Reconst_loss: 9948.422 | Kldiv loss: 3167.677 | Classifcation loss: 2.241 | Constrast loss: 224.17 | Total loss: 64661.914 | Train acc: 48.050 % ||| Val Loss: 58698.982 | Val acc: 50.763 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 1 / 10 | Reconst_loss: 1885.799 | Kldiv loss: 541.227 | Classifcation loss: 2.350 | Constrast loss: 16.15 | Total loss: 105926.597 | Train acc: 26.596 % ||| Val Loss: 58403.056 | Val acc: 34.976 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 2 / 10 | Reconst_loss: 1658.096 | Kldiv loss: 415.642 | Classifcation loss: 2.230 | Constrast loss: 10.04 | Total loss: 54924.406 | Train acc: 39.266 % ||| Val Loss: 52040.879 | Val acc: 41.967 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 3 / 10 | Reconst_loss: 2055.417 | Kldiv loss: 378.990 | Classifcation loss: 2.220 | Constrast loss: 8.62 | Total loss: 49686.800 | Train acc: 44.661 % ||| Val Loss: 47537.367 | Val acc: 46.658 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 4 / 10 | Reconst_loss: 1395.603 | Kldiv loss: 419.157 | Classifcation loss: 2.250 | Constrast loss: 5.46 | Total loss: 46633.090 | Train acc: 47.412 % ||| Val Loss: 44223.144 | Val acc: 50.214 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 5 / 10 | Reconst_loss: 1438.119 | Kldiv loss: 457.922 | Classifcation loss: 2.109 | Constrast loss: 12.55 | Total loss: 44874.498 | Train acc: 49.446 % ||| Val Loss: 42810.299 | Val acc: 53.461 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 6 / 10 | Reconst_loss: 1504.555 | Kldiv loss: 376.624 | Classifcation loss: 2.221 | Constrast loss: 14.49 | Total loss: 43755.382 | Train acc: 51.182 % ||| Val Loss: 43076.858 | Val acc: 52.142 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 7 / 10 | Reconst_loss: 1629.209 | Kldiv loss: 391.748 | Classifcation loss: 2.200 | Constrast loss: 6.82 | Total loss: 43042.437 | Train acc: 52.389 % ||| Val Loss: 41158.023 | Val acc: 53.673 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 8 / 10 | Reconst_loss: 1540.910 | Kldiv loss: 524.654 | Classifcation loss: 2.163 | Constrast loss: 3.30 | Total loss: 42333.618 | Train acc: 53.078 % ||| Val Loss: 41357.306 | Val acc: 53.854 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 9 / 10 | Reconst_loss: 1642.436 | Kldiv loss: 461.208 | Classifcation loss: 2.056 | Constrast loss: 1.00 | Total loss: 41653.125 | Train acc: 54.276 % ||| Val Loss: 40736.819 | Val acc: 54.771 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2023-02-27 05:14:47,592]\u001b[0m Trial 33 finished with value: 0.5682785164894393 and parameters: {'optuna_batch_size': 531, 'optimizer': 'RMSprop', 'lr': 0.00844400595686352, 'alpha': 9.378343670134038, 'beta': 5.7629711453343635, 'gamma': 0.9490840863360247, 'delta': 8.317298953014268}. Best is trial 19 with value: 0.7874105244106601.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 10 / 10 | Reconst_loss: 1438.340 | Kldiv loss: 463.156 | Classifcation loss: 2.026 | Constrast loss: 3.37 | Total loss: 40336.778 | Train acc: 56.828 % ||| Val Loss: 39645.302 | Val acc: 59.268 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 1 / 10 | Reconst_loss: 9193.494 | Kldiv loss: 2593.789 | Classifcation loss: 2.419 | Constrast loss: 589.58 | Total loss: 149371.987 | Train acc: 21.647 % ||| Val Loss: 66791.536 | Val acc: 32.875 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 2 / 10 | Reconst_loss: 8676.480 | Kldiv loss: 2156.067 | Classifcation loss: 2.327 | Constrast loss: 341.16 | Total loss: 64761.762 | Train acc: 36.134 % ||| Val Loss: 57761.851 | Val acc: 40.828 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 3 / 10 | Reconst_loss: 8533.955 | Kldiv loss: 2270.048 | Classifcation loss: 2.260 | Constrast loss: 328.90 | Total loss: 58846.754 | Train acc: 43.727 % ||| Val Loss: 53560.995 | Val acc: 48.709 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 4 / 10 | Reconst_loss: 7261.637 | Kldiv loss: 2709.080 | Classifcation loss: 2.214 | Constrast loss: 203.37 | Total loss: 55768.620 | Train acc: 48.990 % ||| Val Loss: 50992.194 | Val acc: 52.325 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 5 / 10 | Reconst_loss: 7677.528 | Kldiv loss: 2169.291 | Classifcation loss: 2.179 | Constrast loss: 205.27 | Total loss: 53080.740 | Train acc: 51.230 % ||| Val Loss: 48009.189 | Val acc: 54.678 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 6 / 10 | Reconst_loss: 6749.176 | Kldiv loss: 2052.394 | Classifcation loss: 2.151 | Constrast loss: 161.87 | Total loss: 50695.005 | Train acc: 54.075 % ||| Val Loss: 46902.110 | Val acc: 56.360 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 7 / 10 | Reconst_loss: 7350.406 | Kldiv loss: 2060.897 | Classifcation loss: 2.100 | Constrast loss: 173.43 | Total loss: 49318.641 | Train acc: 56.317 % ||| Val Loss: 45104.181 | Val acc: 58.512 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 8 / 10 | Reconst_loss: 6745.341 | Kldiv loss: 2027.516 | Classifcation loss: 2.133 | Constrast loss: 127.18 | Total loss: 47829.149 | Train acc: 57.748 % ||| Val Loss: 43855.969 | Val acc: 59.350 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 9 / 10 | Reconst_loss: 6022.972 | Kldiv loss: 1925.669 | Classifcation loss: 2.128 | Constrast loss: 162.11 | Total loss: 46935.959 | Train acc: 58.554 % ||| Val Loss: 43144.638 | Val acc: 60.630 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2023-02-27 05:15:07,151]\u001b[0m Trial 34 finished with value: 0.598764795442267 and parameters: {'optuna_batch_size': 617, 'optimizer': 'RMSprop', 'lr': 0.00554375770198276, 'alpha': 7.700678712084797, 'beta': 6.6915357888586815, 'gamma': 1.8956492285250968, 'delta': 4.2821260081100805}. Best is trial 19 with value: 0.7874105244106601.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 10 / 10 | Reconst_loss: 6958.687 | Kldiv loss: 2100.332 | Classifcation loss: 2.144 | Constrast loss: 166.92 | Total loss: 45940.597 | Train acc: 59.876 % ||| Val Loss: 43427.023 | Val acc: 60.345 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 1 / 10 | Reconst_loss: 18207.869 | Kldiv loss: 8641.753 | Classifcation loss: 2.364 | Constrast loss: 1615.21 | Total loss: 313674.438 | Train acc: 24.858 % ||| Val Loss: 118068.558 | Val acc: 35.861 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 2 / 10 | Reconst_loss: 17765.178 | Kldiv loss: 5855.774 | Classifcation loss: 2.334 | Constrast loss: 1604.02 | Total loss: 112569.090 | Train acc: 37.616 % ||| Val Loss: 105732.193 | Val acc: 39.584 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 3 / 10 | Reconst_loss: 20789.234 | Kldiv loss: 5549.207 | Classifcation loss: 2.300 | Constrast loss: 1101.25 | Total loss: 104068.656 | Train acc: 39.868 % ||| Val Loss: 100200.713 | Val acc: 41.298 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 4 / 10 | Reconst_loss: 18015.508 | Kldiv loss: 5196.684 | Classifcation loss: 2.250 | Constrast loss: 1050.37 | Total loss: 99402.809 | Train acc: 43.573 % ||| Val Loss: 95618.918 | Val acc: 46.243 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 5 / 10 | Reconst_loss: 18670.535 | Kldiv loss: 4846.556 | Classifcation loss: 2.247 | Constrast loss: 721.93 | Total loss: 96927.102 | Train acc: 44.623 % ||| Val Loss: 91844.556 | Val acc: 46.254 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 6 / 10 | Reconst_loss: 17862.633 | Kldiv loss: 5265.566 | Classifcation loss: 2.166 | Constrast loss: 624.57 | Total loss: 91858.562 | Train acc: 47.136 % ||| Val Loss: 89301.065 | Val acc: 50.679 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 7 / 10 | Reconst_loss: 16784.508 | Kldiv loss: 4081.358 | Classifcation loss: 2.204 | Constrast loss: 723.87 | Total loss: 89547.548 | Train acc: 48.519 % ||| Val Loss: 85537.204 | Val acc: 50.236 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 8 / 10 | Reconst_loss: 17212.473 | Kldiv loss: 4088.776 | Classifcation loss: 2.247 | Constrast loss: 652.65 | Total loss: 87595.801 | Train acc: 49.909 % ||| Val Loss: 83357.887 | Val acc: 52.065 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 9 / 10 | Reconst_loss: 17786.309 | Kldiv loss: 4838.769 | Classifcation loss: 2.186 | Constrast loss: 500.36 | Total loss: 85659.574 | Train acc: 50.996 % ||| Val Loss: 80809.134 | Val acc: 53.957 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2023-02-27 05:15:30,738]\u001b[0m Trial 35 finished with value: 0.5211006520416892 and parameters: {'optuna_batch_size': 921, 'optimizer': 'RMSprop', 'lr': 0.0067114005384752776, 'alpha': 8.543639004212672, 'beta': 0.19445702233667728, 'gamma': 0.9293891369716167, 'delta': 8.469382592327147}. Best is trial 19 with value: 0.7874105244106601.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 10 / 10 | Reconst_loss: 15186.555 | Kldiv loss: 4140.043 | Classifcation loss: 2.220 | Constrast loss: 605.87 | Total loss: 83673.408 | Train acc: 52.110 % ||| Val Loss: 80270.876 | Val acc: 55.144 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 1 / 10 | Reconst_loss: 1900.759 | Kldiv loss: 202.983 | Classifcation loss: 2.249 | Constrast loss: 23.70 | Total loss: 7203.647 | Train acc: 44.710 % ||| Val Loss: 5852.814 | Val acc: 62.117 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 2 / 10 | Reconst_loss: 1215.417 | Kldiv loss: 222.196 | Classifcation loss: 2.029 | Constrast loss: 14.16 | Total loss: 5662.154 | Train acc: 62.377 % ||| Val Loss: 5228.011 | Val acc: 66.430 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 3 / 10 | Reconst_loss: 1369.572 | Kldiv loss: 255.947 | Classifcation loss: 2.076 | Constrast loss: 8.61 | Total loss: 5262.801 | Train acc: 65.781 % ||| Val Loss: 5000.099 | Val acc: 67.452 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 4 / 10 | Reconst_loss: 840.723 | Kldiv loss: 237.676 | Classifcation loss: 2.019 | Constrast loss: 18.47 | Total loss: 5080.903 | Train acc: 66.827 % ||| Val Loss: 4896.904 | Val acc: 68.656 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 5 / 10 | Reconst_loss: 1269.036 | Kldiv loss: 286.760 | Classifcation loss: 2.042 | Constrast loss: 21.02 | Total loss: 4982.668 | Train acc: 71.483 % ||| Val Loss: 4796.146 | Val acc: 73.537 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 6 / 10 | Reconst_loss: 1253.978 | Kldiv loss: 252.633 | Classifcation loss: 1.992 | Constrast loss: 6.90 | Total loss: 4928.376 | Train acc: 72.217 % ||| Val Loss: 4720.699 | Val acc: 73.755 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 7 / 10 | Reconst_loss: 1185.354 | Kldiv loss: 251.905 | Classifcation loss: 1.949 | Constrast loss: 23.44 | Total loss: 4897.603 | Train acc: 72.715 % ||| Val Loss: 4699.995 | Val acc: 74.587 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 8 / 10 | Reconst_loss: 977.799 | Kldiv loss: 246.704 | Classifcation loss: 1.967 | Constrast loss: 15.77 | Total loss: 4849.933 | Train acc: 73.145 % ||| Val Loss: 4654.490 | Val acc: 74.151 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 9 / 10 | Reconst_loss: 1326.761 | Kldiv loss: 292.716 | Classifcation loss: 1.970 | Constrast loss: 8.62 | Total loss: 4817.451 | Train acc: 73.671 % ||| Val Loss: 4709.727 | Val acc: 72.373 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2023-02-27 05:16:13,527]\u001b[0m Trial 36 finished with value: 0.7332650196138628 and parameters: {'optuna_batch_size': 83, 'optimizer': 'RMSprop', 'lr': 0.0077733721271955585, 'alpha': 5.452670093419762, 'beta': 6.004751184430708, 'gamma': 1.3219224261335287, 'delta': 9.654242839794462}. Best is trial 19 with value: 0.7874105244106601.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 10 / 10 | Reconst_loss: 1681.220 | Kldiv loss: 232.092 | Classifcation loss: 2.037 | Constrast loss: 24.25 | Total loss: 4805.151 | Train acc: 73.327 % ||| Val Loss: 4847.241 | Val acc: 71.391 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 1 / 10 | Reconst_loss: 300.483 | Kldiv loss: 66.128 | Classifcation loss: 2.178 | Constrast loss: 0.58 | Total loss: 7953.529 | Train acc: 36.891 % ||| Val Loss: 6734.235 | Val acc: 50.486 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 2 / 10 | Reconst_loss: 223.901 | Kldiv loss: 77.445 | Classifcation loss: 1.875 | Constrast loss: 3.77 | Total loss: 6439.312 | Train acc: 58.058 % ||| Val Loss: 6058.098 | Val acc: 66.211 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 3 / 10 | Reconst_loss: 237.314 | Kldiv loss: 76.123 | Classifcation loss: 1.827 | Constrast loss: 0.00 | Total loss: 5896.576 | Train acc: 65.916 % ||| Val Loss: 5513.485 | Val acc: 70.471 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 4 / 10 | Reconst_loss: 392.009 | Kldiv loss: 65.985 | Classifcation loss: 2.058 | Constrast loss: 0.00 | Total loss: 5669.047 | Train acc: 68.290 % ||| Val Loss: 5422.039 | Val acc: 68.766 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 5 / 10 | Reconst_loss: 363.027 | Kldiv loss: 86.637 | Classifcation loss: 1.803 | Constrast loss: 0.00 | Total loss: 5560.907 | Train acc: 69.053 % ||| Val Loss: 5814.725 | Val acc: 68.720 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 6 / 10 | Reconst_loss: 318.331 | Kldiv loss: 47.702 | Classifcation loss: 2.091 | Constrast loss: 1.25 | Total loss: 5575.048 | Train acc: 68.891 % ||| Val Loss: 5599.296 | Val acc: 68.595 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 7 / 10 | Reconst_loss: 368.841 | Kldiv loss: 41.254 | Classifcation loss: 1.940 | Constrast loss: 1.67 | Total loss: 5450.551 | Train acc: 69.838 % ||| Val Loss: 5289.255 | Val acc: 69.263 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 8 / 10 | Reconst_loss: 313.665 | Kldiv loss: 69.050 | Classifcation loss: 1.875 | Constrast loss: 0.00 | Total loss: 5419.689 | Train acc: 69.999 % ||| Val Loss: 5216.414 | Val acc: 70.776 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 9 / 10 | Reconst_loss: 321.473 | Kldiv loss: 54.123 | Classifcation loss: 1.897 | Constrast loss: 0.06 | Total loss: 5353.244 | Train acc: 70.053 % ||| Val Loss: 5461.282 | Val acc: 69.783 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2023-02-27 05:16:54,470]\u001b[0m Trial 37 finished with value: 0.7023412493051954 and parameters: {'optuna_batch_size': 93, 'optimizer': 'RMSprop', 'lr': 0.007829806730102013, 'alpha': 5.297774791468458, 'beta': 6.087421087704899, 'gamma': 1.3878622102304976, 'delta': 9.9556943309808}. Best is trial 19 with value: 0.7874105244106601.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 10 / 10 | Reconst_loss: 151.762 | Kldiv loss: 65.491 | Classifcation loss: 2.097 | Constrast loss: 0.00 | Total loss: 5379.840 | Train acc: 70.234 % ||| Val Loss: 5206.978 | Val acc: 70.995 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 1 / 10 | Reconst_loss: 6177.736 | Kldiv loss: 3068.501 | Classifcation loss: 2.341 | Constrast loss: 1345.73 | Total loss: 38632.721 | Train acc: 21.886 % ||| Val Loss: 28961.265 | Val acc: 28.092 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 2 / 10 | Reconst_loss: 6876.090 | Kldiv loss: 1117.958 | Classifcation loss: 2.274 | Constrast loss: 273.08 | Total loss: 22977.190 | Train acc: 33.528 % ||| Val Loss: 16670.867 | Val acc: 40.699 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 3 / 10 | Reconst_loss: 6865.174 | Kldiv loss: 1221.677 | Classifcation loss: 2.244 | Constrast loss: 226.39 | Total loss: 16186.059 | Train acc: 43.830 % ||| Val Loss: 15688.800 | Val acc: 47.995 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 4 / 10 | Reconst_loss: 6321.637 | Kldiv loss: 957.759 | Classifcation loss: 2.301 | Constrast loss: 186.42 | Total loss: 15321.138 | Train acc: 48.484 % ||| Val Loss: 15162.173 | Val acc: 50.603 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 5 / 10 | Reconst_loss: 5637.570 | Kldiv loss: 760.975 | Classifcation loss: 2.236 | Constrast loss: 198.89 | Total loss: 14923.367 | Train acc: 50.626 % ||| Val Loss: 14276.616 | Val acc: 53.637 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 6 / 10 | Reconst_loss: 4564.671 | Kldiv loss: 990.953 | Classifcation loss: 2.074 | Constrast loss: 62.89 | Total loss: 14407.856 | Train acc: 56.351 % ||| Val Loss: 14280.924 | Val acc: 58.477 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 7 / 10 | Reconst_loss: 4735.807 | Kldiv loss: 835.366 | Classifcation loss: 2.024 | Constrast loss: 126.11 | Total loss: 14008.883 | Train acc: 59.593 % ||| Val Loss: 13365.413 | Val acc: 61.920 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 8 / 10 | Reconst_loss: 6586.677 | Kldiv loss: 1178.643 | Classifcation loss: 2.307 | Constrast loss: 220.10 | Total loss: 13714.261 | Train acc: 61.479 % ||| Val Loss: 15442.860 | Val acc: 58.857 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 9 / 10 | Reconst_loss: 4714.025 | Kldiv loss: 784.221 | Classifcation loss: 2.044 | Constrast loss: 119.39 | Total loss: 13478.635 | Train acc: 62.874 % ||| Val Loss: 12934.709 | Val acc: 63.740 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2023-02-27 05:17:18,955]\u001b[0m Trial 38 finished with value: 0.6361013241220497 and parameters: {'optuna_batch_size': 193, 'optimizer': 'RMSprop', 'lr': 0.009980969089178315, 'alpha': 4.894710694548126, 'beta': 5.37607535742805, 'gamma': 2.8799526134275943, 'delta': 9.60364020477835}. Best is trial 19 with value: 0.7874105244106601.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 10 / 10 | Reconst_loss: 5377.742 | Kldiv loss: 1077.162 | Classifcation loss: 2.015 | Constrast loss: 64.80 | Total loss: 13382.001 | Train acc: 63.610 % ||| Val Loss: 15207.889 | Val acc: 59.640 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 1 / 10 | Reconst_loss: 3340.646 | Kldiv loss: 551.338 | Classifcation loss: 2.219 | Constrast loss: 109.80 | Total loss: 10031.908 | Train acc: 41.014 % ||| Val Loss: 8593.117 | Val acc: 49.283 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 2 / 10 | Reconst_loss: 2880.690 | Kldiv loss: 496.679 | Classifcation loss: 2.052 | Constrast loss: 73.55 | Total loss: 7981.200 | Train acc: 56.794 % ||| Val Loss: 7343.568 | Val acc: 61.862 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 3 / 10 | Reconst_loss: 2829.747 | Kldiv loss: 532.999 | Classifcation loss: 2.046 | Constrast loss: 86.72 | Total loss: 7553.482 | Train acc: 62.597 % ||| Val Loss: 7384.620 | Val acc: 64.428 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 4 / 10 | Reconst_loss: 2471.136 | Kldiv loss: 514.645 | Classifcation loss: 2.027 | Constrast loss: 47.78 | Total loss: 7293.963 | Train acc: 64.524 % ||| Val Loss: 6917.904 | Val acc: 65.876 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 5 / 10 | Reconst_loss: 3197.603 | Kldiv loss: 509.382 | Classifcation loss: 2.008 | Constrast loss: 86.43 | Total loss: 7143.547 | Train acc: 66.348 % ||| Val Loss: 7010.615 | Val acc: 68.753 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 6 / 10 | Reconst_loss: 3058.859 | Kldiv loss: 607.048 | Classifcation loss: 2.003 | Constrast loss: 29.52 | Total loss: 7036.539 | Train acc: 67.260 % ||| Val Loss: 6796.787 | Val acc: 68.592 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 7 / 10 | Reconst_loss: 2552.397 | Kldiv loss: 464.460 | Classifcation loss: 1.993 | Constrast loss: 96.20 | Total loss: 6927.255 | Train acc: 67.454 % ||| Val Loss: 7026.670 | Val acc: 66.782 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 8 / 10 | Reconst_loss: 2400.894 | Kldiv loss: 496.815 | Classifcation loss: 2.017 | Constrast loss: 70.68 | Total loss: 6923.069 | Train acc: 67.266 % ||| Val Loss: 6974.695 | Val acc: 68.934 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 9 / 10 | Reconst_loss: 2503.339 | Kldiv loss: 528.142 | Classifcation loss: 2.012 | Constrast loss: 30.40 | Total loss: 6857.281 | Train acc: 67.795 % ||| Val Loss: 6851.029 | Val acc: 65.592 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2023-02-27 05:17:52,549]\u001b[0m Trial 39 finished with value: 0.6733457127499975 and parameters: {'optuna_batch_size': 113, 'optimizer': 'RMSprop', 'lr': 0.008349454281847333, 'alpha': 6.486453330915346, 'beta': 6.010929449940265, 'gamma': 1.9836254281593084, 'delta': 9.084207176146519}. Best is trial 19 with value: 0.7874105244106601.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 10 / 10 | Reconst_loss: 3131.234 | Kldiv loss: 555.637 | Classifcation loss: 2.084 | Constrast loss: 49.79 | Total loss: 6914.595 | Train acc: 67.335 % ||| Val Loss: 7208.038 | Val acc: 64.719 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 1 / 10 | Reconst_loss: 278.673 | Kldiv loss: 45.370 | Classifcation loss: 2.037 | Constrast loss: 3.08 | Total loss: 841.938 | Train acc: 42.817 % ||| Val Loss: 735.408 | Val acc: 55.845 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 2 / 10 | Reconst_loss: 256.079 | Kldiv loss: 53.664 | Classifcation loss: 2.294 | Constrast loss: 1.20 | Total loss: 724.535 | Train acc: 57.114 % ||| Val Loss: 698.454 | Val acc: 58.080 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 3 / 10 | Reconst_loss: 287.559 | Kldiv loss: 45.559 | Classifcation loss: 2.147 | Constrast loss: 5.57 | Total loss: 711.338 | Train acc: 59.343 % ||| Val Loss: 685.233 | Val acc: 63.234 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 4 / 10 | Reconst_loss: 435.066 | Kldiv loss: 44.404 | Classifcation loss: 2.021 | Constrast loss: 0.82 | Total loss: 708.854 | Train acc: 61.510 % ||| Val Loss: 712.357 | Val acc: 62.941 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 5 / 10 | Reconst_loss: 285.270 | Kldiv loss: 49.179 | Classifcation loss: 1.854 | Constrast loss: 0.13 | Total loss: 709.549 | Train acc: 61.850 % ||| Val Loss: 681.171 | Val acc: 64.110 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 6 / 10 | Reconst_loss: 450.593 | Kldiv loss: 43.957 | Classifcation loss: 2.122 | Constrast loss: 1.93 | Total loss: 698.769 | Train acc: 63.532 % ||| Val Loss: 683.568 | Val acc: 63.689 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 7 / 10 | Reconst_loss: 201.590 | Kldiv loss: 39.629 | Classifcation loss: 1.942 | Constrast loss: 2.73 | Total loss: 695.769 | Train acc: 63.751 % ||| Val Loss: 673.464 | Val acc: 64.818 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 8 / 10 | Reconst_loss: 309.488 | Kldiv loss: 49.862 | Classifcation loss: 1.982 | Constrast loss: 2.50 | Total loss: 706.276 | Train acc: 63.419 % ||| Val Loss: 683.239 | Val acc: 64.714 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 9 / 10 | Reconst_loss: 175.292 | Kldiv loss: 54.540 | Classifcation loss: 2.030 | Constrast loss: 3.68 | Total loss: 702.778 | Train acc: 63.745 % ||| Val Loss: 692.659 | Val acc: 64.069 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2023-02-27 05:22:08,566]\u001b[0m Trial 40 finished with value: 0.6455117868386709 and parameters: {'optuna_batch_size': 12, 'optimizer': 'RMSprop', 'lr': 0.005861181793773917, 'alpha': 4.168162842186266, 'beta': 4.383589084033595, 'gamma': 1.24892947162737, 'delta': 8.831024517439548}. Best is trial 19 with value: 0.7874105244106601.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 10 / 10 | Reconst_loss: 170.318 | Kldiv loss: 51.226 | Classifcation loss: 2.066 | Constrast loss: 5.38 | Total loss: 699.852 | Train acc: 64.551 % ||| Val Loss: 671.922 | Val acc: 65.221 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 1 / 10 | Reconst_loss: 9065.072 | Kldiv loss: 3257.776 | Classifcation loss: 2.332 | Constrast loss: 405.10 | Total loss: 171579.724 | Train acc: 26.504 % ||| Val Loss: 74877.301 | Val acc: 37.874 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 2 / 10 | Reconst_loss: 9287.033 | Kldiv loss: 2529.708 | Classifcation loss: 2.271 | Constrast loss: 288.23 | Total loss: 74081.851 | Train acc: 42.360 % ||| Val Loss: 67415.155 | Val acc: 45.582 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 3 / 10 | Reconst_loss: 8471.817 | Kldiv loss: 2285.413 | Classifcation loss: 2.214 | Constrast loss: 233.17 | Total loss: 68346.414 | Train acc: 47.266 % ||| Val Loss: 62140.471 | Val acc: 52.124 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 4 / 10 | Reconst_loss: 7825.395 | Kldiv loss: 2166.993 | Classifcation loss: 2.239 | Constrast loss: 258.37 | Total loss: 64192.611 | Train acc: 50.511 % ||| Val Loss: 59353.268 | Val acc: 52.930 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 5 / 10 | Reconst_loss: 9485.548 | Kldiv loss: 2231.371 | Classifcation loss: 2.159 | Constrast loss: 143.03 | Total loss: 61640.741 | Train acc: 55.150 % ||| Val Loss: 58447.345 | Val acc: 57.401 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 6 / 10 | Reconst_loss: 9948.563 | Kldiv loss: 2561.663 | Classifcation loss: 2.131 | Constrast loss: 307.04 | Total loss: 60182.488 | Train acc: 56.936 % ||| Val Loss: 59799.192 | Val acc: 59.477 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 7 / 10 | Reconst_loss: 8466.715 | Kldiv loss: 2073.957 | Classifcation loss: 2.083 | Constrast loss: 128.63 | Total loss: 58778.979 | Train acc: 59.039 % ||| Val Loss: 53855.231 | Val acc: 61.732 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 8 / 10 | Reconst_loss: 7978.536 | Kldiv loss: 2121.074 | Classifcation loss: 2.078 | Constrast loss: 98.02 | Total loss: 57910.203 | Train acc: 59.674 % ||| Val Loss: 52839.513 | Val acc: 64.706 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 9 / 10 | Reconst_loss: 7716.278 | Kldiv loss: 2060.481 | Classifcation loss: 2.057 | Constrast loss: 108.31 | Total loss: 56798.622 | Train acc: 61.376 % ||| Val Loss: 52002.631 | Val acc: 65.458 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2023-02-27 05:22:29,166]\u001b[0m Trial 41 finished with value: 0.6392901696019588 and parameters: {'optuna_batch_size': 691, 'optimizer': 'RMSprop', 'lr': 0.009294208626530569, 'alpha': 6.875422098250624, 'beta': 6.8043564394987825, 'gamma': 0.5781091268840388, 'delta': 7.975211048915318}. Best is trial 19 with value: 0.7874105244106601.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 10 / 10 | Reconst_loss: 7812.954 | Kldiv loss: 1843.688 | Classifcation loss: 2.077 | Constrast loss: 134.22 | Total loss: 54889.920 | Train acc: 63.929 % ||| Val Loss: 51220.771 | Val acc: 64.278 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 1 / 10 | Reconst_loss: 8279.913 | Kldiv loss: 2422.016 | Classifcation loss: 2.413 | Constrast loss: 1072.56 | Total loss: 113514845750.476 | Train acc: 21.893 % ||| Val Loss: 35639.691 | Val acc: 25.403 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 2 / 10 | Reconst_loss: 8513.701 | Kldiv loss: 2246.018 | Classifcation loss: 2.388 | Constrast loss: 798.61 | Total loss: 34203.280 | Train acc: 26.928 % ||| Val Loss: 31904.755 | Val acc: 28.810 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 3 / 10 | Reconst_loss: 7882.991 | Kldiv loss: 2301.562 | Classifcation loss: 2.412 | Constrast loss: 800.98 | Total loss: 32463.820 | Train acc: 29.406 % ||| Val Loss: 31144.616 | Val acc: 31.390 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 4 / 10 | Reconst_loss: 7896.997 | Kldiv loss: 2671.614 | Classifcation loss: 2.361 | Constrast loss: 638.56 | Total loss: 31754.213 | Train acc: 30.784 % ||| Val Loss: 30504.753 | Val acc: 32.171 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 5 / 10 | Reconst_loss: 8047.311 | Kldiv loss: 2498.479 | Classifcation loss: 2.355 | Constrast loss: 690.53 | Total loss: 31394.482 | Train acc: 31.543 % ||| Val Loss: 30393.568 | Val acc: 33.109 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 6 / 10 | Reconst_loss: 8720.259 | Kldiv loss: 2271.437 | Classifcation loss: 2.419 | Constrast loss: 766.43 | Total loss: 31078.725 | Train acc: 32.302 % ||| Val Loss: 30430.373 | Val acc: 33.463 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 7 / 10 | Reconst_loss: 7083.878 | Kldiv loss: 2265.469 | Classifcation loss: 2.353 | Constrast loss: 718.96 | Total loss: 30935.546 | Train acc: 33.592 % ||| Val Loss: 30097.103 | Val acc: 35.355 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 8 / 10 | Reconst_loss: 8171.835 | Kldiv loss: 2282.077 | Classifcation loss: 2.346 | Constrast loss: 710.28 | Total loss: 30806.207 | Train acc: 34.744 % ||| Val Loss: 30110.965 | Val acc: 36.409 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 9 / 10 | Reconst_loss: 7164.933 | Kldiv loss: 2194.190 | Classifcation loss: 2.365 | Constrast loss: 693.96 | Total loss: 30716.421 | Train acc: 35.605 % ||| Val Loss: 29760.315 | Val acc: 35.969 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2023-02-27 05:22:50,686]\u001b[0m Trial 42 finished with value: 0.3621119125846808 and parameters: {'optuna_batch_size': 318, 'optimizer': 'RMSprop', 'lr': 0.00868639249725449, 'alpha': 7.582618211004345, 'beta': 6.365886640229547, 'gamma': 0.528143560834037, 'delta': 7.635575308840176}. Best is trial 19 with value: 0.7874105244106601.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 10 / 10 | Reconst_loss: 7270.862 | Kldiv loss: 2406.176 | Classifcation loss: 2.338 | Constrast loss: 698.62 | Total loss: 30468.247 | Train acc: 36.211 % ||| Val Loss: 29849.882 | Val acc: 36.556 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 1 / 10 | Reconst_loss: 1683.735 | Kldiv loss: 294.258 | Classifcation loss: 2.124 | Constrast loss: 27.34 | Total loss: 4647.990 | Train acc: 46.773 % ||| Val Loss: 4421.826 | Val acc: 54.414 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 2 / 10 | Reconst_loss: 1384.456 | Kldiv loss: 221.490 | Classifcation loss: 1.988 | Constrast loss: 33.55 | Total loss: 3839.382 | Train acc: 69.358 % ||| Val Loss: 3557.459 | Val acc: 71.430 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 3 / 10 | Reconst_loss: 1002.156 | Kldiv loss: 251.572 | Classifcation loss: 1.898 | Constrast loss: 24.23 | Total loss: 3601.771 | Train acc: 73.242 % ||| Val Loss: 3388.550 | Val acc: 75.490 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 4 / 10 | Reconst_loss: 1735.437 | Kldiv loss: 297.683 | Classifcation loss: 1.891 | Constrast loss: 12.76 | Total loss: 3530.582 | Train acc: 74.479 % ||| Val Loss: 4175.680 | Val acc: 68.027 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 5 / 10 | Reconst_loss: 2047.766 | Kldiv loss: 276.255 | Classifcation loss: 2.090 | Constrast loss: 47.92 | Total loss: 3549.679 | Train acc: 74.574 % ||| Val Loss: 3868.386 | Val acc: 75.895 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 6 / 10 | Reconst_loss: 1160.214 | Kldiv loss: 275.107 | Classifcation loss: 1.923 | Constrast loss: 17.62 | Total loss: 3509.871 | Train acc: 75.326 % ||| Val Loss: 3422.113 | Val acc: 72.998 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 7 / 10 | Reconst_loss: 1672.348 | Kldiv loss: 274.007 | Classifcation loss: 2.023 | Constrast loss: 20.35 | Total loss: 3448.251 | Train acc: 73.993 % ||| Val Loss: 3760.503 | Val acc: 66.977 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 8 / 10 | Reconst_loss: 1292.069 | Kldiv loss: 272.671 | Classifcation loss: 1.802 | Constrast loss: 7.43 | Total loss: 3396.882 | Train acc: 74.798 % ||| Val Loss: 3498.923 | Val acc: 75.246 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 9 / 10 | Reconst_loss: 1268.324 | Kldiv loss: 277.641 | Classifcation loss: 1.839 | Constrast loss: 17.38 | Total loss: 3372.436 | Train acc: 75.896 % ||| Val Loss: 3365.704 | Val acc: 74.258 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2023-02-27 05:23:47,305]\u001b[0m Trial 43 finished with value: 0.7612334967748915 and parameters: {'optuna_batch_size': 59, 'optimizer': 'RMSprop', 'lr': 0.007966595572081295, 'alpha': 5.77206140457089, 'beta': 7.378876655738958, 'gamma': 1.4893881113126912, 'delta': 8.407388577478905}. Best is trial 19 with value: 0.7874105244106601.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 10 / 10 | Reconst_loss: 1076.884 | Kldiv loss: 270.688 | Classifcation loss: 1.900 | Constrast loss: 10.32 | Total loss: 3408.987 | Train acc: 76.123 % ||| Val Loss: 3264.619 | Val acc: 77.661 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 1 / 10 | Reconst_loss: 3040.435 | Kldiv loss: 392.771 | Classifcation loss: 2.205 | Constrast loss: 45.81 | Total loss: 12072.239 | Train acc: 39.801 % ||| Val Loss: 9974.880 | Val acc: 50.287 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 2 / 10 | Reconst_loss: 3151.053 | Kldiv loss: 370.276 | Classifcation loss: 2.097 | Constrast loss: 25.19 | Total loss: 9905.129 | Train acc: 52.967 % ||| Val Loss: 9185.740 | Val acc: 58.819 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 3 / 10 | Reconst_loss: 3137.211 | Kldiv loss: 353.674 | Classifcation loss: 2.207 | Constrast loss: 47.81 | Total loss: 9401.143 | Train acc: 59.047 % ||| Val Loss: 9187.628 | Val acc: 58.618 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 4 / 10 | Reconst_loss: 2527.256 | Kldiv loss: 401.951 | Classifcation loss: 2.122 | Constrast loss: 45.74 | Total loss: 9230.701 | Train acc: 60.752 % ||| Val Loss: 8840.193 | Val acc: 61.308 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 5 / 10 | Reconst_loss: 2267.103 | Kldiv loss: 372.390 | Classifcation loss: 2.096 | Constrast loss: 32.51 | Total loss: 9019.788 | Train acc: 62.491 % ||| Val Loss: 8724.022 | Val acc: 62.232 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 6 / 10 | Reconst_loss: 2500.279 | Kldiv loss: 337.395 | Classifcation loss: 2.072 | Constrast loss: 43.02 | Total loss: 8841.388 | Train acc: 64.260 % ||| Val Loss: 8551.354 | Val acc: 66.460 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 7 / 10 | Reconst_loss: 2527.618 | Kldiv loss: 433.692 | Classifcation loss: 2.057 | Constrast loss: 17.39 | Total loss: 8765.753 | Train acc: 65.103 % ||| Val Loss: 8485.101 | Val acc: 66.708 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 8 / 10 | Reconst_loss: 2318.501 | Kldiv loss: 396.923 | Classifcation loss: 1.985 | Constrast loss: 31.03 | Total loss: 8609.980 | Train acc: 66.271 % ||| Val Loss: 8361.684 | Val acc: 68.083 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 9 / 10 | Reconst_loss: 2318.755 | Kldiv loss: 455.036 | Classifcation loss: 2.056 | Constrast loss: 24.80 | Total loss: 8595.139 | Train acc: 66.114 % ||| Val Loss: 8670.520 | Val acc: 64.350 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2023-02-27 05:24:18,484]\u001b[0m Trial 44 finished with value: 0.6407480462722798 and parameters: {'optuna_batch_size': 130, 'optimizer': 'RMSprop', 'lr': 0.00902353794672669, 'alpha': 5.727740441637538, 'beta': 7.4683273999699225, 'gamma': 1.5017528330121381, 'delta': 9.431552523797484}. Best is trial 19 with value: 0.7874105244106601.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 10 / 10 | Reconst_loss: 2362.677 | Kldiv loss: 424.155 | Classifcation loss: 2.025 | Constrast loss: 30.66 | Total loss: 8647.707 | Train acc: 64.075 % ||| Val Loss: 8381.143 | Val acc: 63.390 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 1 / 10 | Reconst_loss: 368.728 | Kldiv loss: 73.950 | Classifcation loss: 1.982 | Constrast loss: 0.00 | Total loss: 4552.864 | Train acc: 49.496 % ||| Val Loss: 3811.499 | Val acc: 65.101 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 2 / 10 | Reconst_loss: 366.776 | Kldiv loss: 51.816 | Classifcation loss: 1.914 | Constrast loss: 0.64 | Total loss: 3771.514 | Train acc: 67.695 % ||| Val Loss: 3599.415 | Val acc: 71.540 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 3 / 10 | Reconst_loss: 155.795 | Kldiv loss: 52.749 | Classifcation loss: 2.070 | Constrast loss: 0.00 | Total loss: 3620.994 | Train acc: 71.544 % ||| Val Loss: 3486.300 | Val acc: 73.034 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 4 / 10 | Reconst_loss: 613.223 | Kldiv loss: 72.198 | Classifcation loss: 1.980 | Constrast loss: 0.16 | Total loss: 3546.944 | Train acc: 72.643 % ||| Val Loss: 3981.918 | Val acc: 69.256 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 5 / 10 | Reconst_loss: 308.688 | Kldiv loss: 51.660 | Classifcation loss: 2.019 | Constrast loss: 0.00 | Total loss: 3510.422 | Train acc: 73.525 % ||| Val Loss: 3367.063 | Val acc: 74.902 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 6 / 10 | Reconst_loss: 249.151 | Kldiv loss: 80.305 | Classifcation loss: 1.856 | Constrast loss: 3.02 | Total loss: 3483.165 | Train acc: 74.202 % ||| Val Loss: 3589.805 | Val acc: 72.790 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 7 / 10 | Reconst_loss: 337.914 | Kldiv loss: 72.749 | Classifcation loss: 2.106 | Constrast loss: 0.41 | Total loss: 3467.318 | Train acc: 74.033 % ||| Val Loss: 3420.328 | Val acc: 74.922 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 8 / 10 | Reconst_loss: 153.574 | Kldiv loss: 49.409 | Classifcation loss: 2.021 | Constrast loss: 2.93 | Total loss: 3474.030 | Train acc: 73.995 % ||| Val Loss: 3385.559 | Val acc: 73.534 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 9 / 10 | Reconst_loss: 262.035 | Kldiv loss: 63.670 | Classifcation loss: 1.731 | Constrast loss: 0.01 | Total loss: 3479.332 | Train acc: 74.166 % ||| Val Loss: 3356.336 | Val acc: 76.477 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2023-02-27 05:25:14,026]\u001b[0m Trial 45 finished with value: 0.7500958956655157 and parameters: {'optuna_batch_size': 60, 'optimizer': 'RMSprop', 'lr': 0.007655803501157023, 'alpha': 4.344466100138756, 'beta': 5.25895915933238, 'gamma': 2.2596388021411524, 'delta': 8.756551622552905}. Best is trial 19 with value: 0.7874105244106601.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 10 / 10 | Reconst_loss: 198.161 | Kldiv loss: 50.043 | Classifcation loss: 1.971 | Constrast loss: 2.81 | Total loss: 3436.219 | Train acc: 75.010 % ||| Val Loss: 3363.538 | Val acc: 73.126 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 1 / 10 | Reconst_loss: 1366.460 | Kldiv loss: 137.359 | Classifcation loss: 2.100 | Constrast loss: 18.99 | Total loss: 3346.059 | Train acc: 48.680 % ||| Val Loss: 2979.796 | Val acc: 63.906 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 2 / 10 | Reconst_loss: 1044.782 | Kldiv loss: 165.459 | Classifcation loss: 1.955 | Constrast loss: 34.26 | Total loss: 2832.030 | Train acc: 69.402 % ||| Val Loss: 2658.690 | Val acc: 72.985 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 3 / 10 | Reconst_loss: 950.720 | Kldiv loss: 177.146 | Classifcation loss: 1.956 | Constrast loss: 8.59 | Total loss: 2722.222 | Train acc: 71.604 % ||| Val Loss: 2674.076 | Val acc: 72.255 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 4 / 10 | Reconst_loss: 854.843 | Kldiv loss: 199.498 | Classifcation loss: 1.938 | Constrast loss: 5.38 | Total loss: 2614.253 | Train acc: 73.883 % ||| Val Loss: 2819.859 | Val acc: 71.602 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 5 / 10 | Reconst_loss: 964.735 | Kldiv loss: 184.804 | Classifcation loss: 1.865 | Constrast loss: 9.40 | Total loss: 2553.962 | Train acc: 75.077 % ||| Val Loss: 2506.056 | Val acc: 74.323 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 6 / 10 | Reconst_loss: 829.290 | Kldiv loss: 176.011 | Classifcation loss: 2.110 | Constrast loss: 11.86 | Total loss: 2534.421 | Train acc: 75.141 % ||| Val Loss: 2474.767 | Val acc: 74.856 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 7 / 10 | Reconst_loss: 803.994 | Kldiv loss: 193.267 | Classifcation loss: 2.014 | Constrast loss: 16.32 | Total loss: 2545.949 | Train acc: 73.187 % ||| Val Loss: 2511.175 | Val acc: 68.660 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 8 / 10 | Reconst_loss: 829.223 | Kldiv loss: 191.829 | Classifcation loss: 1.996 | Constrast loss: 20.00 | Total loss: 2610.226 | Train acc: 67.970 % ||| Val Loss: 2587.917 | Val acc: 70.140 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 9 / 10 | Reconst_loss: 594.905 | Kldiv loss: 172.481 | Classifcation loss: 1.995 | Constrast loss: 36.03 | Total loss: 2565.701 | Train acc: 70.176 % ||| Val Loss: 2498.952 | Val acc: 71.969 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2023-02-27 05:26:25,770]\u001b[0m Trial 46 finished with value: 0.6981898802211306 and parameters: {'optuna_batch_size': 44, 'optimizer': 'RMSprop', 'lr': 0.007951472255509335, 'alpha': 4.246039200978231, 'beta': 5.038504777118756, 'gamma': 3.0202354303496355, 'delta': 8.581838809317372}. Best is trial 19 with value: 0.7874105244106601.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 10 / 10 | Reconst_loss: 977.117 | Kldiv loss: 198.805 | Classifcation loss: 1.962 | Constrast loss: 14.39 | Total loss: 2522.500 | Train acc: 69.819 % ||| Val Loss: 2480.733 | Val acc: 69.852 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 1 / 10 | Reconst_loss: 3334.208 | Kldiv loss: 662.072 | Classifcation loss: 2.332 | Constrast loss: 123.72 | Total loss: 26211.159 | Train acc: 28.104 % ||| Val Loss: 18522.383 | Val acc: 30.361 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 2 / 10 | Reconst_loss: 3087.898 | Kldiv loss: 693.389 | Classifcation loss: 2.161 | Constrast loss: 79.10 | Total loss: 14279.509 | Train acc: 48.658 % ||| Val Loss: 13023.781 | Val acc: 54.780 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 3 / 10 | Reconst_loss: 2276.088 | Kldiv loss: 692.758 | Classifcation loss: 2.111 | Constrast loss: 81.91 | Total loss: 12659.191 | Train acc: 58.525 % ||| Val Loss: 12607.079 | Val acc: 59.575 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 4 / 10 | Reconst_loss: 2691.143 | Kldiv loss: 790.273 | Classifcation loss: 2.058 | Constrast loss: 42.94 | Total loss: 12191.894 | Train acc: 61.411 % ||| Val Loss: 12155.682 | Val acc: 62.347 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 5 / 10 | Reconst_loss: 2087.409 | Kldiv loss: 651.722 | Classifcation loss: 1.999 | Constrast loss: 44.13 | Total loss: 11947.054 | Train acc: 61.867 % ||| Val Loss: 12773.067 | Val acc: 58.466 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 6 / 10 | Reconst_loss: 2436.967 | Kldiv loss: 653.178 | Classifcation loss: 2.082 | Constrast loss: 72.01 | Total loss: 11745.864 | Train acc: 62.807 % ||| Val Loss: 11719.461 | Val acc: 63.330 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 7 / 10 | Reconst_loss: 2162.508 | Kldiv loss: 655.516 | Classifcation loss: 2.058 | Constrast loss: 50.60 | Total loss: 11574.244 | Train acc: 63.193 % ||| Val Loss: 11690.622 | Val acc: 63.318 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 8 / 10 | Reconst_loss: 2198.279 | Kldiv loss: 631.823 | Classifcation loss: 2.055 | Constrast loss: 81.45 | Total loss: 11532.835 | Train acc: 63.228 % ||| Val Loss: 11517.207 | Val acc: 62.659 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 9 / 10 | Reconst_loss: 2913.504 | Kldiv loss: 691.834 | Classifcation loss: 2.031 | Constrast loss: 23.58 | Total loss: 11325.652 | Train acc: 63.614 % ||| Val Loss: 11257.326 | Val acc: 63.330 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2023-02-27 05:26:54,465]\u001b[0m Trial 47 finished with value: 0.641022664437508 and parameters: {'optuna_batch_size': 187, 'optimizer': 'Adam', 'lr': 0.008778175069512539, 'alpha': 3.0784286286469187, 'beta': 5.419582261725213, 'gamma': 2.2655557819585037, 'delta': 7.470520262320026}. Best is trial 19 with value: 0.7874105244106601.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 10 / 10 | Reconst_loss: 2833.171 | Kldiv loss: 666.807 | Classifcation loss: 1.986 | Constrast loss: 29.60 | Total loss: 11345.093 | Train acc: 64.102 % ||| Val Loss: 11168.135 | Val acc: 64.489 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 1 / 10 | Reconst_loss: 227.948 | Kldiv loss: 46.996 | Classifcation loss: 2.223 | Constrast loss: 3.97 | Total loss: 5783.012 | Train acc: 36.696 % ||| Val Loss: 4067.617 | Val acc: 54.374 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 2 / 10 | Reconst_loss: 464.629 | Kldiv loss: 53.302 | Classifcation loss: 2.028 | Constrast loss: 1.21 | Total loss: 4059.592 | Train acc: 57.054 % ||| Val Loss: 3962.326 | Val acc: 58.684 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 3 / 10 | Reconst_loss: 330.040 | Kldiv loss: 42.882 | Classifcation loss: 2.109 | Constrast loss: 5.92 | Total loss: 3870.388 | Train acc: 61.993 % ||| Val Loss: 3651.794 | Val acc: 63.862 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 4 / 10 | Reconst_loss: 185.998 | Kldiv loss: 58.043 | Classifcation loss: 1.940 | Constrast loss: 0.00 | Total loss: 3789.158 | Train acc: 64.231 % ||| Val Loss: 3589.556 | Val acc: 66.686 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 5 / 10 | Reconst_loss: 281.582 | Kldiv loss: 41.274 | Classifcation loss: 2.188 | Constrast loss: 1.79 | Total loss: 3754.596 | Train acc: 65.040 % ||| Val Loss: 3633.961 | Val acc: 65.653 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 6 / 10 | Reconst_loss: 342.662 | Kldiv loss: 71.562 | Classifcation loss: 2.028 | Constrast loss: 2.48 | Total loss: 3712.946 | Train acc: 66.024 % ||| Val Loss: 3657.639 | Val acc: 66.847 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 7 / 10 | Reconst_loss: 361.065 | Kldiv loss: 53.738 | Classifcation loss: 2.153 | Constrast loss: 0.10 | Total loss: 3710.239 | Train acc: 66.144 % ||| Val Loss: 3631.356 | Val acc: 66.531 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 8 / 10 | Reconst_loss: 236.022 | Kldiv loss: 75.084 | Classifcation loss: 1.866 | Constrast loss: 0.00 | Total loss: 3707.954 | Train acc: 67.467 % ||| Val Loss: 3544.893 | Val acc: 67.656 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 9 / 10 | Reconst_loss: 235.599 | Kldiv loss: 64.117 | Classifcation loss: 2.135 | Constrast loss: 2.50 | Total loss: 3669.863 | Train acc: 66.906 % ||| Val Loss: 3523.884 | Val acc: 67.111 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2023-02-27 05:27:47,679]\u001b[0m Trial 48 finished with value: 0.6696904606651084 and parameters: {'optuna_batch_size': 62, 'optimizer': 'RMSprop', 'lr': 0.009528273030254242, 'alpha': 6.553279167132152, 'beta': 8.36048647649309, 'gamma': 2.0719656226493823, 'delta': 7.158150698738277}. Best is trial 19 with value: 0.7874105244106601.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 10 / 10 | Reconst_loss: 209.068 | Kldiv loss: 61.714 | Classifcation loss: 2.161 | Constrast loss: 0.98 | Total loss: 3679.043 | Train acc: 66.969 % ||| Val Loss: 3845.023 | Val acc: 65.107 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 1 / 10 | Reconst_loss: 5239.536 | Kldiv loss: 1060.456 | Classifcation loss: 2.341 | Constrast loss: 225.00 | Total loss: 2446789.022 | Train acc: 26.183 % ||| Val Loss: 22046.977 | Val acc: 36.557 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 2 / 10 | Reconst_loss: 4695.848 | Kldiv loss: 995.658 | Classifcation loss: 2.302 | Constrast loss: 212.68 | Total loss: 21305.342 | Train acc: 41.252 % ||| Val Loss: 18879.778 | Val acc: 48.876 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 3 / 10 | Reconst_loss: 3507.563 | Kldiv loss: 1005.989 | Classifcation loss: 2.084 | Constrast loss: 72.62 | Total loss: 18793.493 | Train acc: 52.978 % ||| Val Loss: 17313.490 | Val acc: 61.088 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 4 / 10 | Reconst_loss: 3372.254 | Kldiv loss: 924.431 | Classifcation loss: 1.987 | Constrast loss: 80.75 | Total loss: 17604.836 | Train acc: 62.376 % ||| Val Loss: 16432.762 | Val acc: 66.816 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 5 / 10 | Reconst_loss: 3381.604 | Kldiv loss: 866.857 | Classifcation loss: 2.020 | Constrast loss: 103.07 | Total loss: 17016.839 | Train acc: 65.711 % ||| Val Loss: 15829.021 | Val acc: 68.439 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 6 / 10 | Reconst_loss: 3503.580 | Kldiv loss: 790.249 | Classifcation loss: 2.082 | Constrast loss: 91.59 | Total loss: 16505.367 | Train acc: 67.662 % ||| Val Loss: 16083.648 | Val acc: 67.414 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 7 / 10 | Reconst_loss: 3283.498 | Kldiv loss: 813.342 | Classifcation loss: 1.962 | Constrast loss: 95.66 | Total loss: 15943.035 | Train acc: 69.295 % ||| Val Loss: 14970.116 | Val acc: 70.264 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 8 / 10 | Reconst_loss: 3122.869 | Kldiv loss: 837.630 | Classifcation loss: 1.892 | Constrast loss: 54.81 | Total loss: 15780.721 | Train acc: 70.604 % ||| Val Loss: 14772.833 | Val acc: 76.912 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 9 / 10 | Reconst_loss: 3878.092 | Kldiv loss: 790.165 | Classifcation loss: 1.955 | Constrast loss: 83.71 | Total loss: 15623.845 | Train acc: 74.831 % ||| Val Loss: 14652.551 | Val acc: 77.380 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2023-02-27 05:28:11,001]\u001b[0m Trial 49 finished with value: 0.7566186616074511 and parameters: {'optuna_batch_size': 234, 'optimizer': 'RMSprop', 'lr': 0.0073973289421470695, 'alpha': 6.135792358695679, 'beta': 8.003569225508933, 'gamma': 1.6918360960527496, 'delta': 6.624488043443004}. Best is trial 19 with value: 0.7874105244106601.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 10 / 10 | Reconst_loss: 3547.989 | Kldiv loss: 779.354 | Classifcation loss: 1.956 | Constrast loss: 63.66 | Total loss: 15384.658 | Train acc: 75.662 % ||| Val Loss: 14505.601 | Val acc: 78.442 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 1 / 10 | Reconst_loss: 4375.720 | Kldiv loss: 951.840 | Classifcation loss: 2.386 | Constrast loss: 200.44 | Total loss: 45395.176 | Train acc: 20.980 % ||| Val Loss: 20547.816 | Val acc: 37.605 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 2 / 10 | Reconst_loss: 3471.180 | Kldiv loss: 885.838 | Classifcation loss: 2.275 | Constrast loss: 121.98 | Total loss: 18846.596 | Train acc: 46.726 % ||| Val Loss: 17146.080 | Val acc: 55.363 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 3 / 10 | Reconst_loss: 2941.052 | Kldiv loss: 827.827 | Classifcation loss: 2.112 | Constrast loss: 112.45 | Total loss: 16446.810 | Train acc: 57.556 % ||| Val Loss: 15741.298 | Val acc: 59.904 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 4 / 10 | Reconst_loss: 2803.507 | Kldiv loss: 873.074 | Classifcation loss: 2.077 | Constrast loss: 107.52 | Total loss: 15572.754 | Train acc: 60.634 % ||| Val Loss: 15231.716 | Val acc: 61.906 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 5 / 10 | Reconst_loss: 2974.448 | Kldiv loss: 843.978 | Classifcation loss: 2.061 | Constrast loss: 72.30 | Total loss: 15191.784 | Train acc: 61.944 % ||| Val Loss: 14960.333 | Val acc: 61.935 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 6 / 10 | Reconst_loss: 3116.908 | Kldiv loss: 877.986 | Classifcation loss: 2.060 | Constrast loss: 99.71 | Total loss: 14989.161 | Train acc: 62.264 % ||| Val Loss: 14651.920 | Val acc: 62.625 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 7 / 10 | Reconst_loss: 2674.496 | Kldiv loss: 894.052 | Classifcation loss: 2.099 | Constrast loss: 77.11 | Total loss: 14697.657 | Train acc: 62.851 % ||| Val Loss: 14656.499 | Val acc: 62.471 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 8 / 10 | Reconst_loss: 2980.821 | Kldiv loss: 883.143 | Classifcation loss: 2.103 | Constrast loss: 83.17 | Total loss: 14508.853 | Train acc: 63.371 % ||| Val Loss: 14452.693 | Val acc: 63.290 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 9 / 10 | Reconst_loss: 2725.203 | Kldiv loss: 917.699 | Classifcation loss: 2.131 | Constrast loss: 98.51 | Total loss: 14352.680 | Train acc: 63.871 % ||| Val Loss: 14098.506 | Val acc: 63.890 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2023-02-27 05:28:35,654]\u001b[0m Trial 50 finished with value: 0.6428695320459337 and parameters: {'optuna_batch_size': 233, 'optimizer': 'Adam', 'lr': 0.006927463433905121, 'alpha': 6.278517683791077, 'beta': 9.06929624359394, 'gamma': 2.5031375446678235, 'delta': 6.858088635390682}. Best is trial 19 with value: 0.7874105244106601.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 10 / 10 | Reconst_loss: 3246.904 | Kldiv loss: 855.674 | Classifcation loss: 2.097 | Constrast loss: 73.21 | Total loss: 14214.120 | Train acc: 64.287 % ||| Val Loss: 14205.793 | Val acc: 64.931 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 1 / 10 | Reconst_loss: 3015.004 | Kldiv loss: 378.831 | Classifcation loss: 2.221 | Constrast loss: 71.43 | Total loss: 18158.454 | Train acc: 29.956 % ||| Val Loss: 9667.644 | Val acc: 45.704 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 2 / 10 | Reconst_loss: 2215.069 | Kldiv loss: 428.900 | Classifcation loss: 2.173 | Constrast loss: 53.23 | Total loss: 9355.556 | Train acc: 51.394 % ||| Val Loss: 9068.993 | Val acc: 53.906 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 3 / 10 | Reconst_loss: 1930.055 | Kldiv loss: 449.640 | Classifcation loss: 2.120 | Constrast loss: 48.19 | Total loss: 8759.902 | Train acc: 56.414 % ||| Val Loss: 8149.301 | Val acc: 60.057 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 4 / 10 | Reconst_loss: 2065.776 | Kldiv loss: 567.488 | Classifcation loss: 2.066 | Constrast loss: 22.83 | Total loss: 8499.074 | Train acc: 59.398 % ||| Val Loss: 8490.274 | Val acc: 57.147 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 5 / 10 | Reconst_loss: 2300.168 | Kldiv loss: 486.068 | Classifcation loss: 2.035 | Constrast loss: 10.35 | Total loss: 8321.524 | Train acc: 61.811 % ||| Val Loss: 7932.934 | Val acc: 63.083 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 6 / 10 | Reconst_loss: 1958.926 | Kldiv loss: 381.160 | Classifcation loss: 2.127 | Constrast loss: 70.53 | Total loss: 8130.268 | Train acc: 63.553 % ||| Val Loss: 7897.207 | Val acc: 64.754 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 7 / 10 | Reconst_loss: 1759.315 | Kldiv loss: 431.123 | Classifcation loss: 2.028 | Constrast loss: 11.34 | Total loss: 7939.014 | Train acc: 65.010 % ||| Val Loss: 7793.829 | Val acc: 65.870 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 8 / 10 | Reconst_loss: 2499.640 | Kldiv loss: 423.045 | Classifcation loss: 2.128 | Constrast loss: 25.83 | Total loss: 7868.597 | Train acc: 65.635 % ||| Val Loss: 7706.715 | Val acc: 66.824 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 9 / 10 | Reconst_loss: 1513.910 | Kldiv loss: 451.652 | Classifcation loss: 1.991 | Constrast loss: 24.61 | Total loss: 7787.986 | Train acc: 66.662 % ||| Val Loss: 7361.491 | Val acc: 67.005 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2023-02-27 05:29:05,765]\u001b[0m Trial 51 finished with value: 0.6671160063565127 and parameters: {'optuna_batch_size': 132, 'optimizer': 'RMSprop', 'lr': 0.008380967519997173, 'alpha': 7.174067263840188, 'beta': 8.102121873830754, 'gamma': 1.6920132447185632, 'delta': 6.443314851725785}. Best is trial 19 with value: 0.7874105244106601.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 10 / 10 | Reconst_loss: 1978.271 | Kldiv loss: 448.729 | Classifcation loss: 2.039 | Constrast loss: 54.20 | Total loss: 7692.720 | Train acc: 66.712 % ||| Val Loss: 7387.884 | Val acc: 67.402 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 1 / 10 | Reconst_loss: 1570.771 | Kldiv loss: 316.340 | Classifcation loss: 2.287 | Constrast loss: 6.78 | Total loss: 36537.194 | Train acc: 34.289 % ||| Val Loss: 24075.063 | Val acc: 49.035 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 2 / 10 | Reconst_loss: 1165.085 | Kldiv loss: 237.559 | Classifcation loss: 2.141 | Constrast loss: 9.48 | Total loss: 23727.222 | Train acc: 52.947 % ||| Val Loss: 21615.913 | Val acc: 59.170 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 3 / 10 | Reconst_loss: 845.749 | Kldiv loss: 188.054 | Classifcation loss: 2.192 | Constrast loss: 12.28 | Total loss: 22210.579 | Train acc: 60.053 % ||| Val Loss: 20613.058 | Val acc: 62.882 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 4 / 10 | Reconst_loss: 1000.521 | Kldiv loss: 247.670 | Classifcation loss: 2.077 | Constrast loss: 3.18 | Total loss: 21473.576 | Train acc: 63.108 % ||| Val Loss: 20091.689 | Val acc: 66.933 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 5 / 10 | Reconst_loss: 727.632 | Kldiv loss: 206.452 | Classifcation loss: 2.094 | Constrast loss: 1.41 | Total loss: 20926.559 | Train acc: 65.347 % ||| Val Loss: 19704.411 | Val acc: 68.613 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 6 / 10 | Reconst_loss: 1143.269 | Kldiv loss: 253.859 | Classifcation loss: 1.969 | Constrast loss: 0.66 | Total loss: 20382.642 | Train acc: 67.410 % ||| Val Loss: 19792.146 | Val acc: 68.019 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 7 / 10 | Reconst_loss: 941.534 | Kldiv loss: 262.161 | Classifcation loss: 2.087 | Constrast loss: 3.48 | Total loss: 20119.763 | Train acc: 69.331 % ||| Val Loss: 19922.865 | Val acc: 70.320 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 8 / 10 | Reconst_loss: 1067.647 | Kldiv loss: 222.546 | Classifcation loss: 1.943 | Constrast loss: 1.40 | Total loss: 19782.537 | Train acc: 70.961 % ||| Val Loss: 18607.206 | Val acc: 73.139 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 9 / 10 | Reconst_loss: 826.317 | Kldiv loss: 208.591 | Classifcation loss: 1.955 | Constrast loss: 3.57 | Total loss: 19527.957 | Train acc: 71.591 % ||| Val Loss: 18534.999 | Val acc: 74.062 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2023-02-27 05:29:26,196]\u001b[0m Trial 52 finished with value: 0.7214533995416352 and parameters: {'optuna_batch_size': 308, 'optimizer': 'RMSprop', 'lr': 0.007473006636485942, 'alpha': 5.889135159610671, 'beta': 7.656806723251755, 'gamma': 0.9797476594556086, 'delta': 7.747509938742043}. Best is trial 19 with value: 0.7874105244106601.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 10 / 10 | Reconst_loss: 1089.038 | Kldiv loss: 245.696 | Classifcation loss: 1.976 | Constrast loss: 0.00 | Total loss: 19289.518 | Train acc: 72.145 % ||| Val Loss: 18412.057 | Val acc: 73.754 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 1 / 10 | Reconst_loss: 812.268 | Kldiv loss: 133.576 | Classifcation loss: 2.042 | Constrast loss: 19.85 | Total loss: 2761.705 | Train acc: 52.900 % ||| Val Loss: 2366.562 | Val acc: 71.619 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 2 / 10 | Reconst_loss: 778.912 | Kldiv loss: 127.917 | Classifcation loss: 1.994 | Constrast loss: 17.94 | Total loss: 2319.501 | Train acc: 73.086 % ||| Val Loss: 2236.172 | Val acc: 75.018 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 3 / 10 | Reconst_loss: 959.854 | Kldiv loss: 160.468 | Classifcation loss: 2.013 | Constrast loss: 5.48 | Total loss: 2266.250 | Train acc: 75.619 % ||| Val Loss: 2323.753 | Val acc: 69.454 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 4 / 10 | Reconst_loss: 429.655 | Kldiv loss: 127.746 | Classifcation loss: 1.905 | Constrast loss: 12.34 | Total loss: 2236.828 | Train acc: 76.450 % ||| Val Loss: 2173.711 | Val acc: 77.367 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 5 / 10 | Reconst_loss: 825.282 | Kldiv loss: 136.583 | Classifcation loss: 1.949 | Constrast loss: 16.73 | Total loss: 2213.790 | Train acc: 77.708 % ||| Val Loss: 2179.061 | Val acc: 77.821 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 6 / 10 | Reconst_loss: 688.896 | Kldiv loss: 139.217 | Classifcation loss: 1.884 | Constrast loss: 6.97 | Total loss: 2204.187 | Train acc: 78.195 % ||| Val Loss: 2144.173 | Val acc: 78.070 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 7 / 10 | Reconst_loss: 714.186 | Kldiv loss: 163.327 | Classifcation loss: 1.926 | Constrast loss: 8.55 | Total loss: 2203.504 | Train acc: 77.417 % ||| Val Loss: 2150.332 | Val acc: 78.795 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 8 / 10 | Reconst_loss: 779.520 | Kldiv loss: 147.542 | Classifcation loss: 1.973 | Constrast loss: 13.49 | Total loss: 2192.482 | Train acc: 77.503 % ||| Val Loss: 2199.240 | Val acc: 77.049 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 9 / 10 | Reconst_loss: 554.676 | Kldiv loss: 142.951 | Classifcation loss: 1.751 | Constrast loss: 2.72 | Total loss: 2194.310 | Train acc: 77.265 % ||| Val Loss: 2123.536 | Val acc: 76.451 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2023-02-27 05:30:50,566]\u001b[0m Trial 53 finished with value: 0.762991141694498 and parameters: {'optuna_batch_size': 38, 'optimizer': 'RMSprop', 'lr': 0.007442050167964611, 'alpha': 6.04947708268854, 'beta': 7.302365470274168, 'gamma': 0.7211443247701267, 'delta': 8.592869639143837}. Best is trial 19 with value: 0.7874105244106601.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 10 / 10 | Reconst_loss: 1226.608 | Kldiv loss: 173.237 | Classifcation loss: 1.967 | Constrast loss: 2.65 | Total loss: 2183.524 | Train acc: 76.299 % ||| Val Loss: 2366.540 | Val acc: 71.297 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 1 / 10 | Reconst_loss: 178.024 | Kldiv loss: 12.424 | Classifcation loss: 2.237 | Constrast loss: 0.00 | Total loss: 3113.207 | Train acc: 31.906 % ||| Val Loss: 2988.536 | Val acc: 37.489 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 2 / 10 | Reconst_loss: 146.904 | Kldiv loss: 6.881 | Classifcation loss: 2.121 | Constrast loss: 0.00 | Total loss: 2996.647 | Train acc: 34.781 % ||| Val Loss: 2956.048 | Val acc: 32.644 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 3 / 10 | Reconst_loss: 74.260 | Kldiv loss: 5.114 | Classifcation loss: 2.502 | Constrast loss: 0.00 | Total loss: 2975.500 | Train acc: 33.989 % ||| Val Loss: 2952.167 | Val acc: 35.221 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 4 / 10 | Reconst_loss: 158.190 | Kldiv loss: 5.095 | Classifcation loss: 2.364 | Constrast loss: 0.00 | Total loss: 2949.266 | Train acc: 33.327 % ||| Val Loss: 2918.398 | Val acc: 31.270 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 5 / 10 | Reconst_loss: 93.730 | Kldiv loss: 6.260 | Classifcation loss: 2.422 | Constrast loss: 0.00 | Total loss: 2937.375 | Train acc: 30.744 % ||| Val Loss: 2903.171 | Val acc: 29.267 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 6 / 10 | Reconst_loss: 114.469 | Kldiv loss: 3.688 | Classifcation loss: 2.178 | Constrast loss: 0.00 | Total loss: 2924.955 | Train acc: 30.001 % ||| Val Loss: 2911.382 | Val acc: 31.870 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 7 / 10 | Reconst_loss: 336.509 | Kldiv loss: 4.261 | Classifcation loss: 2.406 | Constrast loss: 0.00 | Total loss: 2918.499 | Train acc: 30.385 % ||| Val Loss: 2879.249 | Val acc: 28.374 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 8 / 10 | Reconst_loss: 154.609 | Kldiv loss: 6.069 | Classifcation loss: 2.241 | Constrast loss: 0.00 | Total loss: 2917.234 | Train acc: 30.068 % ||| Val Loss: 2883.597 | Val acc: 29.371 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 9 / 10 | Reconst_loss: 113.156 | Kldiv loss: 5.315 | Classifcation loss: 2.676 | Constrast loss: 0.00 | Total loss: 2913.049 | Train acc: 30.095 % ||| Val Loss: 2895.515 | Val acc: 30.838 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2023-02-27 05:32:20,565]\u001b[0m Trial 54 finished with value: 0.2988181573999464 and parameters: {'optuna_batch_size': 34, 'optimizer': 'RMSprop', 'lr': 0.007227827486784831, 'alpha': 6.165619460450572, 'beta': 7.238025650217676, 'gamma': 2.1886946086678085, 'delta': 8.685270878399018}. Best is trial 19 with value: 0.7874105244106601.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 10 / 10 | Reconst_loss: 279.504 | Kldiv loss: 5.738 | Classifcation loss: 2.244 | Constrast loss: 0.00 | Total loss: 2914.137 | Train acc: 29.882 % ||| Val Loss: 2880.227 | Val acc: 29.538 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 1 / 10 | Reconst_loss: 1114.663 | Kldiv loss: 132.027 | Classifcation loss: 2.110 | Constrast loss: 16.73 | Total loss: 8401.115 | Train acc: 41.182 % ||| Val Loss: 7091.316 | Val acc: 57.633 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 2 / 10 | Reconst_loss: 739.496 | Kldiv loss: 140.587 | Classifcation loss: 2.119 | Constrast loss: 1.84 | Total loss: 6810.382 | Train acc: 60.578 % ||| Val Loss: 6300.218 | Val acc: 64.924 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 3 / 10 | Reconst_loss: 898.504 | Kldiv loss: 186.849 | Classifcation loss: 2.027 | Constrast loss: 2.97 | Total loss: 6300.931 | Train acc: 66.947 % ||| Val Loss: 5855.154 | Val acc: 71.244 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 4 / 10 | Reconst_loss: 1085.972 | Kldiv loss: 127.358 | Classifcation loss: 2.106 | Constrast loss: 19.65 | Total loss: 6062.662 | Train acc: 69.668 % ||| Val Loss: 5790.738 | Val acc: 71.509 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 5 / 10 | Reconst_loss: 709.817 | Kldiv loss: 142.598 | Classifcation loss: 1.911 | Constrast loss: 5.50 | Total loss: 5948.674 | Train acc: 70.504 % ||| Val Loss: 5691.688 | Val acc: 70.656 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 6 / 10 | Reconst_loss: 806.112 | Kldiv loss: 189.852 | Classifcation loss: 1.980 | Constrast loss: 1.02 | Total loss: 5846.471 | Train acc: 70.912 % ||| Val Loss: 5583.300 | Val acc: 71.996 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 7 / 10 | Reconst_loss: 534.335 | Kldiv loss: 135.961 | Classifcation loss: 1.804 | Constrast loss: 8.85 | Total loss: 5829.687 | Train acc: 69.972 % ||| Val Loss: 5511.327 | Val acc: 72.509 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 8 / 10 | Reconst_loss: 893.518 | Kldiv loss: 142.167 | Classifcation loss: 2.017 | Constrast loss: 11.36 | Total loss: 5761.722 | Train acc: 70.962 % ||| Val Loss: 5537.669 | Val acc: 71.796 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 9 / 10 | Reconst_loss: 993.107 | Kldiv loss: 149.756 | Classifcation loss: 1.959 | Constrast loss: 11.21 | Total loss: 5685.860 | Train acc: 71.399 % ||| Val Loss: 5495.041 | Val acc: 72.279 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2023-02-27 05:32:59,850]\u001b[0m Trial 55 finished with value: 0.7090823027514134 and parameters: {'optuna_batch_size': 95, 'optimizer': 'RMSprop', 'lr': 0.008033861242792716, 'alpha': 5.272388127185164, 'beta': 7.684615006507706, 'gamma': 1.621445142006651, 'delta': 8.286910524978012}. Best is trial 19 with value: 0.7874105244106601.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 10 / 10 | Reconst_loss: 911.624 | Kldiv loss: 165.443 | Classifcation loss: 1.875 | Constrast loss: 11.32 | Total loss: 5667.566 | Train acc: 70.908 % ||| Val Loss: 5632.895 | Val acc: 71.794 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 1 / 10 | Reconst_loss: 1279.387 | Kldiv loss: 242.891 | Classifcation loss: 2.289 | Constrast loss: 14.64 | Total loss: 18733.511 | Train acc: 28.543 % ||| Val Loss: 13718.019 | Val acc: 43.502 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 2 / 10 | Reconst_loss: 1097.551 | Kldiv loss: 234.398 | Classifcation loss: 2.163 | Constrast loss: 19.30 | Total loss: 12897.363 | Train acc: 52.528 % ||| Val Loss: 12159.949 | Val acc: 60.563 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 3 / 10 | Reconst_loss: 1284.919 | Kldiv loss: 205.630 | Classifcation loss: 2.072 | Constrast loss: 0.46 | Total loss: 11590.365 | Train acc: 67.349 % ||| Val Loss: 11114.725 | Val acc: 74.040 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 4 / 10 | Reconst_loss: 971.417 | Kldiv loss: 236.922 | Classifcation loss: 2.011 | Constrast loss: 3.41 | Total loss: 11089.659 | Train acc: 73.896 % ||| Val Loss: 10612.804 | Val acc: 77.803 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 5 / 10 | Reconst_loss: 908.575 | Kldiv loss: 214.065 | Classifcation loss: 1.930 | Constrast loss: 3.38 | Total loss: 10824.993 | Train acc: 76.998 % ||| Val Loss: 10490.505 | Val acc: 78.808 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 6 / 10 | Reconst_loss: 1220.289 | Kldiv loss: 227.110 | Classifcation loss: 1.795 | Constrast loss: 2.61 | Total loss: 10618.305 | Train acc: 78.661 % ||| Val Loss: 10279.669 | Val acc: 79.754 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 7 / 10 | Reconst_loss: 943.590 | Kldiv loss: 206.066 | Classifcation loss: 1.903 | Constrast loss: 1.98 | Total loss: 10454.453 | Train acc: 79.219 % ||| Val Loss: 10143.434 | Val acc: 81.005 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 8 / 10 | Reconst_loss: 1155.053 | Kldiv loss: 237.880 | Classifcation loss: 1.937 | Constrast loss: 4.69 | Total loss: 10243.806 | Train acc: 80.263 % ||| Val Loss: 10172.043 | Val acc: 80.788 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 9 / 10 | Reconst_loss: 763.948 | Kldiv loss: 261.808 | Classifcation loss: 1.891 | Constrast loss: 5.46 | Total loss: 10148.608 | Train acc: 80.402 % ||| Val Loss: 10026.979 | Val acc: 80.870 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2023-02-27 05:33:26,949]\u001b[0m Trial 56 finished with value: 0.8085334443997629 and parameters: {'optuna_batch_size': 169, 'optimizer': 'RMSprop', 'lr': 0.004314526443409444, 'alpha': 4.495713297911321, 'beta': 8.366160499015448, 'gamma': 0.7618291914837088, 'delta': 7.415517278194275}. Best is trial 56 with value: 0.8085334443997629.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 10 / 10 | Reconst_loss: 747.931 | Kldiv loss: 227.495 | Classifcation loss: 1.868 | Constrast loss: 0.98 | Total loss: 10037.210 | Train acc: 80.853 % ||| Val Loss: 9835.184 | Val acc: 80.754 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 1 / 10 | Reconst_loss: 6790.239 | Kldiv loss: 1434.086 | Classifcation loss: 2.267 | Constrast loss: 401.87 | Total loss: 32028.441 | Train acc: 31.420 % ||| Val Loss: 23383.809 | Val acc: 41.974 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 2 / 10 | Reconst_loss: 7588.612 | Kldiv loss: 1422.179 | Classifcation loss: 2.186 | Constrast loss: 181.43 | Total loss: 23083.794 | Train acc: 45.399 % ||| Val Loss: 21593.612 | Val acc: 52.131 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 3 / 10 | Reconst_loss: 5659.989 | Kldiv loss: 1286.819 | Classifcation loss: 2.100 | Constrast loss: 177.23 | Total loss: 21573.441 | Train acc: 53.356 % ||| Val Loss: 20059.321 | Val acc: 59.044 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 4 / 10 | Reconst_loss: 6528.029 | Kldiv loss: 1283.088 | Classifcation loss: 2.140 | Constrast loss: 308.76 | Total loss: 20645.471 | Train acc: 57.010 % ||| Val Loss: 19422.615 | Val acc: 60.242 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 5 / 10 | Reconst_loss: 5594.726 | Kldiv loss: 1418.017 | Classifcation loss: 2.172 | Constrast loss: 110.06 | Total loss: 19697.891 | Train acc: 59.591 % ||| Val Loss: 19017.500 | Val acc: 60.645 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 6 / 10 | Reconst_loss: 5629.005 | Kldiv loss: 1452.526 | Classifcation loss: 2.072 | Constrast loss: 144.90 | Total loss: 18952.581 | Train acc: 61.685 % ||| Val Loss: 17898.618 | Val acc: 67.547 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 7 / 10 | Reconst_loss: 5366.007 | Kldiv loss: 1451.599 | Classifcation loss: 2.038 | Constrast loss: 86.91 | Total loss: 18323.886 | Train acc: 66.408 % ||| Val Loss: 17673.886 | Val acc: 68.897 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 8 / 10 | Reconst_loss: 6594.529 | Kldiv loss: 1334.423 | Classifcation loss: 2.024 | Constrast loss: 95.54 | Total loss: 17983.381 | Train acc: 67.248 % ||| Val Loss: 17228.886 | Val acc: 69.078 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 9 / 10 | Reconst_loss: 6031.837 | Kldiv loss: 1381.731 | Classifcation loss: 1.972 | Constrast loss: 108.25 | Total loss: 17764.553 | Train acc: 67.818 % ||| Val Loss: 17028.794 | Val acc: 69.761 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2023-02-27 05:33:49,431]\u001b[0m Trial 57 finished with value: 0.6810398224010784 and parameters: {'optuna_batch_size': 273, 'optimizer': 'RMSprop', 'lr': 0.006131778641717383, 'alpha': 4.513182784845949, 'beta': 8.394599691321304, 'gamma': 1.2217799875896633, 'delta': 7.332690473304888}. Best is trial 56 with value: 0.8085334443997629.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 10 / 10 | Reconst_loss: 5161.738 | Kldiv loss: 1443.189 | Classifcation loss: 2.029 | Constrast loss: 67.74 | Total loss: 17658.019 | Train acc: 68.104 % ||| Val Loss: 17249.599 | Val acc: 68.334 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 1 / 10 | Reconst_loss: 2091.393 | Kldiv loss: 352.400 | Classifcation loss: 2.380 | Constrast loss: 41.83 | Total loss: 21865.472 | Train acc: 21.271 % ||| Val Loss: 12084.552 | Val acc: 34.333 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 2 / 10 | Reconst_loss: 1939.050 | Kldiv loss: 354.090 | Classifcation loss: 2.115 | Constrast loss: 44.44 | Total loss: 10500.868 | Train acc: 55.527 % ||| Val Loss: 9571.270 | Val acc: 65.956 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 3 / 10 | Reconst_loss: 1317.055 | Kldiv loss: 335.765 | Classifcation loss: 2.009 | Constrast loss: 35.55 | Total loss: 9381.566 | Train acc: 67.575 % ||| Val Loss: 9057.635 | Val acc: 68.154 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 4 / 10 | Reconst_loss: 1179.569 | Kldiv loss: 380.211 | Classifcation loss: 1.931 | Constrast loss: 15.42 | Total loss: 8927.179 | Train acc: 69.259 % ||| Val Loss: 8745.865 | Val acc: 69.189 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 5 / 10 | Reconst_loss: 1427.144 | Kldiv loss: 341.782 | Classifcation loss: 1.980 | Constrast loss: 26.93 | Total loss: 8690.453 | Train acc: 69.731 % ||| Val Loss: 8556.907 | Val acc: 69.468 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 6 / 10 | Reconst_loss: 1386.739 | Kldiv loss: 338.815 | Classifcation loss: 2.012 | Constrast loss: 25.26 | Total loss: 8544.354 | Train acc: 70.334 % ||| Val Loss: 8385.098 | Val acc: 70.812 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 7 / 10 | Reconst_loss: 1288.765 | Kldiv loss: 353.719 | Classifcation loss: 2.030 | Constrast loss: 24.41 | Total loss: 8442.001 | Train acc: 71.430 % ||| Val Loss: 8217.786 | Val acc: 71.195 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 8 / 10 | Reconst_loss: 1520.733 | Kldiv loss: 358.680 | Classifcation loss: 1.969 | Constrast loss: 23.88 | Total loss: 8309.804 | Train acc: 72.392 % ||| Val Loss: 8219.069 | Val acc: 73.769 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 9 / 10 | Reconst_loss: 1216.155 | Kldiv loss: 352.588 | Classifcation loss: 1.930 | Constrast loss: 10.34 | Total loss: 8309.719 | Train acc: 73.231 % ||| Val Loss: 8205.801 | Val acc: 73.637 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2023-02-27 05:34:21,923]\u001b[0m Trial 58 finished with value: 0.73088803088803 and parameters: {'optuna_batch_size': 141, 'optimizer': 'Adam', 'lr': 0.006943376891343172, 'alpha': 4.9290393012317315, 'beta': 8.852981674897492, 'gamma': 0.6726279852405604, 'delta': 9.076080766341276}. Best is trial 56 with value: 0.8085334443997629.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 10 / 10 | Reconst_loss: 1538.601 | Kldiv loss: 325.050 | Classifcation loss: 1.929 | Constrast loss: 15.61 | Total loss: 8307.331 | Train acc: 73.089 % ||| Val Loss: 8313.553 | Val acc: 72.173 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 1 / 10 | Reconst_loss: 5553.068 | Kldiv loss: 1117.477 | Classifcation loss: 2.307 | Constrast loss: 245.60 | Total loss: 22370.318 | Train acc: 33.338 % ||| Val Loss: 17150.769 | Val acc: 44.341 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 2 / 10 | Reconst_loss: 4947.307 | Kldiv loss: 1169.377 | Classifcation loss: 2.204 | Constrast loss: 202.31 | Total loss: 17044.378 | Train acc: 49.549 % ||| Val Loss: 15726.446 | Val acc: 57.823 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 3 / 10 | Reconst_loss: 5439.547 | Kldiv loss: 1254.202 | Classifcation loss: 2.080 | Constrast loss: 117.66 | Total loss: 15778.162 | Train acc: 58.491 % ||| Val Loss: 14999.406 | Val acc: 60.972 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 4 / 10 | Reconst_loss: 4777.715 | Kldiv loss: 1089.475 | Classifcation loss: 2.049 | Constrast loss: 176.40 | Total loss: 15089.981 | Train acc: 63.589 % ||| Val Loss: 14358.306 | Val acc: 66.995 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 5 / 10 | Reconst_loss: 5043.985 | Kldiv loss: 1268.159 | Classifcation loss: 2.008 | Constrast loss: 120.10 | Total loss: 14570.602 | Train acc: 66.191 % ||| Val Loss: 13886.517 | Val acc: 68.590 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 6 / 10 | Reconst_loss: 4416.561 | Kldiv loss: 982.249 | Classifcation loss: 2.042 | Constrast loss: 240.31 | Total loss: 14226.155 | Train acc: 68.012 % ||| Val Loss: 13532.934 | Val acc: 69.924 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 7 / 10 | Reconst_loss: 4414.805 | Kldiv loss: 1051.927 | Classifcation loss: 1.983 | Constrast loss: 105.54 | Total loss: 13924.258 | Train acc: 69.685 % ||| Val Loss: 13262.475 | Val acc: 71.597 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 8 / 10 | Reconst_loss: 4263.952 | Kldiv loss: 1066.126 | Classifcation loss: 1.989 | Constrast loss: 121.47 | Total loss: 13872.146 | Train acc: 69.766 % ||| Val Loss: 13183.900 | Val acc: 70.326 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 9 / 10 | Reconst_loss: 4526.833 | Kldiv loss: 1065.831 | Classifcation loss: 2.007 | Constrast loss: 98.73 | Total loss: 13720.375 | Train acc: 70.242 % ||| Val Loss: 13290.792 | Val acc: 70.442 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2023-02-27 05:34:45,059]\u001b[0m Trial 59 finished with value: 0.7120058239515269 and parameters: {'optuna_batch_size': 211, 'optimizer': 'RMSprop', 'lr': 0.0053944368952987525, 'alpha': 5.606048735215445, 'beta': 7.998330522718606, 'gamma': 2.8985136184348566, 'delta': 8.505403892081782}. Best is trial 56 with value: 0.8085334443997629.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 10 / 10 | Reconst_loss: 4528.153 | Kldiv loss: 1045.851 | Classifcation loss: 1.985 | Constrast loss: 110.43 | Total loss: 13512.380 | Train acc: 71.201 % ||| Val Loss: 13367.167 | Val acc: 71.999 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 1 / 10 | Reconst_loss: 1260.746 | Kldiv loss: 110.530 | Classifcation loss: 2.286 | Constrast loss: 26.95 | Total loss: 5443.179 | Train acc: 41.909 % ||| Val Loss: 4804.320 | Val acc: 51.421 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 2 / 10 | Reconst_loss: 1108.071 | Kldiv loss: 153.558 | Classifcation loss: 2.027 | Constrast loss: 8.35 | Total loss: 4716.906 | Train acc: 57.272 % ||| Val Loss: 4368.847 | Val acc: 62.512 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 3 / 10 | Reconst_loss: 763.459 | Kldiv loss: 128.682 | Classifcation loss: 2.097 | Constrast loss: 6.50 | Total loss: 4386.240 | Train acc: 63.632 % ||| Val Loss: 4113.729 | Val acc: 66.227 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 4 / 10 | Reconst_loss: 861.185 | Kldiv loss: 153.941 | Classifcation loss: 2.130 | Constrast loss: 23.46 | Total loss: 4193.271 | Train acc: 65.264 % ||| Val Loss: 4080.967 | Val acc: 65.807 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 5 / 10 | Reconst_loss: 910.325 | Kldiv loss: 139.561 | Classifcation loss: 2.154 | Constrast loss: 16.30 | Total loss: 4082.943 | Train acc: 66.419 % ||| Val Loss: 4031.487 | Val acc: 67.024 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 6 / 10 | Reconst_loss: 803.895 | Kldiv loss: 154.493 | Classifcation loss: 2.012 | Constrast loss: 4.36 | Total loss: 4027.567 | Train acc: 67.133 % ||| Val Loss: 3928.395 | Val acc: 67.862 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 7 / 10 | Reconst_loss: 823.191 | Kldiv loss: 137.477 | Classifcation loss: 1.883 | Constrast loss: 10.42 | Total loss: 3995.635 | Train acc: 67.937 % ||| Val Loss: 3881.629 | Val acc: 68.758 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 8 / 10 | Reconst_loss: 712.907 | Kldiv loss: 160.869 | Classifcation loss: 1.929 | Constrast loss: 9.18 | Total loss: 3967.692 | Train acc: 68.367 % ||| Val Loss: 3832.530 | Val acc: 69.188 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 9 / 10 | Reconst_loss: 655.065 | Kldiv loss: 155.482 | Classifcation loss: 1.869 | Constrast loss: 5.33 | Total loss: 3939.266 | Train acc: 68.119 % ||| Val Loss: 3838.805 | Val acc: 67.582 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2023-02-27 05:35:33,784]\u001b[0m Trial 60 finished with value: 0.6875798618498986 and parameters: {'optuna_batch_size': 67, 'optimizer': 'RMSprop', 'lr': 0.008079693416212081, 'alpha': 3.8251693387466053, 'beta': 8.483504068522798, 'gamma': 1.7521791470602994, 'delta': 6.685767365997383}. Best is trial 56 with value: 0.8085334443997629.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 10 / 10 | Reconst_loss: 712.341 | Kldiv loss: 169.508 | Classifcation loss: 1.888 | Constrast loss: 2.10 | Total loss: 3933.610 | Train acc: 68.758 % ||| Val Loss: 3967.415 | Val acc: 66.755 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 1 / 10 | Reconst_loss: 1110.312 | Kldiv loss: 223.045 | Classifcation loss: 2.209 | Constrast loss: 18.65 | Total loss: 17333.964 | Train acc: 36.075 % ||| Val Loss: 12765.773 | Val acc: 52.367 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 2 / 10 | Reconst_loss: 1120.750 | Kldiv loss: 289.733 | Classifcation loss: 1.987 | Constrast loss: 8.37 | Total loss: 12424.589 | Train acc: 57.880 % ||| Val Loss: 11857.291 | Val acc: 63.395 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 3 / 10 | Reconst_loss: 1061.688 | Kldiv loss: 239.953 | Classifcation loss: 2.075 | Constrast loss: 2.24 | Total loss: 11530.026 | Train acc: 63.764 % ||| Val Loss: 10930.061 | Val acc: 66.153 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 4 / 10 | Reconst_loss: 567.235 | Kldiv loss: 248.012 | Classifcation loss: 2.045 | Constrast loss: 6.07 | Total loss: 11154.134 | Train acc: 65.473 % ||| Val Loss: 10742.789 | Val acc: 67.450 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 5 / 10 | Reconst_loss: 795.688 | Kldiv loss: 219.587 | Classifcation loss: 2.000 | Constrast loss: 5.58 | Total loss: 10873.053 | Train acc: 66.951 % ||| Val Loss: 10388.596 | Val acc: 69.692 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 6 / 10 | Reconst_loss: 821.302 | Kldiv loss: 212.953 | Classifcation loss: 2.096 | Constrast loss: 14.52 | Total loss: 10655.346 | Train acc: 69.027 % ||| Val Loss: 10205.921 | Val acc: 71.778 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 7 / 10 | Reconst_loss: 1193.734 | Kldiv loss: 246.593 | Classifcation loss: 2.016 | Constrast loss: 6.28 | Total loss: 10431.656 | Train acc: 70.591 % ||| Val Loss: 10124.190 | Val acc: 72.051 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 8 / 10 | Reconst_loss: 884.834 | Kldiv loss: 209.791 | Classifcation loss: 1.907 | Constrast loss: 0.21 | Total loss: 10329.974 | Train acc: 71.391 % ||| Val Loss: 9942.174 | Val acc: 72.036 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 9 / 10 | Reconst_loss: 1112.761 | Kldiv loss: 263.733 | Classifcation loss: 1.879 | Constrast loss: 5.05 | Total loss: 10216.428 | Train acc: 71.740 % ||| Val Loss: 9884.750 | Val acc: 73.524 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2023-02-27 05:35:59,242]\u001b[0m Trial 61 finished with value: 0.7249990425307817 and parameters: {'optuna_batch_size': 169, 'optimizer': 'RMSprop', 'lr': 0.004276240965845163, 'alpha': 5.239413863060127, 'beta': 7.803084000062914, 'gamma': 1.0049634444177566, 'delta': 7.827285343312189}. Best is trial 56 with value: 0.8085334443997629.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 10 / 10 | Reconst_loss: 1310.411 | Kldiv loss: 260.874 | Classifcation loss: 2.123 | Constrast loss: 9.91 | Total loss: 10077.835 | Train acc: 72.500 % ||| Val Loss: 10706.015 | Val acc: 63.970 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 1 / 10 | Reconst_loss: 5113.578 | Kldiv loss: 1286.149 | Classifcation loss: 2.265 | Constrast loss: 217.64 | Total loss: 48055.884 | Train acc: 27.982 % ||| Val Loss: 31508.925 | Val acc: 42.386 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 2 / 10 | Reconst_loss: 5451.387 | Kldiv loss: 1212.213 | Classifcation loss: 2.210 | Constrast loss: 221.49 | Total loss: 31030.160 | Train acc: 45.616 % ||| Val Loss: 28923.149 | Val acc: 50.478 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 3 / 10 | Reconst_loss: 5193.137 | Kldiv loss: 1402.193 | Classifcation loss: 2.116 | Constrast loss: 99.92 | Total loss: 29261.265 | Train acc: 50.988 % ||| Val Loss: 27411.611 | Val acc: 54.881 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 4 / 10 | Reconst_loss: 4626.274 | Kldiv loss: 1221.783 | Classifcation loss: 2.153 | Constrast loss: 112.69 | Total loss: 27849.252 | Train acc: 54.491 % ||| Val Loss: 26056.601 | Val acc: 57.215 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 5 / 10 | Reconst_loss: 5078.597 | Kldiv loss: 1233.209 | Classifcation loss: 2.172 | Constrast loss: 115.38 | Total loss: 26756.946 | Train acc: 57.345 % ||| Val Loss: 25247.306 | Val acc: 63.816 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 6 / 10 | Reconst_loss: 4347.868 | Kldiv loss: 1371.692 | Classifcation loss: 2.024 | Constrast loss: 85.99 | Total loss: 25481.705 | Train acc: 64.216 % ||| Val Loss: 24239.141 | Val acc: 70.009 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 7 / 10 | Reconst_loss: 4690.613 | Kldiv loss: 1190.551 | Classifcation loss: 1.974 | Constrast loss: 69.28 | Total loss: 24744.998 | Train acc: 68.575 % ||| Val Loss: 23521.759 | Val acc: 72.780 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 8 / 10 | Reconst_loss: 4090.953 | Kldiv loss: 1221.229 | Classifcation loss: 1.963 | Constrast loss: 77.08 | Total loss: 24080.645 | Train acc: 74.127 % ||| Val Loss: 23054.977 | Val acc: 78.139 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 9 / 10 | Reconst_loss: 5132.407 | Kldiv loss: 1278.421 | Classifcation loss: 1.985 | Constrast loss: 80.82 | Total loss: 23864.849 | Train acc: 74.783 % ||| Val Loss: 22867.653 | Val acc: 78.399 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2023-02-27 05:36:18,746]\u001b[0m Trial 62 finished with value: 0.7627140756797985 and parameters: {'optuna_batch_size': 363, 'optimizer': 'RMSprop', 'lr': 0.0045690640395325, 'alpha': 5.989177293722115, 'beta': 7.32195054250508, 'gamma': 0.7195014849378772, 'delta': 7.263656764666556}. Best is trial 56 with value: 0.8085334443997629.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 10 / 10 | Reconst_loss: 4209.468 | Kldiv loss: 1190.393 | Classifcation loss: 1.909 | Constrast loss: 72.25 | Total loss: 23549.616 | Train acc: 76.271 % ||| Val Loss: 22589.207 | Val acc: 79.405 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 1 / 10 | Reconst_loss: 7451.581 | Kldiv loss: 1541.825 | Classifcation loss: 2.333 | Constrast loss: 405.80 | Total loss: 28052.618 | Train acc: 28.749 % ||| Val Loss: 20552.666 | Val acc: 37.229 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 2 / 10 | Reconst_loss: 6567.370 | Kldiv loss: 1498.446 | Classifcation loss: 2.277 | Constrast loss: 259.02 | Total loss: 19467.310 | Train acc: 41.189 % ||| Val Loss: 19019.599 | Val acc: 42.412 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 3 / 10 | Reconst_loss: 6271.087 | Kldiv loss: 1236.087 | Classifcation loss: 2.214 | Constrast loss: 302.33 | Total loss: 18001.444 | Train acc: 51.288 % ||| Val Loss: 17405.096 | Val acc: 54.467 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 4 / 10 | Reconst_loss: 6009.895 | Kldiv loss: 1533.089 | Classifcation loss: 2.113 | Constrast loss: 136.70 | Total loss: 16994.671 | Train acc: 55.994 % ||| Val Loss: 16085.546 | Val acc: 58.676 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 5 / 10 | Reconst_loss: 6457.902 | Kldiv loss: 1421.864 | Classifcation loss: 2.166 | Constrast loss: 221.49 | Total loss: 16110.786 | Train acc: 58.449 % ||| Val Loss: 15512.947 | Val acc: 60.173 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 6 / 10 | Reconst_loss: 6028.499 | Kldiv loss: 1197.913 | Classifcation loss: 2.102 | Constrast loss: 146.05 | Total loss: 15327.567 | Train acc: 59.693 % ||| Val Loss: 17433.378 | Val acc: 58.850 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 7 / 10 | Reconst_loss: 6222.919 | Kldiv loss: 1339.349 | Classifcation loss: 2.091 | Constrast loss: 220.71 | Total loss: 15069.602 | Train acc: 59.984 % ||| Val Loss: 16716.654 | Val acc: 56.398 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 8 / 10 | Reconst_loss: 5700.256 | Kldiv loss: 1422.128 | Classifcation loss: 2.120 | Constrast loss: 202.71 | Total loss: 14755.070 | Train acc: 61.026 % ||| Val Loss: 14931.360 | Val acc: 61.425 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 9 / 10 | Reconst_loss: 5659.471 | Kldiv loss: 1428.057 | Classifcation loss: 2.126 | Constrast loss: 151.78 | Total loss: 14518.973 | Train acc: 58.630 % ||| Val Loss: 14699.765 | Val acc: 60.869 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2023-02-27 05:36:41,337]\u001b[0m Trial 63 finished with value: 0.5978862590494721 and parameters: {'optuna_batch_size': 239, 'optimizer': 'RMSprop', 'lr': 0.004984962126222282, 'alpha': 6.091030340477078, 'beta': 7.254032812792494, 'gamma': 0.502213273459071, 'delta': 7.299974469546803}. Best is trial 56 with value: 0.8085334443997629.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 10 / 10 | Reconst_loss: 4878.018 | Kldiv loss: 1291.546 | Classifcation loss: 2.084 | Constrast loss: 118.27 | Total loss: 14247.189 | Train acc: 59.789 % ||| Val Loss: 14266.582 | Val acc: 58.195 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 1 / 10 | Reconst_loss: 79.312 | Kldiv loss: 10.921 | Classifcation loss: 1.759 | Constrast loss: 0.00 | Total loss: 646.951 | Train acc: 47.992 % ||| Val Loss: 567.580 | Val acc: 62.476 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 2 / 10 | Reconst_loss: 14.310 | Kldiv loss: 5.142 | Classifcation loss: 2.184 | Constrast loss: 0.00 | Total loss: 569.283 | Train acc: 63.443 % ||| Val Loss: 548.230 | Val acc: 63.745 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 3 / 10 | Reconst_loss: 30.197 | Kldiv loss: 5.935 | Classifcation loss: 2.294 | Constrast loss: 0.00 | Total loss: 553.648 | Train acc: 65.186 % ||| Val Loss: 537.455 | Val acc: 67.772 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 4 / 10 | Reconst_loss: 34.717 | Kldiv loss: 9.099 | Classifcation loss: 2.120 | Constrast loss: 0.00 | Total loss: 544.867 | Train acc: 68.267 % ||| Val Loss: 550.264 | Val acc: 67.663 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 5 / 10 | Reconst_loss: 63.225 | Kldiv loss: 10.158 | Classifcation loss: 1.853 | Constrast loss: 0.00 | Total loss: 541.328 | Train acc: 70.067 % ||| Val Loss: 533.935 | Val acc: 71.269 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 6 / 10 | Reconst_loss: 28.422 | Kldiv loss: 8.226 | Classifcation loss: 2.190 | Constrast loss: 0.00 | Total loss: 537.957 | Train acc: 71.004 % ||| Val Loss: 534.231 | Val acc: 70.357 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 7 / 10 | Reconst_loss: 124.324 | Kldiv loss: 12.691 | Classifcation loss: 1.689 | Constrast loss: 0.00 | Total loss: 540.598 | Train acc: 70.758 % ||| Val Loss: 534.117 | Val acc: 72.594 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 8 / 10 | Reconst_loss: 23.635 | Kldiv loss: 5.499 | Classifcation loss: 2.190 | Constrast loss: 0.00 | Total loss: 536.852 | Train acc: 71.004 % ||| Val Loss: 525.554 | Val acc: 71.517 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 9 / 10 | Reconst_loss: 97.782 | Kldiv loss: 5.260 | Classifcation loss: 2.671 | Constrast loss: 0.00 | Total loss: 535.636 | Train acc: 72.194 % ||| Val Loss: 525.803 | Val acc: 73.011 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2023-02-27 05:41:47,053]\u001b[0m Trial 64 finished with value: 0.728944337811903 and parameters: {'optuna_batch_size': 10, 'optimizer': 'RMSprop', 'lr': 0.003737065160109007, 'alpha': 4.610953861753081, 'beta': 8.19719808125374, 'gamma': 0.8259749232730146, 'delta': 6.015541033020039}. Best is trial 56 with value: 0.8085334443997629.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 10 / 10 | Reconst_loss: 23.143 | Kldiv loss: 7.522 | Classifcation loss: 2.189 | Constrast loss: 0.00 | Total loss: 533.766 | Train acc: 72.894 % ||| Val Loss: 522.792 | Val acc: 73.759 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 1 / 10 | Reconst_loss: 4617.600 | Kldiv loss: 1389.470 | Classifcation loss: 2.317 | Constrast loss: 119.66 | Total loss: 56075.350 | Train acc: 28.213 % ||| Val Loss: 33348.987 | Val acc: 44.021 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 2 / 10 | Reconst_loss: 4433.742 | Kldiv loss: 1177.771 | Classifcation loss: 2.281 | Constrast loss: 135.96 | Total loss: 32038.776 | Train acc: 44.887 % ||| Val Loss: 29219.541 | Val acc: 52.253 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 3 / 10 | Reconst_loss: 4140.213 | Kldiv loss: 1226.113 | Classifcation loss: 2.122 | Constrast loss: 97.74 | Total loss: 29653.323 | Train acc: 49.957 % ||| Val Loss: 27864.328 | Val acc: 56.214 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 4 / 10 | Reconst_loss: 3636.875 | Kldiv loss: 990.379 | Classifcation loss: 2.180 | Constrast loss: 98.97 | Total loss: 28488.718 | Train acc: 54.792 % ||| Val Loss: 27769.091 | Val acc: 60.046 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 5 / 10 | Reconst_loss: 4125.442 | Kldiv loss: 919.325 | Classifcation loss: 2.198 | Constrast loss: 102.82 | Total loss: 27731.793 | Train acc: 57.861 % ||| Val Loss: 26892.383 | Val acc: 60.808 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 6 / 10 | Reconst_loss: 4414.678 | Kldiv loss: 1040.235 | Classifcation loss: 2.066 | Constrast loss: 78.79 | Total loss: 26985.007 | Train acc: 59.729 % ||| Val Loss: 25642.913 | Val acc: 62.557 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 7 / 10 | Reconst_loss: 3697.317 | Kldiv loss: 935.053 | Classifcation loss: 2.081 | Constrast loss: 78.97 | Total loss: 26471.770 | Train acc: 60.686 % ||| Val Loss: 25034.836 | Val acc: 63.360 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 8 / 10 | Reconst_loss: 4146.510 | Kldiv loss: 993.373 | Classifcation loss: 2.080 | Constrast loss: 61.25 | Total loss: 25690.240 | Train acc: 61.605 % ||| Val Loss: 24472.533 | Val acc: 63.298 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 9 / 10 | Reconst_loss: 4042.855 | Kldiv loss: 1069.365 | Classifcation loss: 2.102 | Constrast loss: 72.22 | Total loss: 25356.672 | Train acc: 62.004 % ||| Val Loss: 24021.916 | Val acc: 63.577 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2023-02-27 05:42:06,357]\u001b[0m Trial 65 finished with value: 0.6238603081368614 and parameters: {'optuna_batch_size': 371, 'optimizer': 'RMSprop', 'lr': 0.004566834458312098, 'alpha': 5.809826705340843, 'beta': 9.38254486325617, 'gamma': 1.3456211571830685, 'delta': 8.182144235914647}. Best is trial 56 with value: 0.8085334443997629.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 10 / 10 | Reconst_loss: 3397.759 | Kldiv loss: 1030.133 | Classifcation loss: 2.068 | Constrast loss: 68.89 | Total loss: 25029.845 | Train acc: 62.386 % ||| Val Loss: 23808.238 | Val acc: 64.282 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 1 / 10 | Reconst_loss: 2496.964 | Kldiv loss: 421.207 | Classifcation loss: 2.255 | Constrast loss: 86.32 | Total loss: 8404.801 | Train acc: 41.495 % ||| Val Loss: 7078.771 | Val acc: 56.068 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 2 / 10 | Reconst_loss: 2213.475 | Kldiv loss: 510.201 | Classifcation loss: 2.051 | Constrast loss: 41.48 | Total loss: 6874.837 | Train acc: 62.168 % ||| Val Loss: 6498.084 | Val acc: 66.239 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 3 / 10 | Reconst_loss: 2285.838 | Kldiv loss: 444.285 | Classifcation loss: 2.113 | Constrast loss: 101.51 | Total loss: 6470.127 | Train acc: 66.716 % ||| Val Loss: 6166.992 | Val acc: 69.131 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 4 / 10 | Reconst_loss: 2769.702 | Kldiv loss: 461.780 | Classifcation loss: 2.011 | Constrast loss: 60.48 | Total loss: 6236.928 | Train acc: 68.373 % ||| Val Loss: 6033.402 | Val acc: 69.470 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 5 / 10 | Reconst_loss: 2572.520 | Kldiv loss: 474.898 | Classifcation loss: 2.065 | Constrast loss: 99.95 | Total loss: 6094.846 | Train acc: 69.061 % ||| Val Loss: 6072.567 | Val acc: 68.720 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 6 / 10 | Reconst_loss: 1713.469 | Kldiv loss: 470.084 | Classifcation loss: 1.908 | Constrast loss: 20.87 | Total loss: 5993.917 | Train acc: 69.715 % ||| Val Loss: 5824.306 | Val acc: 70.340 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 7 / 10 | Reconst_loss: 1957.290 | Kldiv loss: 457.831 | Classifcation loss: 1.932 | Constrast loss: 28.48 | Total loss: 5940.927 | Train acc: 70.348 % ||| Val Loss: 5811.042 | Val acc: 70.737 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 8 / 10 | Reconst_loss: 1516.120 | Kldiv loss: 513.295 | Classifcation loss: 1.979 | Constrast loss: 28.96 | Total loss: 5909.309 | Train acc: 70.604 % ||| Val Loss: 5832.236 | Val acc: 71.486 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 9 / 10 | Reconst_loss: 2268.864 | Kldiv loss: 469.205 | Classifcation loss: 1.991 | Constrast loss: 32.25 | Total loss: 5866.795 | Train acc: 70.924 % ||| Val Loss: 5791.090 | Val acc: 70.720 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2023-02-27 05:42:42,347]\u001b[0m Trial 66 finished with value: 0.7114399962616571 and parameters: {'optuna_batch_size': 104, 'optimizer': 'RMSprop', 'lr': 0.004027396366492671, 'alpha': 5.573336803137772, 'beta': 7.1064493363762455, 'gamma': 2.072911753441611, 'delta': 6.976104064074682}. Best is trial 56 with value: 0.8085334443997629.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 10 / 10 | Reconst_loss: 1803.905 | Kldiv loss: 459.286 | Classifcation loss: 1.947 | Constrast loss: 10.01 | Total loss: 5808.069 | Train acc: 71.144 % ||| Val Loss: 5724.489 | Val acc: 71.924 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 1 / 10 | Reconst_loss: 9156.485 | Kldiv loss: 2833.359 | Classifcation loss: 2.310 | Constrast loss: 696.87 | Total loss: 55926.056 | Train acc: 26.283 % ||| Val Loss: 32570.639 | Val acc: 36.327 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 2 / 10 | Reconst_loss: 8776.178 | Kldiv loss: 1957.517 | Classifcation loss: 2.283 | Constrast loss: 346.36 | Total loss: 30295.375 | Train acc: 42.028 % ||| Val Loss: 28018.634 | Val acc: 49.623 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 3 / 10 | Reconst_loss: 7727.424 | Kldiv loss: 2085.012 | Classifcation loss: 2.225 | Constrast loss: 349.09 | Total loss: 27764.330 | Train acc: 50.135 % ||| Val Loss: 26488.562 | Val acc: 53.438 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 4 / 10 | Reconst_loss: 7577.173 | Kldiv loss: 1893.640 | Classifcation loss: 2.234 | Constrast loss: 311.55 | Total loss: 26612.239 | Train acc: 53.515 % ||| Val Loss: 25752.589 | Val acc: 54.688 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 5 / 10 | Reconst_loss: 7187.560 | Kldiv loss: 1919.389 | Classifcation loss: 2.128 | Constrast loss: 313.74 | Total loss: 25625.501 | Train acc: 55.347 % ||| Val Loss: 24602.203 | Val acc: 57.264 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 6 / 10 | Reconst_loss: 6992.590 | Kldiv loss: 1744.940 | Classifcation loss: 2.149 | Constrast loss: 344.23 | Total loss: 24823.232 | Train acc: 56.704 % ||| Val Loss: 24026.397 | Val acc: 58.459 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 7 / 10 | Reconst_loss: 7171.695 | Kldiv loss: 1961.726 | Classifcation loss: 2.095 | Constrast loss: 316.35 | Total loss: 24047.091 | Train acc: 57.979 % ||| Val Loss: 22943.784 | Val acc: 59.002 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 8 / 10 | Reconst_loss: 6082.789 | Kldiv loss: 1809.424 | Classifcation loss: 2.129 | Constrast loss: 277.39 | Total loss: 23474.941 | Train acc: 59.040 % ||| Val Loss: 22414.355 | Val acc: 61.182 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 9 / 10 | Reconst_loss: 6884.967 | Kldiv loss: 1923.547 | Classifcation loss: 2.060 | Constrast loss: 161.87 | Total loss: 22946.879 | Train acc: 60.086 % ||| Val Loss: 22024.308 | Val acc: 61.739 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2023-02-27 05:43:02,040]\u001b[0m Trial 67 finished with value: 0.6361716071921092 and parameters: {'optuna_batch_size': 350, 'optimizer': 'RMSprop', 'lr': 0.0035066594644715403, 'alpha': 5.075235747152614, 'beta': 6.498945098082624, 'gamma': 1.5875701296883138, 'delta': 6.640907480224585}. Best is trial 56 with value: 0.8085334443997629.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 10 / 10 | Reconst_loss: 6954.474 | Kldiv loss: 1821.623 | Classifcation loss: 2.073 | Constrast loss: 242.98 | Total loss: 22595.352 | Train acc: 63.617 % ||| Val Loss: 21724.131 | Val acc: 65.213 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 1 / 10 | Reconst_loss: 4677.582 | Kldiv loss: 3221.196 | Classifcation loss: 2.513 | Constrast loss: 797.42 | Total loss: 224485.453 | Train acc: 11.574 % ||| Val Loss: 91073.278 | Val acc: 16.245 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 2 / 10 | Reconst_loss: 4567.074 | Kldiv loss: 1333.457 | Classifcation loss: 2.410 | Constrast loss: 171.26 | Total loss: 64337.537 | Train acc: 20.641 % ||| Val Loss: 47333.620 | Val acc: 28.217 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 3 / 10 | Reconst_loss: 3973.702 | Kldiv loss: 1237.962 | Classifcation loss: 2.383 | Constrast loss: 141.74 | Total loss: 43766.365 | Train acc: 33.460 % ||| Val Loss: 39767.890 | Val acc: 37.488 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 4 / 10 | Reconst_loss: 3349.779 | Kldiv loss: 1135.669 | Classifcation loss: 2.253 | Constrast loss: 110.24 | Total loss: 38251.484 | Train acc: 40.248 % ||| Val Loss: 35750.785 | Val acc: 42.228 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 5 / 10 | Reconst_loss: 3710.342 | Kldiv loss: 1100.606 | Classifcation loss: 2.320 | Constrast loss: 98.04 | Total loss: 35031.421 | Train acc: 43.955 % ||| Val Loss: 33782.183 | Val acc: 44.627 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 6 / 10 | Reconst_loss: 2699.148 | Kldiv loss: 1123.559 | Classifcation loss: 2.280 | Constrast loss: 77.97 | Total loss: 33377.365 | Train acc: 45.700 % ||| Val Loss: 32294.740 | Val acc: 46.243 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 7 / 10 | Reconst_loss: 3475.776 | Kldiv loss: 1174.292 | Classifcation loss: 2.226 | Constrast loss: 58.95 | Total loss: 32107.996 | Train acc: 46.700 % ||| Val Loss: 31298.852 | Val acc: 46.705 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 8 / 10 | Reconst_loss: 3025.369 | Kldiv loss: 973.874 | Classifcation loss: 2.206 | Constrast loss: 84.35 | Total loss: 31273.421 | Train acc: 47.270 % ||| Val Loss: 30725.622 | Val acc: 47.065 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 9 / 10 | Reconst_loss: 2973.012 | Kldiv loss: 1108.869 | Classifcation loss: 2.246 | Constrast loss: 77.28 | Total loss: 30724.174 | Train acc: 47.775 % ||| Val Loss: 30179.397 | Val acc: 47.888 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2023-02-27 05:43:23,677]\u001b[0m Trial 68 finished with value: 0.48262056751740473 and parameters: {'optuna_batch_size': 433, 'optimizer': 'Adam', 'lr': 0.0031073633151594013, 'alpha': 6.280004608252385, 'beta': 8.693578324386502, 'gamma': 1.1330232143094883, 'delta': 6.34301868349064}. Best is trial 56 with value: 0.8085334443997629.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 10 / 10 | Reconst_loss: 2839.506 | Kldiv loss: 1025.461 | Classifcation loss: 2.211 | Constrast loss: 47.49 | Total loss: 30370.687 | Train acc: 48.262 % ||| Val Loss: 29706.402 | Val acc: 47.992 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 1 / 10 | Reconst_loss: 297.283 | Kldiv loss: 41.791 | Classifcation loss: 2.163 | Constrast loss: 4.85 | Total loss: 3739.441 | Train acc: 38.925 % ||| Val Loss: 3185.300 | Val acc: 53.196 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 2 / 10 | Reconst_loss: 353.459 | Kldiv loss: 61.530 | Classifcation loss: 2.069 | Constrast loss: 0.00 | Total loss: 3075.822 | Train acc: 57.376 % ||| Val Loss: 3019.161 | Val acc: 60.641 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 3 / 10 | Reconst_loss: 272.153 | Kldiv loss: 46.990 | Classifcation loss: 2.290 | Constrast loss: 2.89 | Total loss: 2912.676 | Train acc: 61.462 % ||| Val Loss: 2783.337 | Val acc: 62.191 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 4 / 10 | Reconst_loss: 331.303 | Kldiv loss: 42.461 | Classifcation loss: 2.032 | Constrast loss: 1.72 | Total loss: 2824.918 | Train acc: 63.390 % ||| Val Loss: 2750.003 | Val acc: 64.673 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 5 / 10 | Reconst_loss: 150.317 | Kldiv loss: 49.014 | Classifcation loss: 2.033 | Constrast loss: 0.00 | Total loss: 2780.446 | Train acc: 64.227 % ||| Val Loss: 2775.577 | Val acc: 64.643 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 6 / 10 | Reconst_loss: 326.886 | Kldiv loss: 46.861 | Classifcation loss: 2.156 | Constrast loss: 0.28 | Total loss: 2751.552 | Train acc: 64.654 % ||| Val Loss: 2702.397 | Val acc: 65.261 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 7 / 10 | Reconst_loss: 400.878 | Kldiv loss: 48.544 | Classifcation loss: 2.159 | Constrast loss: 4.84 | Total loss: 2727.078 | Train acc: 65.489 % ||| Val Loss: 2674.188 | Val acc: 66.396 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 8 / 10 | Reconst_loss: 374.000 | Kldiv loss: 50.307 | Classifcation loss: 2.013 | Constrast loss: 3.89 | Total loss: 2706.898 | Train acc: 66.007 % ||| Val Loss: 2777.047 | Val acc: 66.452 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 9 / 10 | Reconst_loss: 224.910 | Kldiv loss: 61.928 | Classifcation loss: 2.169 | Constrast loss: 0.35 | Total loss: 2699.430 | Train acc: 66.128 % ||| Val Loss: 2671.026 | Val acc: 67.492 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2023-02-27 05:44:30,715]\u001b[0m Trial 69 finished with value: 0.6677025782688761 and parameters: {'optuna_batch_size': 48, 'optimizer': 'RMSprop', 'lr': 0.004448922639656691, 'alpha': 6.730154909891339, 'beta': 7.733124947002658, 'gamma': 2.388810249704015, 'delta': 7.618503069335748}. Best is trial 56 with value: 0.8085334443997629.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 10 / 10 | Reconst_loss: 341.803 | Kldiv loss: 40.886 | Classifcation loss: 2.109 | Constrast loss: 3.96 | Total loss: 2684.166 | Train acc: 66.770 % ||| Val Loss: 2772.895 | Val acc: 65.454 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 1 / 10 | Reconst_loss: 1787.966 | Kldiv loss: 660.233 | Classifcation loss: 2.452 | Constrast loss: 105.74 | Total loss: 35271.826 | Train acc: 20.172 % ||| Val Loss: 28536.578 | Val acc: 27.989 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 2 / 10 | Reconst_loss: 1900.324 | Kldiv loss: 736.989 | Classifcation loss: 2.406 | Constrast loss: 83.06 | Total loss: 27441.689 | Train acc: 33.695 % ||| Val Loss: 25516.168 | Val acc: 42.588 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 3 / 10 | Reconst_loss: 1382.150 | Kldiv loss: 555.516 | Classifcation loss: 2.226 | Constrast loss: 69.72 | Total loss: 25632.379 | Train acc: 42.758 % ||| Val Loss: 24347.424 | Val acc: 48.122 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 4 / 10 | Reconst_loss: 1487.344 | Kldiv loss: 297.138 | Classifcation loss: 2.147 | Constrast loss: 11.69 | Total loss: 18139.062 | Train acc: 47.428 % ||| Val Loss: 15097.346 | Val acc: 49.267 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 5 / 10 | Reconst_loss: 1282.037 | Kldiv loss: 267.646 | Classifcation loss: 2.040 | Constrast loss: 5.98 | Total loss: 15208.015 | Train acc: 57.155 % ||| Val Loss: 14445.334 | Val acc: 62.247 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 6 / 10 | Reconst_loss: 1523.063 | Kldiv loss: 195.143 | Classifcation loss: 2.031 | Constrast loss: 34.75 | Total loss: 14506.595 | Train acc: 66.780 % ||| Val Loss: 13637.201 | Val acc: 71.154 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 7 / 10 | Reconst_loss: 1167.311 | Kldiv loss: 283.408 | Classifcation loss: 2.017 | Constrast loss: 2.78 | Total loss: 14017.071 | Train acc: 70.994 % ||| Val Loss: 13146.007 | Val acc: 72.147 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 8 / 10 | Reconst_loss: 885.204 | Kldiv loss: 234.045 | Classifcation loss: 2.006 | Constrast loss: 8.84 | Total loss: 13453.472 | Train acc: 72.114 % ||| Val Loss: 12820.149 | Val acc: 73.994 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 9 / 10 | Reconst_loss: 1229.781 | Kldiv loss: 263.947 | Classifcation loss: 1.942 | Constrast loss: 0.88 | Total loss: 13120.090 | Train acc: 72.936 % ||| Val Loss: 12519.187 | Val acc: 74.974 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2023-02-27 05:44:53,904]\u001b[0m Trial 70 finished with value: 0.7411239328267175 and parameters: {'optuna_batch_size': 209, 'optimizer': 'RMSprop', 'lr': 0.004965065788855471, 'alpha': 5.947303895312832, 'beta': 7.364884790100438, 'gamma': 0.5330182191316393, 'delta': 7.128559247202816}. Best is trial 56 with value: 0.8085334443997629.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 10 / 10 | Reconst_loss: 1124.970 | Kldiv loss: 228.734 | Classifcation loss: 1.978 | Constrast loss: 7.89 | Total loss: 12892.431 | Train acc: 74.112 % ||| Val Loss: 12811.517 | Val acc: 74.763 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 1 / 10 | Reconst_loss: 311.908 | Kldiv loss: 76.260 | Classifcation loss: 2.187 | Constrast loss: 0.23 | Total loss: 14974.184 | Train acc: 37.282 % ||| Val Loss: 11837.038 | Val acc: 52.798 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 2 / 10 | Reconst_loss: 335.293 | Kldiv loss: 60.667 | Classifcation loss: 2.069 | Constrast loss: 0.00 | Total loss: 11431.468 | Train acc: 57.167 % ||| Val Loss: 10463.923 | Val acc: 64.894 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 3 / 10 | Reconst_loss: 561.346 | Kldiv loss: 66.944 | Classifcation loss: 2.236 | Constrast loss: 2.02 | Total loss: 10321.448 | Train acc: 66.717 % ||| Val Loss: 10182.328 | Val acc: 68.784 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 4 / 10 | Reconst_loss: 302.678 | Kldiv loss: 48.673 | Classifcation loss: 1.971 | Constrast loss: 0.00 | Total loss: 9800.627 | Train acc: 70.074 % ||| Val Loss: 9490.959 | Val acc: 70.839 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 5 / 10 | Reconst_loss: 241.804 | Kldiv loss: 57.124 | Classifcation loss: 2.143 | Constrast loss: 0.00 | Total loss: 9527.648 | Train acc: 70.718 % ||| Val Loss: 9150.394 | Val acc: 71.357 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 6 / 10 | Reconst_loss: 234.374 | Kldiv loss: 59.593 | Classifcation loss: 1.952 | Constrast loss: 0.00 | Total loss: 9392.106 | Train acc: 70.962 % ||| Val Loss: 9084.926 | Val acc: 70.268 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 7 / 10 | Reconst_loss: 175.486 | Kldiv loss: 66.167 | Classifcation loss: 1.848 | Constrast loss: 0.00 | Total loss: 9204.550 | Train acc: 71.167 % ||| Val Loss: 9006.316 | Val acc: 72.556 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 8 / 10 | Reconst_loss: 435.243 | Kldiv loss: 91.803 | Classifcation loss: 1.868 | Constrast loss: 0.00 | Total loss: 9123.248 | Train acc: 71.160 % ||| Val Loss: 9269.893 | Val acc: 71.089 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 9 / 10 | Reconst_loss: 174.811 | Kldiv loss: 45.528 | Classifcation loss: 2.132 | Constrast loss: 1.00 | Total loss: 9015.281 | Train acc: 71.660 % ||| Val Loss: 8838.240 | Val acc: 71.392 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2023-02-27 05:45:20,833]\u001b[0m Trial 71 finished with value: 0.7156185188730424 and parameters: {'optuna_batch_size': 155, 'optimizer': 'RMSprop', 'lr': 0.00469987728779605, 'alpha': 6.004011574137485, 'beta': 7.242828249760041, 'gamma': 0.5253031101465064, 'delta': 6.979424401134076}. Best is trial 56 with value: 0.8085334443997629.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 10 / 10 | Reconst_loss: 265.955 | Kldiv loss: 57.647 | Classifcation loss: 2.039 | Constrast loss: 0.00 | Total loss: 8972.421 | Train acc: 71.562 % ||| Val Loss: 8815.771 | Val acc: 71.763 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 1 / 10 | Reconst_loss: 9575.994 | Kldiv loss: 1914.970 | Classifcation loss: 2.340 | Constrast loss: 510.49 | Total loss: 39539.723 | Train acc: 29.331 % ||| Val Loss: 26899.427 | Val acc: 40.207 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 2 / 10 | Reconst_loss: 8207.366 | Kldiv loss: 2171.820 | Classifcation loss: 2.210 | Constrast loss: 394.13 | Total loss: 25184.228 | Train acc: 47.188 % ||| Val Loss: 23788.841 | Val acc: 52.099 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 3 / 10 | Reconst_loss: 8505.872 | Kldiv loss: 1985.567 | Classifcation loss: 2.151 | Constrast loss: 523.26 | Total loss: 23400.784 | Train acc: 54.682 % ||| Val Loss: 22740.558 | Val acc: 55.910 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 4 / 10 | Reconst_loss: 7185.648 | Kldiv loss: 1809.573 | Classifcation loss: 2.116 | Constrast loss: 394.51 | Total loss: 21724.515 | Train acc: 59.743 % ||| Val Loss: 20438.010 | Val acc: 62.745 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 5 / 10 | Reconst_loss: 6871.868 | Kldiv loss: 1888.430 | Classifcation loss: 2.099 | Constrast loss: 249.15 | Total loss: 20764.122 | Train acc: 61.507 % ||| Val Loss: 19637.575 | Val acc: 63.701 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 6 / 10 | Reconst_loss: 7262.309 | Kldiv loss: 1679.247 | Classifcation loss: 2.088 | Constrast loss: 356.98 | Total loss: 20142.691 | Train acc: 63.561 % ||| Val Loss: 19617.368 | Val acc: 64.580 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 7 / 10 | Reconst_loss: 6385.503 | Kldiv loss: 1843.673 | Classifcation loss: 2.025 | Constrast loss: 176.83 | Total loss: 19846.859 | Train acc: 65.484 % ||| Val Loss: 19074.236 | Val acc: 67.397 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 8 / 10 | Reconst_loss: 6798.993 | Kldiv loss: 1744.156 | Classifcation loss: 2.033 | Constrast loss: 210.11 | Total loss: 19179.240 | Train acc: 67.705 % ||| Val Loss: 18733.691 | Val acc: 68.068 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 9 / 10 | Reconst_loss: 7626.046 | Kldiv loss: 1907.234 | Classifcation loss: 2.020 | Constrast loss: 199.75 | Total loss: 18895.682 | Train acc: 68.390 % ||| Val Loss: 24080.566 | Val acc: 61.379 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2023-02-27 05:45:40,832]\u001b[0m Trial 72 finished with value: 0.6912388824846013 and parameters: {'optuna_batch_size': 296, 'optimizer': 'RMSprop', 'lr': 0.005220445840573477, 'alpha': 7.010673400292074, 'beta': 7.99920311560895, 'gamma': 0.7613588028869182, 'delta': 7.255315493612928}. Best is trial 56 with value: 0.8085334443997629.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 10 / 10 | Reconst_loss: 6283.778 | Kldiv loss: 1728.455 | Classifcation loss: 2.007 | Constrast loss: 171.94 | Total loss: 18675.982 | Train acc: 69.124 % ||| Val Loss: 17750.245 | Val acc: 71.100 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 1 / 10 | Reconst_loss: 1025.512 | Kldiv loss: 219.560 | Classifcation loss: 2.212 | Constrast loss: 8.72 | Total loss: 24955.334 | Train acc: 27.676 % ||| Val Loss: 15579.231 | Val acc: 42.232 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 2 / 10 | Reconst_loss: 884.585 | Kldiv loss: 201.923 | Classifcation loss: 2.091 | Constrast loss: 3.23 | Total loss: 15118.406 | Train acc: 49.692 % ||| Val Loss: 15067.980 | Val acc: 51.876 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 3 / 10 | Reconst_loss: 772.090 | Kldiv loss: 230.593 | Classifcation loss: 2.080 | Constrast loss: 5.62 | Total loss: 13957.864 | Train acc: 58.044 % ||| Val Loss: 14223.742 | Val acc: 58.245 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 4 / 10 | Reconst_loss: 756.489 | Kldiv loss: 180.311 | Classifcation loss: 2.063 | Constrast loss: 5.95 | Total loss: 13313.917 | Train acc: 62.874 % ||| Val Loss: 12772.669 | Val acc: 66.920 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 5 / 10 | Reconst_loss: 656.806 | Kldiv loss: 209.416 | Classifcation loss: 2.101 | Constrast loss: 2.78 | Total loss: 12765.775 | Train acc: 66.536 % ||| Val Loss: 12208.240 | Val acc: 68.597 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 6 / 10 | Reconst_loss: 731.655 | Kldiv loss: 203.427 | Classifcation loss: 2.056 | Constrast loss: 1.39 | Total loss: 12369.476 | Train acc: 68.113 % ||| Val Loss: 11994.051 | Val acc: 69.292 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 7 / 10 | Reconst_loss: 604.751 | Kldiv loss: 197.148 | Classifcation loss: 1.994 | Constrast loss: 6.40 | Total loss: 12137.670 | Train acc: 68.692 % ||| Val Loss: 11672.682 | Val acc: 69.727 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 8 / 10 | Reconst_loss: 624.060 | Kldiv loss: 191.068 | Classifcation loss: 2.010 | Constrast loss: 9.22 | Total loss: 11981.950 | Train acc: 69.242 % ||| Val Loss: 11595.215 | Val acc: 70.306 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 9 / 10 | Reconst_loss: 1055.735 | Kldiv loss: 200.441 | Classifcation loss: 2.124 | Constrast loss: 4.65 | Total loss: 11791.541 | Train acc: 69.703 % ||| Val Loss: 11476.381 | Val acc: 70.635 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2023-02-27 05:46:04,475]\u001b[0m Trial 73 finished with value: 0.7044515186306237 and parameters: {'optuna_batch_size': 201, 'optimizer': 'RMSprop', 'lr': 0.004046822285740424, 'alpha': 6.526492064454768, 'beta': 7.544177357010719, 'gamma': 0.1022736901923832, 'delta': 7.973206947996797}. Best is trial 56 with value: 0.8085334443997629.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 10 / 10 | Reconst_loss: 839.222 | Kldiv loss: 238.376 | Classifcation loss: 2.152 | Constrast loss: 4.21 | Total loss: 11724.067 | Train acc: 70.445 % ||| Val Loss: 12096.466 | Val acc: 69.648 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 1 / 10 | Reconst_loss: 741.953 | Kldiv loss: 181.748 | Classifcation loss: 2.265 | Constrast loss: 1.26 | Total loss: 35691.119 | Train acc: 26.385 % ||| Val Loss: 21679.103 | Val acc: 38.070 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 2 / 10 | Reconst_loss: 576.356 | Kldiv loss: 129.854 | Classifcation loss: 2.155 | Constrast loss: 3.31 | Total loss: 20559.470 | Train acc: 45.640 % ||| Val Loss: 18746.912 | Val acc: 52.161 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 3 / 10 | Reconst_loss: 385.804 | Kldiv loss: 138.102 | Classifcation loss: 2.173 | Constrast loss: 6.76 | Total loss: 18711.828 | Train acc: 54.543 % ||| Val Loss: 17544.178 | Val acc: 58.371 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 4 / 10 | Reconst_loss: 819.061 | Kldiv loss: 170.706 | Classifcation loss: 2.238 | Constrast loss: 0.00 | Total loss: 17578.269 | Train acc: 59.914 % ||| Val Loss: 16572.568 | Val acc: 62.061 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 5 / 10 | Reconst_loss: 345.976 | Kldiv loss: 128.934 | Classifcation loss: 2.187 | Constrast loss: 3.29 | Total loss: 16624.369 | Train acc: 61.897 % ||| Val Loss: 15668.712 | Val acc: 63.436 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 6 / 10 | Reconst_loss: 392.601 | Kldiv loss: 118.783 | Classifcation loss: 2.092 | Constrast loss: 3.64 | Total loss: 16034.711 | Train acc: 63.655 % ||| Val Loss: 15891.790 | Val acc: 64.356 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 7 / 10 | Reconst_loss: 749.267 | Kldiv loss: 160.743 | Classifcation loss: 2.102 | Constrast loss: 3.55 | Total loss: 15635.977 | Train acc: 64.802 % ||| Val Loss: 20507.098 | Val acc: 53.653 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 8 / 10 | Reconst_loss: 443.793 | Kldiv loss: 109.712 | Classifcation loss: 1.994 | Constrast loss: 3.67 | Total loss: 15291.850 | Train acc: 65.490 % ||| Val Loss: 14722.909 | Val acc: 65.450 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 9 / 10 | Reconst_loss: 407.946 | Kldiv loss: 124.943 | Classifcation loss: 2.104 | Constrast loss: 0.00 | Total loss: 15125.117 | Train acc: 65.779 % ||| Val Loss: 14702.287 | Val acc: 65.953 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2023-02-27 05:46:25,632]\u001b[0m Trial 74 finished with value: 0.6612870158661763 and parameters: {'optuna_batch_size': 254, 'optimizer': 'RMSprop', 'lr': 0.005004478223388858, 'alpha': 5.4066021734051395, 'beta': 6.6587328426115855, 'gamma': 1.0461900733162355, 'delta': 6.0962798852970135}. Best is trial 56 with value: 0.8085334443997629.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 10 / 10 | Reconst_loss: 654.908 | Kldiv loss: 127.981 | Classifcation loss: 2.019 | Constrast loss: 0.00 | Total loss: 15001.195 | Train acc: 66.129 % ||| Val Loss: 14679.969 | Val acc: 66.166 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 1 / 10 | Reconst_loss: 308.137 | Kldiv loss: 54.086 | Classifcation loss: 2.216 | Constrast loss: 0.00 | Total loss: 11196.794 | Train acc: 35.264 % ||| Val Loss: 9184.866 | Val acc: 52.235 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 2 / 10 | Reconst_loss: 365.216 | Kldiv loss: 65.649 | Classifcation loss: 2.142 | Constrast loss: 0.24 | Total loss: 8794.804 | Train acc: 57.284 % ||| Val Loss: 8089.313 | Val acc: 64.991 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 3 / 10 | Reconst_loss: 130.702 | Kldiv loss: 59.267 | Classifcation loss: 1.926 | Constrast loss: 0.00 | Total loss: 8045.812 | Train acc: 65.900 % ||| Val Loss: 7638.115 | Val acc: 69.466 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 4 / 10 | Reconst_loss: 366.681 | Kldiv loss: 76.847 | Classifcation loss: 2.171 | Constrast loss: 2.63 | Total loss: 7685.714 | Train acc: 69.460 % ||| Val Loss: 8290.948 | Val acc: 62.377 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 5 / 10 | Reconst_loss: 199.111 | Kldiv loss: 54.159 | Classifcation loss: 1.975 | Constrast loss: 0.78 | Total loss: 7389.646 | Train acc: 71.036 % ||| Val Loss: 7903.517 | Val acc: 68.171 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 6 / 10 | Reconst_loss: 284.758 | Kldiv loss: 70.816 | Classifcation loss: 2.106 | Constrast loss: 0.00 | Total loss: 7246.262 | Train acc: 71.745 % ||| Val Loss: 7295.935 | Val acc: 72.114 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 7 / 10 | Reconst_loss: 178.678 | Kldiv loss: 58.884 | Classifcation loss: 1.819 | Constrast loss: 0.00 | Total loss: 7193.868 | Train acc: 72.362 % ||| Val Loss: 6977.189 | Val acc: 72.235 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 8 / 10 | Reconst_loss: 159.743 | Kldiv loss: 54.257 | Classifcation loss: 1.944 | Constrast loss: 3.57 | Total loss: 7087.973 | Train acc: 73.034 % ||| Val Loss: 7013.362 | Val acc: 72.620 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 9 / 10 | Reconst_loss: 287.982 | Kldiv loss: 60.796 | Classifcation loss: 1.938 | Constrast loss: 0.00 | Total loss: 7053.057 | Train acc: 73.192 % ||| Val Loss: 6840.014 | Val acc: 73.548 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2023-02-27 05:46:57,772]\u001b[0m Trial 75 finished with value: 0.7282375478927205 and parameters: {'optuna_batch_size': 120, 'optimizer': 'RMSprop', 'lr': 0.005524618750866037, 'alpha': 5.729901999269573, 'beta': 7.13168174731025, 'gamma': 1.8560075847239386, 'delta': 5.646514017075377}. Best is trial 56 with value: 0.8085334443997629.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 10 / 10 | Reconst_loss: 349.698 | Kldiv loss: 63.791 | Classifcation loss: 1.689 | Constrast loss: 0.00 | Total loss: 7056.128 | Train acc: 72.824 % ||| Val Loss: 6861.506 | Val acc: 73.076 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 1 / 10 | Reconst_loss: 250.114 | Kldiv loss: 28.696 | Classifcation loss: 2.050 | Constrast loss: 0.00 | Total loss: 6495.392 | Train acc: 44.197 % ||| Val Loss: 5490.418 | Val acc: 57.846 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 2 / 10 | Reconst_loss: 276.422 | Kldiv loss: 45.846 | Classifcation loss: 2.157 | Constrast loss: 1.22 | Total loss: 5431.336 | Train acc: 60.954 % ||| Val Loss: 4955.273 | Val acc: 65.353 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 3 / 10 | Reconst_loss: 280.771 | Kldiv loss: 45.647 | Classifcation loss: 2.007 | Constrast loss: 0.00 | Total loss: 4977.894 | Train acc: 65.894 % ||| Val Loss: 4809.427 | Val acc: 68.394 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 4 / 10 | Reconst_loss: 151.119 | Kldiv loss: 39.024 | Classifcation loss: 2.132 | Constrast loss: 1.02 | Total loss: 4830.904 | Train acc: 67.265 % ||| Val Loss: 4651.273 | Val acc: 67.727 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 5 / 10 | Reconst_loss: 119.414 | Kldiv loss: 38.892 | Classifcation loss: 2.142 | Constrast loss: 0.05 | Total loss: 4753.121 | Train acc: 67.100 % ||| Val Loss: 4769.311 | Val acc: 66.490 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 6 / 10 | Reconst_loss: 263.652 | Kldiv loss: 37.429 | Classifcation loss: 1.983 | Constrast loss: 0.00 | Total loss: 4677.344 | Train acc: 67.932 % ||| Val Loss: 4554.007 | Val acc: 68.879 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 7 / 10 | Reconst_loss: 196.178 | Kldiv loss: 35.775 | Classifcation loss: 1.935 | Constrast loss: 0.00 | Total loss: 4616.285 | Train acc: 69.015 % ||| Val Loss: 4578.090 | Val acc: 68.806 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 8 / 10 | Reconst_loss: 137.292 | Kldiv loss: 35.315 | Classifcation loss: 2.026 | Constrast loss: 1.71 | Total loss: 4606.403 | Train acc: 69.529 % ||| Val Loss: 4500.501 | Val acc: 69.985 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 9 / 10 | Reconst_loss: 143.098 | Kldiv loss: 42.098 | Classifcation loss: 1.802 | Constrast loss: 0.00 | Total loss: 4564.424 | Train acc: 70.296 % ||| Val Loss: 4536.879 | Val acc: 70.584 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2023-02-27 05:47:41,729]\u001b[0m Trial 76 finished with value: 0.7077294685990325 and parameters: {'optuna_batch_size': 81, 'optimizer': 'RMSprop', 'lr': 0.004499677895795173, 'alpha': 5.11854291937501, 'beta': 8.278889273370062, 'gamma': 0.3491926070637657, 'delta': 7.523201483629975}. Best is trial 56 with value: 0.8085334443997629.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 10 / 10 | Reconst_loss: 263.759 | Kldiv loss: 40.746 | Classifcation loss: 2.112 | Constrast loss: 0.00 | Total loss: 4511.314 | Train acc: 70.773 % ||| Val Loss: 4639.605 | Val acc: 69.991 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 1 / 10 | Reconst_loss: 1822.626 | Kldiv loss: 389.095 | Classifcation loss: 2.322 | Constrast loss: 47.46 | Total loss: 28100.688 | Train acc: 32.399 % ||| Val Loss: 17980.032 | Val acc: 39.760 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 2 / 10 | Reconst_loss: 2081.740 | Kldiv loss: 471.961 | Classifcation loss: 2.200 | Constrast loss: 17.81 | Total loss: 17456.065 | Train acc: 44.252 % ||| Val Loss: 16188.104 | Val acc: 47.199 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 3 / 10 | Reconst_loss: 1445.981 | Kldiv loss: 373.586 | Classifcation loss: 2.195 | Constrast loss: 19.80 | Total loss: 16130.315 | Train acc: 50.443 % ||| Val Loss: 14930.814 | Val acc: 50.880 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 4 / 10 | Reconst_loss: 1591.871 | Kldiv loss: 324.077 | Classifcation loss: 2.180 | Constrast loss: 32.79 | Total loss: 15291.044 | Train acc: 53.109 % ||| Val Loss: 14665.711 | Val acc: 57.633 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 5 / 10 | Reconst_loss: 1258.587 | Kldiv loss: 299.321 | Classifcation loss: 2.045 | Constrast loss: 17.02 | Total loss: 14984.015 | Train acc: 57.612 % ||| Val Loss: 14520.863 | Val acc: 60.078 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 6 / 10 | Reconst_loss: 1591.331 | Kldiv loss: 321.738 | Classifcation loss: 1.982 | Constrast loss: 15.26 | Total loss: 14480.821 | Train acc: 60.745 % ||| Val Loss: 13465.022 | Val acc: 62.955 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 7 / 10 | Reconst_loss: 1501.609 | Kldiv loss: 317.472 | Classifcation loss: 2.071 | Constrast loss: 12.63 | Total loss: 13961.470 | Train acc: 62.862 % ||| Val Loss: 13417.461 | Val acc: 65.123 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 8 / 10 | Reconst_loss: 1858.978 | Kldiv loss: 292.040 | Classifcation loss: 2.077 | Constrast loss: 22.47 | Total loss: 13770.567 | Train acc: 64.197 % ||| Val Loss: 13042.654 | Val acc: 65.608 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 9 / 10 | Reconst_loss: 1330.844 | Kldiv loss: 313.936 | Classifcation loss: 1.990 | Constrast loss: 6.16 | Total loss: 13529.480 | Train acc: 65.326 % ||| Val Loss: 13067.182 | Val acc: 65.615 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2023-02-27 05:48:03,447]\u001b[0m Trial 77 finished with value: 0.658037657562539 and parameters: {'optuna_batch_size': 215, 'optimizer': 'RMSprop', 'lr': 0.007611750951387062, 'alpha': 6.361931543447064, 'beta': 7.911586699247236, 'gamma': 1.5378893302035364, 'delta': 8.23954000382201}. Best is trial 56 with value: 0.8085334443997629.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 10 / 10 | Reconst_loss: 1096.695 | Kldiv loss: 323.758 | Classifcation loss: 2.053 | Constrast loss: 2.60 | Total loss: 13373.995 | Train acc: 65.804 % ||| Val Loss: 12819.836 | Val acc: 67.150 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 1 / 10 | Reconst_loss: 4282.670 | Kldiv loss: 763.131 | Classifcation loss: 2.179 | Constrast loss: 141.99 | Total loss: 14881.517 | Train acc: 39.447 % ||| Val Loss: 11818.345 | Val acc: 52.058 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 2 / 10 | Reconst_loss: 3492.427 | Kldiv loss: 664.414 | Classifcation loss: 2.032 | Constrast loss: 127.50 | Total loss: 11507.963 | Train acc: 58.967 % ||| Val Loss: 10608.716 | Val acc: 66.139 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 3 / 10 | Reconst_loss: 3775.618 | Kldiv loss: 824.332 | Classifcation loss: 1.962 | Constrast loss: 85.25 | Total loss: 10803.170 | Train acc: 65.867 % ||| Val Loss: 10307.128 | Val acc: 69.649 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 4 / 10 | Reconst_loss: 3299.650 | Kldiv loss: 701.189 | Classifcation loss: 1.999 | Constrast loss: 103.42 | Total loss: 10402.229 | Train acc: 70.378 % ||| Val Loss: 9881.884 | Val acc: 72.765 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 5 / 10 | Reconst_loss: 3427.544 | Kldiv loss: 646.496 | Classifcation loss: 2.000 | Constrast loss: 114.03 | Total loss: 9993.384 | Train acc: 72.149 % ||| Val Loss: 10016.338 | Val acc: 72.022 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 6 / 10 | Reconst_loss: 3700.930 | Kldiv loss: 664.972 | Classifcation loss: 1.894 | Constrast loss: 78.25 | Total loss: 9716.837 | Train acc: 72.746 % ||| Val Loss: 9648.480 | Val acc: 70.643 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 7 / 10 | Reconst_loss: 3603.835 | Kldiv loss: 700.590 | Classifcation loss: 2.004 | Constrast loss: 59.01 | Total loss: 9627.551 | Train acc: 72.679 % ||| Val Loss: 9289.572 | Val acc: 74.107 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 8 / 10 | Reconst_loss: 3620.996 | Kldiv loss: 605.822 | Classifcation loss: 2.040 | Constrast loss: 104.71 | Total loss: 9416.884 | Train acc: 73.653 % ||| Val Loss: 9377.530 | Val acc: 73.792 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 9 / 10 | Reconst_loss: 3271.472 | Kldiv loss: 705.773 | Classifcation loss: 1.900 | Constrast loss: 62.40 | Total loss: 9357.578 | Train acc: 73.450 % ||| Val Loss: 9020.179 | Val acc: 74.624 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2023-02-27 05:48:31,216]\u001b[0m Trial 78 finished with value: 0.7402390731357802 and parameters: {'optuna_batch_size': 156, 'optimizer': 'RMSprop', 'lr': 0.006195386381967196, 'alpha': 5.984810855889338, 'beta': 6.321709095577936, 'gamma': 0.7024759115428689, 'delta': 8.732029330777216}. Best is trial 56 with value: 0.8085334443997629.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 10 / 10 | Reconst_loss: 3069.287 | Kldiv loss: 718.192 | Classifcation loss: 1.994 | Constrast loss: 95.56 | Total loss: 9231.282 | Train acc: 74.024 % ||| Val Loss: 9012.661 | Val acc: 75.079 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 1 / 10 | Reconst_loss: 3102.123 | Kldiv loss: 563.859 | Classifcation loss: 2.126 | Constrast loss: 98.43 | Total loss: 10419.056 | Train acc: 41.431 % ||| Val Loss: 8291.193 | Val acc: 57.604 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 2 / 10 | Reconst_loss: 3046.093 | Kldiv loss: 543.643 | Classifcation loss: 2.076 | Constrast loss: 112.01 | Total loss: 8205.778 | Train acc: 61.687 % ||| Val Loss: 7823.408 | Val acc: 64.942 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 3 / 10 | Reconst_loss: 2663.046 | Kldiv loss: 544.880 | Classifcation loss: 2.015 | Constrast loss: 69.23 | Total loss: 7609.314 | Train acc: 68.500 % ||| Val Loss: 7392.712 | Val acc: 69.268 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 4 / 10 | Reconst_loss: 2717.547 | Kldiv loss: 580.367 | Classifcation loss: 1.875 | Constrast loss: 15.23 | Total loss: 7313.690 | Train acc: 73.704 % ||| Val Loss: 7149.031 | Val acc: 74.167 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 5 / 10 | Reconst_loss: 3222.484 | Kldiv loss: 717.180 | Classifcation loss: 1.946 | Constrast loss: 34.35 | Total loss: 7169.606 | Train acc: 75.643 % ||| Val Loss: 7313.335 | Val acc: 76.891 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 6 / 10 | Reconst_loss: 3063.167 | Kldiv loss: 618.718 | Classifcation loss: 1.895 | Constrast loss: 22.50 | Total loss: 7054.668 | Train acc: 76.584 % ||| Val Loss: 7000.313 | Val acc: 77.160 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 7 / 10 | Reconst_loss: 2466.351 | Kldiv loss: 581.530 | Classifcation loss: 1.884 | Constrast loss: 27.46 | Total loss: 6950.575 | Train acc: 77.600 % ||| Val Loss: 6677.742 | Val acc: 78.177 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 8 / 10 | Reconst_loss: 2444.913 | Kldiv loss: 564.666 | Classifcation loss: 1.892 | Constrast loss: 31.99 | Total loss: 6841.237 | Train acc: 77.459 % ||| Val Loss: 6654.759 | Val acc: 77.981 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 9 / 10 | Reconst_loss: 2493.864 | Kldiv loss: 494.281 | Classifcation loss: 1.954 | Constrast loss: 38.19 | Total loss: 6795.567 | Train acc: 77.915 % ||| Val Loss: 6721.633 | Val acc: 78.290 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2023-02-27 05:49:05,646]\u001b[0m Trial 79 finished with value: 0.7874550526571721 and parameters: {'optuna_batch_size': 114, 'optimizer': 'RMSprop', 'lr': 0.006728401674710652, 'alpha': 7.274410841385267, 'beta': 7.423028063647211, 'gamma': 1.2384367686298587, 'delta': 6.69928813861562}. Best is trial 56 with value: 0.8085334443997629.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 10 / 10 | Reconst_loss: 2378.688 | Kldiv loss: 607.370 | Classifcation loss: 1.893 | Constrast loss: 40.09 | Total loss: 6737.886 | Train acc: 78.746 % ||| Val Loss: 6536.692 | Val acc: 80.022 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 1 / 10 | Reconst_loss: 3486.497 | Kldiv loss: 427.150 | Classifcation loss: 2.234 | Constrast loss: 149.23 | Total loss: 9956.562 | Train acc: 35.761 % ||| Val Loss: 8539.754 | Val acc: 47.263 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 2 / 10 | Reconst_loss: 2140.928 | Kldiv loss: 472.368 | Classifcation loss: 2.085 | Constrast loss: 88.44 | Total loss: 8015.004 | Train acc: 53.847 % ||| Val Loss: 7356.572 | Val acc: 60.597 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 3 / 10 | Reconst_loss: 2131.318 | Kldiv loss: 515.671 | Classifcation loss: 2.067 | Constrast loss: 58.82 | Total loss: 7541.058 | Train acc: 60.106 % ||| Val Loss: 7142.429 | Val acc: 64.036 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 4 / 10 | Reconst_loss: 2697.996 | Kldiv loss: 579.661 | Classifcation loss: 2.026 | Constrast loss: 76.14 | Total loss: 7213.936 | Train acc: 62.433 % ||| Val Loss: 6955.924 | Val acc: 64.921 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 5 / 10 | Reconst_loss: 2288.467 | Kldiv loss: 622.715 | Classifcation loss: 2.038 | Constrast loss: 28.90 | Total loss: 7008.653 | Train acc: 63.868 % ||| Val Loss: 6711.598 | Val acc: 66.134 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 6 / 10 | Reconst_loss: 2783.369 | Kldiv loss: 522.926 | Classifcation loss: 2.094 | Constrast loss: 45.40 | Total loss: 6894.019 | Train acc: 64.974 % ||| Val Loss: 6997.330 | Val acc: 67.956 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 7 / 10 | Reconst_loss: 2065.906 | Kldiv loss: 538.409 | Classifcation loss: 1.977 | Constrast loss: 51.12 | Total loss: 6814.986 | Train acc: 71.111 % ||| Val Loss: 6496.711 | Val acc: 74.297 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 8 / 10 | Reconst_loss: 2101.968 | Kldiv loss: 535.457 | Classifcation loss: 1.972 | Constrast loss: 56.80 | Total loss: 6761.535 | Train acc: 73.030 % ||| Val Loss: 6466.320 | Val acc: 75.285 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 9 / 10 | Reconst_loss: 2436.908 | Kldiv loss: 495.773 | Classifcation loss: 1.946 | Constrast loss: 47.33 | Total loss: 6630.597 | Train acc: 73.428 % ||| Val Loss: 6498.461 | Val acc: 74.321 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2023-02-27 05:49:40,011]\u001b[0m Trial 80 finished with value: 0.7379347968960654 and parameters: {'optuna_batch_size': 109, 'optimizer': 'RMSprop', 'lr': 0.007426788261894859, 'alpha': 4.731527907839201, 'beta': 6.879571067199526, 'gamma': 1.2541377191779837, 'delta': 6.542983900309207}. Best is trial 56 with value: 0.8085334443997629.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 10 / 10 | Reconst_loss: 2416.260 | Kldiv loss: 569.859 | Classifcation loss: 1.909 | Constrast loss: 28.33 | Total loss: 6538.686 | Train acc: 73.793 % ||| Val Loss: 6386.854 | Val acc: 74.041 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 1 / 10 | Reconst_loss: 595.599 | Kldiv loss: 137.282 | Classifcation loss: 2.021 | Constrast loss: 22.16 | Total loss: 2706.007 | Train acc: 42.450 % ||| Val Loss: 2312.064 | Val acc: 58.759 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 2 / 10 | Reconst_loss: 789.716 | Kldiv loss: 162.617 | Classifcation loss: 1.977 | Constrast loss: 5.98 | Total loss: 2293.972 | Train acc: 59.771 % ||| Val Loss: 2165.157 | Val acc: 63.906 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 3 / 10 | Reconst_loss: 1014.868 | Kldiv loss: 141.329 | Classifcation loss: 2.123 | Constrast loss: 9.38 | Total loss: 2210.421 | Train acc: 62.906 % ||| Val Loss: 2147.494 | Val acc: 62.100 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 4 / 10 | Reconst_loss: 740.139 | Kldiv loss: 145.047 | Classifcation loss: 2.068 | Constrast loss: 14.52 | Total loss: 2180.062 | Train acc: 63.422 % ||| Val Loss: 2220.059 | Val acc: 62.164 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 5 / 10 | Reconst_loss: 945.461 | Kldiv loss: 155.851 | Classifcation loss: 2.078 | Constrast loss: 19.86 | Total loss: 2155.634 | Train acc: 64.113 % ||| Val Loss: 2190.189 | Val acc: 63.458 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 6 / 10 | Reconst_loss: 836.996 | Kldiv loss: 129.250 | Classifcation loss: 2.155 | Constrast loss: 17.65 | Total loss: 2139.292 | Train acc: 64.279 % ||| Val Loss: 2095.096 | Val acc: 64.044 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 7 / 10 | Reconst_loss: 814.873 | Kldiv loss: 151.616 | Classifcation loss: 2.047 | Constrast loss: 23.99 | Total loss: 2117.701 | Train acc: 64.924 % ||| Val Loss: 2074.276 | Val acc: 66.218 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 8 / 10 | Reconst_loss: 869.223 | Kldiv loss: 154.806 | Classifcation loss: 2.125 | Constrast loss: 8.01 | Total loss: 2135.042 | Train acc: 60.704 % ||| Val Loss: 2094.451 | Val acc: 60.565 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 9 / 10 | Reconst_loss: 977.212 | Kldiv loss: 159.232 | Classifcation loss: 2.061 | Constrast loss: 17.44 | Total loss: 2096.848 | Train acc: 61.119 % ||| Val Loss: 2066.248 | Val acc: 61.646 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2023-02-27 05:51:07,888]\u001b[0m Trial 81 finished with value: 0.614681716962298 and parameters: {'optuna_batch_size': 36, 'optimizer': 'RMSprop', 'lr': 0.007263398951421736, 'alpha': 7.354351900133695, 'beta': 7.419313028910244, 'gamma': 0.9263517055940352, 'delta': 6.202285918244402}. Best is trial 56 with value: 0.8085334443997629.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 10 / 10 | Reconst_loss: 1025.065 | Kldiv loss: 155.962 | Classifcation loss: 2.070 | Constrast loss: 5.78 | Total loss: 2083.392 | Train acc: 61.468 % ||| Val Loss: 2158.183 | Val acc: 59.380 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 1 / 10 | Reconst_loss: 2149.563 | Kldiv loss: 355.002 | Classifcation loss: 2.151 | Constrast loss: 28.27 | Total loss: 5797.431 | Train acc: 38.328 % ||| Val Loss: 4934.223 | Val acc: 53.636 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 2 / 10 | Reconst_loss: 1556.785 | Kldiv loss: 351.770 | Classifcation loss: 2.109 | Constrast loss: 31.15 | Total loss: 4738.362 | Train acc: 58.124 % ||| Val Loss: 4459.511 | Val acc: 60.955 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 3 / 10 | Reconst_loss: 2179.741 | Kldiv loss: 319.126 | Classifcation loss: 2.045 | Constrast loss: 45.88 | Total loss: 4535.181 | Train acc: 62.050 % ||| Val Loss: 4401.226 | Val acc: 65.150 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 4 / 10 | Reconst_loss: 1657.106 | Kldiv loss: 358.946 | Classifcation loss: 1.967 | Constrast loss: 11.83 | Total loss: 4398.752 | Train acc: 65.909 % ||| Val Loss: 4229.946 | Val acc: 67.621 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 5 / 10 | Reconst_loss: 1501.239 | Kldiv loss: 332.151 | Classifcation loss: 2.041 | Constrast loss: 28.88 | Total loss: 4303.104 | Train acc: 67.814 % ||| Val Loss: 4491.355 | Val acc: 67.828 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 6 / 10 | Reconst_loss: 1594.180 | Kldiv loss: 345.156 | Classifcation loss: 1.998 | Constrast loss: 18.11 | Total loss: 4235.480 | Train acc: 69.429 % ||| Val Loss: 4131.799 | Val acc: 70.714 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 7 / 10 | Reconst_loss: 1523.223 | Kldiv loss: 352.432 | Classifcation loss: 1.994 | Constrast loss: 16.28 | Total loss: 4187.470 | Train acc: 69.894 % ||| Val Loss: 4077.878 | Val acc: 71.189 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 8 / 10 | Reconst_loss: 1936.194 | Kldiv loss: 340.425 | Classifcation loss: 2.061 | Constrast loss: 60.12 | Total loss: 4158.875 | Train acc: 70.619 % ||| Val Loss: 4784.377 | Val acc: 68.184 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 9 / 10 | Reconst_loss: 1631.703 | Kldiv loss: 353.219 | Classifcation loss: 1.971 | Constrast loss: 21.50 | Total loss: 4128.530 | Train acc: 70.831 % ||| Val Loss: 4061.450 | Val acc: 71.643 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2023-02-27 05:51:52,551]\u001b[0m Trial 82 finished with value: 0.7090196121446116 and parameters: {'optuna_batch_size': 74, 'optimizer': 'RMSprop', 'lr': 0.004882697269840992, 'alpha': 6.75967107746934, 'beta': 7.648424197051665, 'gamma': 0.46984878498408256, 'delta': 6.766417163802853}. Best is trial 56 with value: 0.8085334443997629.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 10 / 10 | Reconst_loss: 1684.941 | Kldiv loss: 360.242 | Classifcation loss: 1.922 | Constrast loss: 10.22 | Total loss: 4110.916 | Train acc: 70.902 % ||| Val Loss: 4025.059 | Val acc: 71.580 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 1 / 10 | Reconst_loss: 2858.972 | Kldiv loss: 692.244 | Classifcation loss: 2.111 | Constrast loss: 67.51 | Total loss: 19389.153 | Train acc: 38.291 % ||| Val Loss: 13673.662 | Val acc: 57.226 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 2 / 10 | Reconst_loss: 3634.443 | Kldiv loss: 483.897 | Classifcation loss: 2.150 | Constrast loss: 110.35 | Total loss: 13383.768 | Train acc: 61.389 % ||| Val Loss: 13537.372 | Val acc: 65.677 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 3 / 10 | Reconst_loss: 3539.792 | Kldiv loss: 551.082 | Classifcation loss: 2.007 | Constrast loss: 61.75 | Total loss: 12493.596 | Train acc: 67.247 % ||| Val Loss: 11620.706 | Val acc: 70.955 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 4 / 10 | Reconst_loss: 2791.978 | Kldiv loss: 660.829 | Classifcation loss: 1.959 | Constrast loss: 61.41 | Total loss: 12041.544 | Train acc: 70.233 % ||| Val Loss: 11589.078 | Val acc: 72.820 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 5 / 10 | Reconst_loss: 2433.017 | Kldiv loss: 570.126 | Classifcation loss: 1.967 | Constrast loss: 65.44 | Total loss: 11781.851 | Train acc: 71.642 % ||| Val Loss: 11289.826 | Val acc: 73.685 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 6 / 10 | Reconst_loss: 2375.372 | Kldiv loss: 547.842 | Classifcation loss: 1.927 | Constrast loss: 63.36 | Total loss: 11601.925 | Train acc: 73.166 % ||| Val Loss: 11068.702 | Val acc: 74.231 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 7 / 10 | Reconst_loss: 2586.361 | Kldiv loss: 564.734 | Classifcation loss: 1.885 | Constrast loss: 26.30 | Total loss: 11462.219 | Train acc: 73.430 % ||| Val Loss: 11150.369 | Val acc: 73.565 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 8 / 10 | Reconst_loss: 2024.178 | Kldiv loss: 544.185 | Classifcation loss: 2.008 | Constrast loss: 70.60 | Total loss: 11351.528 | Train acc: 73.306 % ||| Val Loss: 10938.867 | Val acc: 73.102 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 9 / 10 | Reconst_loss: 2525.616 | Kldiv loss: 543.056 | Classifcation loss: 1.901 | Constrast loss: 27.87 | Total loss: 11281.171 | Train acc: 73.247 % ||| Val Loss: 10748.083 | Val acc: 73.959 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2023-02-27 05:52:18,200]\u001b[0m Trial 83 finished with value: 0.7416216574498543 and parameters: {'optuna_batch_size': 185, 'optimizer': 'RMSprop', 'lr': 0.006728598941325726, 'alpha': 5.477657043114043, 'beta': 6.590127371143064, 'gamma': 1.513179316641068, 'delta': 7.0936486709336055}. Best is trial 56 with value: 0.8085334443997629.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 10 / 10 | Reconst_loss: 2111.469 | Kldiv loss: 586.943 | Classifcation loss: 1.985 | Constrast loss: 43.49 | Total loss: 11199.329 | Train acc: 74.162 % ||| Val Loss: 10886.191 | Val acc: 73.821 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 1 / 10 | Reconst_loss: 314.704 | Kldiv loss: 22.586 | Classifcation loss: 2.498 | Constrast loss: 0.00 | Total loss: 14591.510 | Train acc: 34.446 % ||| Val Loss: 10268.847 | Val acc: 49.940 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 2 / 10 | Reconst_loss: 84.216 | Kldiv loss: 9.600 | Classifcation loss: 2.137 | Constrast loss: 0.00 | Total loss: 9953.962 | Train acc: 54.125 % ||| Val Loss: 9039.529 | Val acc: 58.889 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 3 / 10 | Reconst_loss: 62.491 | Kldiv loss: 20.434 | Classifcation loss: 2.101 | Constrast loss: 1.04 | Total loss: 9197.902 | Train acc: 62.174 % ||| Val Loss: 8573.963 | Val acc: 65.559 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 4 / 10 | Reconst_loss: 198.617 | Kldiv loss: 12.517 | Classifcation loss: 2.042 | Constrast loss: 0.00 | Total loss: 8790.261 | Train acc: 67.523 % ||| Val Loss: 8466.780 | Val acc: 68.573 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 5 / 10 | Reconst_loss: 37.284 | Kldiv loss: 16.927 | Classifcation loss: 1.718 | Constrast loss: 0.00 | Total loss: 8569.727 | Train acc: 68.907 % ||| Val Loss: 8178.348 | Val acc: 69.484 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 6 / 10 | Reconst_loss: 147.725 | Kldiv loss: 16.835 | Classifcation loss: 1.941 | Constrast loss: 0.00 | Total loss: 8382.392 | Train acc: 70.353 % ||| Val Loss: 8174.417 | Val acc: 69.908 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 7 / 10 | Reconst_loss: 113.924 | Kldiv loss: 25.143 | Classifcation loss: 2.189 | Constrast loss: 1.67 | Total loss: 8185.296 | Train acc: 71.406 % ||| Val Loss: 8073.832 | Val acc: 71.686 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 8 / 10 | Reconst_loss: 36.312 | Kldiv loss: 19.557 | Classifcation loss: 1.944 | Constrast loss: 0.00 | Total loss: 8042.106 | Train acc: 72.049 % ||| Val Loss: 7809.196 | Val acc: 71.942 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 9 / 10 | Reconst_loss: 155.685 | Kldiv loss: 15.317 | Classifcation loss: 2.202 | Constrast loss: 1.54 | Total loss: 7978.790 | Train acc: 72.260 % ||| Val Loss: 7812.679 | Val acc: 73.056 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2023-02-27 05:52:47,984]\u001b[0m Trial 84 finished with value: 0.7309283088235294 and parameters: {'optuna_batch_size': 136, 'optimizer': 'RMSprop', 'lr': 0.006721247225034509, 'alpha': 5.414637805518095, 'beta': 6.950445092010863, 'gamma': 1.9223831924690282, 'delta': 6.379358095297376}. Best is trial 56 with value: 0.8085334443997629.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 10 / 10 | Reconst_loss: 44.177 | Kldiv loss: 32.505 | Classifcation loss: 2.189 | Constrast loss: 0.00 | Total loss: 7960.701 | Train acc: 73.093 % ||| Val Loss: 7714.661 | Val acc: 73.324 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 1 / 10 | Reconst_loss: 3812.035 | Kldiv loss: 588.838 | Classifcation loss: 2.281 | Constrast loss: 110.26 | Total loss: 17311.026 | Train acc: 34.482 % ||| Val Loss: 13345.566 | Val acc: 47.298 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 2 / 10 | Reconst_loss: 3060.382 | Kldiv loss: 597.286 | Classifcation loss: 2.168 | Constrast loss: 128.31 | Total loss: 13169.912 | Train acc: 50.532 % ||| Val Loss: 12040.713 | Val acc: 57.127 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 3 / 10 | Reconst_loss: 3003.648 | Kldiv loss: 667.325 | Classifcation loss: 2.141 | Constrast loss: 47.02 | Total loss: 12230.107 | Train acc: 56.979 % ||| Val Loss: 11385.837 | Val acc: 61.418 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 4 / 10 | Reconst_loss: 2981.280 | Kldiv loss: 689.461 | Classifcation loss: 2.101 | Constrast loss: 44.40 | Total loss: 11964.347 | Train acc: 59.998 % ||| Val Loss: 11288.444 | Val acc: 60.321 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 5 / 10 | Reconst_loss: 2894.819 | Kldiv loss: 657.894 | Classifcation loss: 2.127 | Constrast loss: 66.07 | Total loss: 11516.449 | Train acc: 62.065 % ||| Val Loss: 10809.851 | Val acc: 62.964 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 6 / 10 | Reconst_loss: 2819.970 | Kldiv loss: 645.433 | Classifcation loss: 2.026 | Constrast loss: 33.89 | Total loss: 11163.109 | Train acc: 63.066 % ||| Val Loss: 10482.540 | Val acc: 64.572 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 7 / 10 | Reconst_loss: 3156.813 | Kldiv loss: 612.209 | Classifcation loss: 2.215 | Constrast loss: 61.23 | Total loss: 10962.918 | Train acc: 63.877 % ||| Val Loss: 10496.053 | Val acc: 65.558 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 8 / 10 | Reconst_loss: 2528.213 | Kldiv loss: 656.036 | Classifcation loss: 2.000 | Constrast loss: 41.18 | Total loss: 10923.672 | Train acc: 63.943 % ||| Val Loss: 10326.416 | Val acc: 65.044 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 9 / 10 | Reconst_loss: 2996.885 | Kldiv loss: 606.702 | Classifcation loss: 2.036 | Constrast loss: 51.86 | Total loss: 10793.148 | Train acc: 64.177 % ||| Val Loss: 10389.027 | Val acc: 66.375 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2023-02-27 05:53:14,288]\u001b[0m Trial 85 finished with value: 0.6477116470405063 and parameters: {'optuna_batch_size': 175, 'optimizer': 'RMSprop', 'lr': 0.006968856170265296, 'alpha': 5.623652533556871, 'beta': 6.72216812817665, 'gamma': 1.5625499058860075, 'delta': 7.951793423052061}. Best is trial 56 with value: 0.8085334443997629.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 10 / 10 | Reconst_loss: 2337.951 | Kldiv loss: 570.121 | Classifcation loss: 2.027 | Constrast loss: 41.40 | Total loss: 10634.039 | Train acc: 64.771 % ||| Val Loss: 10249.676 | Val acc: 64.810 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 1 / 10 | Reconst_loss: 7304.821 | Kldiv loss: 1789.433 | Classifcation loss: 2.353 | Constrast loss: 507.04 | Total loss: 69879.500 | Train acc: 21.772 % ||| Val Loss: 26497.304 | Val acc: 40.325 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 2 / 10 | Reconst_loss: 6477.053 | Kldiv loss: 1589.452 | Classifcation loss: 2.161 | Constrast loss: 308.48 | Total loss: 23868.824 | Train acc: 49.357 % ||| Val Loss: 22287.830 | Val acc: 54.814 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 3 / 10 | Reconst_loss: 6017.499 | Kldiv loss: 1399.228 | Classifcation loss: 2.176 | Constrast loss: 363.75 | Total loss: 21689.190 | Train acc: 55.852 % ||| Val Loss: 20967.565 | Val acc: 55.974 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 4 / 10 | Reconst_loss: 4574.250 | Kldiv loss: 1523.611 | Classifcation loss: 2.089 | Constrast loss: 279.00 | Total loss: 20211.230 | Train acc: 59.865 % ||| Val Loss: 19778.874 | Val acc: 61.100 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 5 / 10 | Reconst_loss: 5830.115 | Kldiv loss: 1603.847 | Classifcation loss: 2.039 | Constrast loss: 135.67 | Total loss: 19369.004 | Train acc: 62.300 % ||| Val Loss: 19001.529 | Val acc: 62.328 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 6 / 10 | Reconst_loss: 4324.688 | Kldiv loss: 1358.947 | Classifcation loss: 2.044 | Constrast loss: 223.68 | Total loss: 18836.957 | Train acc: 63.028 % ||| Val Loss: 18760.898 | Val acc: 62.626 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 7 / 10 | Reconst_loss: 4594.928 | Kldiv loss: 1486.906 | Classifcation loss: 2.117 | Constrast loss: 144.21 | Total loss: 18483.870 | Train acc: 63.442 % ||| Val Loss: 18624.170 | Val acc: 62.636 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 8 / 10 | Reconst_loss: 5782.791 | Kldiv loss: 1513.005 | Classifcation loss: 2.052 | Constrast loss: 179.25 | Total loss: 18224.593 | Train acc: 63.632 % ||| Val Loss: 18057.821 | Val acc: 63.398 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 9 / 10 | Reconst_loss: 5748.936 | Kldiv loss: 1407.317 | Classifcation loss: 2.022 | Constrast loss: 122.45 | Total loss: 18129.938 | Train acc: 63.788 % ||| Val Loss: 17965.230 | Val acc: 64.315 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2023-02-27 05:53:37,193]\u001b[0m Trial 86 finished with value: 0.6428750579742818 and parameters: {'optuna_batch_size': 285, 'optimizer': 'Adam', 'lr': 0.006388695218093524, 'alpha': 4.937474172684352, 'beta': 5.818129802548895, 'gamma': 1.2394305481244055, 'delta': 7.3740745905899505}. Best is trial 56 with value: 0.8085334443997629.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 10 / 10 | Reconst_loss: 4219.254 | Kldiv loss: 1289.252 | Classifcation loss: 2.038 | Constrast loss: 194.79 | Total loss: 17758.473 | Train acc: 64.288 % ||| Val Loss: 17646.188 | Val acc: 64.222 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 1 / 10 | Reconst_loss: 576.016 | Kldiv loss: 78.989 | Classifcation loss: 2.194 | Constrast loss: 2.63 | Total loss: 8372.315 | Train acc: 39.705 % ||| Val Loss: 7030.817 | Val acc: 55.232 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 2 / 10 | Reconst_loss: 417.860 | Kldiv loss: 88.479 | Classifcation loss: 1.921 | Constrast loss: 1.31 | Total loss: 6882.700 | Train acc: 59.623 % ||| Val Loss: 6320.588 | Val acc: 65.401 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 3 / 10 | Reconst_loss: 514.984 | Kldiv loss: 64.931 | Classifcation loss: 1.886 | Constrast loss: 5.20 | Total loss: 6299.529 | Train acc: 66.606 % ||| Val Loss: 6849.752 | Val acc: 63.251 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 4 / 10 | Reconst_loss: 317.893 | Kldiv loss: 65.449 | Classifcation loss: 1.968 | Constrast loss: 1.88 | Total loss: 6010.243 | Train acc: 68.807 % ||| Val Loss: 5709.275 | Val acc: 69.726 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 5 / 10 | Reconst_loss: 472.772 | Kldiv loss: 108.438 | Classifcation loss: 2.268 | Constrast loss: 0.28 | Total loss: 5851.301 | Train acc: 69.276 % ||| Val Loss: 5597.893 | Val acc: 69.974 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 6 / 10 | Reconst_loss: 352.068 | Kldiv loss: 68.451 | Classifcation loss: 1.898 | Constrast loss: 2.62 | Total loss: 5770.285 | Train acc: 69.288 % ||| Val Loss: 5542.365 | Val acc: 71.807 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 7 / 10 | Reconst_loss: 407.198 | Kldiv loss: 98.666 | Classifcation loss: 2.122 | Constrast loss: 4.10 | Total loss: 5695.709 | Train acc: 70.048 % ||| Val Loss: 5493.829 | Val acc: 70.859 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 8 / 10 | Reconst_loss: 446.850 | Kldiv loss: 101.983 | Classifcation loss: 2.190 | Constrast loss: 8.34 | Total loss: 5668.326 | Train acc: 71.024 % ||| Val Loss: 5541.288 | Val acc: 71.081 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 9 / 10 | Reconst_loss: 520.981 | Kldiv loss: 80.320 | Classifcation loss: 2.106 | Constrast loss: 2.98 | Total loss: 5633.027 | Train acc: 71.631 % ||| Val Loss: 5621.232 | Val acc: 72.931 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2023-02-27 05:54:17,652]\u001b[0m Trial 87 finished with value: 0.7323988882499521 and parameters: {'optuna_batch_size': 94, 'optimizer': 'RMSprop', 'lr': 0.007795512217896448, 'alpha': 7.2810252994495634, 'beta': 6.311086634019349, 'gamma': 2.25228975138632, 'delta': 7.665924722532942}. Best is trial 56 with value: 0.8085334443997629.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 10 / 10 | Reconst_loss: 343.915 | Kldiv loss: 83.494 | Classifcation loss: 1.842 | Constrast loss: 0.00 | Total loss: 5600.303 | Train acc: 73.240 % ||| Val Loss: 5539.285 | Val acc: 73.410 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 1 / 10 | Reconst_loss: 264.373 | Kldiv loss: 34.293 | Classifcation loss: 2.063 | Constrast loss: 1.46 | Total loss: 5028.341 | Train acc: 35.183 % ||| Val Loss: 4062.717 | Val acc: 48.635 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 2 / 10 | Reconst_loss: 253.133 | Kldiv loss: 39.328 | Classifcation loss: 1.708 | Constrast loss: 0.00 | Total loss: 3874.426 | Train acc: 51.772 % ||| Val Loss: 3710.633 | Val acc: 55.705 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 3 / 10 | Reconst_loss: 138.983 | Kldiv loss: 39.409 | Classifcation loss: 2.236 | Constrast loss: 0.00 | Total loss: 3689.653 | Train acc: 56.158 % ||| Val Loss: 3892.084 | Val acc: 46.002 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 4 / 10 | Reconst_loss: 191.134 | Kldiv loss: 36.633 | Classifcation loss: 1.975 | Constrast loss: 0.00 | Total loss: 3604.089 | Train acc: 59.348 % ||| Val Loss: 3449.649 | Val acc: 65.995 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 5 / 10 | Reconst_loss: 203.398 | Kldiv loss: 27.600 | Classifcation loss: 2.087 | Constrast loss: 0.00 | Total loss: 3506.866 | Train acc: 64.631 % ||| Val Loss: 3381.048 | Val acc: 68.166 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 6 / 10 | Reconst_loss: 114.857 | Kldiv loss: 35.430 | Classifcation loss: 2.299 | Constrast loss: 0.00 | Total loss: 3464.815 | Train acc: 65.972 % ||| Val Loss: 3423.143 | Val acc: 65.808 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 7 / 10 | Reconst_loss: 161.361 | Kldiv loss: 31.723 | Classifcation loss: 1.837 | Constrast loss: 0.82 | Total loss: 3442.098 | Train acc: 66.918 % ||| Val Loss: 3421.479 | Val acc: 67.744 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 8 / 10 | Reconst_loss: 77.819 | Kldiv loss: 23.703 | Classifcation loss: 1.971 | Constrast loss: 0.00 | Total loss: 3442.829 | Train acc: 67.291 % ||| Val Loss: 3351.690 | Val acc: 68.891 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 9 / 10 | Reconst_loss: 152.098 | Kldiv loss: 38.389 | Classifcation loss: 2.075 | Constrast loss: 0.00 | Total loss: 3386.381 | Train acc: 68.020 % ||| Val Loss: 3399.558 | Val acc: 69.923 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2023-02-27 05:55:19,042]\u001b[0m Trial 88 finished with value: 0.6813496629952336 and parameters: {'optuna_batch_size': 55, 'optimizer': 'RMSprop', 'lr': 0.008154763582046995, 'alpha': 6.935039997559243, 'beta': 6.479918073540272, 'gamma': 1.3956331551471493, 'delta': 6.904451949458261}. Best is trial 56 with value: 0.8085334443997629.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 10 / 10 | Reconst_loss: 65.118 | Kldiv loss: 32.674 | Classifcation loss: 2.281 | Constrast loss: 0.34 | Total loss: 3349.551 | Train acc: 68.135 % ||| Val Loss: 3255.624 | Val acc: 71.049 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 1 / 10 | Reconst_loss: 424.034 | Kldiv loss: 44.995 | Classifcation loss: 2.149 | Constrast loss: 1.59 | Total loss: 2158.780 | Train acc: 46.866 % ||| Val Loss: 1854.774 | Val acc: 65.466 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 2 / 10 | Reconst_loss: 270.190 | Kldiv loss: 54.459 | Classifcation loss: 2.128 | Constrast loss: 1.93 | Total loss: 1852.762 | Train acc: 69.347 % ||| Val Loss: 1763.157 | Val acc: 73.008 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 3 / 10 | Reconst_loss: 396.778 | Kldiv loss: 51.790 | Classifcation loss: 2.028 | Constrast loss: 1.60 | Total loss: 1789.807 | Train acc: 72.938 % ||| Val Loss: 1772.426 | Val acc: 73.644 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 4 / 10 | Reconst_loss: 301.785 | Kldiv loss: 46.842 | Classifcation loss: 2.240 | Constrast loss: 1.57 | Total loss: 1768.222 | Train acc: 72.985 % ||| Val Loss: 1734.436 | Val acc: 73.565 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 5 / 10 | Reconst_loss: 491.339 | Kldiv loss: 56.343 | Classifcation loss: 1.781 | Constrast loss: 0.00 | Total loss: 1742.630 | Train acc: 74.704 % ||| Val Loss: 1813.564 | Val acc: 74.541 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 6 / 10 | Reconst_loss: 206.848 | Kldiv loss: 44.227 | Classifcation loss: 1.874 | Constrast loss: 3.95 | Total loss: 1730.335 | Train acc: 74.836 % ||| Val Loss: 1694.836 | Val acc: 75.636 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 7 / 10 | Reconst_loss: 293.776 | Kldiv loss: 45.902 | Classifcation loss: 1.893 | Constrast loss: 2.34 | Total loss: 1731.590 | Train acc: 74.934 % ||| Val Loss: 1713.930 | Val acc: 76.541 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 8 / 10 | Reconst_loss: 262.129 | Kldiv loss: 43.663 | Classifcation loss: 2.069 | Constrast loss: 2.49 | Total loss: 1720.129 | Train acc: 75.418 % ||| Val Loss: 1678.371 | Val acc: 76.035 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 9 / 10 | Reconst_loss: 257.071 | Kldiv loss: 59.607 | Classifcation loss: 2.261 | Constrast loss: 0.63 | Total loss: 1712.161 | Train acc: 75.674 % ||| Val Loss: 1692.459 | Val acc: 76.195 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2023-02-27 05:57:02,723]\u001b[0m Trial 89 finished with value: 0.7448090577624258 and parameters: {'optuna_batch_size': 30, 'optimizer': 'RMSprop', 'lr': 0.007113863081253526, 'alpha': 6.394507151964459, 'beta': 7.071246449187573, 'gamma': 2.6569305672908854, 'delta': 9.31290422944837}. Best is trial 56 with value: 0.8085334443997629.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 10 / 10 | Reconst_loss: 311.591 | Kldiv loss: 47.920 | Classifcation loss: 1.863 | Constrast loss: 0.00 | Total loss: 1717.087 | Train acc: 74.481 % ||| Val Loss: 1703.222 | Val acc: 73.542 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 1 / 10 | Reconst_loss: 571.326 | Kldiv loss: 59.447 | Classifcation loss: 2.126 | Constrast loss: 13.19 | Total loss: 1920.649 | Train acc: 37.452 % ||| Val Loss: 1650.829 | Val acc: 48.950 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 2 / 10 | Reconst_loss: 465.998 | Kldiv loss: 72.515 | Classifcation loss: 2.462 | Constrast loss: 18.84 | Total loss: 1581.651 | Train acc: 52.134 % ||| Val Loss: 2370.070 | Val acc: 42.154 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 3 / 10 | Reconst_loss: 211.001 | Kldiv loss: 79.795 | Classifcation loss: 2.152 | Constrast loss: 3.13 | Total loss: 1496.588 | Train acc: 54.779 % ||| Val Loss: 1442.200 | Val acc: 55.557 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 4 / 10 | Reconst_loss: 333.916 | Kldiv loss: 64.997 | Classifcation loss: 2.203 | Constrast loss: 6.02 | Total loss: 1491.284 | Train acc: 55.005 % ||| Val Loss: 1488.997 | Val acc: 55.747 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 5 / 10 | Reconst_loss: 393.398 | Kldiv loss: 65.521 | Classifcation loss: 2.157 | Constrast loss: 12.04 | Total loss: 1505.783 | Train acc: 53.427 % ||| Val Loss: 1518.503 | Val acc: 50.377 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 6 / 10 | Reconst_loss: 370.925 | Kldiv loss: 74.055 | Classifcation loss: 2.202 | Constrast loss: 0.00 | Total loss: 1496.845 | Train acc: 53.130 % ||| Val Loss: 1434.860 | Val acc: 54.798 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 7 / 10 | Reconst_loss: 529.242 | Kldiv loss: 72.785 | Classifcation loss: 2.271 | Constrast loss: 4.25 | Total loss: 1466.251 | Train acc: 54.747 % ||| Val Loss: 1438.808 | Val acc: 55.908 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 8 / 10 | Reconst_loss: 346.143 | Kldiv loss: 89.651 | Classifcation loss: 2.274 | Constrast loss: 3.50 | Total loss: 1441.292 | Train acc: 55.741 % ||| Val Loss: 1395.940 | Val acc: 57.779 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 9 / 10 | Reconst_loss: 369.902 | Kldiv loss: 81.632 | Classifcation loss: 2.159 | Constrast loss: 5.84 | Total loss: 1435.905 | Train acc: 56.058 % ||| Val Loss: 1411.320 | Val acc: 57.100 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2023-02-27 05:59:10,373]\u001b[0m Trial 90 finished with value: 0.5556192841819999 and parameters: {'optuna_batch_size': 25, 'optimizer': 'RMSprop', 'lr': 0.00712509653949808, 'alpha': 6.563354563843254, 'beta': 8.081190125831782, 'gamma': 2.5269333619345553, 'delta': 8.959516899475393}. Best is trial 56 with value: 0.8085334443997629.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 10 / 10 | Reconst_loss: 393.076 | Kldiv loss: 76.022 | Classifcation loss: 2.212 | Constrast loss: 3.97 | Total loss: 1444.177 | Train acc: 55.562 % ||| Val Loss: 1478.668 | Val acc: 54.308 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 1 / 10 | Reconst_loss: 562.621 | Kldiv loss: 120.445 | Classifcation loss: 2.236 | Constrast loss: 6.89 | Total loss: 5255.441 | Train acc: 44.975 % ||| Val Loss: 4445.250 | Val acc: 61.163 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 2 / 10 | Reconst_loss: 346.152 | Kldiv loss: 110.991 | Classifcation loss: 2.028 | Constrast loss: 2.85 | Total loss: 4427.074 | Train acc: 64.887 % ||| Val Loss: 4151.642 | Val acc: 69.008 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 3 / 10 | Reconst_loss: 226.576 | Kldiv loss: 70.775 | Classifcation loss: 1.853 | Constrast loss: 4.15 | Total loss: 4191.670 | Train acc: 70.520 % ||| Val Loss: 4068.497 | Val acc: 73.238 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 4 / 10 | Reconst_loss: 424.584 | Kldiv loss: 84.991 | Classifcation loss: 1.991 | Constrast loss: 2.39 | Total loss: 4082.240 | Train acc: 73.787 % ||| Val Loss: 3859.481 | Val acc: 74.874 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 5 / 10 | Reconst_loss: 330.277 | Kldiv loss: 90.318 | Classifcation loss: 1.862 | Constrast loss: 0.28 | Total loss: 4001.632 | Train acc: 75.487 % ||| Val Loss: 3906.897 | Val acc: 77.795 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 6 / 10 | Reconst_loss: 627.177 | Kldiv loss: 124.166 | Classifcation loss: 1.920 | Constrast loss: 0.00 | Total loss: 3941.169 | Train acc: 76.834 % ||| Val Loss: 3751.492 | Val acc: 79.500 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 7 / 10 | Reconst_loss: 294.859 | Kldiv loss: 85.068 | Classifcation loss: 1.937 | Constrast loss: 1.66 | Total loss: 3870.294 | Train acc: 78.193 % ||| Val Loss: 3694.911 | Val acc: 81.204 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 8 / 10 | Reconst_loss: 500.768 | Kldiv loss: 92.158 | Classifcation loss: 1.896 | Constrast loss: 0.66 | Total loss: 3819.050 | Train acc: 80.553 % ||| Val Loss: 3658.679 | Val acc: 80.940 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 9 / 10 | Reconst_loss: 513.231 | Kldiv loss: 89.386 | Classifcation loss: 1.804 | Constrast loss: 0.47 | Total loss: 3805.468 | Train acc: 81.595 % ||| Val Loss: 3692.292 | Val acc: 82.059 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2023-02-27 06:00:00,707]\u001b[0m Trial 91 finished with value: 0.8201125175808737 and parameters: {'optuna_batch_size': 66, 'optimizer': 'RMSprop', 'lr': 0.006661582980767222, 'alpha': 6.095305338071538, 'beta': 7.102592478744805, 'gamma': 1.813603629531665, 'delta': 9.387700064368634}. Best is trial 91 with value: 0.8201125175808737.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 10 / 10 | Reconst_loss: 234.935 | Kldiv loss: 68.463 | Classifcation loss: 1.973 | Constrast loss: 5.96 | Total loss: 3796.707 | Train acc: 82.011 % ||| Val Loss: 3897.689 | Val acc: 82.071 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 1 / 10 | Reconst_loss: 362.475 | Kldiv loss: 49.404 | Classifcation loss: 2.270 | Constrast loss: 4.04 | Total loss: 5957.387 | Train acc: 37.127 % ||| Val Loss: 4436.437 | Val acc: 44.256 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 2 / 10 | Reconst_loss: 255.729 | Kldiv loss: 51.640 | Classifcation loss: 2.191 | Constrast loss: 4.50 | Total loss: 4224.254 | Train acc: 48.602 % ||| Val Loss: 3926.591 | Val acc: 54.736 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 3 / 10 | Reconst_loss: 341.665 | Kldiv loss: 45.627 | Classifcation loss: 2.075 | Constrast loss: 2.97 | Total loss: 3886.165 | Train acc: 54.632 % ||| Val Loss: 3894.039 | Val acc: 52.006 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 4 / 10 | Reconst_loss: 231.465 | Kldiv loss: 61.631 | Classifcation loss: 2.270 | Constrast loss: 2.61 | Total loss: 3738.995 | Train acc: 55.545 % ||| Val Loss: 3901.505 | Val acc: 57.178 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 5 / 10 | Reconst_loss: 221.382 | Kldiv loss: 59.472 | Classifcation loss: 2.158 | Constrast loss: 0.18 | Total loss: 3664.919 | Train acc: 55.721 % ||| Val Loss: 3688.515 | Val acc: 50.575 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 6 / 10 | Reconst_loss: 259.582 | Kldiv loss: 38.079 | Classifcation loss: 2.014 | Constrast loss: 6.51 | Total loss: 3624.236 | Train acc: 50.773 % ||| Val Loss: 3726.813 | Val acc: 50.356 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 7 / 10 | Reconst_loss: 343.531 | Kldiv loss: 57.862 | Classifcation loss: 2.242 | Constrast loss: 0.88 | Total loss: 3548.598 | Train acc: 51.461 % ||| Val Loss: 3409.695 | Val acc: 52.290 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 8 / 10 | Reconst_loss: 295.867 | Kldiv loss: 57.603 | Classifcation loss: 2.269 | Constrast loss: 0.00 | Total loss: 3502.994 | Train acc: 51.613 % ||| Val Loss: 3403.178 | Val acc: 51.848 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 9 / 10 | Reconst_loss: 315.009 | Kldiv loss: 58.021 | Classifcation loss: 2.356 | Constrast loss: 0.56 | Total loss: 3476.318 | Train acc: 51.467 % ||| Val Loss: 3378.267 | Val acc: 52.874 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2023-02-27 06:00:56,397]\u001b[0m Trial 92 finished with value: 0.5159953970080552 and parameters: {'optuna_batch_size': 60, 'optimizer': 'RMSprop', 'lr': 0.007445069964091751, 'alpha': 6.141624779387532, 'beta': 7.061890535918779, 'gamma': 2.0053400277496833, 'delta': 9.310811327199554}. Best is trial 91 with value: 0.8201125175808737.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 10 / 10 | Reconst_loss: 171.502 | Kldiv loss: 47.566 | Classifcation loss: 1.958 | Constrast loss: 0.00 | Total loss: 3459.929 | Train acc: 51.600 % ||| Val Loss: 3383.219 | Val acc: 52.178 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 1 / 10 | Reconst_loss: 369.118 | Kldiv loss: 41.851 | Classifcation loss: 2.194 | Constrast loss: 0.00 | Total loss: 2146.654 | Train acc: 39.816 % ||| Val Loss: 2032.726 | Val acc: 43.625 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 2 / 10 | Reconst_loss: 140.818 | Kldiv loss: 26.344 | Classifcation loss: 2.201 | Constrast loss: 5.54 | Total loss: 1764.420 | Train acc: 58.127 % ||| Val Loss: 1861.913 | Val acc: 50.246 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 3 / 10 | Reconst_loss: 128.668 | Kldiv loss: 34.111 | Classifcation loss: 2.087 | Constrast loss: 0.05 | Total loss: 1721.546 | Train acc: 55.215 % ||| Val Loss: 1641.925 | Val acc: 53.282 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 4 / 10 | Reconst_loss: 125.994 | Kldiv loss: 33.201 | Classifcation loss: 2.186 | Constrast loss: 0.00 | Total loss: 1782.700 | Train acc: 46.369 % ||| Val Loss: 1676.593 | Val acc: 43.881 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 5 / 10 | Reconst_loss: 193.903 | Kldiv loss: 29.749 | Classifcation loss: 2.084 | Constrast loss: 2.88 | Total loss: 1739.700 | Train acc: 44.544 % ||| Val Loss: 1729.874 | Val acc: 44.038 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 6 / 10 | Reconst_loss: 260.091 | Kldiv loss: 31.494 | Classifcation loss: 2.314 | Constrast loss: 2.20 | Total loss: 1746.284 | Train acc: 45.605 % ||| Val Loss: 1761.517 | Val acc: 46.450 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 7 / 10 | Reconst_loss: 110.367 | Kldiv loss: 34.177 | Classifcation loss: 2.064 | Constrast loss: 1.79 | Total loss: 1764.880 | Train acc: 45.995 % ||| Val Loss: 1800.435 | Val acc: 46.167 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 8 / 10 | Reconst_loss: 229.228 | Kldiv loss: 42.941 | Classifcation loss: 2.434 | Constrast loss: 1.54 | Total loss: 1725.880 | Train acc: 44.439 % ||| Val Loss: 1675.690 | Val acc: 46.376 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 9 / 10 | Reconst_loss: 71.008 | Kldiv loss: 35.914 | Classifcation loss: 1.922 | Constrast loss: 0.00 | Total loss: 1759.892 | Train acc: 43.639 % ||| Val Loss: 1747.580 | Val acc: 43.468 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2023-02-27 06:02:44,843]\u001b[0m Trial 93 finished with value: 0.43157417534971565 and parameters: {'optuna_batch_size': 29, 'optimizer': 'RMSprop', 'lr': 0.007732062565718277, 'alpha': 6.38860870615297, 'beta': 7.53807400976952, 'gamma': 1.8233462020456557, 'delta': 9.322380873234902}. Best is trial 91 with value: 0.8201125175808737.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 10 / 10 | Reconst_loss: 339.141 | Kldiv loss: 34.456 | Classifcation loss: 2.562 | Constrast loss: 2.45 | Total loss: 1734.092 | Train acc: 43.157 % ||| Val Loss: 1689.688 | Val acc: 41.862 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 1 / 10 | Reconst_loss: 2061.990 | Kldiv loss: 518.647 | Classifcation loss: 2.212 | Constrast loss: 44.95 | Total loss: 9950.100 | Train acc: 38.583 % ||| Val Loss: 8256.988 | Val acc: 54.194 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 2 / 10 | Reconst_loss: 1954.818 | Kldiv loss: 508.043 | Classifcation loss: 2.085 | Constrast loss: 82.20 | Total loss: 7982.791 | Train acc: 59.048 % ||| Val Loss: 7470.925 | Val acc: 63.562 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 3 / 10 | Reconst_loss: 2177.765 | Kldiv loss: 456.512 | Classifcation loss: 2.100 | Constrast loss: 60.05 | Total loss: 7476.061 | Train acc: 66.135 % ||| Val Loss: 7352.744 | Val acc: 67.247 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 4 / 10 | Reconst_loss: 1568.731 | Kldiv loss: 443.784 | Classifcation loss: 2.009 | Constrast loss: 44.66 | Total loss: 7277.273 | Train acc: 69.315 % ||| Val Loss: 7065.506 | Val acc: 70.309 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 5 / 10 | Reconst_loss: 1970.832 | Kldiv loss: 472.475 | Classifcation loss: 1.951 | Constrast loss: 35.36 | Total loss: 7125.084 | Train acc: 71.338 % ||| Val Loss: 6852.640 | Val acc: 72.007 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 6 / 10 | Reconst_loss: 1817.185 | Kldiv loss: 439.063 | Classifcation loss: 1.990 | Constrast loss: 56.45 | Total loss: 7036.864 | Train acc: 72.223 % ||| Val Loss: 6807.791 | Val acc: 72.389 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 7 / 10 | Reconst_loss: 2091.141 | Kldiv loss: 482.544 | Classifcation loss: 1.952 | Constrast loss: 38.28 | Total loss: 6950.480 | Train acc: 72.553 % ||| Val Loss: 6931.420 | Val acc: 72.982 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 8 / 10 | Reconst_loss: 2023.787 | Kldiv loss: 455.316 | Classifcation loss: 1.961 | Constrast loss: 28.52 | Total loss: 6852.045 | Train acc: 73.091 % ||| Val Loss: 6640.441 | Val acc: 74.992 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 9 / 10 | Reconst_loss: 2417.826 | Kldiv loss: 461.705 | Classifcation loss: 1.901 | Constrast loss: 29.24 | Total loss: 6829.771 | Train acc: 74.579 % ||| Val Loss: 6692.103 | Val acc: 74.642 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2023-02-27 06:03:16,927]\u001b[0m Trial 94 finished with value: 0.7500337367515876 and parameters: {'optuna_batch_size': 119, 'optimizer': 'RMSprop', 'lr': 0.005958583249858324, 'alpha': 6.305567090690728, 'beta': 7.811107487475429, 'gamma': 2.6724449204142116, 'delta': 9.55910862510503}. Best is trial 91 with value: 0.8201125175808737.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 10 / 10 | Reconst_loss: 2090.538 | Kldiv loss: 522.780 | Classifcation loss: 1.932 | Constrast loss: 16.30 | Total loss: 6804.845 | Train acc: 75.003 % ||| Val Loss: 6582.746 | Val acc: 74.669 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 1 / 10 | Reconst_loss: 1535.757 | Kldiv loss: 253.436 | Classifcation loss: 2.272 | Constrast loss: 13.02 | Total loss: 9852.254 | Train acc: 40.955 % ||| Val Loss: 8306.672 | Val acc: 48.733 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 2 / 10 | Reconst_loss: 1560.969 | Kldiv loss: 311.562 | Classifcation loss: 2.224 | Constrast loss: 16.69 | Total loss: 7954.056 | Train acc: 52.829 % ||| Val Loss: 7246.256 | Val acc: 56.235 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 3 / 10 | Reconst_loss: 1283.094 | Kldiv loss: 341.461 | Classifcation loss: 2.115 | Constrast loss: 15.52 | Total loss: 7429.279 | Train acc: 57.288 % ||| Val Loss: 7277.021 | Val acc: 62.514 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 4 / 10 | Reconst_loss: 924.072 | Kldiv loss: 253.241 | Classifcation loss: 2.087 | Constrast loss: 12.27 | Total loss: 7256.061 | Train acc: 63.150 % ||| Val Loss: 6977.212 | Val acc: 64.375 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 5 / 10 | Reconst_loss: 1119.505 | Kldiv loss: 256.108 | Classifcation loss: 2.070 | Constrast loss: 19.95 | Total loss: 7155.738 | Train acc: 64.108 % ||| Val Loss: 6766.022 | Val acc: 64.831 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 6 / 10 | Reconst_loss: 1103.037 | Kldiv loss: 271.110 | Classifcation loss: 1.982 | Constrast loss: 7.37 | Total loss: 7026.214 | Train acc: 64.792 % ||| Val Loss: 6735.511 | Val acc: 65.475 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 7 / 10 | Reconst_loss: 1225.929 | Kldiv loss: 289.379 | Classifcation loss: 2.111 | Constrast loss: 15.65 | Total loss: 7025.472 | Train acc: 64.616 % ||| Val Loss: 6787.712 | Val acc: 66.958 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 8 / 10 | Reconst_loss: 991.418 | Kldiv loss: 267.220 | Classifcation loss: 2.115 | Constrast loss: 6.56 | Total loss: 6870.507 | Train acc: 66.331 % ||| Val Loss: 6613.199 | Val acc: 66.781 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 9 / 10 | Reconst_loss: 1416.135 | Kldiv loss: 295.246 | Classifcation loss: 2.060 | Constrast loss: 22.93 | Total loss: 6818.680 | Train acc: 66.566 % ||| Val Loss: 6745.421 | Val acc: 67.771 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2023-02-27 06:03:48,648]\u001b[0m Trial 95 finished with value: 0.667395250146995 and parameters: {'optuna_batch_size': 118, 'optimizer': 'RMSprop', 'lr': 0.005730935895474021, 'alpha': 7.02576767853218, 'beta': 8.51355669592406, 'gamma': 1.0669417974801214, 'delta': 9.789072721080153}. Best is trial 91 with value: 0.8201125175808737.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 10 / 10 | Reconst_loss: 1535.586 | Kldiv loss: 317.043 | Classifcation loss: 2.027 | Constrast loss: 2.97 | Total loss: 6770.084 | Train acc: 66.740 % ||| Val Loss: 6859.783 | Val acc: 66.952 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 1 / 10 | Reconst_loss: 1147.803 | Kldiv loss: 278.424 | Classifcation loss: 2.096 | Constrast loss: 3.77 | Total loss: 13142.264 | Train acc: 41.880 % ||| Val Loss: 10345.484 | Val acc: 57.983 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 2 / 10 | Reconst_loss: 659.236 | Kldiv loss: 217.703 | Classifcation loss: 1.973 | Constrast loss: 6.56 | Total loss: 10184.790 | Train acc: 60.670 % ||| Val Loss: 9307.949 | Val acc: 65.955 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 3 / 10 | Reconst_loss: 952.368 | Kldiv loss: 199.249 | Classifcation loss: 2.088 | Constrast loss: 5.70 | Total loss: 9536.219 | Train acc: 65.803 % ||| Val Loss: 9821.580 | Val acc: 65.549 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 4 / 10 | Reconst_loss: 783.870 | Kldiv loss: 236.562 | Classifcation loss: 1.875 | Constrast loss: 2.96 | Total loss: 9186.813 | Train acc: 69.208 % ||| Val Loss: 8682.260 | Val acc: 72.190 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 5 / 10 | Reconst_loss: 806.672 | Kldiv loss: 197.677 | Classifcation loss: 1.971 | Constrast loss: 7.11 | Total loss: 8925.957 | Train acc: 71.354 % ||| Val Loss: 8531.099 | Val acc: 73.614 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 6 / 10 | Reconst_loss: 890.631 | Kldiv loss: 164.216 | Classifcation loss: 1.920 | Constrast loss: 5.60 | Total loss: 8808.536 | Train acc: 72.135 % ||| Val Loss: 8407.942 | Val acc: 73.380 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 7 / 10 | Reconst_loss: 742.805 | Kldiv loss: 230.498 | Classifcation loss: 1.915 | Constrast loss: 1.29 | Total loss: 8603.430 | Train acc: 72.687 % ||| Val Loss: 8284.806 | Val acc: 73.698 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 8 / 10 | Reconst_loss: 654.317 | Kldiv loss: 190.827 | Classifcation loss: 1.896 | Constrast loss: 4.83 | Total loss: 8461.211 | Train acc: 74.294 % ||| Val Loss: 8115.681 | Val acc: 76.066 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 9 / 10 | Reconst_loss: 682.910 | Kldiv loss: 167.694 | Classifcation loss: 2.006 | Constrast loss: 5.70 | Total loss: 8354.012 | Train acc: 75.653 % ||| Val Loss: 8658.372 | Val acc: 75.784 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2023-02-27 06:04:17,148]\u001b[0m Trial 96 finished with value: 0.7571181526353947 and parameters: {'optuna_batch_size': 145, 'optimizer': 'RMSprop', 'lr': 0.006026811222776968, 'alpha': 6.269933198251735, 'beta': 7.819916656631253, 'gamma': 2.3088457019654447, 'delta': 8.817796200822405}. Best is trial 91 with value: 0.8201125175808737.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 10 / 10 | Reconst_loss: 949.307 | Kldiv loss: 195.146 | Classifcation loss: 1.895 | Constrast loss: 2.35 | Total loss: 8561.030 | Train acc: 75.712 % ||| Val Loss: 8176.861 | Val acc: 77.071 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 1 / 10 | Reconst_loss: 992.738 | Kldiv loss: 163.433 | Classifcation loss: 2.298 | Constrast loss: 17.11 | Total loss: 13386.710 | Train acc: 34.791 % ||| Val Loss: 10881.463 | Val acc: 50.187 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 2 / 10 | Reconst_loss: 981.058 | Kldiv loss: 235.334 | Classifcation loss: 2.128 | Constrast loss: 9.87 | Total loss: 10732.532 | Train acc: 56.978 % ||| Val Loss: 10083.781 | Val acc: 64.457 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 3 / 10 | Reconst_loss: 864.823 | Kldiv loss: 192.040 | Classifcation loss: 2.057 | Constrast loss: 18.02 | Total loss: 9878.965 | Train acc: 66.542 % ||| Val Loss: 9231.466 | Val acc: 69.420 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 4 / 10 | Reconst_loss: 969.086 | Kldiv loss: 208.013 | Classifcation loss: 2.100 | Constrast loss: 10.26 | Total loss: 9539.180 | Train acc: 69.167 % ||| Val Loss: 8959.392 | Val acc: 70.746 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 5 / 10 | Reconst_loss: 1255.372 | Kldiv loss: 173.283 | Classifcation loss: 2.059 | Constrast loss: 11.32 | Total loss: 9208.917 | Train acc: 71.548 % ||| Val Loss: 11852.849 | Val acc: 65.867 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 6 / 10 | Reconst_loss: 897.680 | Kldiv loss: 178.702 | Classifcation loss: 1.892 | Constrast loss: 4.54 | Total loss: 9090.945 | Train acc: 72.834 % ||| Val Loss: 8623.981 | Val acc: 74.077 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 7 / 10 | Reconst_loss: 873.618 | Kldiv loss: 249.989 | Classifcation loss: 1.925 | Constrast loss: 0.53 | Total loss: 8959.343 | Train acc: 74.415 % ||| Val Loss: 8901.556 | Val acc: 75.953 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 8 / 10 | Reconst_loss: 1019.857 | Kldiv loss: 203.043 | Classifcation loss: 2.029 | Constrast loss: 4.64 | Total loss: 8826.183 | Train acc: 74.979 % ||| Val Loss: 9117.321 | Val acc: 75.202 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 9 / 10 | Reconst_loss: 1048.943 | Kldiv loss: 170.406 | Classifcation loss: 1.946 | Constrast loss: 12.94 | Total loss: 8785.192 | Train acc: 75.603 % ||| Val Loss: 9441.805 | Val acc: 71.472 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2023-02-27 06:04:48,519]\u001b[0m Trial 97 finished with value: 0.7674707466086785 and parameters: {'optuna_batch_size': 145, 'optimizer': 'RMSprop', 'lr': 0.006550281403086249, 'alpha': 7.829695388842611, 'beta': 8.150610510857058, 'gamma': 2.1259745186066987, 'delta': 8.526688031634096}. Best is trial 91 with value: 0.8201125175808737.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 10 / 10 | Reconst_loss: 890.187 | Kldiv loss: 196.536 | Classifcation loss: 1.998 | Constrast loss: 2.10 | Total loss: 8673.682 | Train acc: 76.747 % ||| Val Loss: 8261.260 | Val acc: 78.552 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 1 / 10 | Reconst_loss: 1230.575 | Kldiv loss: 168.307 | Classifcation loss: 2.206 | Constrast loss: 19.26 | Total loss: 13455.835 | Train acc: 40.441 % ||| Val Loss: 11046.740 | Val acc: 52.756 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 2 / 10 | Reconst_loss: 1132.772 | Kldiv loss: 227.972 | Classifcation loss: 2.102 | Constrast loss: 4.52 | Total loss: 10533.440 | Train acc: 60.067 % ||| Val Loss: 9826.805 | Val acc: 63.610 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 3 / 10 | Reconst_loss: 962.369 | Kldiv loss: 199.891 | Classifcation loss: 2.081 | Constrast loss: 4.63 | Total loss: 9835.201 | Train acc: 67.991 % ||| Val Loss: 9250.892 | Val acc: 74.443 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 4 / 10 | Reconst_loss: 938.531 | Kldiv loss: 180.466 | Classifcation loss: 2.081 | Constrast loss: 7.84 | Total loss: 9414.209 | Train acc: 73.380 % ||| Val Loss: 8911.575 | Val acc: 75.524 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 5 / 10 | Reconst_loss: 913.193 | Kldiv loss: 211.646 | Classifcation loss: 1.938 | Constrast loss: 1.42 | Total loss: 9120.955 | Train acc: 75.676 % ||| Val Loss: 8649.252 | Val acc: 77.345 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 6 / 10 | Reconst_loss: 1128.506 | Kldiv loss: 188.914 | Classifcation loss: 2.073 | Constrast loss: 1.67 | Total loss: 8885.919 | Train acc: 77.002 % ||| Val Loss: 8883.637 | Val acc: 77.516 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 7 / 10 | Reconst_loss: 649.585 | Kldiv loss: 198.802 | Classifcation loss: 1.923 | Constrast loss: 2.00 | Total loss: 8802.885 | Train acc: 77.961 % ||| Val Loss: 8513.399 | Val acc: 80.056 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 8 / 10 | Reconst_loss: 1118.436 | Kldiv loss: 198.001 | Classifcation loss: 1.857 | Constrast loss: 0.99 | Total loss: 8637.798 | Train acc: 78.725 % ||| Val Loss: 8331.162 | Val acc: 79.788 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 9 / 10 | Reconst_loss: 794.147 | Kldiv loss: 166.899 | Classifcation loss: 1.858 | Constrast loss: 0.77 | Total loss: 8469.199 | Train acc: 79.675 % ||| Val Loss: 8133.165 | Val acc: 80.631 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2023-02-27 06:05:18,618]\u001b[0m Trial 98 finished with value: 0.8007372890131523 and parameters: {'optuna_batch_size': 145, 'optimizer': 'RMSprop', 'lr': 0.006421282217093909, 'alpha': 6.739116108852722, 'beta': 8.245905935793383, 'gamma': 2.0661861683065794, 'delta': 8.36783613451325}. Best is trial 91 with value: 0.8201125175808737.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 10 / 10 | Reconst_loss: 775.304 | Kldiv loss: 171.329 | Classifcation loss: 1.853 | Constrast loss: 0.00 | Total loss: 8402.669 | Train acc: 80.074 % ||| Val Loss: 8163.645 | Val acc: 80.792 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 1 / 10 | Reconst_loss: 16485.162 | Kldiv loss: 4264.509 | Classifcation loss: 2.341 | Constrast loss: 1622.12 | Total loss: 105743.835 | Train acc: 23.848 % ||| Val Loss: 49175.533 | Val acc: 34.818 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 2 / 10 | Reconst_loss: 14506.017 | Kldiv loss: 3896.439 | Classifcation loss: 2.282 | Constrast loss: 1112.79 | Total loss: 46858.946 | Train acc: 38.143 % ||| Val Loss: 42418.114 | Val acc: 41.180 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 3 / 10 | Reconst_loss: 13994.390 | Kldiv loss: 3517.510 | Classifcation loss: 2.242 | Constrast loss: 836.55 | Total loss: 41866.516 | Train acc: 43.495 % ||| Val Loss: 39764.928 | Val acc: 45.247 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 4 / 10 | Reconst_loss: 13716.740 | Kldiv loss: 3501.050 | Classifcation loss: 2.263 | Constrast loss: 697.11 | Total loss: 39550.502 | Train acc: 46.872 % ||| Val Loss: 37386.783 | Val acc: 47.649 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 5 / 10 | Reconst_loss: 13124.590 | Kldiv loss: 3191.518 | Classifcation loss: 2.198 | Constrast loss: 461.44 | Total loss: 37882.884 | Train acc: 48.734 % ||| Val Loss: 36402.493 | Val acc: 47.374 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 6 / 10 | Reconst_loss: 11884.280 | Kldiv loss: 3679.893 | Classifcation loss: 2.183 | Constrast loss: 373.61 | Total loss: 36435.705 | Train acc: 50.701 % ||| Val Loss: 34396.949 | Val acc: 52.357 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 7 / 10 | Reconst_loss: 10720.568 | Kldiv loss: 3217.732 | Classifcation loss: 2.167 | Constrast loss: 435.16 | Total loss: 35538.007 | Train acc: 51.459 % ||| Val Loss: 33112.596 | Val acc: 52.735 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 8 / 10 | Reconst_loss: 12563.123 | Kldiv loss: 3245.300 | Classifcation loss: 2.217 | Constrast loss: 342.58 | Total loss: 34582.690 | Train acc: 52.055 % ||| Val Loss: 32974.437 | Val acc: 51.841 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 9 / 10 | Reconst_loss: 11843.762 | Kldiv loss: 3894.203 | Classifcation loss: 2.177 | Constrast loss: 218.66 | Total loss: 34436.412 | Train acc: 52.307 % ||| Val Loss: 32569.594 | Val acc: 53.243 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2023-02-27 06:05:38,983]\u001b[0m Trial 99 finished with value: 0.5334465847570746 and parameters: {'optuna_batch_size': 487, 'optimizer': 'RMSprop', 'lr': 0.006503475151610851, 'alpha': 7.7316999200002865, 'beta': 8.286422833366723, 'gamma': 2.1552486359601475, 'delta': 8.536841641171442}. Best is trial 91 with value: 0.8201125175808737.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 10 / 10 | Reconst_loss: 12391.432 | Kldiv loss: 3504.371 | Classifcation loss: 2.150 | Constrast loss: 322.43 | Total loss: 33552.938 | Train acc: 53.345 % ||| Val Loss: 32750.068 | Val acc: 52.409 %\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_trial = study.best_trial\n",
        "\n",
        "for key, value in best_trial.params.items():\n",
        "    print(\"{}: {}\".format(key, value))"
      ],
      "metadata": {
        "id": "NsAEDPdGOOj2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1a95592b-1490-4d3c-d637-6bc8da3b2dd9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "optuna_batch_size: 66\n",
            "optimizer: RMSprop\n",
            "lr: 0.006661582980767222\n",
            "alpha: 6.095305338071538\n",
            "beta: 7.102592478744805\n",
            "gamma: 1.813603629531665\n",
            "delta: 9.387700064368634\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "![image.png](data:image/png;base64,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)"
      ],
      "metadata": {
        "id": "mgH_Wszz3uLX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![image.png](data:image/png;base64,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)![image.png](\n",
        "  \n",
        ")"
      ],
      "metadata": {
        "id": "f2k6G1iXpVJQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "optuna.visualization.plot_parallel_coordinate(study)"
      ],
      "metadata": {
        "id": "lRYaeU6SFLeL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "outputId": "96d3257e-23ff-4ba8-a1a5-f6fe4786c6a7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-2.8.3.min.js\"></script>                <div id=\"cb72372c-1812-4055-9ad8-9550b33f2fad\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"cb72372c-1812-4055-9ad8-9550b33f2fad\")) {                    Plotly.newPlot(                        \"cb72372c-1812-4055-9ad8-9550b33f2fad\",                        [{\"dimensions\":[{\"label\":\"Objective Value\",\"range\":[0.158119106367514,0.8201125175808737],\"values\":[0.6206991811354621,0.6122965641952984,0.6532950327487305,0.4908862594390505,0.6995341326701048,0.6906420859975907,0.6310760629046062,0.6055410951178668,0.7036271618198428,0.32268788367545104,0.158119106367514,0.7086864732074313,0.613801407771425,0.5351631477927036,0.6712230526767499,0.5331472982463082,0.5753347753530915,0.6801244660335211,0.7392859876023578,0.7874105244106601,0.7116912428928207,0.6227977849841653,0.5092795847220627,0.5580963602327033,0.5304686992661861,0.6956212643878942,0.6116592353666637,0.6900355182434613,0.6418208185045366,0.7371519131877476,0.5541767474182295,0.47621065546313446,0.4804974546037598,0.5682785164894393,0.598764795442267,0.5211006520416892,0.7332650196138628,0.7023412493051954,0.6361013241220497,0.6733457127499975,0.6455117868386709,0.6392901696019588,0.3621119125846808,0.7612334967748915,0.6407480462722798,0.7500958956655157,0.6981898802211306,0.641022664437508,0.6696904606651084,0.7566186616074511,0.6428695320459337,0.6671160063565127,0.7214533995416352,0.762991141694498,0.2988181573999464,0.7090823027514134,0.8085334443997629,0.6810398224010784,0.73088803088803,0.7120058239515269,0.6875798618498986,0.7249990425307817,0.7627140756797985,0.5978862590494721,0.728944337811903,0.6238603081368614,0.7114399962616571,0.6361716071921092,0.48262056751740473,0.6677025782688761,0.7411239328267175,0.7156185188730424,0.6912388824846013,0.7044515186306237,0.6612870158661763,0.7282375478927205,0.7077294685990325,0.658037657562539,0.7402390731357802,0.7874550526571721,0.7379347968960654,0.614681716962298,0.7090196121446116,0.7416216574498543,0.7309283088235294,0.6477116470405063,0.6428750579742818,0.7323988882499521,0.6813496629952336,0.7448090577624258,0.5556192841819999,0.8201125175808737,0.5159953970080552,0.43157417534971565,0.7500337367515876,0.667395250146995,0.7571181526353947,0.7674707466086785,0.8007372890131523,0.5334465847570746]},{\"label\":\"alpha\",\"range\":[0.19827390499842593,9.99153147499835],\"values\":[3.2162710834834574,3.909100924977496,0.6751162450804987,3.390768343889916,4.815267307543385,0.8469236419659504,0.19827390499842593,7.163965699200228,9.28638495530031,8.80619852346651,9.79227806639333,6.348718998181586,7.247937357584653,7.12734713071115,9.99153147499835,6.085822592489251,8.545625000845847,5.822725855703346,8.090879914376183,8.280888310348951,8.14611577931032,8.118506613073375,8.057628050718588,9.091926878119938,7.9966350863665765,7.5696959889388875,9.047195414421548,8.46615902651586,6.678471634972052,7.569781980368177,7.580865348434209,8.132269039808701,6.890565420229657,9.378343670134038,7.700678712084797,8.543639004212672,5.452670093419762,5.297774791468458,4.894710694548126,6.486453330915346,4.168162842186266,6.875422098250624,7.582618211004345,5.77206140457089,5.727740441637538,4.344466100138756,4.246039200978231,3.0784286286469187,6.553279167132152,6.135792358695679,6.278517683791077,7.174067263840188,5.889135159610671,6.04947708268854,6.165619460450572,5.272388127185164,4.495713297911321,4.513182784845949,4.9290393012317315,5.606048735215445,3.8251693387466053,5.239413863060127,5.989177293722115,6.091030340477078,4.610953861753081,5.809826705340843,5.573336803137772,5.075235747152614,6.280004608252385,6.730154909891339,5.947303895312832,6.004011574137485,7.010673400292074,6.526492064454768,5.4066021734051395,5.729901999269573,5.11854291937501,6.361931543447064,5.984810855889338,7.274410841385267,4.731527907839201,7.354351900133695,6.75967107746934,5.477657043114043,5.414637805518095,5.623652533556871,4.937474172684352,7.2810252994495634,6.935039997559243,6.394507151964459,6.563354563843254,6.095305338071538,6.141624779387532,6.38860870615297,6.305567090690728,7.02576767853218,6.269933198251735,7.829695388842611,6.739116108852722,7.7316999200002865]},{\"label\":\"beta\",\"range\":[0.19445702233667728,9.902983410783248],\"values\":[3.1628201715005972,1.0316845120419385,3.385299775999059,9.593216992828463,9.67674005317561,6.14969027121666,7.433612799850968,5.648476722632847,9.350961131733353,4.724615522414608,7.939767486641814,9.830274382925392,9.672335315193042,8.135677684971698,8.623050901482578,7.139558316553357,8.784268997968853,9.902983410783248,6.946878848461386,6.828714629358917,6.773118626096289,6.892185183792005,6.449289476973492,7.4187086784860785,5.568431491163764,6.188908304752374,7.874008272763823,6.5516473134723086,4.942050617034708,6.885585159891202,4.246538524029619,6.956863430251919,7.471614959559053,5.7629711453343635,6.6915357888586815,0.19445702233667728,6.004751184430708,6.087421087704899,5.37607535742805,6.010929449940265,4.383589084033595,6.8043564394987825,6.365886640229547,7.378876655738958,7.4683273999699225,5.25895915933238,5.038504777118756,5.419582261725213,8.36048647649309,8.003569225508933,9.06929624359394,8.102121873830754,7.656806723251755,7.302365470274168,7.238025650217676,7.684615006507706,8.366160499015448,8.394599691321304,8.852981674897492,7.998330522718606,8.483504068522798,7.803084000062914,7.32195054250508,7.254032812792494,8.19719808125374,9.38254486325617,7.1064493363762455,6.498945098082624,8.693578324386502,7.733124947002658,7.364884790100438,7.242828249760041,7.99920311560895,7.544177357010719,6.6587328426115855,7.13168174731025,8.278889273370062,7.911586699247236,6.321709095577936,7.423028063647211,6.879571067199526,7.419313028910244,7.648424197051665,6.590127371143064,6.950445092010863,6.72216812817665,5.818129802548895,6.311086634019349,6.479918073540272,7.071246449187573,8.081190125831782,7.102592478744805,7.061890535918779,7.53807400976952,7.811107487475429,8.51355669592406,7.819916656631253,8.150610510857058,8.245905935793383,8.286422833366723]},{\"label\":\"delta\",\"range\":[0.7184508849712268,9.9556943309808],\"values\":[4.123415553751628,8.452433881636516,9.485558049627901,8.539225040482275,2.2007460761161273,1.5649722090851543,0.7184508849712268,9.00299888468433,7.461047207784562,4.769746152060371,7.235782514161249,6.459866630196646,6.80540134543722,6.3247242493050475,5.833116996308775,7.501802834361564,9.921727013256158,5.1778221522684085,7.75461694301157,6.021646289570443,8.06746447279243,8.125092390102814,7.824721212341584,9.192458818018663,8.04698289120069,7.075061414183983,8.87919921786162,5.926967213163463,6.86282377974869,4.017815030192448,3.756134372074066,3.8218062650160345,5.319341153138201,8.317298953014268,4.2821260081100805,8.469382592327147,9.654242839794462,9.9556943309808,9.60364020477835,9.084207176146519,8.831024517439548,7.975211048915318,7.635575308840176,8.407388577478905,9.431552523797484,8.756551622552905,8.581838809317372,7.470520262320026,7.158150698738277,6.624488043443004,6.858088635390682,6.443314851725785,7.747509938742043,8.592869639143837,8.685270878399018,8.286910524978012,7.415517278194275,7.332690473304888,9.076080766341276,8.505403892081782,6.685767365997383,7.827285343312189,7.263656764666556,7.299974469546803,6.015541033020039,8.182144235914647,6.976104064074682,6.640907480224585,6.34301868349064,7.618503069335748,7.128559247202816,6.979424401134076,7.255315493612928,7.973206947996797,6.0962798852970135,5.646514017075377,7.523201483629975,8.23954000382201,8.732029330777216,6.69928813861562,6.542983900309207,6.202285918244402,6.766417163802853,7.0936486709336055,6.379358095297376,7.951793423052061,7.3740745905899505,7.665924722532942,6.904451949458261,9.31290422944837,8.959516899475393,9.387700064368634,9.310811327199554,9.322380873234902,9.55910862510503,9.789072721080153,8.817796200822405,8.526688031634096,8.36783613451325,8.536841641171442]},{\"label\":\"gamma\",\"range\":[0.1022736901923832,9.892900229613428],\"values\":[7.745098714381568,3.5408275409935115,9.892900229613428,5.31952440654823,5.417006825232157,1.5226720949545016,9.503789443341585,9.43029343943856,3.8350716421937894,6.910660787282006,1.1140333127500925,4.031997371774362,3.5018160397344236,3.359807372723433,2.628378552349232,4.801971214679744,0.572446927602229,2.2916781938455215,0.22907758535130718,1.6879434577552987,0.18783197628407364,0.21164001482467942,0.10758160955759248,1.1516544900551586,1.844340504125797,0.8031906298248189,1.7542802179172636,0.7690447215654844,2.4829365967887544,0.2721475985916,1.4326460660194282,0.3718747296717911,0.18939462554584363,0.9490840863360247,1.8956492285250968,0.9293891369716167,1.3219224261335287,1.3878622102304976,2.8799526134275943,1.9836254281593084,1.24892947162737,0.5781091268840388,0.528143560834037,1.4893881113126912,1.5017528330121381,2.2596388021411524,3.0202354303496355,2.2655557819585037,2.0719656226493823,1.6918360960527496,2.5031375446678235,1.6920132447185632,0.9797476594556086,0.7211443247701267,2.1886946086678085,1.621445142006651,0.7618291914837088,1.2217799875896633,0.6726279852405604,2.8985136184348566,1.7521791470602994,1.0049634444177566,0.7195014849378772,0.502213273459071,0.8259749232730146,1.3456211571830685,2.072911753441611,1.5875701296883138,1.1330232143094883,2.388810249704015,0.5330182191316393,0.5253031101465064,0.7613588028869182,0.1022736901923832,1.0461900733162355,1.8560075847239386,0.3491926070637657,1.5378893302035364,0.7024759115428689,1.2384367686298587,1.2541377191779837,0.9263517055940352,0.46984878498408256,1.513179316641068,1.9223831924690282,1.5625499058860075,1.2394305481244055,2.25228975138632,1.3956331551471493,2.6569305672908854,2.5269333619345553,1.813603629531665,2.0053400277496833,1.8233462020456557,2.6724449204142116,1.0669417974801214,2.3088457019654447,2.1259745186066987,2.0661861683065794,2.1552486359601475]},{\"label\":\"lr\",\"range\":[0.00015379999898672107,0.009980969089178315],\"values\":[0.007044878226407033,0.009491602538775758,0.0026636660004030074,0.009709010774104979,0.0037383955283961825,0.0060571810422021975,0.008104382736509676,0.009066990202001284,0.003606224568103176,0.001429273119000515,0.00015379999898672107,0.0038623416470803065,0.004293815734801606,0.0053620127698157695,0.00337286766867469,0.004826744325701524,0.0026317769914188257,0.005801942944535984,0.004241535378828112,0.004719220775933039,0.006616922409655494,0.007054013630777302,0.004764002886543785,0.0063523434319295415,0.0047594786989160545,0.005783294358100279,0.005166173283602819,0.007173328093453042,0.006356990700504342,0.0076246127126403124,0.007311511201884055,0.007606265910226082,0.006507592632714543,0.00844400595686352,0.00554375770198276,0.0067114005384752776,0.0077733721271955585,0.007829806730102013,0.009980969089178315,0.008349454281847333,0.005861181793773917,0.009294208626530569,0.00868639249725449,0.007966595572081295,0.00902353794672669,0.007655803501157023,0.007951472255509335,0.008778175069512539,0.009528273030254242,0.0073973289421470695,0.006927463433905121,0.008380967519997173,0.007473006636485942,0.007442050167964611,0.007227827486784831,0.008033861242792716,0.004314526443409444,0.006131778641717383,0.006943376891343172,0.0053944368952987525,0.008079693416212081,0.004276240965845163,0.0045690640395325,0.004984962126222282,0.003737065160109007,0.004566834458312098,0.004027396366492671,0.0035066594644715403,0.0031073633151594013,0.004448922639656691,0.004965065788855471,0.00469987728779605,0.005220445840573477,0.004046822285740424,0.005004478223388858,0.005524618750866037,0.004499677895795173,0.007611750951387062,0.006195386381967196,0.006728401674710652,0.007426788261894859,0.007263398951421736,0.004882697269840992,0.006728598941325726,0.006721247225034509,0.006968856170265296,0.006388695218093524,0.007795512217896448,0.008154763582046995,0.007113863081253526,0.00712509653949808,0.006661582980767222,0.007445069964091751,0.007732062565718277,0.005958583249858324,0.005730935895474021,0.006026811222776968,0.006550281403086249,0.006421282217093909,0.006503475151610851]},{\"label\":\"optimizer\",\"range\":[0,1],\"ticktext\":[\"RMSprop\",\"Adam\"],\"tickvals\":[0,1],\"values\":[0,0,1,0,0,1,0,1,1,1,1,0,1,0,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,1,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0]},{\"label\":\"optuna_batch_size\",\"range\":[10,991],\"values\":[743,132,553,824,79,327,863,746,262,991,333,52,241,10,215,505,485,379,179,139,615,651,154,446,580,411,635,163,276,705,691,756,808,531,617,921,83,93,193,113,12,691,318,59,130,60,44,187,62,234,233,132,308,38,34,95,169,273,141,211,67,169,363,239,10,371,104,350,433,48,209,155,296,201,254,120,81,215,156,114,109,36,74,185,136,175,285,94,55,30,25,66,60,29,119,118,145,145,145,487]}],\"labelangle\":30,\"labelside\":\"bottom\",\"line\":{\"color\":[0.6206991811354621,0.6122965641952984,0.6532950327487305,0.4908862594390505,0.6995341326701048,0.6906420859975907,0.6310760629046062,0.6055410951178668,0.7036271618198428,0.32268788367545104,0.158119106367514,0.7086864732074313,0.613801407771425,0.5351631477927036,0.6712230526767499,0.5331472982463082,0.5753347753530915,0.6801244660335211,0.7392859876023578,0.7874105244106601,0.7116912428928207,0.6227977849841653,0.5092795847220627,0.5580963602327033,0.5304686992661861,0.6956212643878942,0.6116592353666637,0.6900355182434613,0.6418208185045366,0.7371519131877476,0.5541767474182295,0.47621065546313446,0.4804974546037598,0.5682785164894393,0.598764795442267,0.5211006520416892,0.7332650196138628,0.7023412493051954,0.6361013241220497,0.6733457127499975,0.6455117868386709,0.6392901696019588,0.3621119125846808,0.7612334967748915,0.6407480462722798,0.7500958956655157,0.6981898802211306,0.641022664437508,0.6696904606651084,0.7566186616074511,0.6428695320459337,0.6671160063565127,0.7214533995416352,0.762991141694498,0.2988181573999464,0.7090823027514134,0.8085334443997629,0.6810398224010784,0.73088803088803,0.7120058239515269,0.6875798618498986,0.7249990425307817,0.7627140756797985,0.5978862590494721,0.728944337811903,0.6238603081368614,0.7114399962616571,0.6361716071921092,0.48262056751740473,0.6677025782688761,0.7411239328267175,0.7156185188730424,0.6912388824846013,0.7044515186306237,0.6612870158661763,0.7282375478927205,0.7077294685990325,0.658037657562539,0.7402390731357802,0.7874550526571721,0.7379347968960654,0.614681716962298,0.7090196121446116,0.7416216574498543,0.7309283088235294,0.6477116470405063,0.6428750579742818,0.7323988882499521,0.6813496629952336,0.7448090577624258,0.5556192841819999,0.8201125175808737,0.5159953970080552,0.43157417534971565,0.7500337367515876,0.667395250146995,0.7571181526353947,0.7674707466086785,0.8007372890131523,0.5334465847570746],\"colorbar\":{\"title\":{\"text\":\"Objective Value\"}},\"colorscale\":[[0.0,\"rgb(247,251,255)\"],[0.125,\"rgb(222,235,247)\"],[0.25,\"rgb(198,219,239)\"],[0.375,\"rgb(158,202,225)\"],[0.5,\"rgb(107,174,214)\"],[0.625,\"rgb(66,146,198)\"],[0.75,\"rgb(33,113,181)\"],[0.875,\"rgb(8,81,156)\"],[1.0,\"rgb(8,48,107)\"]],\"reversescale\":false,\"showscale\":true},\"type\":\"parcoords\"}],                        {\"title\":{\"text\":\"Parallel Coordinate Plot\"},\"template\":{\"data\":{\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"white\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2}}}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('cb72372c-1812-4055-9ad8-9550b33f2fad');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "optuna.visualization.plot_param_importances(study)"
      ],
      "metadata": {
        "id": "_vOH85Dlpssz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "outputId": "2dd506e9-ab5a-4f2f-cdaf-d06d12a78f48"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-2.8.3.min.js\"></script>                <div id=\"14fcfab6-0baa-4490-87a0-7c259dc674cf\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"14fcfab6-0baa-4490-87a0-7c259dc674cf\")) {                    Plotly.newPlot(                        \"14fcfab6-0baa-4490-87a0-7c259dc674cf\",                        [{\"cliponaxis\":false,\"hovertemplate\":[\"optimizer (CategoricalDistribution): 0.006903964330765218<extra></extra>\",\"delta (FloatDistribution): 0.01484764452777474<extra></extra>\",\"gamma (FloatDistribution): 0.016936601851946773<extra></extra>\",\"beta (FloatDistribution): 0.018193751256228363<extra></extra>\",\"alpha (FloatDistribution): 0.07691296992721672<extra></extra>\",\"optuna_batch_size (IntDistribution): 0.4231880601168326<extra></extra>\",\"lr (FloatDistribution): 0.4430170079892356<extra></extra>\"],\"marker\":{\"color\":\"rgb(66,146,198)\"},\"orientation\":\"h\",\"text\":[\"<0.01\",\"0.01\",\"0.02\",\"0.02\",\"0.08\",\"0.42\",\"0.44\"],\"textposition\":\"outside\",\"x\":[0.006903964330765218,0.01484764452777474,0.016936601851946773,0.018193751256228363,0.07691296992721672,0.4231880601168326,0.4430170079892356],\"y\":[\"optimizer\",\"delta\",\"gamma\",\"beta\",\"alpha\",\"optuna_batch_size\",\"lr\"],\"type\":\"bar\"}],                        {\"showlegend\":false,\"title\":{\"text\":\"Hyperparameter Importances\"},\"xaxis\":{\"title\":{\"text\":\"Importance for Objective Value\"}},\"yaxis\":{\"title\":{\"text\":\"Hyperparameter\"}},\"template\":{\"data\":{\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"white\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2}}}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('14fcfab6-0baa-4490-87a0-7c259dc674cf');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "optuna.visualization.plot_optimization_history(study)"
      ],
      "metadata": {
        "id": "3r3cLVSWHHzV",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "outputId": "223f4580-b4e1-4870-a0b6-e5c1dd657f10"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-2.8.3.min.js\"></script>                <div id=\"29aa8dea-2264-4acc-b7cd-52b9f4aff82a\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"29aa8dea-2264-4acc-b7cd-52b9f4aff82a\")) {                    Plotly.newPlot(                        \"29aa8dea-2264-4acc-b7cd-52b9f4aff82a\",                        [{\"mode\":\"markers\",\"name\":\"Objective Value\",\"x\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99],\"y\":[0.6206991811354621,0.6122965641952984,0.6532950327487305,0.4908862594390505,0.6995341326701048,0.6906420859975907,0.6310760629046062,0.6055410951178668,0.7036271618198428,0.32268788367545104,0.158119106367514,0.7086864732074313,0.613801407771425,0.5351631477927036,0.6712230526767499,0.5331472982463082,0.5753347753530915,0.6801244660335211,0.7392859876023578,0.7874105244106601,0.7116912428928207,0.6227977849841653,0.5092795847220627,0.5580963602327033,0.5304686992661861,0.6956212643878942,0.6116592353666637,0.6900355182434613,0.6418208185045366,0.7371519131877476,0.5541767474182295,0.47621065546313446,0.4804974546037598,0.5682785164894393,0.598764795442267,0.5211006520416892,0.7332650196138628,0.7023412493051954,0.6361013241220497,0.6733457127499975,0.6455117868386709,0.6392901696019588,0.3621119125846808,0.7612334967748915,0.6407480462722798,0.7500958956655157,0.6981898802211306,0.641022664437508,0.6696904606651084,0.7566186616074511,0.6428695320459337,0.6671160063565127,0.7214533995416352,0.762991141694498,0.2988181573999464,0.7090823027514134,0.8085334443997629,0.6810398224010784,0.73088803088803,0.7120058239515269,0.6875798618498986,0.7249990425307817,0.7627140756797985,0.5978862590494721,0.728944337811903,0.6238603081368614,0.7114399962616571,0.6361716071921092,0.48262056751740473,0.6677025782688761,0.7411239328267175,0.7156185188730424,0.6912388824846013,0.7044515186306237,0.6612870158661763,0.7282375478927205,0.7077294685990325,0.658037657562539,0.7402390731357802,0.7874550526571721,0.7379347968960654,0.614681716962298,0.7090196121446116,0.7416216574498543,0.7309283088235294,0.6477116470405063,0.6428750579742818,0.7323988882499521,0.6813496629952336,0.7448090577624258,0.5556192841819999,0.8201125175808737,0.5159953970080552,0.43157417534971565,0.7500337367515876,0.667395250146995,0.7571181526353947,0.7674707466086785,0.8007372890131523,0.5334465847570746],\"type\":\"scatter\"},{\"name\":\"Best Value\",\"x\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99],\"y\":[0.6206991811354621,0.6206991811354621,0.6532950327487305,0.6532950327487305,0.6995341326701048,0.6995341326701048,0.6995341326701048,0.6995341326701048,0.7036271618198428,0.7036271618198428,0.7036271618198428,0.7086864732074313,0.7086864732074313,0.7086864732074313,0.7086864732074313,0.7086864732074313,0.7086864732074313,0.7086864732074313,0.7392859876023578,0.7874105244106601,0.7874105244106601,0.7874105244106601,0.7874105244106601,0.7874105244106601,0.7874105244106601,0.7874105244106601,0.7874105244106601,0.7874105244106601,0.7874105244106601,0.7874105244106601,0.7874105244106601,0.7874105244106601,0.7874105244106601,0.7874105244106601,0.7874105244106601,0.7874105244106601,0.7874105244106601,0.7874105244106601,0.7874105244106601,0.7874105244106601,0.7874105244106601,0.7874105244106601,0.7874105244106601,0.7874105244106601,0.7874105244106601,0.7874105244106601,0.7874105244106601,0.7874105244106601,0.7874105244106601,0.7874105244106601,0.7874105244106601,0.7874105244106601,0.7874105244106601,0.7874105244106601,0.7874105244106601,0.7874105244106601,0.8085334443997629,0.8085334443997629,0.8085334443997629,0.8085334443997629,0.8085334443997629,0.8085334443997629,0.8085334443997629,0.8085334443997629,0.8085334443997629,0.8085334443997629,0.8085334443997629,0.8085334443997629,0.8085334443997629,0.8085334443997629,0.8085334443997629,0.8085334443997629,0.8085334443997629,0.8085334443997629,0.8085334443997629,0.8085334443997629,0.8085334443997629,0.8085334443997629,0.8085334443997629,0.8085334443997629,0.8085334443997629,0.8085334443997629,0.8085334443997629,0.8085334443997629,0.8085334443997629,0.8085334443997629,0.8085334443997629,0.8085334443997629,0.8085334443997629,0.8085334443997629,0.8085334443997629,0.8201125175808737,0.8201125175808737,0.8201125175808737,0.8201125175808737,0.8201125175808737,0.8201125175808737,0.8201125175808737,0.8201125175808737,0.8201125175808737],\"type\":\"scatter\"}],                        {\"title\":{\"text\":\"Optimization History Plot\"},\"xaxis\":{\"title\":{\"text\":\"Trial\"}},\"yaxis\":{\"title\":{\"text\":\"Objective Value\"}},\"template\":{\"data\":{\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"white\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2}}}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('29aa8dea-2264-4acc-b7cd-52b9f4aff82a');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "optuna.visualization.plot_slice(study,params=['lr'])"
      ],
      "metadata": {
        "id": "7CxMNDlDI5w3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "outputId": "89fae53b-1c9c-43fc-9c47-35bba319b121"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-2.8.3.min.js\"></script>                <div id=\"f13b6f4a-cc42-404d-b13a-f3f3bd5806e2\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"f13b6f4a-cc42-404d-b13a-f3f3bd5806e2\")) {                    Plotly.newPlot(                        \"f13b6f4a-cc42-404d-b13a-f3f3bd5806e2\",                        [{\"marker\":{\"color\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99],\"colorbar\":{\"title\":{\"text\":\"Trial\"},\"x\":1.0,\"xpad\":40},\"colorscale\":[[0.0,\"rgb(247,251,255)\"],[0.125,\"rgb(222,235,247)\"],[0.25,\"rgb(198,219,239)\"],[0.375,\"rgb(158,202,225)\"],[0.5,\"rgb(107,174,214)\"],[0.625,\"rgb(66,146,198)\"],[0.75,\"rgb(33,113,181)\"],[0.875,\"rgb(8,81,156)\"],[1.0,\"rgb(8,48,107)\"]],\"line\":{\"color\":\"Grey\",\"width\":0.5}},\"mode\":\"markers\",\"showlegend\":false,\"x\":[0.007044878226407033,0.009491602538775758,0.0026636660004030074,0.009709010774104979,0.0037383955283961825,0.0060571810422021975,0.008104382736509676,0.009066990202001284,0.003606224568103176,0.001429273119000515,0.00015379999898672107,0.0038623416470803065,0.004293815734801606,0.0053620127698157695,0.00337286766867469,0.004826744325701524,0.0026317769914188257,0.005801942944535984,0.004241535378828112,0.004719220775933039,0.006616922409655494,0.007054013630777302,0.004764002886543785,0.0063523434319295415,0.0047594786989160545,0.005783294358100279,0.005166173283602819,0.007173328093453042,0.006356990700504342,0.0076246127126403124,0.007311511201884055,0.007606265910226082,0.006507592632714543,0.00844400595686352,0.00554375770198276,0.0067114005384752776,0.0077733721271955585,0.007829806730102013,0.009980969089178315,0.008349454281847333,0.005861181793773917,0.009294208626530569,0.00868639249725449,0.007966595572081295,0.00902353794672669,0.007655803501157023,0.007951472255509335,0.008778175069512539,0.009528273030254242,0.0073973289421470695,0.006927463433905121,0.008380967519997173,0.007473006636485942,0.007442050167964611,0.007227827486784831,0.008033861242792716,0.004314526443409444,0.006131778641717383,0.006943376891343172,0.0053944368952987525,0.008079693416212081,0.004276240965845163,0.0045690640395325,0.004984962126222282,0.003737065160109007,0.004566834458312098,0.004027396366492671,0.0035066594644715403,0.0031073633151594013,0.004448922639656691,0.004965065788855471,0.00469987728779605,0.005220445840573477,0.004046822285740424,0.005004478223388858,0.005524618750866037,0.004499677895795173,0.007611750951387062,0.006195386381967196,0.006728401674710652,0.007426788261894859,0.007263398951421736,0.004882697269840992,0.006728598941325726,0.006721247225034509,0.006968856170265296,0.006388695218093524,0.007795512217896448,0.008154763582046995,0.007113863081253526,0.00712509653949808,0.006661582980767222,0.007445069964091751,0.007732062565718277,0.005958583249858324,0.005730935895474021,0.006026811222776968,0.006550281403086249,0.006421282217093909,0.006503475151610851],\"y\":[0.6206991811354621,0.6122965641952984,0.6532950327487305,0.4908862594390505,0.6995341326701048,0.6906420859975907,0.6310760629046062,0.6055410951178668,0.7036271618198428,0.32268788367545104,0.158119106367514,0.7086864732074313,0.613801407771425,0.5351631477927036,0.6712230526767499,0.5331472982463082,0.5753347753530915,0.6801244660335211,0.7392859876023578,0.7874105244106601,0.7116912428928207,0.6227977849841653,0.5092795847220627,0.5580963602327033,0.5304686992661861,0.6956212643878942,0.6116592353666637,0.6900355182434613,0.6418208185045366,0.7371519131877476,0.5541767474182295,0.47621065546313446,0.4804974546037598,0.5682785164894393,0.598764795442267,0.5211006520416892,0.7332650196138628,0.7023412493051954,0.6361013241220497,0.6733457127499975,0.6455117868386709,0.6392901696019588,0.3621119125846808,0.7612334967748915,0.6407480462722798,0.7500958956655157,0.6981898802211306,0.641022664437508,0.6696904606651084,0.7566186616074511,0.6428695320459337,0.6671160063565127,0.7214533995416352,0.762991141694498,0.2988181573999464,0.7090823027514134,0.8085334443997629,0.6810398224010784,0.73088803088803,0.7120058239515269,0.6875798618498986,0.7249990425307817,0.7627140756797985,0.5978862590494721,0.728944337811903,0.6238603081368614,0.7114399962616571,0.6361716071921092,0.48262056751740473,0.6677025782688761,0.7411239328267175,0.7156185188730424,0.6912388824846013,0.7044515186306237,0.6612870158661763,0.7282375478927205,0.7077294685990325,0.658037657562539,0.7402390731357802,0.7874550526571721,0.7379347968960654,0.614681716962298,0.7090196121446116,0.7416216574498543,0.7309283088235294,0.6477116470405063,0.6428750579742818,0.7323988882499521,0.6813496629952336,0.7448090577624258,0.5556192841819999,0.8201125175808737,0.5159953970080552,0.43157417534971565,0.7500337367515876,0.667395250146995,0.7571181526353947,0.7674707466086785,0.8007372890131523,0.5334465847570746],\"type\":\"scatter\"}],                        {\"title\":{\"text\":\"Slice Plot\"},\"template\":{\"data\":{\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"white\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2}}},\"xaxis\":{\"title\":{\"text\":\"lr\"}},\"yaxis\":{\"title\":{\"text\":\"Objective Value\"}}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('f13b6f4a-cc42-404d-b13a-f3f3bd5806e2');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "optuna.visualization.plot_intermediate_values(study)"
      ],
      "metadata": {
        "id": "D0tsHeBYpsqP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 559
        },
        "outputId": "e4605ab8-9188-425a-8d13-8fb6656835d6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[33m[W 2023-02-27 06:05:43,305]\u001b[0m You need to set up the pruning feature to utilize `plot_intermediate_values()`\u001b[0m\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-2.8.3.min.js\"></script>                <div id=\"6cc58d43-4632-4e69-a2a2-5b775dfc3588\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"6cc58d43-4632-4e69-a2a2-5b775dfc3588\")) {                    Plotly.newPlot(                        \"6cc58d43-4632-4e69-a2a2-5b775dfc3588\",                        [],                        {\"showlegend\":false,\"title\":{\"text\":\"Intermediate Values Plot\"},\"xaxis\":{\"title\":{\"text\":\"Step\"}},\"yaxis\":{\"title\":{\"text\":\"Intermediate Value\"}},\"template\":{\"data\":{\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"white\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2}}}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('6cc58d43-4632-4e69-a2a2-5b775dfc3588');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PyG4shxFpsnY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QqmsOzO4pskg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "mOCQlIN1psdp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XCQKErX5BSdv"
      },
      "outputs": [],
      "source": [
        "# #Model and Optmimizer\n",
        "# model  = VAE(input_dim, hidden_dim, latent_dim).to(device)\n",
        "# optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=l2_lambda)\n",
        "\n",
        "# print(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-k0KXnR3yxzw"
      },
      "outputs": [],
      "source": [
        "class ContrastiveLoss(nn.Module):\n",
        "  def __init__(self, margin=1.0):\n",
        "    super(ContrastiveLoss, self).__init__()\n",
        "    self.margin = margin\n",
        "        \n",
        "  def forward(self, z_reparmeterized, labels):\n",
        "    # Compute the pairwise euclidean distances between the examples in the latent space\n",
        "    distances = torch.pow(z_reparmeterized, 2).sum(dim=1, keepdim=True) + torch.pow(z_reparmeterized, 2).sum(dim=1, keepdim=True).t() - 2 * torch.matmul(z_reparmeterized, z_reparmeterized.t())\n",
        "    # Create a mask for the positive pairs (i.e. examples with the same label)\n",
        "    positive_mask = labels.expand(z_reparmeterized.size(0), z_reparmeterized.size(0)).eq(labels.expand(z_reparmeterized.size(0), z_reparmeterized.size(0)).t())\n",
        "    # Create a mask for the negative pairs (i.e. examples with different labels)\n",
        "    negative_mask = labels.expand(z_reparmeterized.size(0), z_reparmeterized.size(0)).ne(labels.expand(z_reparmeterized.size(0), z_reparmeterized.size(0)).t())\n",
        "    # Set the distances for the positive pairs to a large value\n",
        "    distances.masked_fill_(positive_mask, 1e7)\n",
        "    # Compute the contrastive loss as the sum of the max(0, margin - distance) for the negative pairs\n",
        "    contrastive_loss = torch.sum(torch.max(torch.zeros_like(distances), self.margin - distances))\n",
        "    return contrastive_loss\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class MagneticLoss(torch.nn.Module):\n",
        "  def __init__(self, num_classes, strength, width):\n",
        "      super().__init__()\n",
        "      self.num_classes = num_classes\n",
        "      self.strength = strength\n",
        "      self.width = width     \n",
        "\n",
        "  def forward(self, z, y):\n",
        "    N = z.shape[0] # number of samples\n",
        "    K = self.num_classes # number of classes\n",
        "    mu = torch.stack([z[y.squeeze==k].mean(dim=0) for k in range(K)], dim=0) # mean of each class\n",
        "    print(f\"mu: {mu}\")\n",
        "    z_center = z[None, :, :] - mu[:, None, :] # centered z\n",
        "    print(f\"z_center: {z_center}\")\n",
        "    z_Norm = z_center.norm(dim=2) # L2 norm of z_Center\n",
        "    print(f\"z_Norm: {z_Norm}\")\n",
        "    exp_term = torch.exp(-self.width * z_Norm)\n",
        "    pairwise_sum = (exp_term[:, :, None] * exp_term[None, :, :]).sum() - exp_term.sum()\n",
        "    loss = 0.5 * self.strength * pairwise_sum / N / (K - 1)\n",
        "    return loss"
      ],
      "metadata": {
        "id": "00s0At_uPOOb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HLawvUR-SpJl"
      },
      "outputs": [],
      "source": [
        "# Loss Functions\n",
        "loss_fn = nn.MSELoss(reduction=\"sum\")\n",
        "classifier_loss_fn = nn.CrossEntropyLoss()\n",
        "triplet_loss_fn = nn.TripletMarginLoss(margin=1.0)\n",
        "#triplet_loss_fn = TripletLoss(margin=1.0)\n",
        "\n",
        "contrastive_loss_fn = ContrastiveLoss(margin=1)\n",
        "magnetic_loss_fn = MagneticLoss(num_classes=num_classes, strength=1, width=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6r4_reRyWuIu"
      },
      "source": [
        "---\n",
        "Train and Validation loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lH7Muoa_Sr-U",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "outputId": "fc93aa21-264a-4792-f3d5-67ae750ecd13"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-55-04e6c7e4a378>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m   \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m   \u001b[0mtrain_running_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
          ]
        }
      ],
      "source": [
        "train_losses=[]\n",
        "train_accuracy = []\n",
        "accuracy_log = []\n",
        "val_losses=[]\n",
        "val_accuracy=[]\n",
        "\n",
        "dic = dict(latent_space = list(), mu_list=list(), logsig2_list=list(), y=list())\n",
        "\n",
        "from tensorboardX import SummaryWriter\n",
        "\n",
        "# Create a SummaryWriter object\n",
        "writer = SummaryWriter() \n",
        "\n",
        "\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "  model.train()\n",
        "  train_running_loss = 0\n",
        "  \n",
        "\n",
        "  z_list, means, logvars , labels_list = list(), list(), list(), list()\n",
        "\n",
        "  for i, data in enumerate(train_loader):\n",
        "    inputs, labels = data\n",
        "    # print(f\"Input shape: {inputs.shape}\")\n",
        "    # print(f\"Labels shape: {labels.shape}\")\n",
        "    optimizer.zero_grad()\n",
        "    \n",
        "    x_reconstructed, z_reparmeterized, classified, mu, logvar = model(inputs)\n",
        "\n",
        "    # Compute the reconstruction loss and KL divergence loss #################################################\n",
        "\n",
        "    reconstruction_loss = loss_fn(x_reconstructed, inputs)\n",
        "    kld_loss = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
        "\n",
        "    # Compute the contrastive loss #############################################################################\n",
        "    contrastive_loss = contrastive_loss_fn(mu, labels)\n",
        "\n",
        "    # Compute the classificaiton loss #########################################################################\n",
        "    classified = classified.view(-1, 13)\n",
        "    classification_loss = classifier_loss_fn(classified, labels.flatten())\n",
        "\n",
        "    # Compute the triplet loss #########################\n",
        "    # Select a random sample as the anchor, then select the positive samples (samples with the same label as the anchor)\n",
        "    # and negative samples (samples with a different label than the anchor) from the mu\n",
        "    batch_size = mu.size(0)\n",
        "    # Select a random sample as the anchor\n",
        "    anchor_index = torch.randint(0, batch_size, (1,))\n",
        "    anchor_embeddings = mu[anchor_index].view(1, -1) # Take the embedding for the current sample\n",
        "    anchor_embeddings = anchor_embeddings.expand(batch_size,-1)\n",
        "    # Select a fixed number of positive samples\n",
        "    positive_indices = torch.randint(0, batch_size, (batch_size,))\n",
        "    positive_embeddings = mu[positive_indices].view(-1,latent_dim)\n",
        "    # Select a fixed number of negative samples\n",
        "    negative_indices = torch.randint(0, batch_size, (batch_size,))\n",
        "    negative_embeddings = mu[negative_indices].view(-1,latent_dim)\n",
        "    #print(f\"anchor_embeddings shape: {anchor_embeddings.shape}, positive_embeddings shape: {positive_embeddings.shape}, negative_embeddings shape: {negative_embeddings.shape}\")\n",
        "    triplet_loss = triplet_loss_fn(anchor_embeddings, positive_embeddings, negative_embeddings)\n",
        "   \n",
        "    loss = (alpha*reconstruction_loss + kld_loss*beta) + gamma*classification_loss + delta*contrastive_loss #+ epsilon*triplet_loss\n",
        "\n",
        "    accuracy = accuracy_score(labels, classified.argmax(dim=1))\n",
        "    train_accuracy.append(accuracy)\n",
        "    train_acc = sum(train_accuracy)/len(train_accuracy)\n",
        "    accuracy_log.append(train_acc)\n",
        "\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    train_running_loss += loss.item()\n",
        "    train_loss= train_running_loss/len(train_loader)\n",
        "\n",
        "   # log for latent space visualziation (gif)...\n",
        "    z_list.append(z_reparmeterized.detach())\n",
        "    means.append(mu.detach())\n",
        "    logvars.append(logvar.detach())\n",
        "    labels_list.append(labels.detach())\n",
        "\n",
        "   # Write the scalar values to TensorBoard\n",
        "    writer.add_scalar('loss/total', loss.item(), i)\n",
        "    writer.add_scalar('loss/reconstruction', reconstruction_loss.item(), i)\n",
        "    writer.add_scalar('loss/kld', kld_loss.item(), i)\n",
        "    writer.add_scalar('loss/classification', classification_loss.item(), i)\n",
        "\n",
        "  writer.add_embedding(z_reparmeterized, metadata=labels, global_step=epoch)\n",
        "\n",
        "  with torch.inference_mode():\n",
        "    val_running_loss = 0\n",
        "    val_running_acc = 0\n",
        "\n",
        "    model.eval()\n",
        "    # Iterate over the validation data\n",
        "    for X, Y in val_loader:\n",
        "      # Pass the data through the model and get the reconstructed data and the latent representation\n",
        "      y_pred, z_reparmeterized, v_classified, mu, logvar = model(X)\n",
        "\n",
        "      # Compute the reconstruction loss\n",
        "      v_reconstruction_loss = loss_fn(y_pred, X)\n",
        "\n",
        "      # Compute the KL divergence loss\n",
        "      v_kld_loss = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
        "\n",
        "      # Compute the contrastive loss\n",
        "      v_contrastive_loss_value = contrastive_loss_fn(mu, Y)\n",
        "\n",
        "      # Reshape the classified output to have the same shape as the labels\n",
        "      v_classified = v_classified.view(-1, 13)\n",
        "      # Compute the classification loss\n",
        "      v_classification_loss = classifier_loss_fn(v_classified, Y.flatten())\n",
        "\n",
        "      # Compute the total loss\n",
        "      vloss = (alpha*v_reconstruction_loss + v_kld_loss*beta) + gamma*v_classification_loss + delta*v_contrastive_loss_value\n",
        "      val_running_loss += vloss.item()\n",
        "      val_loss = val_running_loss/len(val_loader)\n",
        "\n",
        "      v_accuracy = accuracy_score(Y, v_classified.argmax(dim=1))\n",
        "      val_accuracy.append(v_accuracy)\n",
        "      val_acc = sum(val_accuracy)/len(val_accuracy)\n",
        "\n",
        "  dic['latent_space'].append(torch.cat(z_list))\n",
        "  dic['mu_list'].append(torch.cat(means))\n",
        "  dic['logsig2_list'].append(torch.cat(logvars))\n",
        "  dic['y'].append(torch.cat(labels_list))\n",
        "\n",
        "  print(f\"Epoch: {epoch+1} / {num_epochs} | Reconst_loss: {reconstruction_loss:.3f} | Kldiv loss: {kld_loss:.3f} | Classifcation loss: {classification_loss:.3f} | Constrast loss: {contrastive_loss:.2f} | Triplet loss: {triplet_loss:.3f} | Total loss: {train_loss:.3f} | Train acc: {train_acc*100:.3f} % ||| Val Loss: {val_loss:.3f} | Val acc: {val_acc*100:.3f} %\")\n",
        "  print(\"-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\")\n",
        "  train_losses.append(train_loss)\n",
        "  val_losses.append(val_loss)\n",
        "\n",
        "# Close the SummaryWriter\n",
        "writer.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mu-g_vKRS7V8"
      },
      "outputs": [],
      "source": [
        "torch.save(model.state_dict(), 'VAE_Model.pt') # Save"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aa3Thi-cW05z"
      },
      "source": [
        "---\n",
        "Model Evaluations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OSD621NES9gA"
      },
      "outputs": [],
      "source": [
        "plt.plot(train_losses,'-o', label=\"Training loss\")\n",
        "plt.plot(val_losses,'-r',  label=\"Validation loss\")\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('losses')\n",
        "plt.title('Training and Validation Losses')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MhYdRnwjW7SS"
      },
      "source": [
        "---\n",
        "Latent Space Visualization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jRW82C1HTAkI"
      },
      "outputs": [],
      "source": [
        "print(\"Latent Space Visualization\")\n",
        "for i in range (num_epochs):\n",
        "  fig = plt.figure(figsize=(12,12))\n",
        "  z_arr = dic['latent_space'][i].cpu().numpy()\n",
        "  y_arr = dic['y'][i].cpu().numpy()\n",
        "\n",
        "  #Experiment 1\n",
        "  plt.scatter(z_arr[:,0], z_arr[:,1], c = y_arr, edgecolor='none', alpha=0.5,\n",
        "              cmap=plt.cm.get_cmap('gist_rainbow', num_classes))\n",
        "  cb = plt.colorbar(ticks=[1,2,3,4,5,6,7,8,9,10,11,12],values=[1,2,3,4,5,6,7,8,9,10,11,12])\n",
        "  #Experiment 3\n",
        "  # plt.scatter(z_arr[:,0], z_arr[:,1], c = y_arr, edgecolor='none', alpha=0.5,\n",
        "  #             cmap=plt.cm.get_cmap('hsv', 23))\n",
        "  #cb = plt.colorbar(ticks=[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23],values=[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23])\n",
        "  cb.ax.tick_params(labelsize=10)\n",
        "  # plt.xlim(-5, 5)\n",
        "  # plt.ylim(-5, 5)\n",
        "  plt.xticks(fontsize= 10)\n",
        "  plt.yticks(fontsize= 10)\n",
        "  plt.xlabel('z[0]', fontsize= 10)\n",
        "  plt.ylabel('z[1]', fontsize= 10)\n",
        "  plt.title(f'VAE train dataset with {input_dim} features| Acc: {train_acc*100:.1f}% | latent space Dim={latent_dim} | Epoch number: {i+1} ', fontsize= 12)\n",
        "  # plt.show()\n",
        "  plt.close()\n",
        "  fig.savefig(f\"/content/drive/MyDrive/WEAR_LAB/Research_Pytorch/VAE_Images/VAEtrain_images{i:001}\" + \".png\")\n",
        "  print(f\"Latent Space Image {i+1} stored.\")\n",
        "print()\n",
        "print(\"Latent Space Gif being created...\")\n",
        "print()\n",
        "\n",
        "import imageio\n",
        "gif = []\n",
        "for i in range(num_epochs):\n",
        "  each_image = imageio.imread(f\"/content/drive/MyDrive/WEAR_LAB/Research_Pytorch/VAE_Images/VAEtrain_images{i}\" + \".png\")# here read all images\n",
        "  gif.append(each_image)\n",
        "imageio.mimsave(f\"/content/Latent_Space_and_Number_Features_{input_dim}.gif\",gif)\n",
        "\n",
        "from IPython.display import Image\n",
        "\n",
        "fname = f'/content/Latent_Space_and_Number_Features_{input_dim}.gif'\n",
        "Image(open(fname, 'rb').read())  # local"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_yhSCW0l98lK"
      },
      "outputs": [],
      "source": [
        "%tensorboard --logdir=runs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sl7Bo_dsuqR7"
      },
      "source": [
        "---\n",
        "Test\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sgihLGe_urdt",
        "outputId": "38047ad7-349d-458b-de3b-db8be24838af"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(130200, 19) <class 'pandas.core.frame.DataFrame'> (130200, 1) <class 'pandas.core.frame.DataFrame'>\n",
            "\n",
            "(85969, 19) <class 'numpy.ndarray'> (85969, 1) <class 'numpy.ndarray'>\n",
            "\n",
            "X_train size: 51581 | X_val size: 17194 | X_test size: 17194\n",
            "y_train size: 51581 | y_val size: 17194 | y_test size: 17194\n",
            "\n",
            "Training Feature Split: (51581, 19) | Training Labels (51581, 1)\n",
            "Validation Feature Split: (17194, 19) | Validation Labels (17194, 1)\n",
            "Testing Feature Split: (17194, 19) | Testing Labels (17194, 1)\n",
            "\n",
            "X_train: <class 'torch.Tensor'> | y_train <class 'torch.Tensor'>\n",
            "X_val: <class 'torch.Tensor'> | y_train <class 'torch.Tensor'>\n",
            "X_test: <class 'torch.Tensor'> | y_test <class 'torch.Tensor'>\n",
            "\n",
            "Training: torch.Size([51581, 19]) , torch.Size([51581, 1])\n",
            "Validation: torch.Size([17194, 19]) , torch.Size([17194, 1])\n",
            "Testing:  torch.Size([17194, 19]) , torch.Size([17194, 1])\n",
            "\n",
            "VAE(\n",
            "  (fc1): Linear(in_features=19, out_features=9, bias=True)\n",
            "  (mu): Linear(in_features=9, out_features=2, bias=True)\n",
            "  (logvar): Linear(in_features=9, out_features=2, bias=True)\n",
            "  (fc3): Linear(in_features=2, out_features=9, bias=True)\n",
            "  (fc4): Linear(in_features=9, out_features=19, bias=True)\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=2, out_features=13, bias=True)\n",
            "    (1): Sigmoid()\n",
            "    (2): Softmax(dim=1)\n",
            "  )\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "import torch   \n",
        "import torch.nn as nn                          \n",
        "import torch.nn.functional as F                \n",
        "import torch.optim as optim   \n",
        "from torch.utils.data import TensorDataset, Dataset, DataLoader\n",
        "from torch.autograd import Variable\n",
        "import torch.utils.data\n",
        "\n",
        "import pandas as pd \n",
        "import numpy as np\n",
        "import os                             \n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns    \n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import preprocessing\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import accuracy_score, roc_auc_score, f1_score, precision_score, recall_score\n",
        "from sklearn.manifold import TSNE\n",
        "from sklearn.decomposition import PCA, TruncatedSVD\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "df = pd.read_csv(\"/content/drive/MyDrive/WEAR_LAB/Research_Pytorch/S1_E1_A1_v6.csv\")\n",
        "\n",
        "X = df.drop('stimulus', axis=1)\n",
        "#y = df['stimulus']\n",
        "y = df.iloc[:, 0:1]\n",
        "print(X.shape, type(X), y.shape, type(y))\n",
        "print()\n",
        "\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "\n",
        "sampling_strategy = \"not minority\"\n",
        "rus = RandomUnderSampler(sampling_strategy=sampling_strategy)\n",
        "X_res, y_res = rus.fit_resample(X, y)\n",
        "\n",
        "X = X_res.values\n",
        "y = y_res.values\n",
        "print(X.shape, type(X), y.shape, type(y))\n",
        "print()\n",
        "\n",
        "# Data Split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.25, random_state=42) # 0.25 x 0.8 = 0.2\n",
        "\n",
        "print(f\"X_train size: {len(X_train)} | X_val size: {len(X_val)} | X_test size: {len(X_test)}\")\n",
        "print(f\"y_train size: {len(y_train)} | y_val size: {len(y_val)} | y_test size: {len(y_test)}\")\n",
        "print()\n",
        "print(f\"Training Feature Split: {X_train.shape} | Training Labels { y_train.shape}\")\n",
        "print(f\"Validation Feature Split: {X_val.shape} | Validation Labels { y_val.shape}\")\n",
        "print(f\"Testing Feature Split: {X_test.shape} | Testing Labels { y_test.shape}\")\n",
        "print()\n",
        "\n",
        "#Normalization Data \n",
        "Minmax = preprocessing.MinMaxScaler()\n",
        "#Standardized = preprocessing.StandardScaler()\n",
        "X_train_Minmax= Minmax.fit_transform(X_train)\n",
        "X_val_Minmax = Minmax.transform(X_val)\n",
        "X_test_Minmax = Minmax.transform(X_test)\n",
        "\n",
        "#Convert to numpy then to torch \n",
        "\n",
        "X_train = torch.from_numpy(X_train_Minmax).float()\n",
        "y_train = torch.from_numpy(y_train).long()\n",
        "\n",
        "X_val = torch.from_numpy(X_val_Minmax).float()\n",
        "y_val = torch.from_numpy(y_val).long()\n",
        "\n",
        "X_test = torch.from_numpy(X_test_Minmax).float()\n",
        "y_test = torch.from_numpy(y_test).long()\n",
        "\n",
        "print(f\"X_train: {type(X_train)} | y_train {type(y_train)}\")\n",
        "print(f\"X_val: {type(X_val)} | y_train {type(y_val)}\")\n",
        "print(f\"X_test: {type(X_test)} | y_test {type(y_test)}\")\n",
        "print()\n",
        "print(f\"Training: {X_train.shape} , { y_train.shape}\")\n",
        "print(f\"Validation: {X_val.shape} , { y_val.shape}\")\n",
        "print(f\"Testing:  {X_test.shape} , { y_test.shape}\")\n",
        "print()\n",
        "\n",
        "class ClassifierDataset(Dataset):\n",
        "    def __init__(self, X_data, y_data):\n",
        "        self.X_data = X_data\n",
        "        self.y_data = y_data\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        return self.X_data[index], self.y_data[index]\n",
        "\n",
        "    def __len__ (self):\n",
        "        return len(self.X_data)\n",
        "\n",
        "training = ClassifierDataset(X_train, y_train)\n",
        "validating = ClassifierDataset(X_val, y_val)\n",
        "testing = ClassifierDataset(X_test, y_test)\n",
        "\n",
        "##########################################################################################################################################################################################################\n",
        "#Hyperparameters\n",
        "latent_dim = 2\n",
        "input_dim= 19\n",
        "hidden_dim= 9\n",
        "output_dim = 19\n",
        "num_classes = 13\n",
        "\n",
        "num_epochs= 70\n",
        "batch_size= 100\n",
        "learning_rate= 0.001 #3e-4 #Karpathy constant\n",
        "\n",
        "\n",
        "#beta = 1\n",
        "beta = 0.005\n",
        "alpha = 1\n",
        "#############################################################################################################################################################################################################\n",
        "\n",
        "train_loader = DataLoader(training, batch_size=batch_size, shuffle=True)\n",
        "val_loader = DataLoader(validating, batch_size=batch_size, shuffle=False)\n",
        "test_loader = DataLoader(testing, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "\n",
        "class VAE(nn.Module):  \n",
        "  def __init__(self, input_dim, hidden_dim, latent_dim):\n",
        "    super(VAE,self).__init__()  \n",
        "    self.fc1 = nn.Linear(input_dim, hidden_dim)  # no labels\n",
        "    self.mu = nn.Linear(hidden_dim, latent_dim)   # mu\n",
        "    self.logvar = nn.Linear(hidden_dim,latent_dim)   # log-var\n",
        "\n",
        "    self.fc3 = nn.Linear(latent_dim, hidden_dim) \n",
        "    self.fc4 = nn.Linear(hidden_dim, input_dim)\n",
        "    \n",
        "    self.classifier = nn.Sequential(\n",
        "        nn.Linear(latent_dim, 13),\n",
        "        nn.Sigmoid(),\n",
        "        nn.Softmax(dim=1)\n",
        "    )\n",
        "\n",
        "  def encode(self, x):     \n",
        "#    print(f'encoder {type(x)}')         \n",
        "    z = F.relu(self.fc1(x))\n",
        "    z = torch.tanh(z) \n",
        "    z1 = self.mu(z)               \n",
        "    z2 = self.logvar(z) \n",
        "    return z1, z2                 # (mu, log-var)\n",
        "\n",
        "  def decode(self, x):\n",
        "#    print(f'decoder {type(x)}')\n",
        "    z = F.relu(self.fc3(x))                    \n",
        "    z = torch.sigmoid(self.fc4(z))      # in [0, 1]\n",
        "    #print(f\"z: {z}\")\n",
        "    return z \n",
        "\n",
        "  def forward(self, x):\n",
        "#    print(f'forward {type(x)}')\n",
        "\n",
        "#  Reparamaterize\n",
        "    mu, logvar = self.encode(x)\n",
        "    stdev = torch.exp(0.5 * logvar)\n",
        "    esp = torch.randn_like(stdev)\n",
        "    z_reparmeterized = mu + (esp * stdev)   \n",
        "    #print(f\"z_reparmeterized : {z_reparmeterized}\")      \n",
        "    x_reconstructed = self.decode(z_reparmeterized)\n",
        "    #print(f\"x_reconstructed : {x_reconstructed}\")\n",
        "\n",
        "    classified = self.classifier(z_reparmeterized)\n",
        "\n",
        "    return (x_reconstructed, z_reparmeterized, classified, mu, logvar)\n",
        "\n",
        "model  = VAE(input_dim, hidden_dim, latent_dim).to(device)\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "print(model)\n",
        "loss_fn = nn.MSELoss(reduction=\"sum\")\n",
        "classifier_loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "train_losses=[]\n",
        "train_accuracy = []\n",
        "val_losses=[]\n",
        "\n",
        "dic = dict(latent_space = list(), mu_list=list(), logsig2_list=list(), y=list())\n",
        "for epoch in range(num_epochs):\n",
        "  model.train()\n",
        "  train_running_loss = 0\n",
        "\n",
        "  z_list, means, logvars , labels_list = list(), list(), list(), list()\n",
        "\n",
        "  for i, data in enumerate(train_loader):\n",
        "    inputs, labels = data\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    x_reconstructed, z_reparmeterized, classified, mu, logvar = model(inputs)\n",
        "\n",
        "    reconstruction_loss = loss_fn(x_reconstructed, inputs)\n",
        "    kld_loss = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
        "\n",
        "    classified = classified.view(-1, 13)\n",
        "    classification_loss = classifier_loss_fn(classified, labels.flatten())\n",
        "\n",
        "    loss = (alpha*reconstruction_loss + kld_loss*beta) + classification_loss\n",
        "\n",
        "    # correct = torch.eq(classified.argmax(dim=1), labels).float()\n",
        "    # classifcaiton_accuracy = correct.mean()\n",
        "\n",
        "    # Calculate classification accuracy\n",
        "    _, predicted = torch.max(classified, 1)\n",
        "    correct = (predicted == labels.flatten()).sum().item()\n",
        "    classifcaiton_accuracy = correct / len(predicted)\n",
        "\n",
        "\n",
        "\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    train_running_loss += loss.item()\n",
        "    train_loss= train_running_loss/len(train_loader)\n",
        "\n",
        "   # log ...\n",
        "    z_list.append(z_reparmeterized.detach())\n",
        "    means.append(mu.detach())\n",
        "    logvars.append(logvar.detach())\n",
        "    labels_list.append(labels.detach())\n",
        "\n",
        "  with torch.inference_mode():\n",
        "    val_running_loss = 0\n",
        "\n",
        "    model.eval()\n",
        "    for X, Y in val_loader:\n",
        "      y_pred, z_reparmeterized, v_classified, mu, logvar = model(X)\n",
        "      v_reconstruction_loss = loss_fn(y_pred, X)\n",
        "      v_kld_loss = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
        "\n",
        "      v_classified = v_classified.view(-1, 13)\n",
        "      v_classification_loss = classifier_loss_fn(v_classified, Y.flatten())\n",
        "\n",
        "      vloss = (alpha*reconstruction_loss + kld_loss*beta) + v_classification_loss\n",
        "\n",
        "      val_running_loss += vloss.item()\n",
        "      val_loss = val_running_loss/len(val_loader)\n",
        "\n",
        "\n",
        "  dic['latent_space'].append(torch.cat(z_list))\n",
        "  dic['mu_list'].append(torch.cat(means))\n",
        "  dic['logsig2_list'].append(torch.cat(logvars))\n",
        "  dic['y'].append(torch.cat(labels_list))\n",
        "\n",
        "  print(f\"Epoch: {epoch+1} / {num_epochs} | reconst_loss: {reconstruction_loss:.3f} | kldiv loss: {kld_loss:.5f} | classifcation loss: {classification_loss:.5f} | total loss: {train_loss:.3f} | train acc: {classifcaiton_accuracy:.3f} ||| Val Loss: {val_loss:.3f} | val acc: {val_acc:.3f}\")\n",
        "  print(\"------------------------------------------------------------------------------------------------------------------\")\n",
        "  #print(f\"Epoch: {epoch+1} / {num_epochs} | reconst_loss: {v_reconstruction_loss:.3f} | kldiv loss: {v_kld_loss:.3f} | Val Loss: {val_loss:.3f}\")\n",
        "  train_losses.append(train_loss)\n",
        "  val_losses.append(val_loss)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sTKEGQ-wqK-a"
      },
      "source": [
        "![image.png](data:image/png;base64,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)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "M8iJEJRDVWqt",
        "nXr0DgjjvCJa",
        "Sl7Bo_dsuqR7"
      ],
      "provenance": [],
      "mount_file_id": "1sYdXpamr7l4UMHLHXpOD1v4Hj_7WX5ou",
      "authorship_tag": "ABX9TyNFmZAm4GDcQNppZhj6y+Ys",
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}