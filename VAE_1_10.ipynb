{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Kcurr01/HUT_Research/blob/main/VAE_1_10.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M8iJEJRDVWqt"
      },
      "source": [
        "---\n",
        "Instalation \n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Du8slAkNSRBk",
        "outputId": "51584171-fa6b-4af1-8421-452e08f29945"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tensorboardX in /usr/local/lib/python3.8/dist-packages (2.5.1)\n",
            "Requirement already satisfied: protobuf<=3.20.1,>=3.8.0 in /usr/local/lib/python3.8/dist-packages (from tensorboardX) (3.19.6)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from tensorboardX) (1.21.6)\n"
          ]
        }
      ],
      "source": [
        "# !pip install captum\n",
        "# !pip install umap-learn\n",
        "# !pip install datashader\n",
        "# !pip install bokeh\n",
        "# !pip install holoviews\n",
        "!pip install tensorboardX"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nXr0DgjjvCJa"
      },
      "source": [
        "---\n",
        "VAE Initializaiton, Visualization and Training\n",
        "--- "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ATqtpHxlVJdO"
      },
      "outputs": [],
      "source": [
        "import torch   \n",
        "import torch.nn as nn                          \n",
        "import torch.nn.functional as F                \n",
        "import torch.optim as optim   \n",
        "from torch.utils.data import TensorDataset, Dataset, DataLoader\n",
        "from torch.autograd import Variable\n",
        "import torch.utils.data\n",
        "\n",
        "import pandas as pd \n",
        "import numpy as np\n",
        "import os                             \n",
        "\n",
        "# from captum.attr import LayerConductance, LayerActivation, LayerIntegratedGradients\n",
        "# from captum.attr import IntegratedGradients, DeepLift, GradientShap, NoiseTunnel, FeatureAblation\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns    \n",
        "# import plotly.offline as py\n",
        "# import plotly.graph_objs as go        \n",
        "                \n",
        "# from tqdm import tqdm\n",
        "\n",
        "# import umap\n",
        "# import umap.plot\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import preprocessing\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import accuracy_score, roc_auc_score, f1_score, precision_score, recall_score\n",
        "from sklearn.manifold import TSNE\n",
        "from sklearn.decomposition import PCA, TruncatedSVD\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "#based on sensor data can you determine the stimulus that is currently in use?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "msgUiu6VVLb2"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(\"/content/drive/MyDrive/WEAR_LAB/Research_Pytorch/S1_E1_A1_v6.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 305
        },
        "id": "1YWNrSbVhwqw",
        "outputId": "2fd0bfd7-af3a-43e8-e795-9f0c6571cca6"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-47cd4fe5-26b8-46e3-9811-6ec9139b0233\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>stimulus</th>\n",
              "      <th>Acc 1</th>\n",
              "      <th>Acc 2</th>\n",
              "      <th>Acc 3</th>\n",
              "      <th>EMG Channel 1</th>\n",
              "      <th>EMG Channel 2</th>\n",
              "      <th>EMG Channe 3</th>\n",
              "      <th>EMG Channel 4</th>\n",
              "      <th>EMG Channel 5</th>\n",
              "      <th>EMG Channel 6</th>\n",
              "      <th>EMG Channel 7</th>\n",
              "      <th>EMG Channel 8</th>\n",
              "      <th>EMG Channel 9</th>\n",
              "      <th>EMG Channel 10</th>\n",
              "      <th>EMG Channel 11</th>\n",
              "      <th>EMG Channel 12</th>\n",
              "      <th>EMG Channel 13</th>\n",
              "      <th>EMG Channel 14</th>\n",
              "      <th>EMG Channel 15</th>\n",
              "      <th>EMG Channel 16</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0.30176</td>\n",
              "      <td>0.78809</td>\n",
              "      <td>-0.66699</td>\n",
              "      <td>-22</td>\n",
              "      <td>-2</td>\n",
              "      <td>-16</td>\n",
              "      <td>-7</td>\n",
              "      <td>-3</td>\n",
              "      <td>-1</td>\n",
              "      <td>-2</td>\n",
              "      <td>-4</td>\n",
              "      <td>-2</td>\n",
              "      <td>-46</td>\n",
              "      <td>-49</td>\n",
              "      <td>-5</td>\n",
              "      <td>9</td>\n",
              "      <td>1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0.30176</td>\n",
              "      <td>0.78809</td>\n",
              "      <td>-0.66699</td>\n",
              "      <td>5</td>\n",
              "      <td>-4</td>\n",
              "      <td>-12</td>\n",
              "      <td>-3</td>\n",
              "      <td>8</td>\n",
              "      <td>25</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>-2</td>\n",
              "      <td>66</td>\n",
              "      <td>28</td>\n",
              "      <td>3</td>\n",
              "      <td>22</td>\n",
              "      <td>10</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0.30176</td>\n",
              "      <td>0.78809</td>\n",
              "      <td>-0.66699</td>\n",
              "      <td>-6</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>-1</td>\n",
              "      <td>-9</td>\n",
              "      <td>0</td>\n",
              "      <td>-10</td>\n",
              "      <td>-3</td>\n",
              "      <td>-9</td>\n",
              "      <td>-52</td>\n",
              "      <td>-24</td>\n",
              "      <td>-2</td>\n",
              "      <td>-52</td>\n",
              "      <td>-14</td>\n",
              "      <td>-24</td>\n",
              "      <td>-3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0.30176</td>\n",
              "      <td>0.78809</td>\n",
              "      <td>-0.66699</td>\n",
              "      <td>15</td>\n",
              "      <td>10</td>\n",
              "      <td>19</td>\n",
              "      <td>9</td>\n",
              "      <td>10</td>\n",
              "      <td>7</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>-4</td>\n",
              "      <td>-13</td>\n",
              "      <td>19</td>\n",
              "      <td>4</td>\n",
              "      <td>28</td>\n",
              "      <td>6</td>\n",
              "      <td>-5</td>\n",
              "      <td>-12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0.24609</td>\n",
              "      <td>0.73535</td>\n",
              "      <td>-0.66309</td>\n",
              "      <td>-1</td>\n",
              "      <td>-16</td>\n",
              "      <td>-17</td>\n",
              "      <td>0</td>\n",
              "      <td>-2</td>\n",
              "      <td>-7</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>-6</td>\n",
              "      <td>27</td>\n",
              "      <td>7</td>\n",
              "      <td>-1</td>\n",
              "      <td>-22</td>\n",
              "      <td>-2</td>\n",
              "      <td>-7</td>\n",
              "      <td>15</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-47cd4fe5-26b8-46e3-9811-6ec9139b0233')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-47cd4fe5-26b8-46e3-9811-6ec9139b0233 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-47cd4fe5-26b8-46e3-9811-6ec9139b0233');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "   stimulus    Acc 1    Acc 2    Acc 3  EMG Channel 1  EMG Channel 2  \\\n",
              "0         0  0.30176  0.78809 -0.66699            -22             -2   \n",
              "1         0  0.30176  0.78809 -0.66699              5             -4   \n",
              "2         0  0.30176  0.78809 -0.66699             -6              1   \n",
              "3         0  0.30176  0.78809 -0.66699             15             10   \n",
              "4         0  0.24609  0.73535 -0.66309             -1            -16   \n",
              "\n",
              "   EMG Channe 3  EMG Channel 4  EMG Channel 5  EMG Channel 6  EMG Channel 7  \\\n",
              "0           -16             -7             -3             -1             -2   \n",
              "1           -12             -3              8             25              1   \n",
              "2             4             -1             -9              0            -10   \n",
              "3            19              9             10              7              2   \n",
              "4           -17              0             -2             -7              2   \n",
              "\n",
              "   EMG Channel 8  EMG Channel 9  EMG Channel 10  EMG Channel 11  \\\n",
              "0             -4             -2             -46             -49   \n",
              "1              1             -2              66              28   \n",
              "2             -3             -9             -52             -24   \n",
              "3              1             -4             -13              19   \n",
              "4              0             -6              27               7   \n",
              "\n",
              "   EMG Channel 12  EMG Channel 13  EMG Channel 14  EMG Channel 15  \\\n",
              "0              -5               9               1              -1   \n",
              "1               3              22              10               2   \n",
              "2              -2             -52             -14             -24   \n",
              "3               4              28               6              -5   \n",
              "4              -1             -22              -2              -7   \n",
              "\n",
              "   EMG Channel 16  \n",
              "0              -2  \n",
              "1               1  \n",
              "2              -3  \n",
              "3             -12  \n",
              "4              15  "
            ]
          },
          "execution_count": 121,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#df = df.drop(columns=['series_id'])\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VLnkrC9o_CzK",
        "outputId": "a3f26ef8-21b4-4676-aabc-f270869e293e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "pandas.core.frame.DataFrame"
            ]
          },
          "execution_count": 122,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "type(df)\n",
        "#df.describe()\n",
        "#df.plot()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A6VzjKYRRBt7",
        "outputId": "407dedf5-5207-4846-f66b-5f4f970e8bae"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(130200, 19) <class 'pandas.core.frame.DataFrame'> (130200, 1) <class 'pandas.core.frame.DataFrame'>\n",
            "\n"
          ]
        }
      ],
      "source": [
        "X = df.iloc[:,1:]\n",
        "y = df.iloc[:, 0:1]\n",
        "print(X.shape, type(X), y.shape, type(y))\n",
        "print()\n",
        "#print(y.value_counts())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 305
        },
        "id": "RkM1pDIrRWqM",
        "outputId": "50765359-b2a4-4125-ad5a-8d1e499f680e"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-3172b9b3-d0b6-43c9-80f8-ee180ff2612c\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Acc 1</th>\n",
              "      <th>Acc 2</th>\n",
              "      <th>Acc 3</th>\n",
              "      <th>EMG Channel 1</th>\n",
              "      <th>EMG Channel 2</th>\n",
              "      <th>EMG Channe 3</th>\n",
              "      <th>EMG Channel 4</th>\n",
              "      <th>EMG Channel 5</th>\n",
              "      <th>EMG Channel 6</th>\n",
              "      <th>EMG Channel 7</th>\n",
              "      <th>EMG Channel 8</th>\n",
              "      <th>EMG Channel 9</th>\n",
              "      <th>EMG Channel 10</th>\n",
              "      <th>EMG Channel 11</th>\n",
              "      <th>EMG Channel 12</th>\n",
              "      <th>EMG Channel 13</th>\n",
              "      <th>EMG Channel 14</th>\n",
              "      <th>EMG Channel 15</th>\n",
              "      <th>EMG Channel 16</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.30176</td>\n",
              "      <td>0.78809</td>\n",
              "      <td>-0.66699</td>\n",
              "      <td>-22</td>\n",
              "      <td>-2</td>\n",
              "      <td>-16</td>\n",
              "      <td>-7</td>\n",
              "      <td>-3</td>\n",
              "      <td>-1</td>\n",
              "      <td>-2</td>\n",
              "      <td>-4</td>\n",
              "      <td>-2</td>\n",
              "      <td>-46</td>\n",
              "      <td>-49</td>\n",
              "      <td>-5</td>\n",
              "      <td>9</td>\n",
              "      <td>1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.30176</td>\n",
              "      <td>0.78809</td>\n",
              "      <td>-0.66699</td>\n",
              "      <td>5</td>\n",
              "      <td>-4</td>\n",
              "      <td>-12</td>\n",
              "      <td>-3</td>\n",
              "      <td>8</td>\n",
              "      <td>25</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>-2</td>\n",
              "      <td>66</td>\n",
              "      <td>28</td>\n",
              "      <td>3</td>\n",
              "      <td>22</td>\n",
              "      <td>10</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.30176</td>\n",
              "      <td>0.78809</td>\n",
              "      <td>-0.66699</td>\n",
              "      <td>-6</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>-1</td>\n",
              "      <td>-9</td>\n",
              "      <td>0</td>\n",
              "      <td>-10</td>\n",
              "      <td>-3</td>\n",
              "      <td>-9</td>\n",
              "      <td>-52</td>\n",
              "      <td>-24</td>\n",
              "      <td>-2</td>\n",
              "      <td>-52</td>\n",
              "      <td>-14</td>\n",
              "      <td>-24</td>\n",
              "      <td>-3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.30176</td>\n",
              "      <td>0.78809</td>\n",
              "      <td>-0.66699</td>\n",
              "      <td>15</td>\n",
              "      <td>10</td>\n",
              "      <td>19</td>\n",
              "      <td>9</td>\n",
              "      <td>10</td>\n",
              "      <td>7</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>-4</td>\n",
              "      <td>-13</td>\n",
              "      <td>19</td>\n",
              "      <td>4</td>\n",
              "      <td>28</td>\n",
              "      <td>6</td>\n",
              "      <td>-5</td>\n",
              "      <td>-12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.24609</td>\n",
              "      <td>0.73535</td>\n",
              "      <td>-0.66309</td>\n",
              "      <td>-1</td>\n",
              "      <td>-16</td>\n",
              "      <td>-17</td>\n",
              "      <td>0</td>\n",
              "      <td>-2</td>\n",
              "      <td>-7</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>-6</td>\n",
              "      <td>27</td>\n",
              "      <td>7</td>\n",
              "      <td>-1</td>\n",
              "      <td>-22</td>\n",
              "      <td>-2</td>\n",
              "      <td>-7</td>\n",
              "      <td>15</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3172b9b3-d0b6-43c9-80f8-ee180ff2612c')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-3172b9b3-d0b6-43c9-80f8-ee180ff2612c button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-3172b9b3-d0b6-43c9-80f8-ee180ff2612c');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "     Acc 1    Acc 2    Acc 3  EMG Channel 1  EMG Channel 2  EMG Channe 3  \\\n",
              "0  0.30176  0.78809 -0.66699            -22             -2           -16   \n",
              "1  0.30176  0.78809 -0.66699              5             -4           -12   \n",
              "2  0.30176  0.78809 -0.66699             -6              1             4   \n",
              "3  0.30176  0.78809 -0.66699             15             10            19   \n",
              "4  0.24609  0.73535 -0.66309             -1            -16           -17   \n",
              "\n",
              "   EMG Channel 4  EMG Channel 5  EMG Channel 6  EMG Channel 7  EMG Channel 8  \\\n",
              "0             -7             -3             -1             -2             -4   \n",
              "1             -3              8             25              1              1   \n",
              "2             -1             -9              0            -10             -3   \n",
              "3              9             10              7              2              1   \n",
              "4              0             -2             -7              2              0   \n",
              "\n",
              "   EMG Channel 9  EMG Channel 10  EMG Channel 11  EMG Channel 12  \\\n",
              "0             -2             -46             -49              -5   \n",
              "1             -2              66              28               3   \n",
              "2             -9             -52             -24              -2   \n",
              "3             -4             -13              19               4   \n",
              "4             -6              27               7              -1   \n",
              "\n",
              "   EMG Channel 13  EMG Channel 14  EMG Channel 15  EMG Channel 16  \n",
              "0               9               1              -1              -2  \n",
              "1              22              10               2               1  \n",
              "2             -52             -14             -24              -3  \n",
              "3              28               6              -5             -12  \n",
              "4             -22              -2              -7              15  "
            ]
          },
          "execution_count": 124,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "6XIsEYVmRloI",
        "outputId": "42e29be5-e062-44b1-8e82-8d10c815d1a9"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-44e89443-b3cc-41f6-ae07-6bc93ff183d5\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>stimulus</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-44e89443-b3cc-41f6-ae07-6bc93ff183d5')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-44e89443-b3cc-41f6-ae07-6bc93ff183d5 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-44e89443-b3cc-41f6-ae07-6bc93ff183d5');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "   stimulus\n",
              "0         0\n",
              "1         0\n",
              "2         0\n",
              "3         0\n",
              "4         0"
            ]
          },
          "execution_count": 125,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IA8-K5g_qNvJ"
      },
      "source": [
        "---\n",
        "Visulaize number of lables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 534
        },
        "id": "6GZFlYtuh4g3",
        "outputId": "37e99769-2533-421e-906b-ed746a834ff9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0     49599\n",
              "8      6795\n",
              "5      6782\n",
              "6      6776\n",
              "7      6776\n",
              "11     6773\n",
              "1      6753\n",
              "12     6701\n",
              "10     6696\n",
              "2      6656\n",
              "4      6654\n",
              "9      6626\n",
              "3      6613\n",
              "Name: stimulus, dtype: int64"
            ]
          },
          "execution_count": 126,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZEAAAEGCAYAAACkQqisAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAWpklEQVR4nO3df7BfdX3n8efLRAR/IEFSioRt2DVjm7qtYgZjtY5ChYAW8AeObi1R0exU3NV1d1zUmVJ/sKOtq5Vq2WElEvxFUURSRSGL2K6dRQiKkIDKlR8lMZBIELSOWuC9f5xP9GtyL1zO/Z4bLnk+Zr5zz/mcz/fzPofk8sr5napCkqQ+HrW7V0CSNHcZIpKk3gwRSVJvhogkqTdDRJLU2/zdvQKz7YADDqjFixfv7tWQpDnj6quv/mFVLZxs2R4XIosXL2b9+vW7ezUkac5IcutUyzycJUnqzRCRJPVmiEiSejNEJEm9DRoiSW5Jcl2Sa5Ksb237J1mX5Mb2c0FrT5IzkkwkuTbJYSPjrGz9b0yycqT9mW38ifbdDLk9kqRfNxt7Ii+oqqdX1bI2fypwWVUtAS5r8wDHAEvaZxVwJnShA5wGPAs4HDhtR/C0Pm8Y+d6K4TdHkrTD7jicdTywpk2vAU4YaT+3OlcA+yU5CDgaWFdV26vqLmAdsKIt27eqrqjuUcTnjowlSZoFQ4dIAZcmuTrJqtZ2YFVtadO3Awe26YOB20a+u6m1PVD7pknad5FkVZL1SdZv27ZtJtsjSRox9M2Gz62qzUl+A1iX5DujC6uqkgz+QpOqOgs4C2DZsmW+QEWSxmTQEKmqze3n1iQX0p3TuCPJQVW1pR2S2tq6bwYOGfn6ota2GXj+Tu1fa+2LJuk/LdvO/ORD2pbpWPhnrx77mJL0cDbY4awkj0vyhB3TwFHABmAtsOMKq5XARW16LXBSu0prOXB3O+x1CXBUkgXthPpRwCVt2T1Jlrersk4aGUuSNAuG3BM5ELiwXXU7H/h0VX0lyVXA+UlOBm4FXtH6XwwcC0wAPwVeC1BV25O8B7iq9Xt3VW1v028EzgH2Ab7cPpKkWTJYiFTVTcDvT9J+J3DkJO0FnDLFWKuB1ZO0rweeNuOVlST14h3rkqTeDBFJUm+GiCSpN0NEktSbISJJ6s0QkST1ZohIknozRCRJvRkikqTeDBFJUm+GiCSpN0NEktSbISJJ6s0QkST1ZohIknozRCRJvRkikqTeDBFJUm+GiCSpN0NEktSbISJJ6s0QkST1ZohIknozRCRJvRkikqTeDBFJUm+GiCSpN0NEktSbISJJ6s0QkST1ZohIknozRCRJvRkikqTeBg+RJPOSfCvJF9v8oUm+kWQiyd8l2au1P6bNT7Tli0fGeHtr/26So0faV7S2iSSnDr0tkqRfNxt7Im8GbhiZfz/woap6CnAXcHJrPxm4q7V/qPUjyVLglcDvAiuAv23BNA/4KHAMsBR4VesrSZolg4ZIkkXAi4CPtfkARwCfa13WACe06ePbPG35ka3/8cB5VfXzqroZmAAOb5+Jqrqpqn4BnNf6SpJmydB7In8NvA24v80/CfhRVd3b5jcBB7fpg4HbANryu1v/X7bv9J2p2neRZFWS9UnWb9u2babbJElqBguRJC8GtlbV1UPVmK6qOquqllXVsoULF+7u1ZGkR4z5A479HOC4JMcCewP7Ah8G9ksyv+1tLAI2t/6bgUOATUnmA08E7hxp32H0O1O1S5JmwWB7IlX19qpaVFWL6U6Mf7Wq/gS4HHh567YSuKhNr23ztOVfrapq7a9sV28dCiwBrgSuApa0q732ajXWDrU9kqRdDbknMpX/DpyX5L3At4CzW/vZwCeSTADb6UKBqtqY5HzgeuBe4JSqug8gyZuAS4B5wOqq2jirWyJJe7hZCZGq+hrwtTZ9E92VVTv3+Rlw4hTfPx04fZL2i4GLx7iqkqSHwDvWJUm9GSKSpN4MEUlSb4aIJKk3Q0SS1JshIknqzRCRJPVmiEiSejNEJEm9GSKSpN4MEUlSb4aIJKk3Q0SS1JshIknqzRCRJPVmiEiSejNEJEm9GSKSpN4MEUlSb4aIJKk3Q0SS1JshIknqzRCRJPVmiEiSejNEJEm9GSKSpN4MEUlSb4aIJKk3Q0SS1JshIknqzRCRJPVmiEiSehssRJLsneTKJN9OsjHJu1r7oUm+kWQiyd8l2au1P6bNT7Tli0fGentr/26So0faV7S2iSSnDrUtkqTJDbkn8nPgiKr6feDpwIoky4H3Ax+qqqcAdwEnt/4nA3e19g+1fiRZCrwS+F1gBfC3SeYlmQd8FDgGWAq8qvWVJM2SwUKkOj9ps49unwKOAD7X2tcAJ7Tp49s8bfmRSdLaz6uqn1fVzcAEcHj7TFTVTVX1C+C81leSNEsGPSfS9hiuAbYC64DvAz+qqntbl03AwW36YOA2gLb8buBJo+07fWeqdknSLBk0RKrqvqp6OrCIbs/ht4esN5Ukq5KsT7J+27Ztu2MVJOkRaVauzqqqHwGXA88G9ksyvy1aBGxu05uBQwDa8icCd4627/Sdqdonq39WVS2rqmULFy4cyzZJkoa9Omthkv3a9D7AC4Eb6MLk5a3bSuCiNr22zdOWf7WqqrW/sl29dSiwBLgSuApY0q722ovu5PvaobZHkrSr+Q/epbeDgDXtKqpHAedX1ReTXA+cl+S9wLeAs1v/s4FPJJkAttOFAlW1Mcn5wPXAvcApVXUfQJI3AZcA84DVVbVxwO2RJO1ksBCpqmuBZ0zSfhPd+ZGd238GnDjFWKcDp0/SfjFw8YxXVpLUy7QOZyW5bDptkqQ9ywPuiSTZG3gscECSBUDaon3xclpJ2uM92OGs/wi8BXgycDW/CpF7gI8MuF6SpDngAUOkqj4MfDjJf6qqv5mldZIkzRHTOrFeVX+T5A+AxaPfqapzB1ovSdIcMK0QSfIJ4N8B1wD3teYCDBFJ2oNN9xLfZcDSdvOfJEnA9O9Y3wD85pArIkmae6a7J3IAcH2SK+neEwJAVR03yFpJkuaE6YbIXwy5EpKkuWm6V2f9w9ArIkmae6Z7ddaP6a7GAtiL7i2F/1JV+w61YpKkh7/p7ok8Ycf0yCtrlw+1UpKkueEhv0+kvTv9C8DRA6yPJGkOme7hrJeOzD6K7r6Rnw2yRpKkOWO6V2f98cj0vcAtdIe0JEl7sOmeE3nt0CsiSZp7pvtSqkVJLkyytX0uSLJo6JWTJD28TffE+seBtXTvFXky8PetTZK0B5tuiCysqo9X1b3tcw6wcMD1kiTNAdMNkTuTvDrJvPZ5NXDnkCsmSXr4m26IvA54BXA7sAV4OfCagdZJkjRHTPcS33cDK6vqLoAk+wMfoAsXSdIearp7Ir+3I0AAqmo78IxhVkmSNFdMN0QelWTBjpm2JzLdvRhJ0iPUdIPgfwL/L8ln2/yJwOnDrJIkaa6Y7h3r5yZZDxzRml5aVdcPt1qSpLlg2oekWmgYHJKkX3rIj4KXJGkHQ0SS1JshIknqzRCRJPVmiEiSehssRJIckuTyJNcn2Zjkza19/yTrktzYfi5o7UlyRpKJJNcmOWxkrJWt/41JVo60PzPJde07ZyTJUNsjSdrVkHsi9wL/taqWAsuBU5IsBU4FLquqJcBlbR7gGGBJ+6wCzoRf3h1/GvAs4HDgtJG7588E3jDyvRUDbo8kaSeDhUhVbamqb7bpHwM3AAfTvZt9Teu2BjihTR8PnFudK4D9khwEHA2sq6rt7fld64AVbdm+VXVFVRVw7shYkqRZMCvnRJIspntg4zeAA6tqS1t0O3Bgmz4YuG3ka5ta2wO1b5qkfbL6q5KsT7J+27ZtM9oWSdKvDB4iSR4PXAC8paruGV3W9iBq6HWoqrOqallVLVu40BcyStK4DBoiSR5NFyCfqqrPt+Y72qEo2s+trX0zcMjI1xe1tgdqXzRJuyRplgx5dVaAs4EbquqDI4vWAjuusFoJXDTSflK7Sms5cHc77HUJcFSSBe2E+lHAJW3ZPUmWt1onjYwlSZoFQ74T5DnAnwLXJbmmtb0DeB9wfpKTgVvpXrsLcDFwLDAB/BR4LXQvwEryHuCq1u/d7aVYAG8EzgH2Ab7cPpKkWTJYiFTV14Gp7ts4cpL+BZwyxVirgdWTtK8HnjaD1ZQkzYB3rEuSejNEJEm9GSKSpN4MEUlSb4aIJKk3Q0SS1JshIknqzRCRJPVmiEiSejNEJEm9GSKSpN4MEUlSb4aIJKk3Q0SS1JshIknqzRCRJPVmiEiSejNEJEm9GSKSpN4MEUlSb4aIJKk3Q0SS1JshIknqzRCRJPVmiEiSejNEJEm9GSKSpN4MEUlSb4aIJKk3Q0SS1JshIknqzRCRJPVmiEiSehssRJKsTrI1yYaRtv2TrEtyY/u5oLUnyRlJJpJcm+Swke+sbP1vTLJypP2ZSa5r3zkjSYbaFknS5IbcEzkHWLFT26nAZVW1BLiszQMcAyxpn1XAmdCFDnAa8CzgcOC0HcHT+rxh5Hs715IkDWywEKmqfwS279R8PLCmTa8BThhpP7c6VwD7JTkIOBpYV1Xbq+ouYB2woi3bt6quqKoCzh0ZS5I0S2b7nMiBVbWlTd8OHNimDwZuG+m3qbU9UPumSdonlWRVkvVJ1m/btm1mWyBJ+qXddmK97UHULNU6q6qWVdWyhQsXzkZJSdojzHaI3NEORdF+bm3tm4FDRvotam0P1L5oknZJ0iya7RBZC+y4wmolcNFI+0ntKq3lwN3tsNclwFFJFrQT6kcBl7Rl9yRZ3q7KOmlkLEnSLJk/1MBJPgM8HzggySa6q6zeB5yf5GTgVuAVrfvFwLHABPBT4LUAVbU9yXuAq1q/d1fVjpP1b6S7Amwf4MvtI0maRYOFSFW9aopFR07St4BTphhnNbB6kvb1wNNmso6SpJnxjnVJUm+GiCSpN0NEktSbISJJ6s0QkST1ZohIknozRCRJvQ12n4j0cHfsF94x9jEvPuF/jH3Mh5OXXXDl2Me84GWHj31MzR5DZGCbPvK6sY+56E273HvJ5R970VhrvOD1X9ql7Zw1R421BsBrVl66S9s7Pzv+V8OcfuJXxj7mdL3ogv891vG+9LI37NL2x5+7cKw1AP7+5S8Z+5jT9cELbx/7mG99yW/u0va1T473qd7Pf/WuD3jd8pdbJuk5Mwe97aBd2u444+tjr3Pgf37ug/bxcJYkqTdDRJLUmyEiSerNEJEk9WaISJJ6M0QkSb0ZIpKk3gwRSVJvhogkqTdDRJLUmyEiSerNEJEk9WaISJJ6M0QkSb0ZIpKk3gwRSVJvhogkqTdDRJLUmyEiSerNEJEk9WaISJJ6M0QkSb0ZIpKk3gwRSVJvcz5EkqxI8t0kE0lO3d3rI0l7kjkdIknmAR8FjgGWAq9KsnT3rpUk7TnmdIgAhwMTVXVTVf0COA84fjevkyTtMVJVu3sdekvycmBFVb2+zf8p8KyqetNO/VYBq9rsU4HvPoQyBwA/HMPqWmdu1rDOw7eGdWavxm9V1cLJFsyf+fo8/FXVWcBZfb6bZH1VLRvzKllnjtSwzsO3hnUeHjXm+uGszcAhI/OLWpskaRbM9RC5CliS5NAkewGvBNbu5nWSpD3GnD6cVVX3JnkTcAkwD1hdVRvHXKbXYTDrzEqdR9K2PNLqPJK25ZFWZ6w15vSJdUnS7jXXD2dJknYjQ0SS1Jsh8gBm45EqSVYn2ZpkwxDjj9Q5JMnlSa5PsjHJmweosXeSK5N8u9V417hr7FRvXpJvJfnigDVuSXJdkmuSrB+wzn5JPpfkO0luSPLsMY//1LYNOz73JHnLOGuM1Pov7c9/Q5LPJNl7oDpvbjU2jnNbJvudTLJ/knVJbmw/FwxQ48S2LfcnGcsluFPU+av29+zaJBcm2W9GRarKzyQfuhP13wf+LbAX8G1g6QB1ngccBmwYeHsOAg5r008Avjfu7QECPL5NPxr4BrB8wG16K/Bp4IsD1rgFOGDIP5tWZw3w+ja9F7DfgLXmAbfT3UA27rEPBm4G9mnz5wOvGaDO04ANwGPpLhD6P8BTxjT2Lr+TwF8Cp7bpU4H3D1Djd+huhv4asGzAbTkKmN+m3z/TbXFPZGqz8kiVqvpHYPu4x52kzpaq+mab/jFwA90v/DhrVFX9pM0+un0GuXIjySLgRcDHhhh/NiV5It0v+9kAVfWLqvrRgCWPBL5fVbcONP58YJ8k8+n+J/+DAWr8DvCNqvppVd0L/APw0nEMPMXv5PF0QU/7ecK4a1TVDVX1UJ6m0bfOpe2/GcAVdPfX9WaITO1g4LaR+U2M+X+6u0uSxcAz6PYUxj32vCTXAFuBdVU19hrNXwNvA+4faPwdCrg0ydXt8TlDOBTYBny8HZ77WJLHDVQLuvupPjPEwFW1GfgA8M/AFuDuqrp0gFIbgD9M8qQkjwWO5ddvPB63A6tqS5u+HThwwFqz6XXAl2cygCGyh0nyeOAC4C1Vdc+4x6+q+6rq6XT/ujk8ydPGXSPJi4GtVXX1uMeexHOr6jC6J0WfkuR5A9SYT3fI4cyqegbwL3SHTMau3ZR7HPDZgcZfQPev9kOBJwOPS/LqcdepqhvoDsVcCnwFuAa4b9x1pqhdDLSHPZuSvBO4F/jUTMYxRKb2iHukSpJH0wXIp6rq80PWaodjLgdWDDD8c4DjktxCd5jxiCSfHKDOjn9ZU1VbgQvpDnOO2yZg08he2+foQmUIxwDfrKo7Bhr/j4Cbq2pbVf0r8HngD4YoVFVnV9Uzq+p5wF105/mGckeSgwDaz60D1hpcktcALwb+pIVib4bI1B5Rj1RJErpj7jdU1QcHqrFwx5UeSfYBXgh8Z9x1qurtVbWoqhbT/bl8tarG/q/dJI9L8oQd03QnJMd+FV1V3Q7cluSprelI4Ppx12lexUCHspp/BpYneWz7O3ck3fm3sUvyG+3nv6E7H/LpIeo0a4GVbXolcNGAtQaVZAXdoeDjquqnMx5wHFcAPFI/dMdZv0d3ldY7B6rxGbpjx/9K9y/Skweq81y6XfBr6Xb9rwGOHXON3wO+1WpsAP58Fv6Mns9AV2fRXZn37fbZONTfgVbr6cD69t/uC8CCAWo8DrgTeOLAfybvovvHwwbgE8BjBqrzf+nC9tvAkWMcd5ffSeBJwGXAjXRXgu0/QI2XtOmfA3cAlwy0LRN053t3/H/gf82kho89kST15uEsSVJvhogkqTdDRJLUmyEiSerNEJEk9WaISGOS5C3tERw75i+e8RNSfzXWTx68lzT7vMRXGpN2B/2yqvrhAGP/pKoeP+5xpZlyT0Tqod3N/qX27pQNSU6je1bU5Ukub31uSXJAksXt/Q3nJPlekk8l+aMk/9TeT3F46/8XSf7bSI0N7WGZo3WfP/r+lCQfaY+wIMn70r0v5tokHxj8P4JE9+A3SQ/dCuAHVfUi+OXj3F8LvGCKPZGnACfSPTX1KuA/0D1F4DjgHczw0eJJnkR3x/NvV1WN6zCa9GDcE5H6uQ54YZL3J/nDqrr7QfrfXFXXVdX9dI9Quay6Y8nXAYvHsD53Az8Dzk7yUmDmz0SSpsEQkXqoqu/RPWn3OuC9Sf78Qb7y85Hp+0fm7+dXRwTu5dd/Jyd7reykfap7ydDhdE8AfjHd49GlwXk4S+ohyZOB7VX1ySQ/Al4P/Jju1cN9T6zfQhcAJDmM7p0cO7sVWJrkMcA+dE/J/Xp7T8xjq+riJP8E3NRzHaSHxBCR+vn3wF8luZ/uCal/Bjwb+EqSH1TVC3qMeQFwUpKNdG+d3OX9GFV1W5Lz6Z6QezPdU5OhC6+LkuxN9677t/aoLz1kXuIrSerNcyKSpN4MEUlSb4aIJKk3Q0SS1JshIknqzRCRJPVmiEiSevv/LmJjH9vCkUoAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "sns.countplot(x = 'stimulus', data=df)\n",
        "df.loc[:,'stimulus'].value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SpiqlKfjqDhy"
      },
      "source": [
        "---\n",
        "Visualize Data Disturbutions\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5sGkzQcdlBZ5"
      },
      "outputs": [],
      "source": [
        "# #distribution of first 19 features\n",
        "\n",
        "\n",
        "# fig, axs = plt.subplots(nrows=5, ncols=4, figsize=(40, 40))\n",
        "# axs = axs.flatten()\n",
        "# index = 0\n",
        "# for k, v in df.items():\n",
        "#   print(f\"[{index +1}] Updating plot\")\n",
        "#   sns.distplot(v, ax=axs[index])\n",
        "#   index += 1\n",
        "#   if index == 20:\n",
        "#     break \n",
        "# plt.tight_layout()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UJ6JhVncSg-a",
        "outputId": "a7e7adbd-e375-429d-9ffc-a2a5f857d181"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(130200, 19) <class 'numpy.ndarray'> (130200, 1) <class 'numpy.ndarray'>\n",
            "\n",
            "X_train size: 78120 | X_val size: 26040 | X_test size: 26040\n",
            "y_train size: 78120 | y_val size: 26040 | y_test size: 26040\n",
            "\n",
            "Training Feature Split: (78120, 19) | Training Labels (78120, 1)\n",
            "Validation Feature Split: (26040, 19) | Validation Labels (26040, 1)\n",
            "Testing Feature Split: (26040, 19) | Testing Labels (26040, 1)\n",
            "\n",
            "X_train: <class 'torch.Tensor'> | y_train <class 'torch.Tensor'>\n",
            "X_val: <class 'torch.Tensor'> | y_train <class 'torch.Tensor'>\n",
            "X_test: <class 'torch.Tensor'> | y_test <class 'torch.Tensor'>\n",
            "\n",
            "Training: torch.Size([78120, 19]) , torch.Size([78120, 1])\n",
            "Validation: torch.Size([26040, 19]) , torch.Size([26040, 1])\n",
            "Testing:  torch.Size([26040, 19]) , torch.Size([26040, 1])\n"
          ]
        }
      ],
      "source": [
        "X = df.iloc[:,1:].values\n",
        "y = df.iloc[:, 0:1].values\n",
        "print(X.shape, type(X), y.shape, type(y))\n",
        "print()\n",
        "\n",
        "# Data Split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.25, random_state=42) # 0.25 x 0.8 = 0.2\n",
        "\n",
        "print(f\"X_train size: {len(X_train)} | X_val size: {len(X_val)} | X_test size: {len(X_test)}\")\n",
        "print(f\"y_train size: {len(y_train)} | y_val size: {len(y_val)} | y_test size: {len(y_test)}\")\n",
        "print()\n",
        "print(f\"Training Feature Split: {X_train.shape} | Training Labels { y_train.shape}\")\n",
        "print(f\"Validation Feature Split: {X_val.shape} | Validation Labels { y_val.shape}\")\n",
        "print(f\"Testing Feature Split: {X_test.shape} | Testing Labels { y_test.shape}\")\n",
        "print()\n",
        "\n",
        "#Normalization Data \n",
        "Minmax = preprocessing.MinMaxScaler()\n",
        "#Standardized = preprocessing.StandardScaler()\n",
        "X_train_Minmax= Minmax.fit_transform(X_train)\n",
        "X_val_Minmax = Minmax.transform(X_val)\n",
        "X_test_Minmax = Minmax.transform(X_test)\n",
        "\n",
        "#Convert to numpy then to torch \n",
        "\n",
        "X_train = torch.from_numpy(X_train_Minmax).float()\n",
        "y_train = torch.from_numpy(y_train).float()\n",
        "\n",
        "X_val = torch.from_numpy(X_val_Minmax).float()\n",
        "y_val = torch.from_numpy(y_val).float()\n",
        "\n",
        "X_test = torch.from_numpy(X_test_Minmax).float()\n",
        "y_test = torch.from_numpy(y_test).float()\n",
        "\n",
        "print(f\"X_train: {type(X_train)} | y_train {type(y_train)}\")\n",
        "print(f\"X_val: {type(X_val)} | y_train {type(y_val)}\")\n",
        "print(f\"X_test: {type(X_test)} | y_test {type(y_test)}\")\n",
        "print()\n",
        "print(f\"Training: {X_train.shape} , { y_train.shape}\")\n",
        "print(f\"Validation: {X_val.shape} , { y_val.shape}\")\n",
        "print(f\"Testing:  {X_test.shape} , { y_test.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y7rZppwdVzdJ"
      },
      "outputs": [],
      "source": [
        "class ClassifierDataset(Dataset):\n",
        "    def __init__(self, X_data, y_data):\n",
        "        self.X_data = X_data\n",
        "        self.y_data = y_data\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        return self.X_data[index], self.y_data[index]\n",
        "\n",
        "    def __len__ (self):\n",
        "        return len(self.X_data)\n",
        "\n",
        "training = ClassifierDataset(X_train, y_train)\n",
        "validating = ClassifierDataset(X_val, y_val)\n",
        "testing = ClassifierDataset(X_test, y_test)\n",
        "\n",
        "##########################################################################################################################################################################################################\n",
        "#############################################################################################################################################################################################################\n",
        "\n",
        "#Hyperparameters\n",
        "latent_dim = 2\n",
        "input_dim= 19\n",
        "hidden_dim= 9\n",
        "output_dim = 19\n",
        "num_classes = 13\n",
        "\n",
        "num_epochs= 100\n",
        "batch_size= 100\n",
        "learning_rate= 0.0001 #3e-4 #Karpathy constant\n",
        "\n",
        "\n",
        "#beta = 1\n",
        "beta = 0.001\n",
        "alpha = 1\n",
        "\n",
        "#############################################################################################################################################################################################################\n",
        "#############################################################################################################################################################################################################\n",
        "\n",
        "train_loader = DataLoader(training, batch_size=batch_size, shuffle=True)\n",
        "val_loader = DataLoader(validating, batch_size=batch_size, shuffle=False)\n",
        "test_loader = DataLoader(testing, batch_size=batch_size, shuffle=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2UbXfasD8HQn",
        "outputId": "ea75c393-aeec-4689-bdc2-ea5d35e2a359"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([100, 19])\n",
            "torch.Size([100, 2])\n",
            "torch.Size([100, 2])\n",
            "torch.Size([100, 2])\n",
            "torch.Size([100, 13])\n"
          ]
        }
      ],
      "source": [
        "class VAE(nn.Module):  \n",
        "  def __init__(self, input_dim, hidden_dim, latent_dim):\n",
        "    super(VAE,self).__init__()  \n",
        "    self.fc1 = nn.Linear(input_dim, hidden_dim)  # no labels\n",
        "    self.mu = nn.Linear(hidden_dim, latent_dim)   # mu\n",
        "    self.logvar = nn.Linear(hidden_dim,latent_dim)   # log-var\n",
        "\n",
        "    self.fc3 = nn.Linear(latent_dim, hidden_dim) \n",
        "    self.fc4 = nn.Linear(hidden_dim, input_dim)\n",
        "    \n",
        "    self.classifier = nn.Sequential(\n",
        "        nn.Linear(latent_dim, 13),\n",
        "        nn.Sigmoid(),\n",
        "        nn.Softmax(dim=1)\n",
        "    )\n",
        "\n",
        "  def encode(self, x):     \n",
        "#    print(f'encoder {type(x)}')         \n",
        "    z = F.relu(self.fc1(x))\n",
        "    z = torch.tanh(z) \n",
        "    z1 = self.mu(z)               \n",
        "    z2 = self.logvar(z) \n",
        "    return z1, z2                 # (mu, log-var)\n",
        "\n",
        "  def decode(self, x):\n",
        "#    print(f'decoder {type(x)}')\n",
        "    z = F.relu(self.fc3(x))                    \n",
        "    z = torch.sigmoid(self.fc4(z))      # in [0, 1]\n",
        "    #print(f\"z: {z}\")\n",
        "    return z \n",
        "\n",
        "  def forward(self, x):\n",
        "#    print(f'forward {type(x)}')\n",
        "\n",
        "#  Reparamaterize\n",
        "    mu, logvar = self.encode(x)\n",
        "    stdev = torch.exp(0.5 * logvar)\n",
        "    esp = torch.randn_like(stdev)\n",
        "    z_reparmeterized = mu + (esp * stdev)   \n",
        "    #print(f\"z_reparmeterized : {z_reparmeterized}\")      \n",
        "    x_reconstructed = self.decode(z_reparmeterized)\n",
        "    #print(f\"x_reconstructed : {x_reconstructed}\")\n",
        "\n",
        "    classified = self.classifier(z_reparmeterized)\n",
        "\n",
        "    return (x_reconstructed, z_reparmeterized, classified, mu, logvar)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "  x = torch.rand(batch_size,input_dim)\n",
        "  vae = VAE(input_dim, hidden_dim, latent_dim)\n",
        "  x_reconstructed, z_reparmeterized, classified, mu, logvar = vae(x)\n",
        "  print(x_reconstructed.shape)\n",
        "  print(mu.shape)\n",
        "  print(logvar.shape)\n",
        "  print(z_reparmeterized.shape)\n",
        "  print(classified.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-UoGJdYPZONI",
        "outputId": "f5b27490-5d7b-4aa8-aff4-b300273506dd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "VAE(\n",
            "  (fc1): Linear(in_features=19, out_features=9, bias=True)\n",
            "  (mu): Linear(in_features=9, out_features=2, bias=True)\n",
            "  (logvar): Linear(in_features=9, out_features=2, bias=True)\n",
            "  (fc3): Linear(in_features=2, out_features=9, bias=True)\n",
            "  (fc4): Linear(in_features=9, out_features=19, bias=True)\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=2, out_features=13, bias=True)\n",
            "    (1): Sigmoid()\n",
            "    (2): Softmax(dim=1)\n",
            "  )\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "model  = VAE(input_dim, hidden_dim, latent_dim).to(device)\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "print(model)\n",
        "loss_fn = nn.MSELoss(reduction=\"sum\")\n",
        "classifier_loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "def accuracy(y_pred, y_act):\n",
        "  y_pred = torch.round(y_pred)\n",
        "  correct = (y_pred == y_act)\n",
        "  acc1 = correct.sum()/len(correct)\n",
        "  acc2 = torch.round(acc1*100)\n",
        "  # print(f\"z_pred: {y_pred} | lable: {y_act} | correct: {correct} | accuracy {acc1} | accuracy {acc2}\")\n",
        "  return acc2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YyxFhL0SXN-_",
        "outputId": "950c75ae-fed5-4d38-bc91-12cd3cac8d08"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 1 / 200 | reconst_loss: 3.104 | kldiv loss: 8.09943 | total loss: 24.054 | train acc: 495.662 ||| Val Loss: 16.296 | val acc: 0.000\n",
            "------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 2 / 200 | reconst_loss: 1.574 | kldiv loss: 24.58802 | total loss: 12.769 | train acc: 495.662 ||| Val Loss: 10.124 | val acc: 0.000\n",
            "------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 3 / 200 | reconst_loss: 0.801 | kldiv loss: 45.93206 | total loss: 8.234 | train acc: 495.463 ||| Val Loss: 6.572 | val acc: 0.000\n",
            "------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 4 / 200 | reconst_loss: 0.830 | kldiv loss: 72.12294 | total loss: 5.349 | train acc: 495.529 ||| Val Loss: 4.502 | val acc: 0.000\n",
            "------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 5 / 200 | reconst_loss: 0.522 | kldiv loss: 93.06513 | total loss: 4.108 | train acc: 495.529 ||| Val Loss: 3.924 | val acc: 0.000\n",
            "------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 6 / 200 | reconst_loss: 0.691 | kldiv loss: 104.21429 | total loss: 3.840 | train acc: 495.064 ||| Val Loss: 3.840 | val acc: 0.000\n",
            "------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 7 / 200 | reconst_loss: 0.595 | kldiv loss: 109.26250 | total loss: 3.799 | train acc: 495.529 ||| Val Loss: 3.823 | val acc: 0.000\n",
            "------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 8 / 200 | reconst_loss: 0.607 | kldiv loss: 112.11343 | total loss: 3.781 | train acc: 495.529 ||| Val Loss: 3.798 | val acc: 0.000\n",
            "------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 9 / 200 | reconst_loss: 0.274 | kldiv loss: 114.97272 | total loss: 3.765 | train acc: 495.662 ||| Val Loss: 3.784 | val acc: 0.000\n",
            "------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 10 / 200 | reconst_loss: 1.492 | kldiv loss: 116.55564 | total loss: 3.749 | train acc: 495.330 ||| Val Loss: 3.773 | val acc: 0.000\n",
            "------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 11 / 200 | reconst_loss: 0.819 | kldiv loss: 115.79742 | total loss: 3.733 | train acc: 495.396 ||| Val Loss: 3.753 | val acc: 0.000\n",
            "------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 12 / 200 | reconst_loss: 0.403 | kldiv loss: 111.90889 | total loss: 3.719 | train acc: 495.662 ||| Val Loss: 3.740 | val acc: 0.000\n",
            "------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 13 / 200 | reconst_loss: 0.705 | kldiv loss: 103.41063 | total loss: 3.698 | train acc: 495.662 ||| Val Loss: 3.708 | val acc: 0.000\n",
            "------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 14 / 200 | reconst_loss: 0.709 | kldiv loss: 90.96264 | total loss: 3.663 | train acc: 495.330 ||| Val Loss: 3.670 | val acc: 0.000\n",
            "------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 15 / 200 | reconst_loss: 0.452 | kldiv loss: 78.40666 | total loss: 3.619 | train acc: 495.529 ||| Val Loss: 3.617 | val acc: 0.000\n",
            "------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 16 / 200 | reconst_loss: 1.203 | kldiv loss: 69.69981 | total loss: 3.564 | train acc: 495.529 ||| Val Loss: 3.556 | val acc: 0.000\n",
            "------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 17 / 200 | reconst_loss: 0.554 | kldiv loss: 63.74577 | total loss: 3.497 | train acc: 495.396 ||| Val Loss: 3.483 | val acc: 0.000\n",
            "------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 18 / 200 | reconst_loss: 0.430 | kldiv loss: 56.12208 | total loss: 3.405 | train acc: 495.596 ||| Val Loss: 3.361 | val acc: 0.000\n",
            "------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 19 / 200 | reconst_loss: 0.619 | kldiv loss: 68.11777 | total loss: 3.227 | train acc: 495.463 ||| Val Loss: 3.159 | val acc: 0.000\n",
            "------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 20 / 200 | reconst_loss: 0.749 | kldiv loss: 83.03758 | total loss: 3.083 | train acc: 495.596 ||| Val Loss: 3.056 | val acc: 0.000\n",
            "------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 21 / 200 | reconst_loss: 0.280 | kldiv loss: 78.99770 | total loss: 3.006 | train acc: 495.662 ||| Val Loss: 3.003 | val acc: 0.000\n",
            "------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 22 / 200 | reconst_loss: 0.293 | kldiv loss: 87.30567 | total loss: 2.970 | train acc: 495.795 ||| Val Loss: 2.977 | val acc: 0.000\n",
            "------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 23 / 200 | reconst_loss: 0.331 | kldiv loss: 96.38091 | total loss: 2.948 | train acc: 495.529 ||| Val Loss: 2.960 | val acc: 0.000\n",
            "------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 24 / 200 | reconst_loss: 0.604 | kldiv loss: 92.92609 | total loss: 2.934 | train acc: 495.396 ||| Val Loss: 2.949 | val acc: 0.000\n",
            "------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 25 / 200 | reconst_loss: 0.658 | kldiv loss: 99.55359 | total loss: 2.925 | train acc: 495.396 ||| Val Loss: 2.939 | val acc: 0.000\n",
            "------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 26 / 200 | reconst_loss: 0.702 | kldiv loss: 113.63976 | total loss: 2.917 | train acc: 495.596 ||| Val Loss: 2.932 | val acc: 0.000\n",
            "------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 27 / 200 | reconst_loss: 0.551 | kldiv loss: 97.64484 | total loss: 2.911 | train acc: 495.330 ||| Val Loss: 2.926 | val acc: 0.000\n",
            "------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 28 / 200 | reconst_loss: 1.006 | kldiv loss: 103.26349 | total loss: 2.905 | train acc: 495.197 ||| Val Loss: 2.920 | val acc: 0.000\n",
            "------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 29 / 200 | reconst_loss: 0.563 | kldiv loss: 102.70401 | total loss: 2.900 | train acc: 495.529 ||| Val Loss: 2.916 | val acc: 0.000\n",
            "------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 30 / 200 | reconst_loss: 0.481 | kldiv loss: 99.59195 | total loss: 2.897 | train acc: 495.263 ||| Val Loss: 2.913 | val acc: 0.000\n",
            "------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 31 / 200 | reconst_loss: 0.651 | kldiv loss: 98.29823 | total loss: 2.893 | train acc: 495.263 ||| Val Loss: 2.909 | val acc: 0.000\n",
            "------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 32 / 200 | reconst_loss: 0.480 | kldiv loss: 97.67671 | total loss: 2.890 | train acc: 495.596 ||| Val Loss: 2.906 | val acc: 0.000\n",
            "------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 33 / 200 | reconst_loss: 0.834 | kldiv loss: 95.61042 | total loss: 2.887 | train acc: 495.463 ||| Val Loss: 2.903 | val acc: 0.000\n",
            "------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 34 / 200 | reconst_loss: 0.809 | kldiv loss: 100.08225 | total loss: 2.885 | train acc: 495.596 ||| Val Loss: 2.902 | val acc: 0.000\n",
            "------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 35 / 200 | reconst_loss: 0.140 | kldiv loss: 96.12631 | total loss: 2.883 | train acc: 495.729 ||| Val Loss: 2.899 | val acc: 0.000\n",
            "------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 36 / 200 | reconst_loss: 0.650 | kldiv loss: 103.84365 | total loss: 2.881 | train acc: 495.662 ||| Val Loss: 2.897 | val acc: 0.000\n",
            "------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 37 / 200 | reconst_loss: 0.509 | kldiv loss: 105.86162 | total loss: 2.879 | train acc: 495.463 ||| Val Loss: 2.895 | val acc: 0.000\n",
            "------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 38 / 200 | reconst_loss: 0.444 | kldiv loss: 91.69939 | total loss: 2.878 | train acc: 495.396 ||| Val Loss: 2.894 | val acc: 0.000\n",
            "------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 39 / 200 | reconst_loss: 0.550 | kldiv loss: 90.71125 | total loss: 2.876 | train acc: 495.529 ||| Val Loss: 2.893 | val acc: 0.000\n",
            "------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 40 / 200 | reconst_loss: 0.194 | kldiv loss: 87.55217 | total loss: 2.874 | train acc: 495.662 ||| Val Loss: 2.889 | val acc: 0.000\n",
            "------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 41 / 200 | reconst_loss: 0.728 | kldiv loss: 90.97185 | total loss: 2.873 | train acc: 495.596 ||| Val Loss: 2.889 | val acc: 0.000\n",
            "------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 42 / 200 | reconst_loss: 0.637 | kldiv loss: 91.90107 | total loss: 2.871 | train acc: 495.396 ||| Val Loss: 2.888 | val acc: 0.000\n",
            "------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 43 / 200 | reconst_loss: 0.578 | kldiv loss: 92.64964 | total loss: 2.869 | train acc: 495.463 ||| Val Loss: 2.886 | val acc: 0.000\n",
            "------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 44 / 200 | reconst_loss: 0.873 | kldiv loss: 85.84353 | total loss: 2.868 | train acc: 495.463 ||| Val Loss: 2.885 | val acc: 0.000\n",
            "------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 45 / 200 | reconst_loss: 0.984 | kldiv loss: 86.80672 | total loss: 2.867 | train acc: 495.463 ||| Val Loss: 2.883 | val acc: 0.000\n",
            "------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 46 / 200 | reconst_loss: 0.304 | kldiv loss: 87.70580 | total loss: 2.866 | train acc: 495.729 ||| Val Loss: 2.883 | val acc: 0.000\n",
            "------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 47 / 200 | reconst_loss: 0.315 | kldiv loss: 87.29476 | total loss: 2.865 | train acc: 495.529 ||| Val Loss: 2.882 | val acc: 0.000\n",
            "------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 48 / 200 | reconst_loss: 0.392 | kldiv loss: 86.65052 | total loss: 2.864 | train acc: 495.263 ||| Val Loss: 2.880 | val acc: 0.000\n",
            "------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 49 / 200 | reconst_loss: 0.554 | kldiv loss: 84.93972 | total loss: 2.863 | train acc: 495.463 ||| Val Loss: 2.879 | val acc: 0.000\n",
            "------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 50 / 200 | reconst_loss: 0.546 | kldiv loss: 81.21242 | total loss: 2.862 | train acc: 495.795 ||| Val Loss: 2.877 | val acc: 0.000\n",
            "------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 51 / 200 | reconst_loss: 0.534 | kldiv loss: 88.47079 | total loss: 2.861 | train acc: 495.330 ||| Val Loss: 2.878 | val acc: 0.000\n",
            "------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 52 / 200 | reconst_loss: 0.888 | kldiv loss: 82.65987 | total loss: 2.860 | train acc: 495.197 ||| Val Loss: 2.876 | val acc: 0.000\n",
            "------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 53 / 200 | reconst_loss: 0.357 | kldiv loss: 84.74307 | total loss: 2.858 | train acc: 495.396 ||| Val Loss: 2.872 | val acc: 0.000\n",
            "------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 54 / 200 | reconst_loss: 0.496 | kldiv loss: 83.46922 | total loss: 2.855 | train acc: 495.596 ||| Val Loss: 2.871 | val acc: 0.000\n",
            "------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 55 / 200 | reconst_loss: 0.625 | kldiv loss: 81.53780 | total loss: 2.853 | train acc: 495.529 ||| Val Loss: 2.866 | val acc: 0.000\n",
            "------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 56 / 200 | reconst_loss: 0.383 | kldiv loss: 81.05933 | total loss: 2.847 | train acc: 495.596 ||| Val Loss: 2.860 | val acc: 0.000\n",
            "------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 57 / 200 | reconst_loss: 0.499 | kldiv loss: 84.16245 | total loss: 2.840 | train acc: 495.463 ||| Val Loss: 2.852 | val acc: 0.000\n",
            "------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 58 / 200 | reconst_loss: 0.536 | kldiv loss: 84.94994 | total loss: 2.832 | train acc: 495.396 ||| Val Loss: 2.844 | val acc: 0.000\n",
            "------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 59 / 200 | reconst_loss: 0.927 | kldiv loss: 82.41914 | total loss: 2.823 | train acc: 495.529 ||| Val Loss: 2.834 | val acc: 0.000\n",
            "------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 60 / 200 | reconst_loss: 0.664 | kldiv loss: 85.95744 | total loss: 2.816 | train acc: 495.596 ||| Val Loss: 2.829 | val acc: 0.000\n",
            "------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 61 / 200 | reconst_loss: 0.758 | kldiv loss: 85.19289 | total loss: 2.808 | train acc: 495.263 ||| Val Loss: 2.819 | val acc: 0.000\n",
            "------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 62 / 200 | reconst_loss: 0.717 | kldiv loss: 90.54928 | total loss: 2.800 | train acc: 495.197 ||| Val Loss: 2.811 | val acc: 0.000\n",
            "------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 63 / 200 | reconst_loss: 0.456 | kldiv loss: 88.14705 | total loss: 2.791 | train acc: 495.396 ||| Val Loss: 2.803 | val acc: 0.000\n",
            "------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 64 / 200 | reconst_loss: 0.974 | kldiv loss: 92.06771 | total loss: 2.782 | train acc: 495.330 ||| Val Loss: 2.793 | val acc: 0.000\n",
            "------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 65 / 200 | reconst_loss: 0.554 | kldiv loss: 92.17776 | total loss: 2.772 | train acc: 495.596 ||| Val Loss: 2.779 | val acc: 0.000\n",
            "------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 66 / 200 | reconst_loss: 0.304 | kldiv loss: 94.58048 | total loss: 2.762 | train acc: 495.529 ||| Val Loss: 2.769 | val acc: 0.000\n",
            "------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 67 / 200 | reconst_loss: 0.390 | kldiv loss: 97.33337 | total loss: 2.749 | train acc: 495.529 ||| Val Loss: 2.755 | val acc: 0.000\n",
            "------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 68 / 200 | reconst_loss: 0.614 | kldiv loss: 96.83952 | total loss: 2.735 | train acc: 495.596 ||| Val Loss: 2.739 | val acc: 0.000\n",
            "------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 69 / 200 | reconst_loss: 0.225 | kldiv loss: 101.70627 | total loss: 2.717 | train acc: 495.662 ||| Val Loss: 2.716 | val acc: 0.000\n",
            "------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 70 / 200 | reconst_loss: 0.456 | kldiv loss: 99.46258 | total loss: 2.693 | train acc: 495.263 ||| Val Loss: 2.688 | val acc: 0.000\n",
            "------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 71 / 200 | reconst_loss: 0.341 | kldiv loss: 102.97295 | total loss: 2.660 | train acc: 495.529 ||| Val Loss: 2.647 | val acc: 0.000\n",
            "------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 72 / 200 | reconst_loss: 0.555 | kldiv loss: 105.28322 | total loss: 2.608 | train acc: 495.330 ||| Val Loss: 2.580 | val acc: 0.000\n",
            "------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 73 / 200 | reconst_loss: 0.641 | kldiv loss: 107.32375 | total loss: 2.539 | train acc: 495.396 ||| Val Loss: 2.500 | val acc: 0.000\n",
            "------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 74 / 200 | reconst_loss: 0.300 | kldiv loss: 111.42205 | total loss: 2.466 | train acc: 495.729 ||| Val Loss: 2.432 | val acc: 0.000\n",
            "------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 75 / 200 | reconst_loss: 0.284 | kldiv loss: 118.67467 | total loss: 2.414 | train acc: 495.463 ||| Val Loss: 2.390 | val acc: 0.000\n",
            "------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 76 / 200 | reconst_loss: 0.218 | kldiv loss: 124.25983 | total loss: 2.383 | train acc: 495.463 ||| Val Loss: 2.368 | val acc: 0.000\n",
            "------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 77 / 200 | reconst_loss: 0.424 | kldiv loss: 129.46614 | total loss: 2.366 | train acc: 495.596 ||| Val Loss: 2.354 | val acc: 0.000\n",
            "------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 78 / 200 | reconst_loss: 0.184 | kldiv loss: 127.46015 | total loss: 2.356 | train acc: 495.596 ||| Val Loss: 2.346 | val acc: 0.000\n",
            "------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 79 / 200 | reconst_loss: 0.382 | kldiv loss: 134.41998 | total loss: 2.348 | train acc: 495.596 ||| Val Loss: 2.339 | val acc: 0.000\n",
            "------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 80 / 200 | reconst_loss: 0.458 | kldiv loss: 140.69247 | total loss: 2.343 | train acc: 495.463 ||| Val Loss: 2.333 | val acc: 0.000\n",
            "------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 81 / 200 | reconst_loss: 0.426 | kldiv loss: 141.71429 | total loss: 2.338 | train acc: 495.463 ||| Val Loss: 2.329 | val acc: 0.000\n",
            "------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 82 / 200 | reconst_loss: 0.878 | kldiv loss: 136.84758 | total loss: 2.334 | train acc: 495.662 ||| Val Loss: 2.325 | val acc: 0.000\n",
            "------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 83 / 200 | reconst_loss: 0.370 | kldiv loss: 137.24780 | total loss: 2.330 | train acc: 495.263 ||| Val Loss: 2.322 | val acc: 0.000\n",
            "------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 84 / 200 | reconst_loss: 0.447 | kldiv loss: 138.06320 | total loss: 2.328 | train acc: 495.529 ||| Val Loss: 2.319 | val acc: 0.000\n",
            "------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 85 / 200 | reconst_loss: 0.395 | kldiv loss: 138.50546 | total loss: 2.324 | train acc: 495.529 ||| Val Loss: 2.316 | val acc: 0.000\n",
            "------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 86 / 200 | reconst_loss: 0.450 | kldiv loss: 140.78322 | total loss: 2.322 | train acc: 495.529 ||| Val Loss: 2.313 | val acc: 0.000\n",
            "------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 87 / 200 | reconst_loss: 0.443 | kldiv loss: 141.70337 | total loss: 2.319 | train acc: 495.330 ||| Val Loss: 2.310 | val acc: 0.000\n",
            "------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 88 / 200 | reconst_loss: 0.355 | kldiv loss: 144.15953 | total loss: 2.316 | train acc: 495.396 ||| Val Loss: 2.307 | val acc: 0.000\n",
            "------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 89 / 200 | reconst_loss: 0.234 | kldiv loss: 138.76797 | total loss: 2.313 | train acc: 495.662 ||| Val Loss: 2.304 | val acc: 0.000\n",
            "------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 90 / 200 | reconst_loss: 0.426 | kldiv loss: 141.67303 | total loss: 2.310 | train acc: 495.463 ||| Val Loss: 2.301 | val acc: 0.000\n",
            "------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 91 / 200 | reconst_loss: 0.497 | kldiv loss: 143.16444 | total loss: 2.307 | train acc: 495.463 ||| Val Loss: 2.299 | val acc: 0.000\n",
            "------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 92 / 200 | reconst_loss: 0.577 | kldiv loss: 142.43713 | total loss: 2.305 | train acc: 495.330 ||| Val Loss: 2.295 | val acc: 0.000\n",
            "------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 93 / 200 | reconst_loss: 0.674 | kldiv loss: 142.08473 | total loss: 2.302 | train acc: 495.596 ||| Val Loss: 2.292 | val acc: 0.000\n",
            "------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 94 / 200 | reconst_loss: 0.199 | kldiv loss: 138.32359 | total loss: 2.299 | train acc: 495.795 ||| Val Loss: 2.290 | val acc: 0.000\n",
            "------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 95 / 200 | reconst_loss: 0.387 | kldiv loss: 142.88745 | total loss: 2.296 | train acc: 495.529 ||| Val Loss: 2.287 | val acc: 0.000\n",
            "------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 96 / 200 | reconst_loss: 0.710 | kldiv loss: 141.31351 | total loss: 2.293 | train acc: 495.529 ||| Val Loss: 2.283 | val acc: 0.000\n",
            "------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 97 / 200 | reconst_loss: 0.345 | kldiv loss: 138.75523 | total loss: 2.290 | train acc: 495.263 ||| Val Loss: 2.281 | val acc: 0.000\n",
            "------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 98 / 200 | reconst_loss: 0.551 | kldiv loss: 142.23102 | total loss: 2.287 | train acc: 495.330 ||| Val Loss: 2.278 | val acc: 0.000\n",
            "------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 99 / 200 | reconst_loss: 0.334 | kldiv loss: 142.68607 | total loss: 2.285 | train acc: 495.330 ||| Val Loss: 2.275 | val acc: 0.000\n",
            "------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 100 / 200 | reconst_loss: 0.425 | kldiv loss: 142.15259 | total loss: 2.282 | train acc: 495.130 ||| Val Loss: 2.273 | val acc: 0.000\n",
            "------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 101 / 200 | reconst_loss: 0.476 | kldiv loss: 138.59444 | total loss: 2.279 | train acc: 495.662 ||| Val Loss: 2.270 | val acc: 0.000\n",
            "------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 102 / 200 | reconst_loss: 0.304 | kldiv loss: 143.63240 | total loss: 2.276 | train acc: 495.529 ||| Val Loss: 2.267 | val acc: 0.000\n",
            "------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 103 / 200 | reconst_loss: 0.458 | kldiv loss: 142.77678 | total loss: 2.274 | train acc: 495.529 ||| Val Loss: 2.264 | val acc: 0.000\n",
            "------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 104 / 200 | reconst_loss: 0.333 | kldiv loss: 139.75171 | total loss: 2.271 | train acc: 495.729 ||| Val Loss: 2.261 | val acc: 0.000\n",
            "------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 105 / 200 | reconst_loss: 0.529 | kldiv loss: 135.37242 | total loss: 2.267 | train acc: 495.463 ||| Val Loss: 2.258 | val acc: 0.000\n",
            "------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 106 / 200 | reconst_loss: 0.510 | kldiv loss: 138.07037 | total loss: 2.265 | train acc: 495.263 ||| Val Loss: 2.255 | val acc: 0.000\n",
            "------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 107 / 200 | reconst_loss: 0.346 | kldiv loss: 138.51350 | total loss: 2.262 | train acc: 495.596 ||| Val Loss: 2.253 | val acc: 0.000\n",
            "------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 108 / 200 | reconst_loss: 0.378 | kldiv loss: 137.05701 | total loss: 2.259 | train acc: 495.529 ||| Val Loss: 2.249 | val acc: 0.000\n",
            "------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 109 / 200 | reconst_loss: 0.423 | kldiv loss: 141.67096 | total loss: 2.255 | train acc: 495.662 ||| Val Loss: 2.246 | val acc: 0.000\n",
            "------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 110 / 200 | reconst_loss: 0.213 | kldiv loss: 133.02591 | total loss: 2.252 | train acc: 495.662 ||| Val Loss: 2.243 | val acc: 0.000\n",
            "------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 111 / 200 | reconst_loss: 0.765 | kldiv loss: 137.58653 | total loss: 2.248 | train acc: 495.529 ||| Val Loss: 2.239 | val acc: 0.000\n",
            "------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 112 / 200 | reconst_loss: 0.183 | kldiv loss: 136.33711 | total loss: 2.245 | train acc: 495.463 ||| Val Loss: 2.235 | val acc: 0.000\n",
            "------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 113 / 200 | reconst_loss: 0.370 | kldiv loss: 136.63336 | total loss: 2.240 | train acc: 495.529 ||| Val Loss: 2.230 | val acc: 0.000\n",
            "------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 114 / 200 | reconst_loss: 0.256 | kldiv loss: 137.76878 | total loss: 2.235 | train acc: 495.463 ||| Val Loss: 2.223 | val acc: 0.000\n",
            "------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 115 / 200 | reconst_loss: 0.441 | kldiv loss: 135.54190 | total loss: 2.227 | train acc: 495.396 ||| Val Loss: 2.216 | val acc: 0.000\n",
            "------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 116 / 200 | reconst_loss: 0.310 | kldiv loss: 138.14645 | total loss: 2.219 | train acc: 495.596 ||| Val Loss: 2.209 | val acc: 0.000\n",
            "------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 117 / 200 | reconst_loss: 0.496 | kldiv loss: 141.41751 | total loss: 2.213 | train acc: 495.529 ||| Val Loss: 2.203 | val acc: 0.000\n",
            "------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 118 / 200 | reconst_loss: 0.362 | kldiv loss: 138.36179 | total loss: 2.207 | train acc: 495.596 ||| Val Loss: 2.199 | val acc: 0.000\n",
            "------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 119 / 200 | reconst_loss: 0.378 | kldiv loss: 135.74316 | total loss: 2.203 | train acc: 495.463 ||| Val Loss: 2.195 | val acc: 0.000\n",
            "------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 120 / 200 | reconst_loss: 0.789 | kldiv loss: 139.33356 | total loss: 2.199 | train acc: 495.463 ||| Val Loss: 2.191 | val acc: 0.000\n",
            "------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 121 / 200 | reconst_loss: 0.444 | kldiv loss: 139.15549 | total loss: 2.195 | train acc: 495.529 ||| Val Loss: 2.188 | val acc: 0.000\n",
            "------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 122 / 200 | reconst_loss: 0.461 | kldiv loss: 136.81302 | total loss: 2.191 | train acc: 495.396 ||| Val Loss: 2.184 | val acc: 0.000\n",
            "------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 123 / 200 | reconst_loss: 0.328 | kldiv loss: 138.72522 | total loss: 2.188 | train acc: 495.529 ||| Val Loss: 2.182 | val acc: 0.000\n",
            "------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 124 / 200 | reconst_loss: 0.728 | kldiv loss: 138.23837 | total loss: 2.185 | train acc: 495.596 ||| Val Loss: 2.180 | val acc: 0.000\n",
            "------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 125 / 200 | reconst_loss: 0.269 | kldiv loss: 139.87233 | total loss: 2.182 | train acc: 495.596 ||| Val Loss: 2.176 | val acc: 0.000\n",
            "------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 126 / 200 | reconst_loss: 0.859 | kldiv loss: 139.52498 | total loss: 2.179 | train acc: 495.330 ||| Val Loss: 2.175 | val acc: 0.000\n",
            "------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 127 / 200 | reconst_loss: 0.240 | kldiv loss: 138.10016 | total loss: 2.177 | train acc: 495.729 ||| Val Loss: 2.173 | val acc: 0.000\n",
            "------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 128 / 200 | reconst_loss: 0.723 | kldiv loss: 138.32599 | total loss: 2.175 | train acc: 495.396 ||| Val Loss: 2.172 | val acc: 0.000\n",
            "------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 129 / 200 | reconst_loss: 0.757 | kldiv loss: 137.69806 | total loss: 2.172 | train acc: 495.396 ||| Val Loss: 2.169 | val acc: 0.000\n",
            "------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 130 / 200 | reconst_loss: 0.440 | kldiv loss: 140.82364 | total loss: 2.171 | train acc: 495.396 ||| Val Loss: 2.167 | val acc: 0.000\n",
            "------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 131 / 200 | reconst_loss: 0.303 | kldiv loss: 139.80075 | total loss: 2.169 | train acc: 495.396 ||| Val Loss: 2.165 | val acc: 0.000\n",
            "------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 132 / 200 | reconst_loss: 0.338 | kldiv loss: 138.98065 | total loss: 2.167 | train acc: 495.596 ||| Val Loss: 2.165 | val acc: 0.000\n",
            "------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 133 / 200 | reconst_loss: 0.440 | kldiv loss: 142.42451 | total loss: 2.165 | train acc: 495.263 ||| Val Loss: 2.163 | val acc: 0.000\n",
            "------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 134 / 200 | reconst_loss: 0.363 | kldiv loss: 140.51610 | total loss: 2.164 | train acc: 495.529 ||| Val Loss: 2.161 | val acc: 0.000\n",
            "------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 135 / 200 | reconst_loss: 0.439 | kldiv loss: 139.77367 | total loss: 2.162 | train acc: 495.729 ||| Val Loss: 2.161 | val acc: 0.000\n",
            "------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 136 / 200 | reconst_loss: 0.226 | kldiv loss: 138.70729 | total loss: 2.161 | train acc: 495.662 ||| Val Loss: 2.158 | val acc: 0.000\n",
            "------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 137 / 200 | reconst_loss: 0.438 | kldiv loss: 143.33315 | total loss: 2.159 | train acc: 495.463 ||| Val Loss: 2.158 | val acc: 0.000\n",
            "------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 138 / 200 | reconst_loss: 0.564 | kldiv loss: 139.66669 | total loss: 2.158 | train acc: 495.529 ||| Val Loss: 2.157 | val acc: 0.000\n",
            "------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 139 / 200 | reconst_loss: 0.287 | kldiv loss: 137.74664 | total loss: 2.157 | train acc: 495.596 ||| Val Loss: 2.156 | val acc: 0.000\n",
            "------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 140 / 200 | reconst_loss: 0.537 | kldiv loss: 141.22557 | total loss: 2.155 | train acc: 495.463 ||| Val Loss: 2.154 | val acc: 0.000\n",
            "------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 141 / 200 | reconst_loss: 0.228 | kldiv loss: 136.17451 | total loss: 2.155 | train acc: 495.596 ||| Val Loss: 2.154 | val acc: 0.000\n",
            "------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 142 / 200 | reconst_loss: 0.241 | kldiv loss: 140.77968 | total loss: 2.154 | train acc: 495.662 ||| Val Loss: 2.152 | val acc: 0.000\n",
            "------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 143 / 200 | reconst_loss: 0.395 | kldiv loss: 141.08438 | total loss: 2.153 | train acc: 495.396 ||| Val Loss: 2.153 | val acc: 0.000\n",
            "------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 144 / 200 | reconst_loss: 0.554 | kldiv loss: 137.74710 | total loss: 2.152 | train acc: 495.662 ||| Val Loss: 2.151 | val acc: 0.000\n",
            "------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 145 / 200 | reconst_loss: 0.138 | kldiv loss: 139.65088 | total loss: 2.151 | train acc: 495.795 ||| Val Loss: 2.151 | val acc: 0.000\n",
            "------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 146 / 200 | reconst_loss: 0.222 | kldiv loss: 139.42560 | total loss: 2.150 | train acc: 495.862 ||| Val Loss: 2.150 | val acc: 0.000\n",
            "------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 147 / 200 | reconst_loss: 0.520 | kldiv loss: 142.05502 | total loss: 2.149 | train acc: 495.330 ||| Val Loss: 2.149 | val acc: 0.000\n",
            "------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 148 / 200 | reconst_loss: 0.720 | kldiv loss: 142.25279 | total loss: 2.148 | train acc: 495.596 ||| Val Loss: 2.148 | val acc: 0.000\n",
            "------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 149 / 200 | reconst_loss: 0.449 | kldiv loss: 140.55119 | total loss: 2.147 | train acc: 495.529 ||| Val Loss: 2.147 | val acc: 0.000\n",
            "------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 150 / 200 | reconst_loss: 0.192 | kldiv loss: 139.12213 | total loss: 2.147 | train acc: 495.662 ||| Val Loss: 2.147 | val acc: 0.000\n",
            "------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 151 / 200 | reconst_loss: 0.397 | kldiv loss: 142.95383 | total loss: 2.146 | train acc: 495.330 ||| Val Loss: 2.146 | val acc: 0.000\n",
            "------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 152 / 200 | reconst_loss: 0.267 | kldiv loss: 139.48586 | total loss: 2.145 | train acc: 495.662 ||| Val Loss: 2.146 | val acc: 0.000\n",
            "------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 153 / 200 | reconst_loss: 0.411 | kldiv loss: 143.26620 | total loss: 2.145 | train acc: 495.463 ||| Val Loss: 2.145 | val acc: 0.000\n",
            "------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 154 / 200 | reconst_loss: 0.661 | kldiv loss: 139.94611 | total loss: 2.144 | train acc: 495.529 ||| Val Loss: 2.144 | val acc: 0.000\n",
            "------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 155 / 200 | reconst_loss: 0.221 | kldiv loss: 138.95024 | total loss: 2.143 | train acc: 495.662 ||| Val Loss: 2.143 | val acc: 0.000\n",
            "------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 156 / 200 | reconst_loss: 0.467 | kldiv loss: 144.52509 | total loss: 2.143 | train acc: 495.463 ||| Val Loss: 2.143 | val acc: 0.000\n",
            "------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 157 / 200 | reconst_loss: 0.511 | kldiv loss: 140.73705 | total loss: 2.142 | train acc: 495.729 ||| Val Loss: 2.143 | val acc: 0.000\n",
            "------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 158 / 200 | reconst_loss: 0.629 | kldiv loss: 142.47038 | total loss: 2.142 | train acc: 495.662 ||| Val Loss: 2.142 | val acc: 0.000\n",
            "------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 159 / 200 | reconst_loss: 0.543 | kldiv loss: 141.81943 | total loss: 2.141 | train acc: 495.396 ||| Val Loss: 2.142 | val acc: 0.000\n",
            "------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 160 / 200 | reconst_loss: 0.353 | kldiv loss: 142.64250 | total loss: 2.140 | train acc: 495.396 ||| Val Loss: 2.141 | val acc: 0.000\n",
            "------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 161 / 200 | reconst_loss: 0.501 | kldiv loss: 144.01517 | total loss: 2.140 | train acc: 495.396 ||| Val Loss: 2.141 | val acc: 0.000\n",
            "------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 162 / 200 | reconst_loss: 0.231 | kldiv loss: 141.36040 | total loss: 2.140 | train acc: 495.596 ||| Val Loss: 2.140 | val acc: 0.000\n",
            "------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 163 / 200 | reconst_loss: 0.556 | kldiv loss: 142.87250 | total loss: 2.139 | train acc: 495.729 ||| Val Loss: 2.140 | val acc: 0.000\n",
            "------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 164 / 200 | reconst_loss: 0.507 | kldiv loss: 142.77478 | total loss: 2.139 | train acc: 495.263 ||| Val Loss: 2.138 | val acc: 0.000\n",
            "------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 165 / 200 | reconst_loss: 0.233 | kldiv loss: 143.34138 | total loss: 2.138 | train acc: 495.596 ||| Val Loss: 2.139 | val acc: 0.000\n",
            "------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 166 / 200 | reconst_loss: 0.588 | kldiv loss: 141.44614 | total loss: 2.138 | train acc: 495.596 ||| Val Loss: 2.138 | val acc: 0.000\n",
            "------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 167 / 200 | reconst_loss: 0.653 | kldiv loss: 144.76392 | total loss: 2.137 | train acc: 495.662 ||| Val Loss: 2.138 | val acc: 0.000\n",
            "------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 168 / 200 | reconst_loss: 0.248 | kldiv loss: 144.06018 | total loss: 2.137 | train acc: 495.662 ||| Val Loss: 2.138 | val acc: 0.000\n",
            "------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 169 / 200 | reconst_loss: 0.218 | kldiv loss: 141.85510 | total loss: 2.136 | train acc: 495.729 ||| Val Loss: 2.137 | val acc: 0.000\n",
            "------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 170 / 200 | reconst_loss: 0.580 | kldiv loss: 144.07993 | total loss: 2.136 | train acc: 495.330 ||| Val Loss: 2.137 | val acc: 0.000\n",
            "------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 171 / 200 | reconst_loss: 0.101 | kldiv loss: 141.81564 | total loss: 2.136 | train acc: 495.662 ||| Val Loss: 2.137 | val acc: 0.000\n",
            "------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 172 / 200 | reconst_loss: 0.618 | kldiv loss: 141.49695 | total loss: 2.135 | train acc: 495.529 ||| Val Loss: 2.136 | val acc: 0.000\n",
            "------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 173 / 200 | reconst_loss: 0.359 | kldiv loss: 142.28528 | total loss: 2.135 | train acc: 495.396 ||| Val Loss: 2.135 | val acc: 0.000\n",
            "------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 174 / 200 | reconst_loss: 0.558 | kldiv loss: 142.59747 | total loss: 2.134 | train acc: 495.463 ||| Val Loss: 2.136 | val acc: 0.000\n",
            "------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 175 / 200 | reconst_loss: 0.511 | kldiv loss: 143.37726 | total loss: 2.134 | train acc: 495.396 ||| Val Loss: 2.137 | val acc: 0.000\n",
            "------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 176 / 200 | reconst_loss: 0.514 | kldiv loss: 145.01210 | total loss: 2.133 | train acc: 495.396 ||| Val Loss: 2.134 | val acc: 0.000\n",
            "------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 177 / 200 | reconst_loss: 0.440 | kldiv loss: 144.63976 | total loss: 2.133 | train acc: 495.396 ||| Val Loss: 2.134 | val acc: 0.000\n",
            "------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 178 / 200 | reconst_loss: 0.166 | kldiv loss: 141.72635 | total loss: 2.133 | train acc: 495.529 ||| Val Loss: 2.134 | val acc: 0.000\n",
            "------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 179 / 200 | reconst_loss: 0.267 | kldiv loss: 141.64264 | total loss: 2.132 | train acc: 495.529 ||| Val Loss: 2.133 | val acc: 0.000\n",
            "------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 180 / 200 | reconst_loss: 0.352 | kldiv loss: 141.72191 | total loss: 2.132 | train acc: 495.662 ||| Val Loss: 2.133 | val acc: 0.000\n",
            "------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 181 / 200 | reconst_loss: 0.550 | kldiv loss: 146.06058 | total loss: 2.132 | train acc: 495.263 ||| Val Loss: 2.132 | val acc: 0.000\n",
            "------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 182 / 200 | reconst_loss: 0.441 | kldiv loss: 145.87247 | total loss: 2.131 | train acc: 495.463 ||| Val Loss: 2.132 | val acc: 0.000\n",
            "------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 183 / 200 | reconst_loss: 0.324 | kldiv loss: 143.25087 | total loss: 2.131 | train acc: 495.396 ||| Val Loss: 2.132 | val acc: 0.000\n",
            "------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 184 / 200 | reconst_loss: 0.166 | kldiv loss: 143.33607 | total loss: 2.131 | train acc: 495.596 ||| Val Loss: 2.132 | val acc: 0.000\n",
            "------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 185 / 200 | reconst_loss: 0.274 | kldiv loss: 147.16003 | total loss: 2.130 | train acc: 495.596 ||| Val Loss: 2.132 | val acc: 0.000\n",
            "------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 186 / 200 | reconst_loss: 0.216 | kldiv loss: 140.36418 | total loss: 2.130 | train acc: 495.330 ||| Val Loss: 2.131 | val acc: 0.000\n",
            "------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 187 / 200 | reconst_loss: 0.321 | kldiv loss: 142.92627 | total loss: 2.129 | train acc: 495.662 ||| Val Loss: 2.130 | val acc: 0.000\n",
            "------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 188 / 200 | reconst_loss: 0.619 | kldiv loss: 142.10585 | total loss: 2.129 | train acc: 495.529 ||| Val Loss: 2.129 | val acc: 0.000\n",
            "------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 189 / 200 | reconst_loss: 0.514 | kldiv loss: 143.98102 | total loss: 2.129 | train acc: 495.596 ||| Val Loss: 2.130 | val acc: 0.000\n",
            "------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 190 / 200 | reconst_loss: 0.136 | kldiv loss: 143.34740 | total loss: 2.129 | train acc: 495.596 ||| Val Loss: 2.129 | val acc: 0.000\n",
            "------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 191 / 200 | reconst_loss: 0.480 | kldiv loss: 144.81976 | total loss: 2.128 | train acc: 495.330 ||| Val Loss: 2.129 | val acc: 0.000\n",
            "------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 192 / 200 | reconst_loss: 0.154 | kldiv loss: 142.92966 | total loss: 2.128 | train acc: 495.596 ||| Val Loss: 2.129 | val acc: 0.000\n",
            "------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 193 / 200 | reconst_loss: 0.493 | kldiv loss: 146.36945 | total loss: 2.128 | train acc: 495.529 ||| Val Loss: 2.129 | val acc: 0.000\n",
            "------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 194 / 200 | reconst_loss: 0.471 | kldiv loss: 144.95583 | total loss: 2.127 | train acc: 495.795 ||| Val Loss: 2.128 | val acc: 0.000\n",
            "------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 195 / 200 | reconst_loss: 0.107 | kldiv loss: 142.22910 | total loss: 2.127 | train acc: 495.862 ||| Val Loss: 2.131 | val acc: 0.000\n",
            "------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 196 / 200 | reconst_loss: 0.437 | kldiv loss: 142.77124 | total loss: 2.126 | train acc: 495.529 ||| Val Loss: 2.128 | val acc: 0.000\n",
            "------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 197 / 200 | reconst_loss: 0.265 | kldiv loss: 143.35211 | total loss: 2.126 | train acc: 495.729 ||| Val Loss: 2.128 | val acc: 0.000\n",
            "------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 198 / 200 | reconst_loss: 0.317 | kldiv loss: 146.34698 | total loss: 2.126 | train acc: 495.529 ||| Val Loss: 2.127 | val acc: 0.000\n",
            "------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 199 / 200 | reconst_loss: 0.393 | kldiv loss: 145.52461 | total loss: 2.126 | train acc: 495.529 ||| Val Loss: 2.127 | val acc: 0.000\n",
            "------------------------------------------------------------------------------------------------------------------\n",
            "Epoch: 200 / 200 | reconst_loss: 0.321 | kldiv loss: 142.17972 | total loss: 2.125 | train acc: 495.463 ||| Val Loss: 2.127 | val acc: 0.000\n",
            "------------------------------------------------------------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "train_losses=[]\n",
        "val_losses=[]\n",
        "train_accuracy = []\n",
        "val_accuracy = []\n",
        "\n",
        "\n",
        "dic = dict(latent_space = list(), mu_list=list(), logsig2_list=list(), y=list())\n",
        "for epoch in range(num_epochs):\n",
        "  model.train()\n",
        "  #print(f\"zvalue loop begin {z}\")\n",
        "  train_running_loss = 0\n",
        "  train_running_acc = 0\n",
        "#  loop = tqdm(train_loader)\n",
        "  for i, data in enumerate(train_loader):\n",
        "    inputs, labels = data\n",
        "    #print(f'type data: {type(data)}')\n",
        "    #print(f'type inputs: {type(inputs)}')\n",
        "    #print(f'type labels: {type(labels)}')\n",
        "\n",
        "    x_reconstructed, z_reparmeterized, classified, mu, logvar = model(inputs)\n",
        "    #print(x_reconstructed, type(x_reconstructed))\n",
        "    #print(mu, type(mu))\n",
        "    #print(logvar, type(logvar))\n",
        "\n",
        "    reconstruction_loss = loss_fn(x_reconstructed, inputs)\n",
        "    kld_loss = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
        "    loss = alpha*reconstruction_loss + kld_loss*beta\n",
        "\n",
        "    acc_train = accuracy(classified, labels)\n",
        "    #print(reconstruction_loss, kld_loss, loss)\n",
        "    \n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    train_running_loss += loss.item()\n",
        "    train_loss= train_running_loss/len(train_loader)\n",
        "\n",
        "    train_running_acc += acc_train.item()\n",
        "    train_acc = train_running_acc/len(train_loader)\n",
        "\n",
        "  \n",
        "  z_list, means, logvars , labels = list(), list(), list(), list()\n",
        "\n",
        "  #Evaluation\n",
        "  with torch.inference_mode():\n",
        "    val_running_loss = 0\n",
        "\n",
        "    model.eval()\n",
        "    for X, Y in val_loader:\n",
        "      #print(labels)\n",
        "      #inputs = torch.autograd.Variable(inputs)\n",
        "      y_pred, z_reparmeterized, classified, mu, logvar = model(X)\n",
        "      v_reconstruction_loss = loss_fn(y_pred, X)\n",
        "      v_kld_loss = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
        "      vloss = alpha*v_reconstruction_loss + v_kld_loss*beta\n",
        "      #print(v_reconstruction_loss, v_kld_loss, vloss)\n",
        "\n",
        "      # yhat = torch.max(z.data,1)\n",
        "      # correct+=(yhat==y_test).sum().int()\n",
        "      # accuracy = correct / n_test\n",
        "      # accuracy_list.append(accuracy)\n",
        "  \n",
        "\n",
        "      # val_acc = accuracy(classified, labels)\n",
        "      val_acc = 0\n",
        "\n",
        "      val_running_loss += vloss.item()\n",
        "      val_loss = val_running_loss/len(val_loader)\n",
        "\n",
        "      # log ...\n",
        "      z_list.append(z_reparmeterized.detach())\n",
        "      means.append(mu.detach())\n",
        "      logvars.append(logvar.detach())\n",
        "      labels.append(Y.detach())\n",
        "\n",
        "  dic['latent_space'].append(torch.cat(z_list))\n",
        "  dic['mu_list'].append(torch.cat(means))\n",
        "  dic['logsig2_list'].append(torch.cat(logvars))\n",
        "  dic['y'].append(torch.cat(labels))\n",
        "\n",
        "  print(f\"Epoch: {epoch+1}/{num_epochs} | reconst_loss: {reconstruction_loss:.3f} | kldiv loss: {kld_loss:.5f} | total loss: {train_loss:.3f} | train acc: {train_acc:.3f} ||| Val Loss: {val_loss:.3f} | val acc: {val_acc:.3f}\")\n",
        "  print(\"--------------------------------------------------------------------------------------------------------------------------------------------------------------\")\n",
        "  #print(f\"Epoch: {epoch+1} / {num_epochs} | reconst_loss: {v_reconstruction_loss:.3f} | kldiv loss: {v_kld_loss:.3f} | Val Loss: {val_loss:.3f}\")\n",
        "  train_losses.append(train_loss)\n",
        "  val_losses.append(val_loss)\n",
        "  train_accuracy.append(train_acc)\n",
        "  \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vaK_eSTWACl3"
      },
      "outputs": [],
      "source": [
        "torch.save(model.state_dict(), 'VAE_Model.pt') # Save"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "Www1IBIuH4EY",
        "outputId": "8b042676-f261-4fd5-cb63-08a8012316de"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.plot(train_losses,'-o', label=\"Training loss\")\n",
        "plt.plot(val_losses,'-r',  label=\"Validation loss\")\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('losses')\n",
        "plt.title('Training and Validation Losses')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "cHWCgtgq6OJd",
        "outputId": "b3ddf39b-207c-4002-ab34-228c4c87c524"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.plot(train_accuracy,'-o', label=\"Training acc\")\n",
        "# plt.plot(val_acc,'-r',  label=\"Validation acc\")\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('acc')\n",
        "plt.title('Training and Validation Losses')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6KSX5IZj2KZ0",
        "outputId": "e53e0192-eece-44a8-da87-cea84678c3a4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Latent Space Visualization\n",
            "Latent Space Image 1 stored.\n",
            "Latent Space Image 2 stored.\n",
            "Latent Space Image 3 stored.\n",
            "Latent Space Image 4 stored.\n",
            "Latent Space Image 5 stored.\n",
            "Latent Space Image 6 stored.\n",
            "Latent Space Image 7 stored.\n",
            "Latent Space Image 8 stored.\n",
            "Latent Space Image 9 stored.\n",
            "Latent Space Image 10 stored.\n",
            "Latent Space Image 11 stored.\n",
            "Latent Space Image 12 stored.\n",
            "Latent Space Image 13 stored.\n",
            "Latent Space Image 14 stored.\n",
            "Latent Space Image 15 stored.\n",
            "Latent Space Image 16 stored.\n",
            "Latent Space Image 17 stored.\n",
            "Latent Space Image 18 stored.\n",
            "Latent Space Image 19 stored.\n",
            "Latent Space Image 20 stored.\n",
            "Latent Space Image 21 stored.\n",
            "Latent Space Image 22 stored.\n",
            "Latent Space Image 23 stored.\n",
            "Latent Space Image 24 stored.\n",
            "Latent Space Image 25 stored.\n",
            "Latent Space Image 26 stored.\n",
            "Latent Space Image 27 stored.\n",
            "Latent Space Image 28 stored.\n",
            "Latent Space Image 29 stored.\n",
            "Latent Space Image 30 stored.\n",
            "Latent Space Image 31 stored.\n",
            "Latent Space Image 32 stored.\n",
            "Latent Space Image 33 stored.\n",
            "Latent Space Image 34 stored.\n",
            "Latent Space Image 35 stored.\n",
            "Latent Space Image 36 stored.\n",
            "Latent Space Image 37 stored.\n",
            "Latent Space Image 38 stored.\n",
            "Latent Space Image 39 stored.\n",
            "Latent Space Image 40 stored.\n",
            "Latent Space Image 41 stored.\n",
            "Latent Space Image 42 stored.\n",
            "Latent Space Image 43 stored.\n",
            "Latent Space Image 44 stored.\n",
            "Latent Space Image 45 stored.\n",
            "Latent Space Image 46 stored.\n",
            "Latent Space Image 47 stored.\n",
            "Latent Space Image 48 stored.\n",
            "Latent Space Image 49 stored.\n",
            "Latent Space Image 50 stored.\n",
            "Latent Space Image 51 stored.\n",
            "Latent Space Image 52 stored.\n",
            "Latent Space Image 53 stored.\n",
            "Latent Space Image 54 stored.\n",
            "Latent Space Image 55 stored.\n",
            "Latent Space Image 56 stored.\n",
            "Latent Space Image 57 stored.\n",
            "Latent Space Image 58 stored.\n",
            "Latent Space Image 59 stored.\n",
            "Latent Space Image 60 stored.\n",
            "Latent Space Image 61 stored.\n",
            "Latent Space Image 62 stored.\n",
            "Latent Space Image 63 stored.\n",
            "Latent Space Image 64 stored.\n",
            "Latent Space Image 65 stored.\n",
            "Latent Space Image 66 stored.\n",
            "Latent Space Image 67 stored.\n",
            "Latent Space Image 68 stored.\n",
            "Latent Space Image 69 stored.\n",
            "Latent Space Image 70 stored.\n",
            "Latent Space Image 71 stored.\n",
            "Latent Space Image 72 stored.\n",
            "Latent Space Image 73 stored.\n",
            "Latent Space Image 74 stored.\n",
            "Latent Space Image 75 stored.\n",
            "Latent Space Image 76 stored.\n",
            "Latent Space Image 77 stored.\n",
            "Latent Space Image 78 stored.\n",
            "Latent Space Image 79 stored.\n",
            "Latent Space Image 80 stored.\n",
            "Latent Space Image 81 stored.\n",
            "Latent Space Image 82 stored.\n",
            "Latent Space Image 83 stored.\n",
            "Latent Space Image 84 stored.\n",
            "Latent Space Image 85 stored.\n",
            "Latent Space Image 86 stored.\n",
            "Latent Space Image 87 stored.\n",
            "Latent Space Image 88 stored.\n",
            "Latent Space Image 89 stored.\n",
            "Latent Space Image 90 stored.\n",
            "Latent Space Image 91 stored.\n",
            "Latent Space Image 92 stored.\n",
            "Latent Space Image 93 stored.\n",
            "Latent Space Image 94 stored.\n",
            "Latent Space Image 95 stored.\n",
            "Latent Space Image 96 stored.\n",
            "Latent Space Image 97 stored.\n",
            "Latent Space Image 98 stored.\n",
            "Latent Space Image 99 stored.\n",
            "Latent Space Image 100 stored.\n",
            "Latent Space Image 101 stored.\n",
            "Latent Space Image 102 stored.\n",
            "Latent Space Image 103 stored.\n",
            "Latent Space Image 104 stored.\n",
            "Latent Space Image 105 stored.\n",
            "Latent Space Image 106 stored.\n",
            "Latent Space Image 107 stored.\n",
            "Latent Space Image 108 stored.\n",
            "Latent Space Image 109 stored.\n",
            "Latent Space Image 110 stored.\n",
            "Latent Space Image 111 stored.\n",
            "Latent Space Image 112 stored.\n",
            "Latent Space Image 113 stored.\n",
            "Latent Space Image 114 stored.\n",
            "Latent Space Image 115 stored.\n",
            "Latent Space Image 116 stored.\n",
            "Latent Space Image 117 stored.\n",
            "Latent Space Image 118 stored.\n",
            "Latent Space Image 119 stored.\n",
            "Latent Space Image 120 stored.\n",
            "Latent Space Image 121 stored.\n",
            "Latent Space Image 122 stored.\n",
            "Latent Space Image 123 stored.\n",
            "Latent Space Image 124 stored.\n",
            "Latent Space Image 125 stored.\n",
            "Latent Space Image 126 stored.\n",
            "Latent Space Image 127 stored.\n",
            "Latent Space Image 128 stored.\n",
            "Latent Space Image 129 stored.\n",
            "Latent Space Image 130 stored.\n",
            "Latent Space Image 131 stored.\n",
            "Latent Space Image 132 stored.\n",
            "Latent Space Image 133 stored.\n",
            "Latent Space Image 134 stored.\n",
            "Latent Space Image 135 stored.\n",
            "Latent Space Image 136 stored.\n",
            "Latent Space Image 137 stored.\n",
            "Latent Space Image 138 stored.\n",
            "Latent Space Image 139 stored.\n",
            "Latent Space Image 140 stored.\n",
            "Latent Space Image 141 stored.\n",
            "Latent Space Image 142 stored.\n",
            "Latent Space Image 143 stored.\n",
            "Latent Space Image 144 stored.\n",
            "Latent Space Image 145 stored.\n",
            "Latent Space Image 146 stored.\n",
            "Latent Space Image 147 stored.\n",
            "Latent Space Image 148 stored.\n",
            "Latent Space Image 149 stored.\n",
            "Latent Space Image 150 stored.\n",
            "Latent Space Image 151 stored.\n",
            "Latent Space Image 152 stored.\n",
            "Latent Space Image 153 stored.\n",
            "Latent Space Image 154 stored.\n",
            "Latent Space Image 155 stored.\n",
            "Latent Space Image 156 stored.\n",
            "Latent Space Image 157 stored.\n",
            "Latent Space Image 158 stored.\n",
            "Latent Space Image 159 stored.\n",
            "Latent Space Image 160 stored.\n",
            "Latent Space Image 161 stored.\n",
            "Latent Space Image 162 stored.\n",
            "Latent Space Image 163 stored.\n",
            "Latent Space Image 164 stored.\n",
            "Latent Space Image 165 stored.\n",
            "Latent Space Image 166 stored.\n",
            "Latent Space Image 167 stored.\n",
            "Latent Space Image 168 stored.\n",
            "Latent Space Image 169 stored.\n",
            "Latent Space Image 170 stored.\n",
            "Latent Space Image 171 stored.\n",
            "Latent Space Image 172 stored.\n",
            "Latent Space Image 173 stored.\n",
            "Latent Space Image 174 stored.\n",
            "Latent Space Image 175 stored.\n",
            "Latent Space Image 176 stored.\n",
            "Latent Space Image 177 stored.\n",
            "Latent Space Image 178 stored.\n",
            "Latent Space Image 179 stored.\n",
            "Latent Space Image 180 stored.\n",
            "Latent Space Image 181 stored.\n",
            "Latent Space Image 182 stored.\n",
            "Latent Space Image 183 stored.\n",
            "Latent Space Image 184 stored.\n",
            "Latent Space Image 185 stored.\n",
            "Latent Space Image 186 stored.\n",
            "Latent Space Image 187 stored.\n",
            "Latent Space Image 188 stored.\n",
            "Latent Space Image 189 stored.\n",
            "Latent Space Image 190 stored.\n",
            "Latent Space Image 191 stored.\n",
            "Latent Space Image 192 stored.\n",
            "Latent Space Image 193 stored.\n",
            "Latent Space Image 194 stored.\n",
            "Latent Space Image 195 stored.\n",
            "Latent Space Image 196 stored.\n",
            "Latent Space Image 197 stored.\n",
            "Latent Space Image 198 stored.\n",
            "Latent Space Image 199 stored.\n",
            "Latent Space Image 200 stored.\n"
          ]
        }
      ],
      "source": [
        "print(\"Latent Space Visualization\")\n",
        "for i in range (num_epochs):\n",
        "  fig = plt.figure(figsize=(10,10))\n",
        "  z_arr = dic['latent_space'][i].cpu().numpy()\n",
        "  y_arr = dic['y'][i].cpu().numpy()\n",
        "\n",
        "  #Experiment 1\n",
        "  plt.scatter(z_arr[:,0], z_arr[:,1], c = y_arr, edgecolor='none', alpha=0.5,\n",
        "              cmap=plt.cm.get_cmap('hsv', 13))\n",
        "  cb = plt.colorbar(ticks=[0,1,2,3,4,5,6,7,8,9,10,11,12],values=[0,1,2,3,4,5,6,7,8,9,10,11,12])\n",
        "\n",
        "  #Experiment 3\n",
        "  # plt.scatter(z_arr[:,0], z_arr[:,1], c = y_arr, edgecolor='none', alpha=0.5,\n",
        "  #             cmap=plt.cm.get_cmap('hsv', 23))\n",
        "  #cb = plt.colorbar(ticks=[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23],values=[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23])\n",
        "  \n",
        "  cb.ax.tick_params(labelsize=10)\n",
        "  plt.xticks(fontsize= 10)\n",
        "  plt.yticks(fontsize= 10)\n",
        "  plt.xlabel('z[0]', fontsize= 10)\n",
        "  plt.ylabel('z[1]', fontsize= 10)\n",
        "  plt.title(f'VAE train dataset with latent space Dim=2  Epoch number: {i+1} ', fontsize= 12)\n",
        "  # plt.show()\n",
        "  plt.close()\n",
        "  fig.savefig(f\"/content/drive/MyDrive/WEAR_LAB/Research_Pytorch/VAE_Images/VAEtrain_images{i:001}\" + \".png\")\n",
        "  print(f\"Latent Space Image {i+1} stored.\")\n",
        "\n",
        "import imageio\n",
        "gif = []\n",
        "for i in range(num_epochs):\n",
        "  each_image = imageio.imread(f\"/content/drive/MyDrive/WEAR_LAB/Research_Pytorch/VAE_Images/VAEtrain_images{i}\" + \".png\")# here read all images\n",
        "  gif.append(each_image)\n",
        "imageio.mimsave(\"/content/result.gif\",gif)\n",
        "\n",
        "from IPython.display import Image\n",
        "\n",
        "fname = '/content/result.gif'\n",
        "Image(open(fname, 'rb').read())  # local"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fKwtgkkkqljv"
      },
      "outputs": [],
      "source": [
        "# for i in range (num_epochs):\n",
        "#   z_arr = dic['latent_space'][i].cpu().numpy()\n",
        "#   y_arr = dic['y'][i].cpu().numpy()\n",
        "#   plt.figure(figsize = (10,5))\n",
        "#   plt.subplot(1,2,1)\n",
        "#   plt.scatter(z_arr[:,0], z_arr[:,1], c = y_arr)\n",
        "#   plt.colorbar()\n",
        "#   plt.tight_layout()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bERxPXvorNic"
      },
      "source": [
        "---\n",
        "VAE Experiment 1 **[]** 1/10\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "R9Op8v3LrcHv"
      },
      "outputs": [],
      "source": [
        "import torch   \n",
        "import torch.nn as nn                          \n",
        "import torch.nn.functional as F                \n",
        "import torch.optim as optim   \n",
        "from torch.utils.data import TensorDataset, Dataset, DataLoader\n",
        "from torch.autograd import Variable\n",
        "import torch.utils.data\n",
        "\n",
        "import pandas as pd \n",
        "import numpy as np\n",
        "import os                             \n",
        "\n",
        "import matplotlib.cm as cm\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns    \n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import preprocessing\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import accuracy_score, roc_auc_score, f1_score, precision_score, recall_score\n",
        "from sklearn.manifold import TSNE\n",
        "from sklearn.decomposition import PCA, TruncatedSVD\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# from captum.attr import LayerConductance, LayerActivation, LayerIntegratedGradients\n",
        "# from captum.attr import IntegratedGradients, DeepLift, GradientShap, NoiseTunnel, FeatureAblation\n",
        "\n",
        "# import plotly.offline as py\n",
        "# import plotly.graph_objs as go        \n",
        "  \n",
        "# from tqdm import tqdm\n",
        "\n",
        "# import umap\n",
        "# import umap.plot\n",
        "\n",
        "#based on sensor data can you determine the stimulus that is currently in use?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "FNJdjUb6ulmv"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(\"/content/drive/MyDrive/WEAR_LAB/Research_Pytorch/S1_E1_A1_v6.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 305
        },
        "id": "XAq5Zx7euqOH",
        "outputId": "07e68807-63eb-46e2-9a7f-0a83ce56f8b9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   stimulus    Acc 1    Acc 2    Acc 3  EMG Channel 1  EMG Channel 2  \\\n",
              "0         0  0.30176  0.78809 -0.66699            -22             -2   \n",
              "1         0  0.30176  0.78809 -0.66699              5             -4   \n",
              "2         0  0.30176  0.78809 -0.66699             -6              1   \n",
              "3         0  0.30176  0.78809 -0.66699             15             10   \n",
              "4         0  0.24609  0.73535 -0.66309             -1            -16   \n",
              "\n",
              "   EMG Channe 3  EMG Channel 4  EMG Channel 5  EMG Channel 6  EMG Channel 7  \\\n",
              "0           -16             -7             -3             -1             -2   \n",
              "1           -12             -3              8             25              1   \n",
              "2             4             -1             -9              0            -10   \n",
              "3            19              9             10              7              2   \n",
              "4           -17              0             -2             -7              2   \n",
              "\n",
              "   EMG Channel 8  EMG Channel 9  EMG Channel 10  EMG Channel 11  \\\n",
              "0             -4             -2             -46             -49   \n",
              "1              1             -2              66              28   \n",
              "2             -3             -9             -52             -24   \n",
              "3              1             -4             -13              19   \n",
              "4              0             -6              27               7   \n",
              "\n",
              "   EMG Channel 12  EMG Channel 13  EMG Channel 14  EMG Channel 15  \\\n",
              "0              -5               9               1              -1   \n",
              "1               3              22              10               2   \n",
              "2              -2             -52             -14             -24   \n",
              "3               4              28               6              -5   \n",
              "4              -1             -22              -2              -7   \n",
              "\n",
              "   EMG Channel 16  \n",
              "0              -2  \n",
              "1               1  \n",
              "2              -3  \n",
              "3             -12  \n",
              "4              15  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-62760488-3153-4477-bd09-7d9823442826\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>stimulus</th>\n",
              "      <th>Acc 1</th>\n",
              "      <th>Acc 2</th>\n",
              "      <th>Acc 3</th>\n",
              "      <th>EMG Channel 1</th>\n",
              "      <th>EMG Channel 2</th>\n",
              "      <th>EMG Channe 3</th>\n",
              "      <th>EMG Channel 4</th>\n",
              "      <th>EMG Channel 5</th>\n",
              "      <th>EMG Channel 6</th>\n",
              "      <th>EMG Channel 7</th>\n",
              "      <th>EMG Channel 8</th>\n",
              "      <th>EMG Channel 9</th>\n",
              "      <th>EMG Channel 10</th>\n",
              "      <th>EMG Channel 11</th>\n",
              "      <th>EMG Channel 12</th>\n",
              "      <th>EMG Channel 13</th>\n",
              "      <th>EMG Channel 14</th>\n",
              "      <th>EMG Channel 15</th>\n",
              "      <th>EMG Channel 16</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0.30176</td>\n",
              "      <td>0.78809</td>\n",
              "      <td>-0.66699</td>\n",
              "      <td>-22</td>\n",
              "      <td>-2</td>\n",
              "      <td>-16</td>\n",
              "      <td>-7</td>\n",
              "      <td>-3</td>\n",
              "      <td>-1</td>\n",
              "      <td>-2</td>\n",
              "      <td>-4</td>\n",
              "      <td>-2</td>\n",
              "      <td>-46</td>\n",
              "      <td>-49</td>\n",
              "      <td>-5</td>\n",
              "      <td>9</td>\n",
              "      <td>1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0.30176</td>\n",
              "      <td>0.78809</td>\n",
              "      <td>-0.66699</td>\n",
              "      <td>5</td>\n",
              "      <td>-4</td>\n",
              "      <td>-12</td>\n",
              "      <td>-3</td>\n",
              "      <td>8</td>\n",
              "      <td>25</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>-2</td>\n",
              "      <td>66</td>\n",
              "      <td>28</td>\n",
              "      <td>3</td>\n",
              "      <td>22</td>\n",
              "      <td>10</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0.30176</td>\n",
              "      <td>0.78809</td>\n",
              "      <td>-0.66699</td>\n",
              "      <td>-6</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>-1</td>\n",
              "      <td>-9</td>\n",
              "      <td>0</td>\n",
              "      <td>-10</td>\n",
              "      <td>-3</td>\n",
              "      <td>-9</td>\n",
              "      <td>-52</td>\n",
              "      <td>-24</td>\n",
              "      <td>-2</td>\n",
              "      <td>-52</td>\n",
              "      <td>-14</td>\n",
              "      <td>-24</td>\n",
              "      <td>-3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0.30176</td>\n",
              "      <td>0.78809</td>\n",
              "      <td>-0.66699</td>\n",
              "      <td>15</td>\n",
              "      <td>10</td>\n",
              "      <td>19</td>\n",
              "      <td>9</td>\n",
              "      <td>10</td>\n",
              "      <td>7</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>-4</td>\n",
              "      <td>-13</td>\n",
              "      <td>19</td>\n",
              "      <td>4</td>\n",
              "      <td>28</td>\n",
              "      <td>6</td>\n",
              "      <td>-5</td>\n",
              "      <td>-12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0.24609</td>\n",
              "      <td>0.73535</td>\n",
              "      <td>-0.66309</td>\n",
              "      <td>-1</td>\n",
              "      <td>-16</td>\n",
              "      <td>-17</td>\n",
              "      <td>0</td>\n",
              "      <td>-2</td>\n",
              "      <td>-7</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>-6</td>\n",
              "      <td>27</td>\n",
              "      <td>7</td>\n",
              "      <td>-1</td>\n",
              "      <td>-22</td>\n",
              "      <td>-2</td>\n",
              "      <td>-7</td>\n",
              "      <td>15</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-62760488-3153-4477-bd09-7d9823442826')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-62760488-3153-4477-bd09-7d9823442826 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-62760488-3153-4477-bd09-7d9823442826');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uBKcgR245EOX",
        "outputId": "925cd776-854a-4f69-9aa2-3ff7c7e8f0f4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(130200, 19) <class 'pandas.core.frame.DataFrame'> (130200, 1) <class 'pandas.core.frame.DataFrame'>\n",
            "\n"
          ]
        }
      ],
      "source": [
        "X = df.drop('stimulus', axis=1)\n",
        "#y = df['stimulus']\n",
        "y = df.iloc[:, 0:1]\n",
        "print(X.shape, type(X), y.shape, type(y))\n",
        "print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 305
        },
        "id": "XlcbdijIOabG",
        "outputId": "78fddaa0-0507-4679-9b58-cfc8daaa1bfb"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     Acc 1    Acc 2    Acc 3  EMG Channel 1  EMG Channel 2  EMG Channe 3  \\\n",
              "0  0.30176  0.78809 -0.66699            -22             -2           -16   \n",
              "1  0.30176  0.78809 -0.66699              5             -4           -12   \n",
              "2  0.30176  0.78809 -0.66699             -6              1             4   \n",
              "3  0.30176  0.78809 -0.66699             15             10            19   \n",
              "4  0.24609  0.73535 -0.66309             -1            -16           -17   \n",
              "\n",
              "   EMG Channel 4  EMG Channel 5  EMG Channel 6  EMG Channel 7  EMG Channel 8  \\\n",
              "0             -7             -3             -1             -2             -4   \n",
              "1             -3              8             25              1              1   \n",
              "2             -1             -9              0            -10             -3   \n",
              "3              9             10              7              2              1   \n",
              "4              0             -2             -7              2              0   \n",
              "\n",
              "   EMG Channel 9  EMG Channel 10  EMG Channel 11  EMG Channel 12  \\\n",
              "0             -2             -46             -49              -5   \n",
              "1             -2              66              28               3   \n",
              "2             -9             -52             -24              -2   \n",
              "3             -4             -13              19               4   \n",
              "4             -6              27               7              -1   \n",
              "\n",
              "   EMG Channel 13  EMG Channel 14  EMG Channel 15  EMG Channel 16  \n",
              "0               9               1              -1              -2  \n",
              "1              22              10               2               1  \n",
              "2             -52             -14             -24              -3  \n",
              "3              28               6              -5             -12  \n",
              "4             -22              -2              -7              15  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9bafde37-14c0-4937-a6f1-b5ec08b8c438\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Acc 1</th>\n",
              "      <th>Acc 2</th>\n",
              "      <th>Acc 3</th>\n",
              "      <th>EMG Channel 1</th>\n",
              "      <th>EMG Channel 2</th>\n",
              "      <th>EMG Channe 3</th>\n",
              "      <th>EMG Channel 4</th>\n",
              "      <th>EMG Channel 5</th>\n",
              "      <th>EMG Channel 6</th>\n",
              "      <th>EMG Channel 7</th>\n",
              "      <th>EMG Channel 8</th>\n",
              "      <th>EMG Channel 9</th>\n",
              "      <th>EMG Channel 10</th>\n",
              "      <th>EMG Channel 11</th>\n",
              "      <th>EMG Channel 12</th>\n",
              "      <th>EMG Channel 13</th>\n",
              "      <th>EMG Channel 14</th>\n",
              "      <th>EMG Channel 15</th>\n",
              "      <th>EMG Channel 16</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.30176</td>\n",
              "      <td>0.78809</td>\n",
              "      <td>-0.66699</td>\n",
              "      <td>-22</td>\n",
              "      <td>-2</td>\n",
              "      <td>-16</td>\n",
              "      <td>-7</td>\n",
              "      <td>-3</td>\n",
              "      <td>-1</td>\n",
              "      <td>-2</td>\n",
              "      <td>-4</td>\n",
              "      <td>-2</td>\n",
              "      <td>-46</td>\n",
              "      <td>-49</td>\n",
              "      <td>-5</td>\n",
              "      <td>9</td>\n",
              "      <td>1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.30176</td>\n",
              "      <td>0.78809</td>\n",
              "      <td>-0.66699</td>\n",
              "      <td>5</td>\n",
              "      <td>-4</td>\n",
              "      <td>-12</td>\n",
              "      <td>-3</td>\n",
              "      <td>8</td>\n",
              "      <td>25</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>-2</td>\n",
              "      <td>66</td>\n",
              "      <td>28</td>\n",
              "      <td>3</td>\n",
              "      <td>22</td>\n",
              "      <td>10</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.30176</td>\n",
              "      <td>0.78809</td>\n",
              "      <td>-0.66699</td>\n",
              "      <td>-6</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>-1</td>\n",
              "      <td>-9</td>\n",
              "      <td>0</td>\n",
              "      <td>-10</td>\n",
              "      <td>-3</td>\n",
              "      <td>-9</td>\n",
              "      <td>-52</td>\n",
              "      <td>-24</td>\n",
              "      <td>-2</td>\n",
              "      <td>-52</td>\n",
              "      <td>-14</td>\n",
              "      <td>-24</td>\n",
              "      <td>-3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.30176</td>\n",
              "      <td>0.78809</td>\n",
              "      <td>-0.66699</td>\n",
              "      <td>15</td>\n",
              "      <td>10</td>\n",
              "      <td>19</td>\n",
              "      <td>9</td>\n",
              "      <td>10</td>\n",
              "      <td>7</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>-4</td>\n",
              "      <td>-13</td>\n",
              "      <td>19</td>\n",
              "      <td>4</td>\n",
              "      <td>28</td>\n",
              "      <td>6</td>\n",
              "      <td>-5</td>\n",
              "      <td>-12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.24609</td>\n",
              "      <td>0.73535</td>\n",
              "      <td>-0.66309</td>\n",
              "      <td>-1</td>\n",
              "      <td>-16</td>\n",
              "      <td>-17</td>\n",
              "      <td>0</td>\n",
              "      <td>-2</td>\n",
              "      <td>-7</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>-6</td>\n",
              "      <td>27</td>\n",
              "      <td>7</td>\n",
              "      <td>-1</td>\n",
              "      <td>-22</td>\n",
              "      <td>-2</td>\n",
              "      <td>-7</td>\n",
              "      <td>15</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9bafde37-14c0-4937-a6f1-b5ec08b8c438')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-9bafde37-14c0-4937-a6f1-b5ec08b8c438 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-9bafde37-14c0-4937-a6f1-b5ec08b8c438');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "X.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3WHYTiyNxjbB"
      },
      "source": [
        "---\n",
        "Visualization number of labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 553
        },
        "id": "GrBPneNpxio1",
        "outputId": "7ce90338-c926-4af0-bc66-a589cc55ea2b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "stimulus\n",
              "0           49599\n",
              "8            6795\n",
              "5            6782\n",
              "6            6776\n",
              "7            6776\n",
              "11           6773\n",
              "1            6753\n",
              "12           6701\n",
              "10           6696\n",
              "2            6656\n",
              "4            6654\n",
              "9            6626\n",
              "3            6613\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 6
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "sns.countplot(x = 'stimulus', data=df)\n",
        "y.value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ac9B5iPx9HWR"
      },
      "source": [
        "---\n",
        "Fixing Data Imbalance via Undersampling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 365
        },
        "id": "F8Pf2yx55xks",
        "outputId": "d3d3ae76-18b2-469b-8673-d963e06a896a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f584ebbddc0>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 576x360 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "\n",
        "sampling_strategy = \"not minority\"\n",
        "rus = RandomUnderSampler(sampling_strategy=sampling_strategy)\n",
        "X_res, y_res = rus.fit_resample(X, y)\n",
        "y_res.value_counts().plot(kind='bar', figsize=(8,5))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yYCz3Q5H9gN9",
        "outputId": "ae996f8f-3d9b-4721-85b3-c91fe1812413"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "stimulus\n",
              "0           6613\n",
              "1           6613\n",
              "2           6613\n",
              "3           6613\n",
              "4           6613\n",
              "5           6613\n",
              "6           6613\n",
              "7           6613\n",
              "8           6613\n",
              "9           6613\n",
              "10          6613\n",
              "11          6613\n",
              "12          6613\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "y_res.value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4F4r6LK29ir9",
        "outputId": "9d294784-8c1d-4b3b-cfe2-df1916d56c88"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "85969"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "len(X_res.value_counts())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hpNYb9reRugs",
        "outputId": "a79383b6-2713-4e6c-bc16-67edcf7d2a8f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "        stimulus\n",
            "0              0\n",
            "1              0\n",
            "2              0\n",
            "3              0\n",
            "4              0\n",
            "...          ...\n",
            "130195        12\n",
            "130196        12\n",
            "130197        12\n",
            "130198        12\n",
            "130199        12\n",
            "\n",
            "[130200 rows x 1 columns]\n"
          ]
        }
      ],
      "source": [
        "print(y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hPN8DmEJxrse"
      },
      "source": [
        "---\n",
        "Visualization of Data Distributions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "y5a9acbLxwRe"
      },
      "outputs": [],
      "source": [
        "# #distribution of first 19 features\n",
        "\n",
        "\n",
        "# fig, axs = plt.subplots(nrows=5, ncols=4, figsize=(40, 40))\n",
        "# axs = axs.flatten()\n",
        "# index = 0\n",
        "# for k, v in df.items():\n",
        "#   print(f\"[{index +1}] Updating plot\")\n",
        "#   sns.distplot(v, ax=axs[index])\n",
        "#   index += 1\n",
        "#   if index == 20:\n",
        "#     break \n",
        "# plt.tight_layout()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j-Q8ps35WPO3"
      },
      "source": [
        "---\n",
        "Defining Hyperparmaeters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "MZoF6guXlSot"
      },
      "outputs": [],
      "source": [
        "#############################################################################################################################################################################################################\n",
        "#############################################################################################################################################################################################################\n",
        "#############################################################################################################################################################################################################\n",
        "#############################################################################################################################################################################################################\n",
        "\n",
        "#Hyperparameters\n",
        "emg_channels = 16\n",
        "imu_channels = 3\n",
        "\n",
        "latent_dim = 2\n",
        "input_dim= 19\n",
        "hidden_dim= 12\n",
        "hidden_dim_2 = 6\n",
        "output_dim = 19\n",
        "num_classes = 13\n",
        "\n",
        "num_epochs= 25\n",
        "batch_size= 100\n",
        "learning_rate= 0.0003 #3e-4 #Karpathy constant\n",
        "\n",
        "beta = 0.65\n",
        "alpha = 1\n",
        "\n",
        "#############################################################################################################################################################################################################\n",
        "#############################################################################################################################################################################################################\n",
        "#############################################################################################################################################################################################################\n",
        "#############################################################################################################################################################################################################"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D3t0Wyvt9zUN"
      },
      "source": [
        "---\n",
        "Train Test Split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XmDYv1vB9Wyh",
        "outputId": "ef493398-9f01-4c20-8b15-92f50502f66b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(85969, 19) <class 'numpy.ndarray'> (85969, 1) <class 'numpy.ndarray'>\n",
            "\n",
            "X_train size: 51581 | X_val size: 17194 | X_test size: 17194\n",
            "y_train size: 51581 | y_val size: 17194 | y_test size: 17194\n",
            "\n",
            "Training Feature Split: (51581, 19) | Training Labels (51581, 1)\n",
            "Validation Feature Split: (17194, 19) | Validation Labels (17194, 1)\n",
            "Testing Feature Split: (17194, 19) | Testing Labels (17194, 1)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "X = X_res.values\n",
        "y = y_res.values\n",
        "print(X.shape, type(X), y.shape, type(y))\n",
        "print()\n",
        "\n",
        "# Data Split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.25, random_state=42) # 0.25 x 0.8 = 0.2\n",
        "\n",
        "print(f\"X_train size: {len(X_train)} | X_val size: {len(X_val)} | X_test size: {len(X_test)}\")\n",
        "print(f\"y_train size: {len(y_train)} | y_val size: {len(y_val)} | y_test size: {len(y_test)}\")\n",
        "print()\n",
        "print(f\"Training Feature Split: {X_train.shape} | Training Labels { y_train.shape}\")\n",
        "print(f\"Validation Feature Split: {X_val.shape} | Validation Labels { y_val.shape}\")\n",
        "print(f\"Testing Feature Split: {X_test.shape} | Testing Labels { y_test.shape}\")\n",
        "print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-IlEU31bWToZ"
      },
      "source": [
        "---\n",
        "Data Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QczobfgmOg9t",
        "outputId": "8a86f1b2-795d-4d6f-9a00-27cb10fe2495"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([51581, 19])\n",
            "torch.Size([17194, 19])\n",
            "torch.Size([17194, 19])\n"
          ]
        }
      ],
      "source": [
        "#Data Preprocessing\n",
        "\n",
        "# Split the data into EMG and IMU channels\n",
        "X_train_emg = X_train[:, imu_channels:]\n",
        "X_train_imu = X_train[:, :imu_channels]\n",
        "X_train_emg = torch.from_numpy(X_train_emg).float()\n",
        "X_train_imu = torch.from_numpy(X_train_imu).float()\n",
        "\n",
        "X_val_emg = X_val[:, imu_channels:]\n",
        "X_val_imu = X_val[:, :imu_channels]\n",
        "X_val_emg = torch.from_numpy(X_val_emg).float()\n",
        "X_val_imu = torch.from_numpy(X_val_imu).float()\n",
        "\n",
        "X_test_emg = X_test[:, imu_channels:]\n",
        "X_test_imu = X_test[:, :imu_channels]\n",
        "X_test_emg = torch.from_numpy(X_test_emg).float()\n",
        "X_test_imu = torch.from_numpy(X_test_imu).float()\n",
        "\n",
        "class Preprocessor:\n",
        "  def __init__(self, emg_channels, imu_channels):\n",
        "    self.emg_channels = emg_channels\n",
        "    self.imu_channels = imu_channels\n",
        "\n",
        "  def preprocess(self, emg_data, imu_data):\n",
        "    # Preprocess the EMG data\n",
        "    emg_data = emg_data.view(emg_data.shape[0], 1, self.emg_channels)\n",
        "    emg_data = nn.Conv1d(1, 1, kernel_size=5, padding=2, bias=False)(emg_data)\n",
        "    emg_data = nn.BatchNorm1d(1)(emg_data)\n",
        "\n",
        "    # Preprocess the IMU data\n",
        "    imu_data = imu_data.view(imu_data.shape[0], 1, self.imu_channels)\n",
        "    imu_data = nn.Conv1d(1, 1, kernel_size=5, padding=2, bias=False)(imu_data)\n",
        "    imu_data = nn.BatchNorm1d(1)(imu_data)\n",
        "\n",
        "    # Concatenate the processed EMG and IMU data\n",
        "    processed_data = torch.cat([emg_data, imu_data], dim=2)\n",
        "\n",
        "    return processed_data\n",
        "\n",
        "# Initialize the preprocessor\n",
        "preprocessor = Preprocessor(emg_channels, imu_channels)\n",
        "\n",
        "# Preprocess the training data\n",
        "X_train_preprocessed = preprocessor.preprocess(X_train_emg, X_train_imu)\n",
        "X_train_preprocessed = X_train_preprocessed.view(X_train_preprocessed.shape[0], -1)\n",
        "print(X_train_preprocessed.shape)\n",
        "\n",
        "X_val_preprocessed = preprocessor.preprocess(X_val_emg, X_val_imu)\n",
        "X_val_preprocessed = X_val_preprocessed.view(X_val_preprocessed.shape[0], -1)\n",
        "print(X_val_preprocessed.shape)\n",
        "\n",
        "X_test_preprocessed = preprocessor.preprocess(X_test_emg, X_test_imu)\n",
        "X_test_preprocessed = X_test_preprocessed.view(X_test_preprocessed.shape[0], -1)\n",
        "print(X_test_preprocessed.shape)\n",
        "\n",
        "X_train_preprocessed = X_train_preprocessed.detach().numpy()\n",
        "X_val_preprocessed = X_val_preprocessed.detach().numpy()\n",
        "X_test_preprocessed = X_test_preprocessed.detach().numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 270
        },
        "id": "PuxW_OYGRYjI",
        "outputId": "e042ba71-1d2d-4a09-f184-f96f4b8b1fd0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         0         1         2         3         4         5         6   \\\n",
              "0 -0.092997  0.202148 -0.007205 -0.352916 -0.074040 -0.122343 -0.178363   \n",
              "1  0.255785  5.602331 -1.341444  0.670416  0.815663  0.586841 -2.331173   \n",
              "2  0.143654 -0.383194  4.448755  0.052446 -0.269873 -0.541622 -0.108931   \n",
              "3  0.364363  0.919496  0.306785  0.480296  0.196881  0.610795 -0.063386   \n",
              "4 -0.001694  0.404424 -0.338703 -0.084692  0.069832  0.064361 -0.153547   \n",
              "\n",
              "         7         8         9         10        11        12        13  \\\n",
              "0 -0.062866 -0.487053 -0.005380 -0.141541 -0.467556 -0.019149  0.041547   \n",
              "1  0.471600  1.660120 -1.737805 -0.356719  0.023257 -0.094070 -0.138989   \n",
              "2 -0.539619 -0.142732 -0.000877 -0.592055 -0.228287  0.028583 -0.143134   \n",
              "3  3.420253 -0.171592 -0.574391  7.302566 -1.239325 -1.771304  1.324185   \n",
              "4 -0.093549 -0.070849 -0.250522 -0.149233 -0.129537 -0.047756 -0.108192   \n",
              "\n",
              "         14        15        16        17        18  \n",
              "0 -0.068914  0.110674  0.129825  0.903862 -1.349723  \n",
              "1  0.056190 -0.138041  0.449199  1.088037 -1.379499  \n",
              "2 -0.832957  0.260175  0.418706  1.078343 -1.367759  \n",
              "3 -0.884188 -0.300911  0.359848  1.044725 -1.303134  \n",
              "4  0.129903 -0.050206  0.375976  1.082549 -1.345143  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5af0ffb1-0494-43fa-9e46-4c06c0722c36\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-0.092997</td>\n",
              "      <td>0.202148</td>\n",
              "      <td>-0.007205</td>\n",
              "      <td>-0.352916</td>\n",
              "      <td>-0.074040</td>\n",
              "      <td>-0.122343</td>\n",
              "      <td>-0.178363</td>\n",
              "      <td>-0.062866</td>\n",
              "      <td>-0.487053</td>\n",
              "      <td>-0.005380</td>\n",
              "      <td>-0.141541</td>\n",
              "      <td>-0.467556</td>\n",
              "      <td>-0.019149</td>\n",
              "      <td>0.041547</td>\n",
              "      <td>-0.068914</td>\n",
              "      <td>0.110674</td>\n",
              "      <td>0.129825</td>\n",
              "      <td>0.903862</td>\n",
              "      <td>-1.349723</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.255785</td>\n",
              "      <td>5.602331</td>\n",
              "      <td>-1.341444</td>\n",
              "      <td>0.670416</td>\n",
              "      <td>0.815663</td>\n",
              "      <td>0.586841</td>\n",
              "      <td>-2.331173</td>\n",
              "      <td>0.471600</td>\n",
              "      <td>1.660120</td>\n",
              "      <td>-1.737805</td>\n",
              "      <td>-0.356719</td>\n",
              "      <td>0.023257</td>\n",
              "      <td>-0.094070</td>\n",
              "      <td>-0.138989</td>\n",
              "      <td>0.056190</td>\n",
              "      <td>-0.138041</td>\n",
              "      <td>0.449199</td>\n",
              "      <td>1.088037</td>\n",
              "      <td>-1.379499</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.143654</td>\n",
              "      <td>-0.383194</td>\n",
              "      <td>4.448755</td>\n",
              "      <td>0.052446</td>\n",
              "      <td>-0.269873</td>\n",
              "      <td>-0.541622</td>\n",
              "      <td>-0.108931</td>\n",
              "      <td>-0.539619</td>\n",
              "      <td>-0.142732</td>\n",
              "      <td>-0.000877</td>\n",
              "      <td>-0.592055</td>\n",
              "      <td>-0.228287</td>\n",
              "      <td>0.028583</td>\n",
              "      <td>-0.143134</td>\n",
              "      <td>-0.832957</td>\n",
              "      <td>0.260175</td>\n",
              "      <td>0.418706</td>\n",
              "      <td>1.078343</td>\n",
              "      <td>-1.367759</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.364363</td>\n",
              "      <td>0.919496</td>\n",
              "      <td>0.306785</td>\n",
              "      <td>0.480296</td>\n",
              "      <td>0.196881</td>\n",
              "      <td>0.610795</td>\n",
              "      <td>-0.063386</td>\n",
              "      <td>3.420253</td>\n",
              "      <td>-0.171592</td>\n",
              "      <td>-0.574391</td>\n",
              "      <td>7.302566</td>\n",
              "      <td>-1.239325</td>\n",
              "      <td>-1.771304</td>\n",
              "      <td>1.324185</td>\n",
              "      <td>-0.884188</td>\n",
              "      <td>-0.300911</td>\n",
              "      <td>0.359848</td>\n",
              "      <td>1.044725</td>\n",
              "      <td>-1.303134</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-0.001694</td>\n",
              "      <td>0.404424</td>\n",
              "      <td>-0.338703</td>\n",
              "      <td>-0.084692</td>\n",
              "      <td>0.069832</td>\n",
              "      <td>0.064361</td>\n",
              "      <td>-0.153547</td>\n",
              "      <td>-0.093549</td>\n",
              "      <td>-0.070849</td>\n",
              "      <td>-0.250522</td>\n",
              "      <td>-0.149233</td>\n",
              "      <td>-0.129537</td>\n",
              "      <td>-0.047756</td>\n",
              "      <td>-0.108192</td>\n",
              "      <td>0.129903</td>\n",
              "      <td>-0.050206</td>\n",
              "      <td>0.375976</td>\n",
              "      <td>1.082549</td>\n",
              "      <td>-1.345143</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5af0ffb1-0494-43fa-9e46-4c06c0722c36')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-5af0ffb1-0494-43fa-9e46-4c06c0722c36 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-5af0ffb1-0494-43fa-9e46-4c06c0722c36');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "#print(X_train_preprocessed)\n",
        "X_train_preprocessed_array = X_train_preprocessed.reshape(-1, 19)\n",
        "X_train_df = pd.DataFrame(X_train_preprocessed_array)\n",
        "X_train_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_val_preprocessed_array = X_val_preprocessed.reshape(-1, 19)\n",
        "X_val_df = pd.DataFrame(X_train_preprocessed_array)\n",
        "X_val_df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 270
        },
        "id": "df0IRkwvLiQU",
        "outputId": "21534e06-007e-43af-ff8b-d9c0c44aba22"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         0         1         2         3         4         5         6   \\\n",
              "0 -0.092997  0.202148 -0.007205 -0.352916 -0.074040 -0.122343 -0.178363   \n",
              "1  0.255785  5.602331 -1.341444  0.670416  0.815663  0.586841 -2.331173   \n",
              "2  0.143654 -0.383194  4.448755  0.052446 -0.269873 -0.541622 -0.108931   \n",
              "3  0.364363  0.919496  0.306785  0.480296  0.196881  0.610795 -0.063386   \n",
              "4 -0.001694  0.404424 -0.338703 -0.084692  0.069832  0.064361 -0.153547   \n",
              "\n",
              "         7         8         9         10        11        12        13  \\\n",
              "0 -0.062866 -0.487053 -0.005380 -0.141541 -0.467556 -0.019149  0.041547   \n",
              "1  0.471600  1.660120 -1.737805 -0.356719  0.023257 -0.094070 -0.138989   \n",
              "2 -0.539619 -0.142732 -0.000877 -0.592055 -0.228287  0.028583 -0.143134   \n",
              "3  3.420253 -0.171592 -0.574391  7.302566 -1.239325 -1.771304  1.324185   \n",
              "4 -0.093549 -0.070849 -0.250522 -0.149233 -0.129537 -0.047756 -0.108192   \n",
              "\n",
              "         14        15        16        17        18  \n",
              "0 -0.068914  0.110674  0.129825  0.903862 -1.349723  \n",
              "1  0.056190 -0.138041  0.449199  1.088037 -1.379499  \n",
              "2 -0.832957  0.260175  0.418706  1.078343 -1.367759  \n",
              "3 -0.884188 -0.300911  0.359848  1.044725 -1.303134  \n",
              "4  0.129903 -0.050206  0.375976  1.082549 -1.345143  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e2451a2c-ad0d-44dc-97b9-9ac4d9960c03\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-0.092997</td>\n",
              "      <td>0.202148</td>\n",
              "      <td>-0.007205</td>\n",
              "      <td>-0.352916</td>\n",
              "      <td>-0.074040</td>\n",
              "      <td>-0.122343</td>\n",
              "      <td>-0.178363</td>\n",
              "      <td>-0.062866</td>\n",
              "      <td>-0.487053</td>\n",
              "      <td>-0.005380</td>\n",
              "      <td>-0.141541</td>\n",
              "      <td>-0.467556</td>\n",
              "      <td>-0.019149</td>\n",
              "      <td>0.041547</td>\n",
              "      <td>-0.068914</td>\n",
              "      <td>0.110674</td>\n",
              "      <td>0.129825</td>\n",
              "      <td>0.903862</td>\n",
              "      <td>-1.349723</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.255785</td>\n",
              "      <td>5.602331</td>\n",
              "      <td>-1.341444</td>\n",
              "      <td>0.670416</td>\n",
              "      <td>0.815663</td>\n",
              "      <td>0.586841</td>\n",
              "      <td>-2.331173</td>\n",
              "      <td>0.471600</td>\n",
              "      <td>1.660120</td>\n",
              "      <td>-1.737805</td>\n",
              "      <td>-0.356719</td>\n",
              "      <td>0.023257</td>\n",
              "      <td>-0.094070</td>\n",
              "      <td>-0.138989</td>\n",
              "      <td>0.056190</td>\n",
              "      <td>-0.138041</td>\n",
              "      <td>0.449199</td>\n",
              "      <td>1.088037</td>\n",
              "      <td>-1.379499</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.143654</td>\n",
              "      <td>-0.383194</td>\n",
              "      <td>4.448755</td>\n",
              "      <td>0.052446</td>\n",
              "      <td>-0.269873</td>\n",
              "      <td>-0.541622</td>\n",
              "      <td>-0.108931</td>\n",
              "      <td>-0.539619</td>\n",
              "      <td>-0.142732</td>\n",
              "      <td>-0.000877</td>\n",
              "      <td>-0.592055</td>\n",
              "      <td>-0.228287</td>\n",
              "      <td>0.028583</td>\n",
              "      <td>-0.143134</td>\n",
              "      <td>-0.832957</td>\n",
              "      <td>0.260175</td>\n",
              "      <td>0.418706</td>\n",
              "      <td>1.078343</td>\n",
              "      <td>-1.367759</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.364363</td>\n",
              "      <td>0.919496</td>\n",
              "      <td>0.306785</td>\n",
              "      <td>0.480296</td>\n",
              "      <td>0.196881</td>\n",
              "      <td>0.610795</td>\n",
              "      <td>-0.063386</td>\n",
              "      <td>3.420253</td>\n",
              "      <td>-0.171592</td>\n",
              "      <td>-0.574391</td>\n",
              "      <td>7.302566</td>\n",
              "      <td>-1.239325</td>\n",
              "      <td>-1.771304</td>\n",
              "      <td>1.324185</td>\n",
              "      <td>-0.884188</td>\n",
              "      <td>-0.300911</td>\n",
              "      <td>0.359848</td>\n",
              "      <td>1.044725</td>\n",
              "      <td>-1.303134</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-0.001694</td>\n",
              "      <td>0.404424</td>\n",
              "      <td>-0.338703</td>\n",
              "      <td>-0.084692</td>\n",
              "      <td>0.069832</td>\n",
              "      <td>0.064361</td>\n",
              "      <td>-0.153547</td>\n",
              "      <td>-0.093549</td>\n",
              "      <td>-0.070849</td>\n",
              "      <td>-0.250522</td>\n",
              "      <td>-0.149233</td>\n",
              "      <td>-0.129537</td>\n",
              "      <td>-0.047756</td>\n",
              "      <td>-0.108192</td>\n",
              "      <td>0.129903</td>\n",
              "      <td>-0.050206</td>\n",
              "      <td>0.375976</td>\n",
              "      <td>1.082549</td>\n",
              "      <td>-1.345143</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e2451a2c-ad0d-44dc-97b9-9ac4d9960c03')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-e2451a2c-ad0d-44dc-97b9-9ac4d9960c03 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-e2451a2c-ad0d-44dc-97b9-9ac4d9960c03');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4cC0dknyWXmN"
      },
      "source": [
        "---\n",
        "Scaling/Normalizing Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f1X-8DFZMt_M",
        "outputId": "b52959ab-41ad-4873-e14d-7f26aaa0ced4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train: <class 'torch.Tensor'> | y_train <class 'torch.Tensor'>\n",
            "X_val: <class 'torch.Tensor'> | y_train <class 'torch.Tensor'>\n",
            "X_test: <class 'torch.Tensor'> | y_test <class 'torch.Tensor'>\n",
            "\n",
            "Training: torch.Size([51581, 19]) , torch.Size([51581, 1])\n",
            "Validation: torch.Size([17194, 19]) , torch.Size([17194, 1])\n",
            "Testing:  torch.Size([17194, 19]) , torch.Size([17194, 1])\n"
          ]
        }
      ],
      "source": [
        "#Normalization Data \n",
        "#----------------------------------------------------------------------------------------------------------\n",
        "# Minmax without preprocessing\n",
        "# Minmax = preprocessing.MinMaxScaler()\n",
        "# X_train_Normalized= Minmax.fit_transform(X_train)\n",
        "# X_val_Normalized = Minmax.transform(X_val)\n",
        "# X_test_Normalized = Minmax.transform(X_test)\n",
        "#----------------------------------------------------------------------------------------------------------\n",
        "# Minmax with preprocessing\n",
        "# Minmax = preprocessing.MinMaxScaler()\n",
        "# X_train_Normalized= Minmax.fit_transform(X_train_preprocessed)\n",
        "# X_val_Normalized = Minmax.transform(X_val_preprocessed)\n",
        "# X_test_Normalized = Minmax.transform(X_test_preprocessed)\n",
        "\n",
        "#----------------------------------------------------------------------------------------------------------\n",
        "# Standardization without preprocessing\n",
        "Standardized = preprocessing.StandardScaler()\n",
        "X_train_Normalized= Standardized.fit_transform(X_train)\n",
        "X_val_Normalized = Standardized.transform(X_val)\n",
        "X_test_Normalized = Standardized.transform(X_test)\n",
        "\n",
        "# Standardization with preprocessing\n",
        "# Standardized = preprocessing.StandardScaler()\n",
        "# X_train_Normalized= Standardized.fit_transform(X_train_preprocessed)\n",
        "# X_val_Normalized = Standardized.transform(X_val_preprocessed)\n",
        "# X_test_Normalized = Standardized.transform(X_test_preprocessed)\n",
        "#----------------------------------------------------------------------------------------------------------\n",
        "\n",
        "#Convert to numpy then to torch \n",
        "\n",
        "X_train = torch.from_numpy(X_train_Normalized).float()\n",
        "y_train = torch.from_numpy(y_train).long()\n",
        "\n",
        "X_val = torch.from_numpy(X_val_Normalized).float()\n",
        "y_val = torch.from_numpy(y_val).long()\n",
        "\n",
        "X_test = torch.from_numpy(X_test_Normalized).float()\n",
        "y_test = torch.from_numpy(y_test).long()\n",
        "\n",
        "print(f\"X_train: {type(X_train)} | y_train {type(y_train)}\")\n",
        "print(f\"X_val: {type(X_val)} | y_train {type(y_val)}\")\n",
        "print(f\"X_test: {type(X_test)} | y_test {type(y_test)}\")\n",
        "print()\n",
        "print(f\"Training: {X_train.shape} , { y_train.shape}\")\n",
        "print(f\"Validation: {X_val.shape} , { y_val.shape}\")\n",
        "print(f\"Testing:  {X_test.shape} , { y_test.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C3UmdyVaWc2f"
      },
      "source": [
        "---\n",
        "Defining Dataloaders\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "pnr0p08ESkXE"
      },
      "outputs": [],
      "source": [
        "class ClassifierDataset(Dataset):\n",
        "    def __init__(self, X_data, y_data):\n",
        "        self.X_data = X_data\n",
        "        self.y_data = y_data\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        return self.X_data[index], self.y_data[index]\n",
        "\n",
        "    def __len__ (self):\n",
        "        return len(self.X_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "45Ta3rYVknAi"
      },
      "outputs": [],
      "source": [
        "training = ClassifierDataset(X_train, y_train)\n",
        "validating = ClassifierDataset(X_val, y_val)\n",
        "testing = ClassifierDataset(X_test, y_test)\n",
        "\n",
        "\n",
        "train_loader = DataLoader(training, batch_size=batch_size, shuffle=True)\n",
        "val_loader = DataLoader(validating, batch_size=batch_size, shuffle=False)\n",
        "test_loader = DataLoader(testing, batch_size=batch_size, shuffle=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dTrRsJbCWmG-"
      },
      "source": [
        "---\n",
        "Defining VAE Model, Loss and Optmizers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sgYYoP4DSnAB",
        "outputId": "ffee97b1-4ebf-41b2-e27f-270a41d44089"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reconstruction X: torch.Size([100, 19])\n",
            "Mu: torch.Size([100, 2]) \n",
            "Logvar: torch.Size([100, 2])\n",
            "Latent Space Z: torch.Size([100, 2])\n",
            "Classifier: torch.Size([100, 13])\n"
          ]
        }
      ],
      "source": [
        "class VAE(nn.Module):  \n",
        "  def __init__(self, input_dim, hidden_dim, latent_dim):\n",
        "    super(VAE,self).__init__()  \n",
        "    self.encoder = nn.Sequential(\n",
        "        nn.Linear(input_dim, hidden_dim),\n",
        "        nn.Dropout(p=0.2),  # add dropout layer with probability p=0.2\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(hidden_dim, hidden_dim),\n",
        "        nn.Dropout(p=0.2),  # add dropout layer with probability p=0.2\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(hidden_dim, hidden_dim_2),\n",
        "    )\n",
        "    self.mu = nn.Linear(hidden_dim_2, latent_dim)   # mu\n",
        "    self.logvar = nn.Linear(hidden_dim_2, latent_dim)   # log-var\n",
        "    self.decoder = nn.Sequential(\n",
        "        nn.Linear(latent_dim, hidden_dim_2),\n",
        "        nn.Dropout(p=0.2),  # add dropout layer with probability p=0.2\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(hidden_dim_2, hidden_dim),\n",
        "        nn.Dropout(p=0.2),  # add dropout layer with probability p=0.2\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(hidden_dim, hidden_dim),\n",
        "        nn.Dropout(p=0.2),  # add dropout layer with probability p=0.2\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(hidden_dim, input_dim),\n",
        "    )\n",
        "    self.classifier = nn.Sequential(\n",
        "        nn.Linear(latent_dim, 6),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(6, 13),\n",
        "        nn.Softmax(dim=1)\n",
        "    )\n",
        "\n",
        "  def encode(self, x):     \n",
        "    z = self.encoder(x)\n",
        "    z1 = self.mu(z)               \n",
        "    z2 = self.logvar(z) \n",
        "    return z1, z2                 # (mu, log-var)\n",
        "\n",
        "  def decode(self, x):\n",
        "\n",
        "    return self.decoder(x)\n",
        "\n",
        "  def forward(self, x):\n",
        "#  Reparamaterize\n",
        "    mu, logvar = self.encode(x)\n",
        "    stdev = torch.exp(0.5 * logvar)\n",
        "    esp = torch.randn_like(stdev)\n",
        "    z_reparmeterized = mu + (esp * stdev)   \n",
        "\n",
        "    x_reconstructed = self.decode(z_reparmeterized)\n",
        "    classified = self.classifier(z_reparmeterized)\n",
        "\n",
        "    return (x_reconstructed, z_reparmeterized, classified, mu, logvar)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "  x = torch.rand(batch_size,input_dim)\n",
        "  vae = VAE(input_dim, hidden_dim, latent_dim)\n",
        "  x_reconstructed, z_reparmeterized, classified, mu, logvar = vae(x)\n",
        "  print(f\"Reconstruction X: {x_reconstructed.shape}\")\n",
        "\n",
        "  print(f\"Mu: {mu.shape} \")\n",
        "  \n",
        "  print(f\"Logvar: {logvar.shape}\")\n",
        " \n",
        "  print(f\"Latent Space Z: {z_reparmeterized.shape}\")\n",
        " \n",
        "  print(f\"Classifier: {classified.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HLawvUR-SpJl",
        "outputId": "d6e22f89-9ddf-404b-d1fe-ef39c01743de"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "VAE(\n",
            "  (encoder): Sequential(\n",
            "    (0): Linear(in_features=19, out_features=12, bias=True)\n",
            "    (1): Dropout(p=0.2, inplace=False)\n",
            "    (2): ReLU()\n",
            "    (3): Linear(in_features=12, out_features=12, bias=True)\n",
            "    (4): Dropout(p=0.2, inplace=False)\n",
            "    (5): ReLU()\n",
            "    (6): Linear(in_features=12, out_features=6, bias=True)\n",
            "  )\n",
            "  (mu): Linear(in_features=6, out_features=2, bias=True)\n",
            "  (logvar): Linear(in_features=6, out_features=2, bias=True)\n",
            "  (decoder): Sequential(\n",
            "    (0): Linear(in_features=2, out_features=6, bias=True)\n",
            "    (1): Dropout(p=0.2, inplace=False)\n",
            "    (2): ReLU()\n",
            "    (3): Linear(in_features=6, out_features=12, bias=True)\n",
            "    (4): Dropout(p=0.2, inplace=False)\n",
            "    (5): ReLU()\n",
            "    (6): Linear(in_features=12, out_features=12, bias=True)\n",
            "    (7): Dropout(p=0.2, inplace=False)\n",
            "    (8): ReLU()\n",
            "    (9): Linear(in_features=12, out_features=19, bias=True)\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=2, out_features=6, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Linear(in_features=6, out_features=13, bias=True)\n",
            "    (3): Softmax(dim=1)\n",
            "  )\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "model  = VAE(input_dim, hidden_dim, latent_dim).to(device)\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "print(model)\n",
        "loss_fn = nn.MSELoss(reduction=\"sum\")\n",
        "classifier_loss_fn = nn.CrossEntropyLoss()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def mutual_information_loss(latent_representation, labels):\n",
        "  \"\"\"\n",
        "  Calculates the mutual information loss between the latent representation\n",
        "  and the labels.\n",
        "\n",
        "  Parameters:\n",
        "  - latent_representation: the latent representation of the data\n",
        "  - labels: the one-hot encoded labels of the data\n",
        "  - device: the device to use for calculations\n",
        "\n",
        "  Returns:\n",
        "  - The mutual information loss between the latent representation and labels\n",
        "  \"\"\"\n",
        "  # Reshape the latent representation tensor to have the same shape as the labels tensor\n",
        "  latent_representation = latent_representation.view(-1, labels.shape[1])\n",
        "\n",
        "  # Calculate the mutual information loss\n",
        "  mutual_information = (latent_representation * torch.log(latent_representation / labels)).sum(dim=1)\n",
        "  return mutual_information.mean()"
      ],
      "metadata": {
        "id": "-k0KXnR3yxzw"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6r4_reRyWuIu"
      },
      "source": [
        "---\n",
        "Train and Validation loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 390
        },
        "id": "lH7Muoa_Sr-U",
        "outputId": "87a6cec0-350a-4e55-c8b9-e3a3e82c84fe"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-23-f51ff341f36e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorboardX\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSummaryWriter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# Create a SummaryWriter object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tensorboardX'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ],
      "source": [
        "train_losses=[]\n",
        "train_accuracy = []\n",
        "val_losses=[]\n",
        "val_accuracy=[]\n",
        "\n",
        "dic = dict(latent_space = list(), mu_list=list(), logsig2_list=list(), y=list())\n",
        "\n",
        "\n",
        "from tensorboardX import SummaryWriter\n",
        "\n",
        "# Create a SummaryWriter object\n",
        "writer = SummaryWriter() \n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "  model.train()\n",
        "  train_running_loss = 0\n",
        "\n",
        "  z_list, means, logvars , labels_list = list(), list(), list(), list()\n",
        "\n",
        "  for i, data in enumerate(train_loader):\n",
        "    inputs, labels = data\n",
        "   \n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    x_reconstructed, z_reparmeterized, classified, mu, logvar = model(inputs)\n",
        "\n",
        "    # Compute the reconstruction loss and KL divergence loss ##########################################\n",
        "\n",
        "    reconstruction_loss = loss_fn(x_reconstructed, inputs)\n",
        "    kld_loss = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
        "\n",
        "\n",
        "\n",
        "    # # Compute the mutual information loss #########################################################\n",
        "\n",
        "    # # Convert the labels to an integer tensor\n",
        "    # int_labels = labels.long()\n",
        "    # # One-hot encode the labels\n",
        "    # num_classes = torch.max(int_labels).item() + 1  # Change this to match the number of unique classes in the labels tensor\n",
        "    # labels_one_hot = F.one_hot(int_labels, num_classes=num_classes).float()\n",
        "\n",
        "    # # Reshape the latent representation tensor to have the same shape as the labels tensor\n",
        "    # z_reparmeterized_mi = z_reparmeterized.view(-1, labels_one_hot.shape[1])\n",
        "    # # Check if any of the values in the latent tensor are nan\n",
        "    # if torch.isnan(z_reparmeterized).any():\n",
        "    #   # Print a message or perform some other action if nan values are present in the tensor\n",
        "    #   print(\"Latent tensor contains nan values\")\n",
        "    # else:\n",
        "    #   # Calculate the mutual information loss\n",
        "    #   mutual_information = (z_reparmeterized_mi * torch.log(z_reparmeterized_mi / (labels_one_hot + 1e-6))).sum(dim=1)\n",
        "\n",
        "    #   # Compute the mutual information loss\n",
        "    #   information_loss = mutual_information.mean()\n",
        "\n",
        "\n",
        "\n",
        "    # Compute the classificaiton loss ########################################################################\n",
        "    classified = classified.view(-1,13)\n",
        "    classification_loss = classifier_loss_fn(classified, labels.flatten())\n",
        "\n",
        "    loss = (alpha*reconstruction_loss + kld_loss*beta) + classification_loss \n",
        "\n",
        "    accuracy = accuracy_score(labels, classified.argmax(dim=1))\n",
        "    train_accuracy.append(accuracy)\n",
        "    train_acc = sum(train_accuracy)/len(train_accuracy)\n",
        "\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    train_running_loss += loss.item()\n",
        "    train_loss= train_running_loss/len(train_loader)\n",
        "\n",
        "   # log for latent space visualziation (gif)...\n",
        "    z_list.append(z_reparmeterized.detach())\n",
        "    means.append(mu.detach())\n",
        "    logvars.append(logvar.detach())\n",
        "    labels_list.append(labels.detach())\n",
        "\n",
        "   # Write the scalar values to TensorBoard\n",
        "    writer.add_scalar('loss/total', loss.item(), i)\n",
        "    writer.add_scalar('loss/reconstruction', reconstruction_loss.item(), i)\n",
        "    writer.add_scalar('loss/kld', kld_loss.item(), i)\n",
        "    writer.add_scalar('loss/classification', classification_loss.item(), i)\n",
        "\n",
        "  writer.add_embedding(z_reparmeterized, metadata=labels, global_step=epoch)\n",
        "\n",
        "  with torch.inference_mode():\n",
        "    val_running_loss = 0\n",
        "    val_running_acc = 0\n",
        "\n",
        "    model.eval()\n",
        "    # Iterate over the validation data\n",
        "    for X, Y in val_loader:\n",
        "      # Pass the data through the model and get the reconstructed data and the latent representation\n",
        "      y_pred, z_reparmeterized, v_classified, mu, logvar = model(X)\n",
        "\n",
        "      # Compute the reconstruction loss\n",
        "      v_reconstruction_loss = loss_fn(y_pred, X)\n",
        "\n",
        "      # Compute the KL divergence loss\n",
        "      v_kld_loss = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
        "\n",
        "      # Reshape the classified output to have the same shape as the labels\n",
        "      v_classified = v_classified.view(-1, 13)\n",
        "\n",
        "      # Compute the classification loss\n",
        "      v_classification_loss = classifier_loss_fn(v_classified, Y.flatten())\n",
        "\n",
        "      # Compute the total loss\n",
        "      vloss = (alpha*v_reconstruction_loss + v_kld_loss*beta) + v_classification_loss\n",
        "\n",
        "      val_running_loss += vloss.item()\n",
        "      val_loss = val_running_loss/len(val_loader)\n",
        "\n",
        "      v_accuracy = accuracy_score(Y, v_classified.argmax(dim=1))\n",
        "      val_accuracy.append(v_accuracy)\n",
        "      val_acc = sum(val_accuracy)/len(val_accuracy)\n",
        "\n",
        "  dic['latent_space'].append(torch.cat(z_list))\n",
        "  dic['mu_list'].append(torch.cat(means))\n",
        "  dic['logsig2_list'].append(torch.cat(logvars))\n",
        "  dic['y'].append(torch.cat(labels_list))\n",
        "\n",
        "  print(f\"Epoch: {epoch+1} / {num_epochs} | reconst_loss: {reconstruction_loss:.3f} | kldiv loss: {kld_loss:.5f} | classifcation loss: {classification_loss:.5f} | total loss: {train_loss:.3f} | train acc: {train_acc*100:.3f} % ||| Val Loss: {val_loss:.3f} | val acc: {val_acc*100:.3f} %\")\n",
        "  print(\"-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\")\n",
        "\n",
        "  #print(f\"Epoch: {epoch+1} / {num_epochs} | reconst_loss: {v_reconstruction_loss:.3f} | kldiv loss: {v_kld_loss:.3f} | Val Loss: {val_loss:.3f}\")\n",
        "  train_losses.append(train_loss)\n",
        "  val_losses.append(val_loss)\n",
        "\n",
        "# Close the SummaryWriter\n",
        "writer.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mu-g_vKRS7V8"
      },
      "outputs": [],
      "source": [
        "torch.save(model.state_dict(), 'VAE_Model.pt') # Save"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aa3Thi-cW05z"
      },
      "source": [
        "---\n",
        "Model Evaluations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OSD621NES9gA"
      },
      "outputs": [],
      "source": [
        "plt.plot(train_losses,'-o', label=\"Training loss\")\n",
        "plt.plot(val_losses,'-r',  label=\"Validation loss\")\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('losses')\n",
        "plt.title('Training and Validation Losses')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MhYdRnwjW7SS"
      },
      "source": [
        "---\n",
        "Latent Space Visualization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jRW82C1HTAkI"
      },
      "outputs": [],
      "source": [
        "print(\"Latent Space Visualization\")\n",
        "for i in range (num_epochs):\n",
        "  fig = plt.figure(figsize=(10,10))\n",
        "  z_arr = dic['latent_space'][i].cpu().numpy()\n",
        "  y_arr = dic['y'][i].cpu().numpy()\n",
        "\n",
        "  #Experiment 1\n",
        "  plt.scatter(z_arr[:,0], z_arr[:,1], c = y_arr, edgecolor='none', alpha=0.5,\n",
        "              cmap=plt.cm.get_cmap('hsv', 13))\n",
        "  cb = plt.colorbar(ticks=[0,1,2,3,4,5,6,7,8,9,10,11,12],values=[0,1,2,3,4,5,6,7,8,9,10,11,12])\n",
        "  #Experiment 3\n",
        "  # plt.scatter(z_arr[:,0], z_arr[:,1], c = y_arr, edgecolor='none', alpha=0.5,\n",
        "  #             cmap=plt.cm.get_cmap('hsv', 23))\n",
        "  #cb = plt.colorbar(ticks=[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23],values=[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23])\n",
        "  cb.ax.tick_params(labelsize=10)\n",
        "  plt.xlim(-5, 5)\n",
        "  plt.ylim(-5, 5)\n",
        "  plt.xticks(fontsize= 10)\n",
        "  plt.yticks(fontsize= 10)\n",
        "  plt.xlabel('z[0]', fontsize= 10)\n",
        "  plt.ylabel('z[1]', fontsize= 10)\n",
        "  plt.title(f'VAE train dataset with latent space Dim=2  Epoch number: {i+1} ', fontsize= 12)\n",
        "  # plt.show()\n",
        "  plt.close()\n",
        "  fig.savefig(f\"/content/drive/MyDrive/WEAR_LAB/Research_Pytorch/VAE_Images/VAEtrain_images{i:001}\" + \".png\")\n",
        "  print(f\"Latent Space Image {i+1} stored.\")\n",
        "print()\n",
        "print(\"Latent Space Gif being created...\")\n",
        "print()\n",
        "\n",
        "import imageio\n",
        "gif = []\n",
        "for i in range(num_epochs):\n",
        "  each_image = imageio.imread(f\"/content/drive/MyDrive/WEAR_LAB/Research_Pytorch/VAE_Images/VAEtrain_images{i}\" + \".png\")# here read all images\n",
        "  gif.append(each_image)\n",
        "imageio.mimsave(\"/content/result.gif\",gif)\n",
        "\n",
        "from IPython.display import Image\n",
        "\n",
        "fname = '/content/result.gif'\n",
        "Image(open(fname, 'rb').read())  # local"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_yhSCW0l98lK"
      },
      "outputs": [],
      "source": [
        "%tensorboard --logdir=runs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sl7Bo_dsuqR7"
      },
      "source": [
        "---\n",
        "Test\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sgihLGe_urdt",
        "outputId": "38047ad7-349d-458b-de3b-db8be24838af"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(130200, 19) <class 'pandas.core.frame.DataFrame'> (130200, 1) <class 'pandas.core.frame.DataFrame'>\n",
            "\n",
            "(85969, 19) <class 'numpy.ndarray'> (85969, 1) <class 'numpy.ndarray'>\n",
            "\n",
            "X_train size: 51581 | X_val size: 17194 | X_test size: 17194\n",
            "y_train size: 51581 | y_val size: 17194 | y_test size: 17194\n",
            "\n",
            "Training Feature Split: (51581, 19) | Training Labels (51581, 1)\n",
            "Validation Feature Split: (17194, 19) | Validation Labels (17194, 1)\n",
            "Testing Feature Split: (17194, 19) | Testing Labels (17194, 1)\n",
            "\n",
            "X_train: <class 'torch.Tensor'> | y_train <class 'torch.Tensor'>\n",
            "X_val: <class 'torch.Tensor'> | y_train <class 'torch.Tensor'>\n",
            "X_test: <class 'torch.Tensor'> | y_test <class 'torch.Tensor'>\n",
            "\n",
            "Training: torch.Size([51581, 19]) , torch.Size([51581, 1])\n",
            "Validation: torch.Size([17194, 19]) , torch.Size([17194, 1])\n",
            "Testing:  torch.Size([17194, 19]) , torch.Size([17194, 1])\n",
            "\n",
            "VAE(\n",
            "  (fc1): Linear(in_features=19, out_features=9, bias=True)\n",
            "  (mu): Linear(in_features=9, out_features=2, bias=True)\n",
            "  (logvar): Linear(in_features=9, out_features=2, bias=True)\n",
            "  (fc3): Linear(in_features=2, out_features=9, bias=True)\n",
            "  (fc4): Linear(in_features=9, out_features=19, bias=True)\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=2, out_features=13, bias=True)\n",
            "    (1): Sigmoid()\n",
            "    (2): Softmax(dim=1)\n",
            "  )\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "import torch   \n",
        "import torch.nn as nn                          \n",
        "import torch.nn.functional as F                \n",
        "import torch.optim as optim   \n",
        "from torch.utils.data import TensorDataset, Dataset, DataLoader\n",
        "from torch.autograd import Variable\n",
        "import torch.utils.data\n",
        "\n",
        "import pandas as pd \n",
        "import numpy as np\n",
        "import os                             \n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns    \n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import preprocessing\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import accuracy_score, roc_auc_score, f1_score, precision_score, recall_score\n",
        "from sklearn.manifold import TSNE\n",
        "from sklearn.decomposition import PCA, TruncatedSVD\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "df = pd.read_csv(\"/content/drive/MyDrive/WEAR_LAB/Research_Pytorch/S1_E1_A1_v6.csv\")\n",
        "\n",
        "X = df.drop('stimulus', axis=1)\n",
        "#y = df['stimulus']\n",
        "y = df.iloc[:, 0:1]\n",
        "print(X.shape, type(X), y.shape, type(y))\n",
        "print()\n",
        "\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "\n",
        "sampling_strategy = \"not minority\"\n",
        "rus = RandomUnderSampler(sampling_strategy=sampling_strategy)\n",
        "X_res, y_res = rus.fit_resample(X, y)\n",
        "\n",
        "X = X_res.values\n",
        "y = y_res.values\n",
        "print(X.shape, type(X), y.shape, type(y))\n",
        "print()\n",
        "\n",
        "# Data Split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.25, random_state=42) # 0.25 x 0.8 = 0.2\n",
        "\n",
        "print(f\"X_train size: {len(X_train)} | X_val size: {len(X_val)} | X_test size: {len(X_test)}\")\n",
        "print(f\"y_train size: {len(y_train)} | y_val size: {len(y_val)} | y_test size: {len(y_test)}\")\n",
        "print()\n",
        "print(f\"Training Feature Split: {X_train.shape} | Training Labels { y_train.shape}\")\n",
        "print(f\"Validation Feature Split: {X_val.shape} | Validation Labels { y_val.shape}\")\n",
        "print(f\"Testing Feature Split: {X_test.shape} | Testing Labels { y_test.shape}\")\n",
        "print()\n",
        "\n",
        "#Normalization Data \n",
        "Minmax = preprocessing.MinMaxScaler()\n",
        "#Standardized = preprocessing.StandardScaler()\n",
        "X_train_Minmax= Minmax.fit_transform(X_train)\n",
        "X_val_Minmax = Minmax.transform(X_val)\n",
        "X_test_Minmax = Minmax.transform(X_test)\n",
        "\n",
        "#Convert to numpy then to torch \n",
        "\n",
        "X_train = torch.from_numpy(X_train_Minmax).float()\n",
        "y_train = torch.from_numpy(y_train).long()\n",
        "\n",
        "X_val = torch.from_numpy(X_val_Minmax).float()\n",
        "y_val = torch.from_numpy(y_val).long()\n",
        "\n",
        "X_test = torch.from_numpy(X_test_Minmax).float()\n",
        "y_test = torch.from_numpy(y_test).long()\n",
        "\n",
        "print(f\"X_train: {type(X_train)} | y_train {type(y_train)}\")\n",
        "print(f\"X_val: {type(X_val)} | y_train {type(y_val)}\")\n",
        "print(f\"X_test: {type(X_test)} | y_test {type(y_test)}\")\n",
        "print()\n",
        "print(f\"Training: {X_train.shape} , { y_train.shape}\")\n",
        "print(f\"Validation: {X_val.shape} , { y_val.shape}\")\n",
        "print(f\"Testing:  {X_test.shape} , { y_test.shape}\")\n",
        "print()\n",
        "\n",
        "class ClassifierDataset(Dataset):\n",
        "    def __init__(self, X_data, y_data):\n",
        "        self.X_data = X_data\n",
        "        self.y_data = y_data\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        return self.X_data[index], self.y_data[index]\n",
        "\n",
        "    def __len__ (self):\n",
        "        return len(self.X_data)\n",
        "\n",
        "training = ClassifierDataset(X_train, y_train)\n",
        "validating = ClassifierDataset(X_val, y_val)\n",
        "testing = ClassifierDataset(X_test, y_test)\n",
        "\n",
        "##########################################################################################################################################################################################################\n",
        "#Hyperparameters\n",
        "latent_dim = 2\n",
        "input_dim= 19\n",
        "hidden_dim= 9\n",
        "output_dim = 19\n",
        "num_classes = 13\n",
        "\n",
        "num_epochs= 70\n",
        "batch_size= 100\n",
        "learning_rate= 0.001 #3e-4 #Karpathy constant\n",
        "\n",
        "\n",
        "#beta = 1\n",
        "beta = 0.005\n",
        "alpha = 1\n",
        "#############################################################################################################################################################################################################\n",
        "\n",
        "train_loader = DataLoader(training, batch_size=batch_size, shuffle=True)\n",
        "val_loader = DataLoader(validating, batch_size=batch_size, shuffle=False)\n",
        "test_loader = DataLoader(testing, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "\n",
        "class VAE(nn.Module):  \n",
        "  def __init__(self, input_dim, hidden_dim, latent_dim):\n",
        "    super(VAE,self).__init__()  \n",
        "    self.fc1 = nn.Linear(input_dim, hidden_dim)  # no labels\n",
        "    self.mu = nn.Linear(hidden_dim, latent_dim)   # mu\n",
        "    self.logvar = nn.Linear(hidden_dim,latent_dim)   # log-var\n",
        "\n",
        "    self.fc3 = nn.Linear(latent_dim, hidden_dim) \n",
        "    self.fc4 = nn.Linear(hidden_dim, input_dim)\n",
        "    \n",
        "    self.classifier = nn.Sequential(\n",
        "        nn.Linear(latent_dim, 13),\n",
        "        nn.Sigmoid(),\n",
        "        nn.Softmax(dim=1)\n",
        "    )\n",
        "\n",
        "  def encode(self, x):     \n",
        "#    print(f'encoder {type(x)}')         \n",
        "    z = F.relu(self.fc1(x))\n",
        "    z = torch.tanh(z) \n",
        "    z1 = self.mu(z)               \n",
        "    z2 = self.logvar(z) \n",
        "    return z1, z2                 # (mu, log-var)\n",
        "\n",
        "  def decode(self, x):\n",
        "#    print(f'decoder {type(x)}')\n",
        "    z = F.relu(self.fc3(x))                    \n",
        "    z = torch.sigmoid(self.fc4(z))      # in [0, 1]\n",
        "    #print(f\"z: {z}\")\n",
        "    return z \n",
        "\n",
        "  def forward(self, x):\n",
        "#    print(f'forward {type(x)}')\n",
        "\n",
        "#  Reparamaterize\n",
        "    mu, logvar = self.encode(x)\n",
        "    stdev = torch.exp(0.5 * logvar)\n",
        "    esp = torch.randn_like(stdev)\n",
        "    z_reparmeterized = mu + (esp * stdev)   \n",
        "    #print(f\"z_reparmeterized : {z_reparmeterized}\")      \n",
        "    x_reconstructed = self.decode(z_reparmeterized)\n",
        "    #print(f\"x_reconstructed : {x_reconstructed}\")\n",
        "\n",
        "    classified = self.classifier(z_reparmeterized)\n",
        "\n",
        "    return (x_reconstructed, z_reparmeterized, classified, mu, logvar)\n",
        "\n",
        "model  = VAE(input_dim, hidden_dim, latent_dim).to(device)\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "print(model)\n",
        "loss_fn = nn.MSELoss(reduction=\"sum\")\n",
        "classifier_loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "train_losses=[]\n",
        "train_accuracy = []\n",
        "val_losses=[]\n",
        "\n",
        "dic = dict(latent_space = list(), mu_list=list(), logsig2_list=list(), y=list())\n",
        "for epoch in range(num_epochs):\n",
        "  model.train()\n",
        "  train_running_loss = 0\n",
        "\n",
        "  z_list, means, logvars , labels_list = list(), list(), list(), list()\n",
        "\n",
        "  for i, data in enumerate(train_loader):\n",
        "    inputs, labels = data\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    x_reconstructed, z_reparmeterized, classified, mu, logvar = model(inputs)\n",
        "\n",
        "    reconstruction_loss = loss_fn(x_reconstructed, inputs)\n",
        "    kld_loss = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
        "\n",
        "    classified = classified.view(-1, 13)\n",
        "    classification_loss = classifier_loss_fn(classified, labels.flatten())\n",
        "\n",
        "    loss = (alpha*reconstruction_loss + kld_loss*beta) + classification_loss\n",
        "\n",
        "    # correct = torch.eq(classified.argmax(dim=1), labels).float()\n",
        "    # classifcaiton_accuracy = correct.mean()\n",
        "\n",
        "    # Calculate classification accuracy\n",
        "    _, predicted = torch.max(classified, 1)\n",
        "    correct = (predicted == labels.flatten()).sum().item()\n",
        "    classifcaiton_accuracy = correct / len(predicted)\n",
        "\n",
        "\n",
        "\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    train_running_loss += loss.item()\n",
        "    train_loss= train_running_loss/len(train_loader)\n",
        "\n",
        "   # log ...\n",
        "    z_list.append(z_reparmeterized.detach())\n",
        "    means.append(mu.detach())\n",
        "    logvars.append(logvar.detach())\n",
        "    labels_list.append(labels.detach())\n",
        "\n",
        "  with torch.inference_mode():\n",
        "    val_running_loss = 0\n",
        "\n",
        "    model.eval()\n",
        "    for X, Y in val_loader:\n",
        "      y_pred, z_reparmeterized, v_classified, mu, logvar = model(X)\n",
        "      v_reconstruction_loss = loss_fn(y_pred, X)\n",
        "      v_kld_loss = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
        "\n",
        "      v_classified = v_classified.view(-1, 13)\n",
        "      v_classification_loss = classifier_loss_fn(v_classified, Y.flatten())\n",
        "\n",
        "      vloss = (alpha*reconstruction_loss + kld_loss*beta) + v_classification_loss\n",
        "\n",
        "      val_running_loss += vloss.item()\n",
        "      val_loss = val_running_loss/len(val_loader)\n",
        "\n",
        "\n",
        "  dic['latent_space'].append(torch.cat(z_list))\n",
        "  dic['mu_list'].append(torch.cat(means))\n",
        "  dic['logsig2_list'].append(torch.cat(logvars))\n",
        "  dic['y'].append(torch.cat(labels_list))\n",
        "\n",
        "  print(f\"Epoch: {epoch+1} / {num_epochs} | reconst_loss: {reconstruction_loss:.3f} | kldiv loss: {kld_loss:.5f} | classifcation loss: {classification_loss:.5f} | total loss: {train_loss:.3f} | train acc: {classifcaiton_accuracy:.3f} ||| Val Loss: {val_loss:.3f} | val acc: {val_acc:.3f}\")\n",
        "  print(\"------------------------------------------------------------------------------------------------------------------\")\n",
        "  #print(f\"Epoch: {epoch+1} / {num_epochs} | reconst_loss: {v_reconstruction_loss:.3f} | kldiv loss: {v_kld_loss:.3f} | Val Loss: {val_loss:.3f}\")\n",
        "  train_losses.append(train_loss)\n",
        "  val_losses.append(val_loss)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sTKEGQ-wqK-a"
      },
      "source": [
        "![image.png](data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAboAAAE0CAYAAABaTfYtAAAAAXNSR0IArs4c6QAAAARnQU1BAACxjwv8YQUAAAAJcEhZcwAAEnQAABJ0Ad5mH3gAAF89SURBVHhe7Z0HgFXVtf4X03tvMJ3ekQ7SVUCavbeYGFvUtH8S3yNq1Fiez5cYNdaosRFRFAugIigI0ntnYHrvvTf+51tzDw7jzDDA3GHm3u+Hx3tnn7ZPufvba+219+51wkAIIYQQG8XB8kkIIYTYJBQ6QgghNg2FjhBCiE1DoSOEEGLTUOgIIYTYNIy6JN2SyspKKS4uFm9vb106QmZmpri5uen2zs7OltSeQXZ2tjg4OIifn5+4uLhYUjuXjIwMvT8+Pj7S0NAgZWVl0qtXLwkKCrJscSpFRUVSU1Oj99PT09OSembgPPn5+XqekJAQSyohXYvjowaW74ScFVVVVVog1tbWnvzEUldXp58AhTgKu46ybds2ef7551WwBg8ebEltm8bGRvn9738veXl5EhERIb6+vpY1PYMHH3xQdu3aJX379pXAwEBLahPmfcQ9xNIcXHd5ebk4OTnp/W3vHt95550qdpGRkVopeP/992X//v0ydepUyxan8vbbb8uHH36owoh8nQ7kBRWU5vmEWP7v//6v7Ny5U2bNmnVG78CZgPOizn6m7xmxD+i6JOfM/fffL4MGDdJlwIABEhMTIwMHDjyZ9s9//lML1jNh0qRJ8o9//EPmz59vSWkfFHAvvPCCFubh4eGWVNvgnXfekTvuuEM2b95sSWmivr5e4uLipF+/frJx40aprq62rDk9w4cPlz/96U/ym9/8xpJy7hw+fFjmzp17Sl4CAgLk8ccfl4ceeugnIt2ZXHvttfKvf/1LSkpKLCmE/AiFjpwzcAp88803uqBAg7g9++yzJ9NuvfXWk24r1PqxnA5YKB4eHmfkgsT2rq6uVi1QzwfTpk2TlJQUOXbsmFpvJnDtrl+/Xu8tKhe49o7i6OiobkwsnYXpDoUFagLryt3dXRdrgvsCbwJbYkhrsI2OdCqff/65vPTSS/KXv/xFLrzwQjl69Ki89dZb6i6DWxEF4YwZM2TIkCHy7rvvSmJiohaQcI1dddVVMnLkSC0U9+7dK19++aVMmTJFpk+frlbC999/L15eXup+g4U4bNgwufrqq9W1CfF8+umn1ZLE9hCBDRs2SFZWlgrgjh079PP222+XcePGaZsT8oJjrlq1SkpLSzUPYWFh6oq9+eabpXfv3paragL5zMnJkddee00SEhLUnQjrccGCBTJ58mQ9JgQJlgXyAQsHfwcHB8vll1+u1wJhgdWBvH388cdaOCO/X3/9td4TWG7YtznY5u6779b83HTTTTJixAhNh/D9+c9/ltjYWLXMcB24ThwflhTOt2jRIm33A9dff71ccMEF+glrEHlAReJnP/uZitPBgwflvffe03uLygraDQGsJTwzXMubb74pqampuj/uF659woQJug7P/d///rdai2j3u/TSS1Wk161bpxUXXAOeE54JtoM1ivPjPZk9e7ZeR1pamqxZs0bvM9bt3r1b3wfcPxzL399f89QS5A/b/PznPz9lGxRveJ5w0+LewNLEfZ4zZ46MHTtWrwPX88Ybb0hSUpLmD5WGK6+8Up9pcnKyfPLJJ7ov7hHcyqi4jRkzRp8lnjHeU9w7iDrerRtvvFG3w3P77rvvZPXq1XrNqIj0799fFi9ebLV2WNI6tOiIVUEbzbfffqttbij8UPhC9CAaaEe75JJLdEHB9tlnn8mRI0d0v4KCAhU7s7BFQbFy5UoVTrjqUJhCJJcuXXqyFr9nzx5NQ8GGwh7nhMWDQhbtQyhoIFI4FkBBD4sTAgixQYEKUUZ7Etp8WoLzoGDEcbA98o2CEwUdCkIAy2LTpk2yZMkSFSacF3nBPUChiO3RLgYxhFBcdNFFGqwB8W7L9YjzoR0NInD8+HFNw7YQFxzziiuu0GvEAiFDviB0EHHcs9aAsONe4nimgD/55JNaWONcqFDgfMgbwDY4JwrwmTNn6oKKC6593759KqaoeKA9DwIBAUSlBXmHCCCfuH+5ubl67agoYLtRo0bJli1bVOiRh4qKCn3uH330kQod7g+OgfV4vmcK8oxn8cMPP6jI4Jx4/l988YW+a4WFhSpkeEYQS4gztsO7gHV4rhBb5GPhwoWaX6zDteC6ULnA8fA+wN2+detWvefm+4v98X7NmzdPjx8aGqr3mHQtFDpidVCzhThddtllWlNGAdinTx/9DmsCtXC07aDgQS2/LVCjRmEKyw/74ZgowFoTJYDCGQU+Ci9Ycrfccou2c8FiQUGP7xAmWEm33Xab5qE9tyfWwVqAsKBWj2OiQEfhjcLQBAUZhALrcFwIB0QB1wbhwLYQY+yP64AYYnuIaFvgGLAgIUywVnEcFLSoPKDwRWQkClJYEzgu7hFEB9bE6UBeDhw4oEICCxD741nBujWDiSCi+BvPDNeEbVC4oyIC4YbVCssO9xvWErZBpca0JgGuD+IMqx+igW1wH6OiovTZm5UcAJEzj4NrwTODBXumQDhhrcFChSWL8yGfyDeeP94d3EdY4xAjWPK4RlRCsG96erq+I7A48axwf9EODfFFRQrPAyKIdwvvESy9r776So+Pyguee3R0tHoecG7cX9xL0rVQ6IjVQaGAAgA/ePzIUYgB04pbtmyZFmSwIGABmhZaS2BNDB06VGvFKHRRQEKwsLQGCi8UWHBtIg9wK6HgRu0d4oQFBbRZS4frDPk089cSCBjatiA0KMzgeoyPjz9ZoJn5xrlQyCOfcG/huDgm9oOVAFcZzon7gW1hCcDKxbHbAqKObXAu85wQposvvvhk2yQKZhTepqsNYohztXU/TVDYw7pDPuHWg+iagURm1w6IPNxtKPhXrFghy5cvV9HCM8TSEWBdwfrB84Ko4NgQ6tGjR2ulBNY4wD3DM4MLF+dEPgBczae7lubADQmRgoijEgALG+eE6xcCjGvGOwIrGHmCAON9hLsS+cF9wDuGfWABfvDBB3osCDbWw9UJyxT3BPcD2+BeQviRVzwvtJ9iG7zjcMm29a4S60KhI1YHhQkKL9NaQiGAghhuRISvw00F4YDQwWprqzBDwWOKEEQBoonCDBZja6Dwh4ABiBQKTXxC7GDF4Dw4npkvrINo4LM1UFCjoHvllVe00EO+4bqD8CAPZr6xP6wp87hmPs0CEtdo5gvgWpC39oQO+Rw/frzme/v27VrI4n7B6sH58Pd//vMfbWNDvlDownJEnnHu9jDvYctrR56wABTgcMvhmcFdjHOsXbtWxamt+98SXDvuPY6J6zHPhecEcF8A7oMpsADb4t7i/p2p0CFv+MS1mc8D58d35AUW6A033KACj/sFQUL7Id5PvLdoP8Q9husV7yquH/cBrknsD1GE+xL7QezQRQQWH/IPAYcbGe8tXNd4Njg2KkW4F6TroNCRLgeWANpcULBBNGAZPfXUU1pzP5OC7FxAjR4FLKw7WFkoeGARQTDaKoRgIaHWD2vqiSee0IIP0aUTJ07U9R3JOwpPuD9haUG0UAjDskQeUHC2B4QOBTQKTbT/oI0TARXAbL+E+wyBF6+++qq6y8Dp8oWCHxYyLBNYHLh+WELIF+4PwHcIKcQJ/eIgdAg4ghvaBOsg6m1VVnC/ISy4Tlw/tsN3WPO4rpb9B88GnNdccEzcI9xvVEZwTRBLuBVRATDbyyBK9913n/YbfOyxx7QCgQAaPBPsC5cn3lO03+K4cAdDrJBfuDTRrQVWNKxBfOK9gOcBzxYegocfflhef/11dW9++umnKqine9akc6HQkS4HBQAKUxSwqL2j0ICVAJHpKlCAwT2GAhzWDwo/tLkgurOtQgiFHApnFNjINwpCuPHgquooEBQE0sDFiAXiiWs3g0zaA25YuBchcgg0gTvOtHCRZ9MtjAIdATEItOkIsD4h1hA67INPiGnzoBxcO0QCljmuHe5KWOGHDh3S9QDnRuGP5wirHXnCszbBvnDXokLz3HPPqdih3RLnwj2FO/dcQF5N9zAWiDbyinYxCDPyaooYLDIEpmAbXLOZZ4gj8oJrgRsd9xrPF9vhHuCdNZ8/LDbccwS74P3Bfcc1IbgGFQS0OcLCw/00n495bNK1UOhIl4P2JnQER+GCwg2BCShs2xqKylrA4kFhh9o62rreffddLRRRw2/uwjNBewtq97DE4JJCkAsKVozE0lFwbLTf3XXXXfLAAw+oawzuP7QVwtprD+QJFhQED65PBLGYwP0GK/X//b//p+mwmBG40xFQAEOAcB9gjSC4AvcCeUUbFYBA//znP1exgMDi3sEtCOE1gYV03XXX6QABaHeExYf2qebgPH/961/VikOwjhmKjy4MuK5zAd1LYOHCdYgF+UR4PywqtM/9+te/1vcO4or8I8AH4ogKBwJQ0HZ3zTXX6LZ4J+FyhFDdc889ug7vCsQQwTFoP0TkKbaH+xLvArbBc4BrGe8IKnBwdcLqQ77gBUCwC545RJ90HexHRzoV1HxRW4YooOBGQYIABPyNghOglo9004WEghYWFvbFJwQPtWMcB64nFOAQFNSSsc4UBKShMEHhiZo2XKJoi8E+sD6wPWroKIBNUMtGxCfygnxgG5wHFibyAlckgggw2gs+m4OfCgp3uC6xLWr1OBcKNRRcOC7Scb1mvnF+XAvOg9o88o+8mXnHMbEtjgvxgmsP27UFClpYgdgP5zMLTNMlh/UA9wj5Q95QsYBIwtrA9sgXrhd5QDpEDMdDPmGpwfow2+vwbJA//I1j4dqQV6TjHmJb5Bv3GMfEM8Qx8B3PEvvCMsJ9QH7Ne4i84ng4Byo52BbHwTpsj/2xPdbj2mAVIQ94j1oDggrXc3PwTiBfOD7yhHuDZ47j4D4j/7DQ8RzwfLCuubsT12i+H9gO63BfkQfzvuM9hvWIe4f9zXcZC94FrEO+cN3ID+493gFcF+k6KHTEbkEBh0IIBRsKKNTs0akZlgGiAlEoEUJ6PhQ6YregXxbah9CPCj8DWBiotWO0EbjsIH6EkJ4PhY7YLQhEQRi52TcKbUUIykBbCwMGCLEdKHSEEEJsGrsSOjS+o/beXmM/IYSQngcCmBBghO47LbEroUMfKYxXhyF/CCGE2A4ILkOkNAY2aIldCR36tzzzzDM6egEhhBDbASPTILjsxRdftKT8CDuME0IIsWkodIQQQmwaCh0hhBCbhm10hBC7BEUfhvbCsGXoR0m6Pxg6DX1cMaxbywEd2EZHCCEtMEUO43ViRBwsGB+US/dc8HwAxhDFGKToTtBRaNF1kOKKWknLL5fc4ippaGwUTzdniQ31kTB/d3HgAK2E9DgwzikGyMaIOBismQMtd38gbnhuZlcCDJRtQovuHCmrqpMd8Xny9rdx8swne+Spj/bI8ysOyJe7UiXHEL76RrupKxBiM2C2ASwUuZ4DLDs8L7iaz8RGo9B1gD1J+fLZliTZeSxXKqvrpb6hUbIKKuTDDfGyek+6IYScLZiQngpFrmdxNs+LQtcBNhzMkrj0YmloZrmhMlFdWy/LNydKcTmFjhBy7sDCxJx8rS0dCZiBlYNjdHRbtE92Jjg32j7x2Z2g0HWA8spaqan76YsDsSsuq5EGw8IjhJBzAQKxd+9ena0cy/jx42XcuHE6Yzz+fv75508rYJjodfXq1Tpb/OnAzOi33nqrimhngfw/9NBDOtxid4JC1wE83JzFxcnR8tePwID29nQRB0e6PgixFw6kFspzXxyQX72yUe59eYM8++k+2ZtUYFl79iBcfvDgwSpSWC677DKZO3euLF68WP+++eabNfKwvWhDTCJ84YUXynXXXWdJaRvM4P7UU0+dEtBxrkCIMds6RLs7wajLDvDlrjT5ZHOiHM8oNkzyptsFN7GLs6Msmhgjt8wcIEHeTVPrE0J6BmVlZRp1GRsba0k5PQdTi2TZpgTZm5AvxeVNlpCPUdkdERMo10/rJyOjAzqtze+FF17QyYAhROg7BgFBaD3EcNiwYTp4Mf6GQEIQMZciBGb37t2SmJioA9h//vnnGqGI6zSvdfbs2TrnYkpKijz22GMqovj+9ddfa9h+ZWWlujVxvCuuuEKFFbO+fPTRR7ouIiJCg0IGDRokCxYssOS2CZSx77zzjlx55ZUyffp0zctXX32lM8dgZgHkKSYmRjIyMuTLL7+UuLg4vV84Ftbh/K+++urJvo0zZ87U4wQHB1vO0OQePX78uB6n+Uw0jLo8R8b1D5JLx0TK0KgAcXNpsuycHB0kNsxH5o6OFB/3zqsREULOD5vjcuTjLUnywcb4Npcl64/JzmN5UlhWrW32WCB4u+PzjHXH5T8bE1rdb/nWJNl2PNdypjMDIrR161Yt/MeMGSN9+/YVDw8PGTt2rEyePFkts127dsmhQ4dU+FJTU1WYIFAQhO+++078/f11Xxxr3bp1KhY43po1a3Q7CNE333yj4g8RhID88MMPkpaWpgL70ksv6THgTsV+27Ztk6SkJEsOW+fw4cOyadMmFU3k1d3dXV5//XUpKiqS77//XgoKCmTIkCEyYcIE6d+/v4roli1bVJBHjhyplilEtTMmQabQdYAQX3eZPqy31thunjVQFk6IlrAAD2k0HmCgt6shenRdEtLTOZxeJD8cyZb1B7PaXHYYIldaUaPt8yb4Xo4uSMa671vZB8sPR3IkLrPEsseZg5FAIBaLFi1SwYJowBKCCEGcMFM+RK01/Pz8tJ3vxhtvlNDQUBU7WIotgWWIKcyuuuoqFVAEqsTHx0t2drbs27dPrcbrr79exQ7HPB0QOuyL/W644QZZuHChCiuEDgv6w+E4uC6IHaxEXAtE15ztH0IIS/BcodB1kFA/d5k1oo/8/GLDxDaWiYNDJT2vQn3zVTUcPoiQnk7/MF8Z1y9IJg4MaXPxcndq1TWJNA9XRxk/ILjV/cYax+0bevYFNqw2dJDGeWD5wMKDpXb06FENQIEVBNFrjX79+qlYuLm5iZeXl7bz4RgtgQjCRWhuB3GF1YXjQ5ACAgLUukI+sO3pgGAhvzg/3K9wNcLixIIgG1iIR44cUfGD9QgrE0IbFBSkFumqVatUYGFBnisUurMA7XGXjIwQXw8XWbEjRbJ0tBS7aeokxCaZOay33DJjgPzCqMi2tYyMDRIPN0PsLPuYuBsiNzQ6QH5+0cBW97t5en+ZOjjMsvWZA2vHHNsR1tCKFSt0Ju0///nPcvfdd0tUVFSbQSrYzxw+yxTp1sL/cY6WIg63I4QPkZkQKOwHqwvW2OnAfgCCh7xBsJAXnAdWHNrkLr74YnW1LlmyRK0/tNU9/PDDMmnSpJNiB6vyXKHQnQXOTg4SFeQpc8ZFytHUItmXWCCllexLR4its2B8lAwI9zOErcmyw4LvaK+/YlKsISjWb8bAOU3xgjhs2LBBgzusASwxtJMhMARtgAhyQXsgxMkUz7aABQexQ/4SEhLUakMaIkPT09NVMBEcA1doWFiY5ObmqlsVlunAgQNlypQpOgpKR0T1dFDozhIvd2e5ynixg3zcZMXOFEnJK9faDyHEdpk4IERunTVQxgwIFm8PZy0HRsQGanPGlMGhnTruLSwf05LDpykscO2hzQvRiehyAMvH3AYiiO3M7+YxTJqvwwJXpPm9ueVnbocFLsZHHnlEo0DRzoeAEdMV2hLznPhEOx8sN0R+Ip9vv/22PProoxISEiJr166VX//613L55ZfrdcAVikhS9L9DOyDaCd98800VRrgzzxV2LzgHMBTY8m1JsnR9vMw3anoLxkVLb38Py1pCSHcGFsWZdi8AdcbvvqauQX//wMkQBVcXR3F27Fy7AQEjKJ7hLoTwwLqCGCEN3QjMNjmIFVyDiJTEgiASrEc7G9riIDpIhwDhmNgWUZs4rhn4AYsNrklsh/NgfxwH58Pf2A7nxbJ8+XLtbD5jxgyZM2eO5sEE+5nHQb5wDJzTvAZYaDgmtoE7FOlm/kwXqRkog3QE3WAdvptgH3Yv6EIcjRf74hHhEhXiLZuO5sjR9CLjIdCqI8SWgaB5uTmLn6erLrDqOlvkAAp5CBIEC58QCIBCH+KD4BAssK4QLILtISYQDKRhOwgL9oXIAWxjBqTgeLAOsR1ECfvguAB/Y18ICcQKfewefPBBuffee7V7AlyLCChpSfPj4LjY3wxkwSfWIx35MNNhMSKPyBPSzetCOq4F258rFLpzALc/wMtVZo+OkBMNJ2RnfL4k5ZU1rSSEEBsA4oRQfwSP3HPPPfLAAw/IJZdcokLVU6DQnSOobSB8uH8fXzmWUSz7kgqkpr7jEwISQs4vdtR6c1bA0kIn9alTp8pFF12kbW/h4eGafj44m+dFoesE0N1gytAwdV/sTcyXxOxz7/dBCLEuqKRiQXsRxa5ngPY5PC8z4KWjMBilkyiprJX31h+TPQkFMnVYmNwwtZ+4uzT51Akh3Q8EPphBFmgbAp3RHkSsA54ThA7PDc8JQTRmuyVoLxiFQteJbD2eK8s2JkiD8TDumD1ERkQHWNYQQrobKPpQaGLkD0QLku4PBA6BLqbINa+YUOgsWFvoqmrr5ZMtSbJqZ6qM6x8s9y8YJq6tTO9DCCGkc2H3gi4CrsoLYgNlQG9f2Z+YLwdSCi1rCCGEnC8odJ0MRG7y4BCprGuQjzclnexUSggh5PxAoetkMBnr4HA/mTQoRCdq/f5IttTVU+wIIeR8QaHrZNA02jvAUyYNDBU3Vyf5bEuSFFfW6tx1hBBCuh4KnRVwM6y6/r19Zdqw3hKXVqQzF1dUc846Qgg5H1DorIS/l6uOZu7p5ixf7UyVpRvi5ZPNibIjPk8Ky2ssW7VNcUWt7ErIN/ZJ0n0/35YsxzJLOjTqSkZhhXy3P0OW/ZCgy/qDmZJZ9NOJFltSXdsgRzOK5dOtTedcblijmFiWUxARQnoyjo9i3gQ7AXM2bdq0SaeBsDb1jY2SX1ojW47mSGJWqexLzFfRyC2pEjcXJwnycTc+W+96gM7nOxPy5POtybJqZ4psOZIjB1OLpLKmXoJ93cXHw0WcWhlEFs7RnOIqWb07TT4z9v1uX7qOv6lTCBnrMLMChLc10DUiLqPEENQU+dQQuM2Hs3U4s4LyavFyd5EAbzdxNSxVQgjpjmC29aSkJJk/f74l5UcodFYir6RaVhoitfNY7snZxxGBmW1YVsUVNTrzwQnjX0FZjVp4RYYFh3SIHATxS8MK3HU8V2rrGlWkagxrKzEHQ4v1UmsRjYEQvopmS3l1nazZm6HWX0Z+hZ4XS5FxjizjvK6GwIYHeqrlVl3XIDXGsfXTsBKTcsq0/98aQySrDdHDORFEk1FQaYhgg4T5uUufAE9cxk/AebOKqoxtyyXXENqyqjrj+nqpC5cQQrqC9oSOHcatxP7kAvnvd7dLSRtuSsxK7O/jKs5OjuKii0PTYohDumGBZRcaQtXw00eDea8mDQmT3gFN896Z4wJggADDiJTVu1KkpKLuJ9MFYeZjWINXTukrjsbG+BuTITsa/8PoAgmZJWoJVhmC2RIPwwq8cnKsXGvsi22xH/bHd5xnt2GtQpj3J+VrnmN6+8jlE2Nk9qgIFTvkjRBCrAlHRrHQlUK3Oz5PfvP6JrWMWqNPkKcMjQ740brCp+V7YWmVVBhWUVvoLMatiYdxstNFd7Y1AzKsy/Z29XR3lgAfN51V2cfdRXw8ncXb+IQVeiCxQPINS87UVghgkK+b3HnpULl4RB+6PAkhVodCZ6G7WHSw5uaMiZR7DCHA7ccDaHoKTWLzzrpjsmpHilS1Eqnp4+kiDywcLiNiAo2/jI2b/tMFrsaH3t8umQU/tQbRphcV4iV/vOoCacA5jcV0bcIq259cKJ9sSpTK6p8KrJNhaYYbwhzq7ykVxnpEkFbW1Gr+cM5aY2lpQer5Qr3lhTuniJ+RZ0IIsSbnTegwMy2mPMeJMUo4wFxGCxcu1LmMMGstFlgAEKD+/fvr9AsYZBX77NixQyf3w4y4Y8eOlTvvvFOPAT/sv//9bzly5Ij06dNH5s2bJ3PnztXjtEdXCh3axD7enCjLDfFo3mEcrsJR/YLkuqn9ZOqQMEvqqWw9lqvRkjuP5xmC9eO+EJzLJsbINRf2lQhDeE7BeIoQMIy1iYGl0VZmPlpYcbAgrzHOedn4aN0Yq8wHj+8peWUawPL1ztRTRnNBW+KkwaEy1xDmAb19ToqjLsZ2T364W5JzfzrZLJ4Egm0+fHCOBHj/ON09IYRYg/aEzqrBKPX19VJeXq4ChEn7hg8frsEg5hTu+GxoaJCEhASZMWOGhIWFqQCWlpaqAGIq9RtvvFFGjRolgwcPluDgYD0uLgRTrOOYOEdaWppOBIjp19ujK4NR4K5DmxhK/NzSKqmta1BLbnS/YJk/LkrGGGLXVrCGj3uTWxBuTASrQFR8PF1lzuhIWTAuWiIN0cLcd7ivzRe0m4Ua54Q4oXsCLC9YVv36+Mq8sVFy0chwPbajcY+Rbi44FqIxA33c1P2YXVxp3NdG8TC2nTgoVM851sgvrsfPyAdmVQ/0dtO/vz+UpYE3LV2mEFcvDxe5anIspysihFid8xZ1icLX1dVVYmNjZcSIETpL7YYNG1TgBg0apBYc5oE6ePCgipYpdBUVFbJt2zZdf8MNN0hMTIyKHCwUCOcrr7wic+bMkUsvvVTPkZKSotYjhLQ9ulLoYLn5eDhrpGJMiLchbMEy0bCMpg7tLcOj/VUw2gIiCSsoPMhLBoX7yvgBITLZ2Bcd0GONY7XV5gUrCoIVYghQdLC3jIgJ0NnPLzQsx3H9g1QE2wJi5+vpolGZfUN9ZKyxPSy5aUZ+B0f4qUC2Rm5ptWQWVkh51Y9uVuORaD4uGhWhI8QgyIYQQqxJe0Jn1RIIbkhvb28VKQgS5n6CIGE+IbgkYYHBLdkaVVVV6mpcsmSJWnc5OTkqdLm5uSqGmI/Iw8NDLTkcKzEx0bLnqaSnp8uaNWvk/fffl2+++UZnp+0qIB59Q71lvmFNXTOlr1wxMUYtI/92RM7E17CGRscGavQi9l04Plr6h/l0SDT6BHjIjOG91ZpCtOS0oWES5tcUpdkesDAHGtbfognRcu3UfnrukYZYtiVyYIYhvjOG95HIYC9xtuQNkaTRxnUvHB/FQBRCyHmny6racDGuX79eJziMiopSt2RbQAgHDhyo1t6ePXtk3bp1smLFCt0Xbk2kOzs3Fb6wGGEhwgpsDViAsPgOHTokycnJmg/SecBahVv0skkxMnt0hLpkYY36ebmqaDo5tt9uSggh1qZLhA7iAvfksmXLZMKECRpYYgpVa8AK/OUvfynPP/+8PPzwwzJmzBhZunSpFBUV6X44HqZUB2jjg6UHsWsNtO3hWE8//bTcddddbVqQ5OyB1XqDYQEuvnaM3D1/mPTr7SuZ+eXaTsjBrAkh5xurCx1ECW1jTz31lAaVzJ49W3r37m1Z2zpwTcItiYATiB7a6Hx9fdV9iSAWWGmw4CByiOaEmzMkJMSyNzmfYASVC/oGqshtO57LKYoIIecdqwsdxOmRRx5RcUMEZUREhGUNwtpPre2bf5eVlUllZaVababrEceByzM0NFRFD2l5eXnaxSAzM1PGjRun+5LzCyIyh0b6Gxa2gw4sjT52hBByPrGq0JWUlMiWLVtk+fLlsnHjRrnlllu0v9vf//53DRCBO/G2226TtWvX6ufNN9+sXQXi4uJk8eLFav1dffXV2j73xz/+UQUOQS0PPPCAHg/r4A5FtOUFF1xgOSs5n+D5YADo0f2DZX9C0yDWnGWdEHI+sWqHcbgt4VpEPzm4IVEIYkEgiqenp1pusMrggkQbG4JM0AUBkZmIroR7Etsj4ARdD3x8fPS4cFXCHQprD+sQ1QmX5unoyg7j9gwGeYbb8vElO+Wu+UNlwdiodrtTEELIucIhwCxQ6LoGDAeWVlAhD76zTYJ83ORPV46SqGAGARFCrEd7Qtdl3QuI/YARWvw9XbSDfGpumaTmlet8d4QQcj6g0BGrgMllZwwN0wCjfSkFOuceIYScDyh0xCpgVJghEX46jBlmRsDM5+xTRwg5H1DoiFXo1atpzE6Ml5lniFxaXrnOiE4IIV0NhY5YjV7GP0xF5OXmJAdTiySjsNKyhhBCug4KHbEasOr6hXrrgM9xmSWSll9uWUMIIV0HhY5YFfSDHD8wRE40NEpKTpkUVTAohRDStVDoiNUZ3z9YgnxcDauuWBKyfzobOSGEWBMKHbE6mAgWs5znl1ZLfGaJzphOCCFdBYWOWB10NRgWFSDuzo6SlFOqXQ0IIaSroNCRLgF96voEekpGQYUczSi2pBJCiPWh0JEuIdTXQ2LDfKSyrl6OpBVJbX2DZQ0hhFgXCh3pEtDVYFC4nwR5uUlSdolkF7NPHSGka6DQkS5jgGHR9e/tK7kl1bIrId+SSggh1oVCR7oMHw8XiQn1FgdHB9l5PF+n8yGEEGtDoSNdSkyItwzs4yuZBeVyNJNBKYQQ60OhI11KRKCnRmBiFvLNcTmWVEIIsR4UOtKluLs4SWSQlwT7eciu43lSVdsgnL2HEGJNKHSkS0H0Ze8ADxkRHSBZ+RVyKK1I6hsbLWsJIaTzodCRLifQy02GRfpLL0cHWXcwU2rq2KeOEGI9KHSky3FzcZSIIE+JCvGWHXG5UlxRy/EvCSFWg0JHzgv+nq4yaVCwZBdWyLZjuXIwpVCOZRRLVlGlVNfSwiOEdB4UOnJe8HJ3llHRgYJIlJdXHZAHXv1BfvOvzfLGmqNyOL1I6hrYbkcI6RwodOS8UF5VJ/sNK06kl9TUNkqjIXhllbXy3d50WfZDogapEEJIZ0ChI+eF3JIq+Xxrkgpcc+rqG2V/coFsPpxtSSGEkHODQkfOC7V1DZJd0PrAzuWGZVdYWm35ixBCzg0KHTkv9HLoJa4ujpa/TsXR0UGcnVtfRwghZwqFjpwXfD1cZMKgUBW15jgYAhgV4iWDI/0sKYQQcm5Q6Mh5IdDbTRaMj5JxA4LFw81ZevXqJU6G6MWE+sjMEeEytl+wZUtCCDk3KHTkvODh6iSjY4PkxhkDZOqwMPFyc5KIIC+ZPTpCZo8K18GfCSGkM7Cq0DU2NkpFRYXExcXJoUOHdElPT5eqqiqprq6WjIwM2b9/vxw4cEAqKyvlRLMIvJKSEklMTJSDBw9KfHy8lJeXW9aIfkca1iUkJOi2pOfh4uQg4/oFyb3zhkmYv4cMjfKXiQNDJJwiRwjpRKwqdLW1tXL48GH5wx/+IPfee6/cc8898ve//12OHDmiIvbWW2/JzTffLFdffbUcPXpUhRE0NDTI+vXr5ZFHHpE77rhDFi9eLJs2bdJ1YPPmzfLwww/rOmzz3Xff6T6kZxLo5aodyPPLq6W0qtaSSgghnYNVhQ7tLqGhofLYY4/JmjVrZOXKlVJUVCQbN27U9RC4Rx99VEaNGqV/m2RmZsqGDRtk3Lhxus+1114rzz33nIoZlhdffFEWLVqk66ZMmaKiCOuQ9EwQgBIa4Cnl1fVSWllnSSWEkM7BqkLn4uIiffr0keHDh4urq6v4+PhIRESEuiixbsCAARIeHq6C2Jzdu3eLv7+/7hcYGCjR0dHi5+cn+/bt0wXHiYmJ0XVDhgyR4OBg2bVrl2Vv0hMJ83eXiuo6HR2FEEI6E6tbdE5OTipqoKCgQNLS0sTDw0NCQkLE2dlZ17ckLy9P3NzcVOwcHBx0+4CAALXasCDd09NT10EA3d3dJSen9dmq0QYId+ldd90lzz77rJSVlVnWkO4E5qhDz7kSQ+gqa+qbEgkhpBOwqtA1p6amRt544w0JCwuTkSNHqlC1RV1dnYqYKYLmdxwDCwQSaQDpEFTs0xo439SpU+XKK6+U6dOnq2VJuh/hAZ46+3hhWbUUVdRYUgkh5NzpEqFDhOWSJUs04nLmzJnqbnR0bHvkC1hw9fX1uh/Ad0RlwmWJBd9NYcM2WN+WcMJynDBhgsybN08mTpx40rok3Ys+/h7i6eokBWU1hthR6AghnYfVhQ5dAdauXasBI7NmzZLx48eLr6+vZW3roP0N+8FNCQuusLBQ3Z79+/eXfv366d9YsA6BK6WlpRIbG2vZm/RE/L1cxdvDRV2XheUUOkJI52FVoYPVhX5uiJiE1QV3I/rMoV9ddna2dj3YunWrft+2bZts2bJFrbWhQ4dqGx0CT77++mvZs2ePBrVAALHgu7kOn3BHDhs2zHJW0hNxdnSQQB9Xqa5vlCIKHSGkE7Gq0MGtaFpcEL0PP/xQXnvtNbXujh07ppbeZ599piL46aefqnuzuLhYoyjRnob90dcuJSVF+8xBKOHyvP3229XawzoEl8yYMUNdlKRnE+TrLg0NjVJcXov5WAkhpFPodaL5cCQ2zvbt2+WZZ56RTz75xJJCuhNr92fIRxvjZVhkgNwzb6i4cgYDQkgHgdH07bffaj/rlnRJMAohHSHEsOi83Zva6fI4Hx0hpJOg0JFuQ6ifu07fo0JXUmVJJYSQc4NCR7oN/p6u4uPuLOXVdZJLi44Q0klQ6Ei3AbMZ+Hm5SuMJMSw6Ch0hpHOg0JFuRYCPm2CQ53y6LgkhnQSFjnQr0HHczdlRistrpKqWY14SQs4dCh3pVgR6u4qvh7OUVdVJQRndl4SQc4dCR7oVgV5uumDKnsxCui8JIecOhY50K+C6xFJZWy9ZRZWWVEIIOXsodKRbgchLH08XcXB0kGwKHSGkE6DQkW6Hj4ezuLk4UugIIZ0ChY50OzA6ire7sxSUVkltfYMllRBCzg4KHel2+Hq6WgJS6tlxnBByzlDoSLcDFl2Ir5tU1zZIWkGFJZUQQs4OCh3pdni7OUuQt5vUNTRS6Agh5wyFjnQ7MA8d3JeOTg6Snl9uSSWEkLPjjIWusbFRZwuvra21pBDSufTqJeLp5qRil5FPi44Qcm50SOgqKipU3DAZeWlpqcTHx8uxY8ekupqBAsQ6eLo5i7+3i2QVVkiDUbkihJCzpUNC97vf/U62bNkiJSUl8uabb8pNN90k//3f/y0vv/yyZQtCOhdYdKE+7lJVXa9z0zVi7h5CCDkLOiR0xcXF4ujoqFYcuO++++Suu+6SHTt26N+EdDZehkXXx99DA1KScsqknkJHCDlLOiR0cFuWlZWpsNXX18vEiRMlKChIqqo46C6xDp6uThJmCF19Y6Mk55bRfUkIOWs6JHSzZs2S7777Tvbu3St9+vSR3r17S2VlpYodIdZAZxv3dBV3Q/CahI4WHSHk7OiQ0C1YsEDGjx8vc+bMkUmTJomPj4/ExMTItddea9mCkM6lV69e4uHqKIE+7pKSW06hI4ScNR0SupCQELXk0E6HbgWIvnRzc5PIyEjLFoR0PuhPF+rvIZkFFTrmpfHaEULIGdMhodu6dat8/fXX8sorr8j333+vYofAlE8++cSyBSGdj6uLo4QHekhpeY2UVNSynY4QclZ0SOjee+89GT58uAwbNkwcHBzE29tbXF1dZefOnZYtCOl83JydJDLQSy25tPwKqamn0BFCzpwOCR0sOLgp/f399W+MjoLF2dlZ/ybEGrg5OxpC56nfU/PLpaaOU/YQQs6cDgmdr6+vFBYWSnl507iDaWlpsmfPHgkICNC/CbEGzo4OEuzjJi4ujjq4M4WOEHI2dEjo7r33Xtm8ebOsXr1annvuObnjjjt0GLD777/fsgUhnQ/GvHQxrLrwIC/JLKiU2jq6LgkhZ06HhG7w4MHys5/9TJ5//nn5xz/+IQ899JDcc889MmjQIMsWhFgHJ8Oqiwr1kpwiWHT1llRCCOk4HRI6uCnRd27KlCnaSXzfvn0afQkXJiHWxMmxl8SEeEtldZ0UV9bqkGCEEHImdEjoVqxYIVlZWVJQUKCjo6BrQXZ2tnz22WeWLQixDrDoYoK9RE6I5BRXSWUNrTpCyJnRIaE7evSojmuJdjkEpUyYMEFHSsGMBu3R0NAgubm5snLlSvn444912bZtmxQVFem65ORkFVGko/0P0wGhMzrO8e2338oHH3wgy5cvl6+++koOHz5sOapR4OXkyJo1a+Sjjz6StWvXSmpqqmUNsTWcHHpJbLC3ODo4SGZhJYWOEHLGdEjoPD09JTExUX744QftUoBhwPz8/Cxr2waDQWdmZsqqVavkm2++0U7nS5Yskf3790t6erqsX79eli5dquvff/99tRYxx11GRob23cOUQBC8jRs36vkBhBCiCAGEgC5btkzWrVvHAaZtFAhcb38PcXN1lOxiCh0h5MzpkNDBeoPYwBpDXzpz6K+wsDD9bAt0Lsc2v/3tb3VUlRdffFGFDG1+ELDjx4/LjTfeqJGckydPVgsO1h7AkGO33367vPTSS/LUU0/JwoULVeQwmDQswNmzZ8s///lPFV20GcI6JLYHIi8xQkqwn7vklVZLBYWOEHKGdEjofvWrX8mf/vQnFZbrr79e3Y4RERHym9/8xrJF67i4uKjQIToT42RiNBXMfIABew8dOqT98hDg4uXlJfPmzVNXqNlXDx3SIYr4G9aa2Un94MGDJ8UWATI4dnBwsIpna2BaIexvHgdiSXoe6GJQVFZDi44QcsZ0SOjQPgb3JQZ3hgsRbkW4DZF2JqBtLS4uToUNndAhQnCBOjk5aTQn2uaQBtDu9n//939yxRVXyF/+8he12CBSaPOD0EE0AY6F79i3NbZv3y6LFy/WGRgg1phElvQsehn/IoM8NfKyvKpW56gjhJCO0iGhgyWHrgSIukQQCCZgzc/P1z51HQECBWvqySeflKFDh6q70RQqWHcAbk4TWGuPPvqotsM98cQTKoKPP/64rsOxsI+5n/nZlqV2wQUXqMC9/fbbKniwAknPIyrYS0dKySuplrLKOksqIYScng4JnWlpwRqD2/KSSy6RMWPGdCja0RS5//mf/xF3d3ed065v3776He5MzFyOY6JtDiKENAwajW3QUR1ChQGlcS5sC2uutLRUx98EaLND0AssxNbw8PBQd2lsbKx+4vikZ4G6TFSQYbk7O0pOSZWUVlHoCCEdp0NCB+tr165d2hUAonThhRdKYGDgSbFpD7gK3333XY2khPsQMyBA5MLDw/UTkZYQq02bNsnIkSM1raamRtvjYOVBxLAegok58AYOHKjCCzco0uHSxN8QRWK7hPl6iIerk+SXVhtCd/r3jhBCTDokdBAoiBqsIwgVRA7dDGBttQeCSdC+99prr6kwweWJ7gXoVgDrCi7KTz/9VNdjpBW0x6HNDtGY6Dbw8ssvyxtvvKFRlXPnzlWhQ+AJokAx9iZcqpgqCMeCABLbBSLn7+2qo6OU0nVJCDkDOiR0l112mXYSnzp1qkZbwnWImQsuv/xyyxatA6sMrsJx48apKKJDOEZUwf4QOXQpgHCVlJSoRTZr1iwNLgHYBuIId2V0dLTcdNNN2h4HK+/aa6/VaE64O+GSxH4d6ddHei5wX4YFeEhFdZ0hdLToCCEdp9eJtqI4moHAE4T1o5M3rDS4FyF4aDuDdddTQATmM888w5nReygfbk6QFVtTZNGEKLl6cl8dHowQQgCGpET/bPTXbkmHSgoMs/Xqq6/qCCQJCQn6ib+RTkhX0cffU1ycHKS4vJYBKYSQDtMhocOYkrfddpuOUvL0009r2xim7cHwXYR0FRgKzMPFSQrKaqSwvMaSSggh7dMhoYN3E6H/Zt83fKItrQNeT0I6jT6G0Hm6QuiqKXSEkA7TIaEbPXq0joYCi+7zzz/XaEhET44dO9ayBSHWx93FUfx8XKWyrl6KKHSEkA7SIaG79dZbZfr06RoJuXv3bo2SnDZtmqYT0lUg6jbIx13q6k9Q6AghHaZDQocQ/osvvlj702HwZXzi75iYGMsWhHQNIb7u8KVLiSF0HPOSENIR2hQ6dCnAsF0Ix8fyzjvv6Hxy6NiNT4wdic7chHQlIb5u6sIsqWDHcUJIx2hT6DD0FsaXbG1JSUnRJSsry7I1IV1DiJ+7+Li7SEllrc5PRwghp6NDHcZtBXYY7/lgnMtXvjws6QUVcv20fjJ1SPuT/xJC7INz7jBOSHfB281ZfD1cpKq2XnJp0RFCOgCFjvQoEHmJwZ17OfSSvJIqSyohhLQNhY70OCB0TobQFRhCx0ELCCGng0JHehyB3m7i7e6sM41j2h5CCGkPCh3pcQR4uYq/p6uUV9dJdjHdl4SQ9qHQkR5HoCF0ELuKmnrJKqq0pBJCSOtQ6EiPw9PNWfwMi66h8QSFjhByWih0pMfh6NBLPNycpN4Qun0J+fL1rlT57kCmJOeVS209hwUjhJwKhY70OOCyrKiuk7LKWtlyJEee+miP/P3TffLZ1iRJySuj2BFCToFCR3ocR9OLZU9igRSX1Wj3gkZjKS6vkc+3JMmXu9IkhwEqhJBmUOhIj2NPYr7sSchXgWtOnWHJfbM7TdLzyy0phBBCoSM9kMqqOqmqaX3mgrKKGqmtb7D8RQghFDrSA3FzdRI3FyfLX6fi6e4izo58rQkhP8ISgfQ4hkUH6ILoy+Y4GQI3dVhvCQvwtKQQQgiFjvRAhkb4yaVjI2XMgGC17noZeufi7CgzR4bLfCM9zM/dsiUhhFDoSA/E38tVJgwIkeum9pNFE6IlxM9D3A3BWzAuSoZE+IuH8Z0QQkwodKRHgiHAJg8Klasv7CsjYgNFTpyQAMxq4HiqO5MQQih0pEfj4+4sY/sHS3lVnRxKLZLKWkZcEkJOhUJHejRebs4yMspfPIzP7fF5UlbFaXsIIadCoSM9GgeHXuLr6SKj+gXJgaQCHSGlZUdyQoh9Q6EjPR5XZ0eZNjRMausaJC6jREo4GSshpBkUOtLjcXVy1ChMTzcn2ZdSIPml1ZY1hBBiZaGrra2VY8eOyeLFi+W+++7T5a233pKUlBRdt2XLFnnwwQflV7/6lfz1r3+V/Px8aWxsGnl+w4YN8thjj8m9994rzz77rKSlpWk62L59uzz66KNy9913y/PPPy+HDx+2rCH2CNyX/p4uMijSXxKySiS/pIruS0LISawqdDqyvCFc4eHhMmXKFJkwYYLs2LFDl927d6tgOTs7y5gxY1TkVq9eLWVlZSqEW7dulfr6ehk9erRUV1fL0qVL9ZiVlZXy4Ycfiqurq4wbN05ycnJk7dq1UlNTo+uJfeLo4CDjBwQbFahGSc4tl5IKui8JIU1YVegcHR2ld+/ectVVV8kNN9wgN954owpUenq6bN68WTIzM2XRokW6btasWbJixQopLi6WvXv3qqBNnTpVbrrpJrngggtk48aNUlpaKnFxcZKdna3rbrnlFhkwYIBkZGRIamqq5azEHsHoKKNjg8Tb3VmOZZZIVjFnHieENGFVoXNychJfX18VOwejxg0LrZdRIsGKy83NlaqqKhk2bJi4u7urtXfo0CFNO378uPj5+Ul0dLR4eXlJSEiIWoYQuP3790tUVJQEBQXpfrAWPT09JT4+3nJWYq9EBHpKZIiXpOaXS0ZBBd2XhBCly4JRGhoa1GUJqwzC5+3trWkQMlh+Pj4+6raEoJWXl6tIQsgAhBHbFRUV6YLvSAPYBttin9YoKSnRdsJdu3bpJ8SW2CYY5BmjpNTUNkh6XoWUV/NZE0K6SOggaGh3e/3117VdDdabi4uLWndYZ7blQbCQBuEz00Dz9VjwHWnA/I59WgPW4fvvvy9PPPGEvPPOO1JRUWFZQ2yRUdGBEujlKkm5ZZKSxwlYCSFdIHQQIlhVf/zjH2Xo0KEyb948iYiIUHcjRAsWGsQOrsyAgAAVLHwiKhPWH0QMwSjYLiwsTK3BwsJCTQOwArEt9mkNCOvjjz8un376qTz55JPqSiW2S98QbwkL8JD0ggpJzC61pBJC7BmrCx2iIh955BEVKASWREZGanrfvn1V7NCNAGKFQBREZsKliUhL7Ic2u4KCAklKSlKBgtAhCAUBKehugMAVuCPxOXLkSD0usW/Q1QDdDFBBSsstlepaui8JsXesKnQQMHQhQHeAnTt3qlWHSMnXXntNgoODZfDgwfLuu+/Kz3/+c9m2bZvceuutapmNGjVKBg4cqOKHdRBD9JmDtYcglCuvvFL+85//6LEgdJdccgktNXKSYYbQhfq6S1p+pcRnl1lSCSH2Si+j5mu10LS6ujq1zNBnDgEkiLwEsO6wIIAkISFBt/Pw8FCBc3Nz03Y6dEGA1YZuBhAxCB8CVkBWVpYkJydre1tgYKBGYeLzdEB0n3nmGfnkk08sKcQWqaypl7fWHpW9SQVy6dgouWZyrGUNIcRW+eyzz+Tbb7+VF1980ZLyI1YVuu4Ghc5+WLEzRVZuT5G+oT7y60XDxd2Fk7ESYsu0J3RdEnVJSFfTP8xXwvw9JKOgnNGXhNg5FDpik0QEeUpsiLeUVtXJ/uRCSyohxB6h0BGbxNvNWSKCMbCAoxxKLZTa+qY+mYQQ+4NCR2wWHRLMWFJzyiSrmAMFEGKvUOiIzQKhGxLhr+7LbcfzLKmEEHuDQkdsFk9XZ22r8/JwkR3HKHSE2CsUOmKzYOqeYF93GdDHR1KySyWzqFIaGjmjASH2BoWO2DTBPm4yMjpAyqvrZOvxXKljUAohdgeFjtg0Xm7OEhPiLb6ervLDoWypqW+wrCGE2AsUOmLTYI66AG83GRzpL3FpRZJXUiX1DbTqCLEnKHTE5vHxcJFx/YOkrKJWDqUV61iYhBD7gUJHbB5PVycZGuEn3h7Osv14rnY3IITYDxQ6YvPAfenv5SYj+gXJ4ZRCKSqvYfQlIXYEhY7YBa7OjjJ9aG+prqmX+KwSKauqtawhhNg6FDpiF7g6O8jEgSHi7uoke5IKJK+0xrKGEGLrUOiIXeDQq5f4ebjIkOgAScwqlfySKrGjqRgJsWsodMRugNiF+rur2/LttXHy1w93y9KNCZKUW2bZghBii1DoiF1Q19Aoh9OLJD6jRCqq6nTqnnX7M+SLbcny1c5USabYEWKzUOiIXYC+c19sT9FO4zV1TaOjYDiwtLxy2XAoSzYeztY0QojtQaEjdgHEbcOBTEPwGqR50xza6XKKKmVfYr4lhRBia1DoiF0AcauurW/60gIMCVbF0VIIsVkodMQuQKfx8GAvcXT86SuPIBXIHzqSMxCTENuDQkfsAk83Z7lpxgDx9XRRYTPpZRG55Jwyeemrw4bVd6prkxDS86HQEbvAzdlRLhreR+6YO0T6h/uKi/G3hyF+Fw4NkzvnDZUpw8Pkh4OZ8l/vb5eUvDLOcECIDUGhI3YBjDg3F0eZOay3PHz9WHnpnqnywl1T5IGFw2Xh2Ci5fko/uerCvnI8vUie/XSf7IzPlwq22xFiE1DoiF2BKXtiQ71lSKS/DI7wk4hAT/H3cpXoEG+ZbwjebRcNlILSanlv3TFZdyBTCsqqLXsSQnoqFDpCDJwdHaRPoIfMHR0p10/rJ7UNjfLlzhT5ek+apOaXW7YihPREKHSEWECQCqy7uWMi5crJsTrjwYaDWfLlrlTZnZgvB1IK5bOtybJ0Q7x+HkotonuTkB4AhY6QFni4OMmcUeFy5aRYCfJxl21xufKBIW4fbkyQV786JC+tPCivfn1Ilm1KpNgR0gOg0BHSCk6ODjJtaJi6McMDPWXb0Rz5/kCGlFfVaXeE8so6Wb8/Q77kOJmEdHsodIS0AfrYjYwOkNGxgeLs5PCT/nXogrA1LlviM0ssKYSQ7giFjpDTgMGfa2ubBoJuSYVh2dW0sY4Q0j2wqtAdO3ZM7rnnHhk9erRcdNFFkpycrOlZWVnyz3/+UxYsWCALFy6U//qv/5Ly8nKjxnxCcnJy5Oabb5bJkyfL3Llz5aabbpI333xT92tsbJTDhw/LbbfdJtOnT5c77rhDvv32W92PEGvh5uIknu7Olr9a0EtkV2KebDIsu/LqOksiIaQ7YVWh8/X1lYsvvlh+/etfS2lpqdTXNzXar1y5UgXt3nvvld///vcSEhIiS5cuNWrNtdLQgCGYTsg111wjzz77rDz00EMyf/583a+urk7+9re/qQg+8cQTEhsbK7t375aEhARdT4g1GNDHVyYODtV2u+Y4OPQSPy83OZ5ZKi+tOCiPf7BLlmyIl+NZJax8EdKNsKrQ+fv7q+U1ZswYcXR0tKSKxMfHi5OTk8yYMUPGjRsnQ4YMkS+++EKFDLi4uEh0dLSMHDlShg4dKr1791YBLCwslCNHjug+kyZN0k+I46FDh3Q/QqxBTKi3LBgXJTNH9hEvw7LDSJleHs5y0ahwuXf+ULnr0iEyeUiYVNTW6ySuiMp83hC+9YeaOpzHZ5fKhz8kyJMf7VYxfH31ETmYWtR0cEKI1bGq0EGwAgIC9LM5+BuiVlJSIjU1NZKRkaECBjEDZWVlsmLFCnn++efl888/V1cn1uXm5oqbm5sKKI4RERGhApqZman7tUZiYqJ8/PHH8txzz8lHH30klZWVljWEdAxPVycZFhkg107pZwjbMLl/0XC5d94wuXZqP5kxvI/MMpbLJ8bI9cbflxji5+7mLDsS8mXZxgT5lyFq73wbp/3u1u5Nl2/3pWuk5sebEuVIerHOfN4aVYZo7ksukH+vjVPhfOObI/LDkWwpLK+xbEEI6ShWFbq2mDBhglp0y5YtU0GLi4tTAYK7x93dXWbOnCl9+/bVdrsdO3bIqlWrVBArKirE09NTHByasg3RQ2Qc1rUHjmsuhJwNnm6G2EX5NwnatP76OSzSX0UQHcujgry0O8LVF/aV6wzBmz82UsL8PWXzEXRLyJS03DINamloPCEFpVWyxRAtiN2O+Dw5nF4kiTllklVUKUUVNWoFonM6+ukt3djUfw/LMsMq3BqXQ7Ej5Aw5L0I3bdo0GT9+vBQXF0t6erq20fn4+KhoeXt7a5DJ4sWL5Ve/+pVERkbKunXrdFsIW3V19UnBgtsSODu3EShgAMG89tprtS3w+uuvFw8PD8saQjoXfX/dnbU7ws3T+8sdswdLiK+78b5aNrCAvyuq6+Rbw8KDSxPL8i2J8sW2ZHV9rjIWWIA/HMySiqo6aTR2wMSwew0r8evdaXIojW5PQs6E8yJ0ELN58+bJY489Jvfff7+K0fDhw0+240HQIF7YLjQ0VN2UsO4giHBrYkFgS3Z2tro0kU5Id6NPgIdh7Tlom15bVBpClplXIQeTC2XjoSwVO7g8NxhWYMupgmANHjYsPViDCdmlkl5QIfmG9Ydoz/rGRu3IDqpqGySzsFKOphfLYUMU47NKpLiiVgWTEHvEqkKHdjgEkOTn5+v3vLw8jb7E32h3g1AhkAQWG6wtCFpBQYGmIyozKSlJF3QrCA8Pl6CgIOnTp48cOHBA29527dql6yCShHRHgvzcxd3VyfLXjyCCMzzYU56+baL8484L5clbJ8iD146WXy0cLhddEHHK5LDNQZ+97/ZnyF8/2i2vfH1Ylm9Nki1xOTpxbH5ptc6Svj+5QP615oj89o1Nct/LG+Wh93fIasN6LKHYETul1wkrNlxBkNA9YPv27SpggYGBcvvtt6s7csuWLZoOa+yKK65Q1yJcP2vXrpWXXnpJhQwWHvrg/fKXv9QuBRC1ffv2qVsTXQoQrXnnnXdqfzzsezpwvmeeeUY++eQTSwoh1mWzIULvfntMjqQWqkUG8K4GeLvK3fOH6WSwmCevOZsMi+3pZXukuJW2OIzQEh7kJb5eLpJqiFtRWc1JizHI30OnISopNwTPSP/xfNjPUe6eN1TmjI4Qf09XTSfElvjss8+0X/WLL75oSfkRqwodrDi0raEtDSKFIBIEkyAQBQEkWCBmaDeDmxKgDc50TaJAgJWHfVxdm36cOBaiNXFsuDe9vLw0gKUjUOhIV1NT1yDbj+fJiu3JsjcxXxoaTkh0qLdcPilW5hiWG2Y+b1lHSyuo0Da65ZsSNIDFBFYgZkS/bGKMDOrjq8dGYEpSbqkk55ZLSl65HE8vlkLDsjNFzgTnCPBxk+um9ZcR0QESHuAhfobgOTqcenJYh19sT5GU7FLjt+kgo/oGyqVjomR4lL9lC0K6J+dN6LobFDpyPqiorpcCw8rSAaGNXxssuCBDdHwN66s1ag1xS8sv1+mBVu9Ok9LyWvFwd5LJg8Nk3thIFSp3Fyc9FtrmqmsbtDtCtSF8L3xxQLYezbEc6VTgDg3ydTsZKeptnD/Q111C/Nw1Pwh4WbcvQ9IMwcR3iCMsxDH9g+WaKX31vK2BaNHNxjlxXrQ5enu6yOzRkTJhQLAG5xDSFVDoLFDoSE8BYpdTXGVYaWVSawgYJoYNM6ywPv6e2tWhLf7n4z3yzZ503aclGMZs/rgocXFykDzD6iuurFURhlDW1xtLQ6PkGudsbkVC7Py8XGWsIVqXT4w1hM9ZBdrHOJYz+rAaIoc2w28MQU43xBnHcHFylL69feSqC/vKpEEh7bpKMYrM1rhcScUMEEZJFBHsJZMGh6rFSsiZQKGzQKEjts7n25Ll0y1JkphdKo3N3JdwQ2Jklxun91crq9SwvMoMoWv6rDMErlLeX3fsJ10hAJoQIHCDI/3Fw7AGMV8fPiG4BWU1ciilUKcqan4+DI82MjZQ3az9DdGDNYk0fMJdimNmFlXIWkOUdx7PU4EFwYaFOX5giE582z8MXY40+SdAnCGSuxPypbK6TlwMC3VQhJ8MifCXQG+2QdojFDoLFDpi62QUGOKxL0PWGVZWal6ThYVhy4ZGBejceuj0DqFqDkqA3JIque3v30llTZN7tTkQpkAfNxndL8hYX69uzUpDaNChIa+4WtsEWytGEDgzIiZQehuWaJPQGcdqJngZhZVyMLlASg3BNXeHAPp5ucj04X1k9gURmne4WiGqcNfCskUeMKoMRH37sVx1l7q6OMoQ49rmjo40rMhQip0d0p7QOT5qYPlu82CosU2bNmlXBkJsEbSpob3Nx9NFvNycdcSW4YbYLBgfLSOjAzX4pSWwmrSPniEeBaU1p/Tfwzo/bzcNgrlj9hAZYlh1Aw3LqX8fX4kM9pKyqlrJKapqtdsCxAztkXX1J1TM0PWh0LAA0Q0it6RaDiQVqGi1BEE2KbnlUlheK0k5peq+zTQEPNsQxmzD8jueWaLuUow4U11br/0HTbdrWXW9BPu5SXRwU3BbS0qMfMDajcsoMc5Rphapo2Mv8TDuVRvGo4LrQ54hsAlZTX0YK41zw5JEeyc5/xw9elS7o5mTADSHFh0hRNsEdybk6bicSYYQVNc0GKVDk3DCksO4npiEtiUfb06UpRviDbHDEH6WRANYZhDCm2YOkKGGOMKticCZBl2ahOnJpbvUkmxZAkFcIR6xYT7aXqjzAdYbFqSxoZOTox4LrlZEsLbEzbD+Lh0TKTfO6K9thWiPhBWI79V19bIlLle+2pWqIos8oKvGvLFRGuTjZ1QOIM4tQSUAHfO/2pWm++Yaguts5A/3BfuOHxCsVic5v9Cis0CLjpDWgXsy0ij04aIsqawzRKRRg1AmDgqVKybHtCpyABZNhWGVpedXSL0hSJAeuCZ9DdG4YnKsTB/a2ziup/YbhKWJIdFC/dylt7+Hik6hISD1LQQLIjcw0k+ev3OKTBseJhf0C5YhUX4SFeoj/kaeausaJccQm5/KXJOAIsgmOa9CrcEcQ0hhdUKs9hji9okhzBA5CDsEE53o4zKKxcsQdIxkA6GrV1FuWrAfxh9dvSdd3vvumBQb+UUaxBdWJqzUIOOaYDmT8wstOgu06AhpH5QGJyAhZqlgGDiwztpz6yXllun4nF8bCwJc/A1Bu2F6f+0nGGAIU1t8dzBT/r3mqKTk/BjIApGElXXHnMFy0Yg+Kjy6xsyP8WXbsVx54qPdhuj8tEM9BBtuSLQPlhgihMOezLvxBcXdTy3IXuLp7iTXGXk2+xYiH2hPxPeC0mp5b90xKTNEsSUY9WbWqHBZfM1oSwo5XzAYxQKFjpDOB1YUxtdEX74ThrJAJCA27i6OrboCTdDvb+PhbPlie7IcTSkyJOyEDIzw10jNmcN7t9qeCDIKK+TTrcnyyQ+ndqhHZOnkIaGycHy0DOjtq5ZmnmHRoV0vq6hCvtmVdjK6syUqdm5Op+TX/AoRLq82rq2VohLbjBsQIv917WgJMQQex+ksthqCvnJHiiRlleo9HRGLzvuRbVrX9g6FzgKFjpDuRVlVnQanYDYH4GGITZCPu/bTawuIW1pBuXy5M62pQ31FjVpWmAV+3pgoGRkToN0fTBdjTX2DtvE9/fFe2ROfd4o4AogTJtK9d95QdbliP4ib8Z9+oj/jku+Pa3Rna2jQT4iXdsaPNQS2X5iPIbQ+6qZ1dXLU/THizOYj2Sc71F9sWLsT+gdrG2hLUHHYlVgg7393TI5nFkulIbLQT3Twb6+91ASuVozGg8hbWKFwy04dGqbRqMGGGNsqFDoLFDpCbAOIFSw1RE4iShPDo6EbA9rZIDyt8cmWJPnMWLCP6SqFgHi4Osu88VFy8wz0MXQ56d7EFvgOIf5oU6K6ZuuMc5kFJqysiCBPGWRYobBGIWgQboibnyEuED6MSYp2wMOGxZqRX2Hku0HbNRFoM3tMhPb7g+VqijHaH8sM0V+1PVUOpxZKtWGVmudDXn09XWXcwGDtZ4huIuhygUAYCD0CbzAkHOZARNcLBBUhvwiciQr2kvmGpTtjWG9tI7VFKHQWKHSE2C8YxQWzvK8/kKntgrDcMP7nxEEhOmFutCEGiNBsCUQoIbtMlm9OlB3HcnWwbSdDVPoZVhv6+43tF6wRoRhtpqCkSgUPw6IVGNth2yJMpWQIYPOSFiKJMU/D/DxUoDDTPCw5fEK4j2eUnAzuaQ6sT3TeR79ITAGFaFIE77gax8AnXKzHDCswLr34pJgDnA8d/m+eOUDFri2Q74OGwJr3x9/bTUb3DVQrtT03dHeAQmeBQkeIfYP2vf3JhZKcU6rdEwINq2uMIVQDe/uqxdQWiMBE/71d8XkaaQlBxDBnGP8TEaQmKE6LDAsu0zgP5gRcvStNtsfl/ESwTDCaCyxRWKRYnA1BQom87mCGuixbls4QLH9vVxnTN0iHeasxhBFWIKxB5BHC2rKrhwksyWmGyE0ZEqauWh/DesUoOXATo2M++hTC3Yk+iolZxv2xVAQmDw5VC7KtioA5NiuiVzGYAAKBooK9JcYQcli27YF5EhEdi/0h7O6GNT4o3E8jdVs7V3tQ6CxQ6AghXckb3xyR99cdV2utJRCEX8wZItOGhqk1pp3PjTR0t3hy2W6dUR7CYWK6LrXz/iWDdJxSdFrXxdiusqZBhRgz10M0WqIi6eWq4u5pCAraI4O93SXE+BtdPzCSzvcHM3Vuw+auXbhFMeAArF5/9DU0jtMUmYq8NmrnfgTNrD+QIaWGcLm6OMkFhhBfOjZSxvULarUdEmAQAbQlrt6TJvsS83WuRV8jfzNH9JFFxvmiQ7zUYu0o7Qkd+9ERQoiVSDbEI9EQDjPYxgQuSAxgDTGAVQjLCm1uKNgxUgsKfAySDVckLM9ehrBAMEYZAoL+if3DfFW0EPASHuApMSHeGmkK0xGjvmD80uZAsNDfb1hMgFpbtbWNkl9cqYNpH0wt0i4bGHMUXSlamj4QM0wDhQ71hRWGxWjsh1Fi0HaJ9O8OZMrK7cknLVC0n6KPIcZRhXjD5QkruOWyxxA3dEvZbZwXVin2hbBjRnxH4z7Ehvic0ewX7EdngRYdIaQrScgu1fn9Vu9KVSFAWx4KfkRQXjutn8wdHXGK67M56FD/+bYkScwsUetpZN9AWTAuWkYZYtUWcM1iBBe0J5YbYmeeT2euMKykReOjVBSRjoGxsyB2hhhjSLOV25JVoFpTBAizh6ujoEclVpuyAXdpazNlAIirl7uL+LUx7ij6QZZX/TjOaXMg9E/cMl5GG8LeUei6tEChI4R0JShdMVbnKkPovkKH+vJa8fNx0wG20aEeI9G01TSIfSFITUU0ZnwQFS18tgW2RDAM3IEYBabYsLp8vdxk0cRo7XqBKNHmuzeV/ogZFfnLf3ZqFwi4EJuD80GY4WZFX0MEy0Ak0Q8y2RByzEDRFphaql+En+WvZhgnjE8v1vbE1kAe//7LC3Umi45CobNAoSOEdDVw/WG2B7jl0PaFNi4vy2wM+N7ZIIgEnffRhmeeD/0K0dbm1M751h/M0nFLj6QW6jEARM7TsMpumTVALh0dqUIHxcBaSAfcj08v26Ntcy3B+eaNi5LbLx5kSTmVN9cc1XkMm7dDmnS2RXdmYS2EEELOCERTIrJRx/g0LBx8IhjEGiIHECjiZRy/+fnQ1tWeyIGx/YLkygtjZcyAEBUpBMtEBHtbhnOL1DZBiLPORWgsOEdMqI92fkd3i+YgD8OiA2SiYZFhGLjWFnRgx9RK2LY5OBaOiZnvOwsKHSGEEBXDiYbI/eKSQbL4ujHy0PVj5beXjdBhxzCiSktBAkifZ6yH5YZBwLENRrcZZwjcAiNtWFTb7YkIwkGb41hjWwgr9kW/vflG2vyxkRJkfO8s6LokhBBy1qAfXXJemRxOLZKq6jrDEnTUPnToUO/v2f4EuIi+jM8u1Q7qiNaESKIzPPrsoSP9mUDXJSGEEKsAQUKH+ysmxsiNMwbINVP6yrj+wacVOQB36HhjW+yDOQQvN46BcULPVOROB4WOEEKITUOhI4QQYtNQ6AghhNg0FDpCCCE2DYWOEEKITWNX3Qt++OEH+eUvfynTp0+3pJw5dXV1UltbK56enpYUYlJTUyONjY3i7m6bEzueK3hv6uvrxcOj9bEN7Znq6mr9dHOz3Rmwz5aqqiod69LV9fRRjPaIeX9yc3MlKChI3nvvPcuaH7ErocON2Lhx4zkVNLt27ZKdO3fK3XffbUkhJuvXr5fMzEy56aabLCmkORs2bJDU1FS55ZZbLCnEZNWqVVoJuPzyyy0pxGTp0qUSHBwsF198sSWFNGfZsmXi5+cnM2fOFH9/f5k2bZplzY/YldB1BitXrtQf5SuvvGJJISbvvPOOHD9+XJ544glLCmnOkiVL5ODBg/L0009bUojJCy+8oB6BP/7xj5YUYvKXv/xFoqOj5Re/+IUlhTTnr3/9q4SFhcmdd95pSfkpbKMjhBBi01DozhAvLy8JDQ21/EWa4+vrqz5y0jo+Pj68P20Al1NAQNvjItozeGfw2yKtExgYeNr7Y1czjHcGmIAQNxauBHIqaBAOCQmR8PBwSwppDu4P2loiIiIsKcTE0dFRevfurS4ociq4N3hnWElqHfyucH/w22oLttERQgixaei6JIQQYtNQ6AghhNg0dF12kOTkZPnyyy9ly5Yt2mg+e/ZsWbhwoWUtefvtt3UuKBcXF21TgL/8ySeftKy1HzIyMuTf//639rdEA/nDDz8s/fr10w7R6Ef3xRdfSGVlpcTExMjvfvc7DW5Cu6+9kJ2dLW+++abeHwTnLF68WAYOHKh/r1ixQo4dO6aDMWDQgRtvvFHGjBljNx2l0b0C3XPeeOMNKSkp0bTJkyfLpZdeqgFwmzdvluXLl0t5eblERkbq+4N3DG1Utg46he/bt08++OADvTf4zaDfHO5NfHy8ls0oo9FHGoFN1113nYwePVrLIsBglA6AugAma8WNnDBhghZOKLTGjh2rP0p7Kqja4tNPP5Xi4mJZsGCBDB8+XAYPHiyxsbGWtfYDBA1ih8CB77//XubNm6eF1N69e2Xbtm1agI8cOVLS09OlqKhI+vfvr5UDe6H5/cHgDZdccon06dNHDh06JIcPH9ZgJqQNGjRIBgwYoGJoDwU5QId5FOIQPJQtffv21XuEMgbvCioDzs7Oug4DD+D3hkqUPVQEMCIV7g3KYlR+ULZ89dVX+u5kZWVp2YyAlFmzZum7g3uHd8csm+m67AB5eXmSlJSkP8JrrrlGaxKoKWDGcrycpAm8fKhhwdLFC2ePoIYNa3/RokWnDIUGocMPFfcGo3+gpv7RRx9pTdWeQOEDIcP9aTlCETwl48eP13uE9wgFl5OTk2Wt7YNrRcTyZZddpssVV1yhQ6JhtCFYc/n5+Xrf8P7MmDFDZ9QuKyuz7G3bQOBRvuC+4PpxbyB6qDRVVFSoB2nixIn67piVp+YGCIWuA+BFg7ChZo7aFYabgbsFpjSFrgm8VAkJCfL555+rGwHuBHsEtWsUViigmv/Q8A7hhwkrxdvbW61evD8Y/9KegPUKAUMloKUnpKCg4KR7btOmTWr92VPLCoQOFQFUqHFv8G40NDToPYPIwaqBtYIKwqhRo3SUHVh/9gCEDpVIeALwTuDeYFxd/N5w3zC8I8YyhvjDc9LyvlDoOgBqDBA6s4aOGwv3JVwH9vRDbA/UtlC44yWDSwGu3sLCQn0ZSZPLDu8KCim8S6gwlZaW8v2xgHYV9E/FO4O2Xrw/O3bssJuCvCUQOLgtcf2oGOB9wW/JfH9QWUJbnb39vvB7wT3BOwLQnxllD4yPnJwcWbNmjYodPCi4hyYUug6AFws32Lxx+A5LDrUM0sRVV10l//jHP+Rvf/ubXH/99VojR0GFWigxfmiWdia8Q+a7xPfnR4YOHSq/+c1v5LXXXtMAHnhPXn75Za0M2BsoW44ePapjx06ZMuVkQA6sPPP9wTaocLe0im0diNyBAwfk9ddfV/clLNxx48bJn/70J3n11VflD3/4gxoheI+ae0sodB0ANU2zMRQ1KNTO0W4HF5W9NJS3B354eLlQ64SbBfcFrhX8WOnabcIMqoDFgh8gXC0YBQSVKCLqLcH7g3uE2jnaeBGBaW8VJQgZ3Nx//vOfVeDmzp2r7wl+X3hXTBcmrBe4OCF29gKu2xw0Hm24c+bM0XZdWLl4f/Du4J5MmjRJ4uLiTrF2WUp3AJjGICUlRV80hEhv3bpVp82wp4i5tkDBDfcuPiFsKMT37NmjtS17+iG2B+4FwHuDtii4XvBD5fxrTcANZwZWwIpDVDPaM+3N6kVwxeOPPy5RUVFy6623alAFQHQurDp4StBkguYBVAZaBvTYMqg4Y5YLRHRjJgdUiADeF5Q/AOUzPEl4d5obIexH10HQf+7jjz/WAhyNohdeeKG6Wih0TVGpcLMgnB6vE2pXiJ67//77Ww06sGUQ5vzss8/qjw0WCcK/EamLKDmEz6MbBioDcM098sgj2p/OnioDaWlp8swzz+j9Qa0bYeBXX321FuK4P3iXUEAh6ADvz7Bhw+zmNwaP0ddffy333nuvChusE1hxsF5gpezfv18jdfH+wJLB+4Pt7KEyAAHDvHOYsgi/KURZolzBuwMvCcplfOJ+oU3znnvukSFDhpz0mFDoOghqDHAp4Ibjhwd3AgcvbgKWHAow3BuAHx5+pHjh7A10BkfEKWqZcLVAxPCuQNjwDqHGjoIKrijT4rWnigC6U+D+oFA37w/uDQokWHRog4HQwVIx+xjay/3B/cBv6MiRI+rGBbh2/JYg/Hh/8DvD+4P7A8sGvzV7uD8oY+BJQ2Q3rt28ZgwEjvuG9wnb4N1BoA4qUM0rSBQ6QgghNg3b6AghhNg0FDpCCCE2DYWOEEKITUOhI4QQYtNQ6AixYxCLZvaDJMRWodARYseg8zoG4v7tb3+rokeILUKhI8SOgbihX5a9Dp5M7AP2oyOkmwLxwdQjGC0DnakxHNT8+fN10tZVq1Zph3OMLoKhkB544AEdwAAdjjFNEkYeQWdsDJaMoaTQARnjI2KGZnTYhrhhtA2M8INtlyxZovN54djohHvDDTfovoTYArToCOmGoN0Mw4nBrYjR2TFTOeqkGOpo/fr1snv3bh1dBeOton1t5cqVKnIQQEwSjFmoMecdjoE07Pvmm2+qYGKWfAwWjCGSIIYQVIz6g+G2MNwU9sFceZjVmhBbgEJHSDcEQ4lBzDARKYQHQ4dhUPFDhw5JamqqzqgBkcNUJRAtzF0Gi80cixXTJi1YsECHQoJFCDFbu3atjBgxQvfBLM0QQwynhGGTzJnRsQ6WIcacxNiBhNgCFDpCuiGYCgrjGsJqw7iZCBqJjIxUqwsiB2GCiMEig3jBmjPHisRYf5jIFC5NjIIPdyTSsR4iZk4ZhH0xxiTGBMS4pEjH3xhXEdPFYB9CbAEKHSHdEIgQRmjHFFFof3vooYd0tPrbbrtNBg4cqIMjQ/ww51ZWVpYKIqb8MV2RsAixDdyPED2kYz0GvzVnO8e+WDBArjnKO8DfWM/me2IrUOgI6YZAuGCpIXAE7WWYiwtuS4zeDgsPc/5hzjZMbYP2udGjR+ssANHR0SqA27dvV9fnwYMHZdq0aeqiRJvd3r17NR1BLKalR4it4/iogeU7IaSbAAsMlhisupdfflnnQsRkm7C8IHSY684MMMGkpb///e/VtYn57SBub731lmzbtk1dlffdd59acxDO1atXa+TlF198oVYf5vZCWxzcpAsXLlRrDkKI88M1ivMT0tNh9wJCujHoBoAITPxMIUIQoNdee00nAoaYoS0N6RAytLvBFYn5uZAOzDY4bIN1OBY+cTwcC/OZYVss5mzn2AZgPY5JSE+HbzEh3RiIDdyO6AeHT1O0IEAQJjPdFCR8YrZupGHBd2xvrsM+5vGwDmkQO1PkAM6BxTwmIT0dWnSE9DDgZiwuLlZXJCHk9FDoCCGE2DT0TRBCCLFhRP4/7+uv7ZImgN8AAAAASUVORK5CYII=)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "M8iJEJRDVWqt",
        "nXr0DgjjvCJa",
        "Sl7Bo_dsuqR7"
      ],
      "provenance": [],
      "mount_file_id": "1KNqrYsWChbQMAVpjH4CTf_cV5ttWVPSZ",
      "authorship_tag": "ABX9TyPkvzWrTLCoHbApbUnZAsP7",
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}